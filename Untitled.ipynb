{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "eb4737e4-b920-41cd-887b-eea2cc1e9b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8877d5de-19bd-4f8d-b9ce-9d453abbc2be",
   "metadata": {},
   "source": [
    "# extract text and create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "44fb714b-e291-4639-b0ed-7dd074b8ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_comment(line):\n",
    "    # Define a function to check if a line is a comment\n",
    "    line = line.strip()\n",
    "    if line.startswith('#') or line.startswith(\"'''\") or line.startswith('\"\"\"'):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def extract_non_comments(source_directory, target_directory):\n",
    "    # Process all .py files in the specified directory and subdirectories\n",
    "    for root, dirs, files in os.walk(source_directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.py'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                target_file_path = os.path.join(target_directory, file.replace('.py', '.txt'))\n",
    "                with open(file_path, 'r') as source_file, open(target_file_path, 'w') as target_file:\n",
    "                    non_comments = []\n",
    "                    comment_block = False\n",
    "                    \n",
    "                    for line in source_file:\n",
    "                        # Check for the start or end of a comment block\n",
    "                        # if \"r'''\" in line and \"'''\" in line or 'r\"\"\"' in line and '\"\"\"' in line:\n",
    "                        #     continue\n",
    "                        # if \"'''\" in line or '\"\"\"' in line:\n",
    "                        #     comment_block = not comment_block\n",
    "                        #     continue\n",
    "                        # if \"r'''\" in line or 'r\"\"\"' in line:\n",
    "                        #     comment_block = not comment_block\n",
    "                        #     continue\n",
    "                        if line.count(\"'''\") == 1 or line.count('\"\"\"') == 1:\n",
    "                            comment_block = not comment_block\n",
    "                            continue\n",
    "                        # If it's not a comment or part of a comment block, save it\n",
    "                        if not is_comment(line) and not comment_block:\n",
    "                            non_comments.append(line)\n",
    "                        # Write non-comment lines to a target .txt file\n",
    "                    target_file.writelines(non_comments)\n",
    "\n",
    "# # Define the path to the local repository (change this to the actual path of your local repo)\n",
    "# # source_directory = '/path/to/your/local/pytorch/repo'\n",
    "source_directory = '../examples/'\n",
    "# # target_directory = '/path/to/your/output/directory'\n",
    "target_directory = './dataset/raw/'\n",
    "\n",
    "\n",
    "# # Create the target directory if it doesn't exist\n",
    "# os.makedirs(target_directory, exist_ok=True)\n",
    "\n",
    "# # Call the function to start extracting non-comment lines\n",
    "# extract_non_comments(source_directory, target_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "954bd61d-0495-4afd-b754-36969e202bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined file created as 'sample_scripts.txt' with contents from 57 files.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def combine_files(directory, output_file, sample=False, num_files_to_sample=100, seed=111, start_token=\"<START>\", end_token=\"<END>\"):\n",
    "    \"\"\"\n",
    "    Combine content from a specified number of text files in a directory into one file, \n",
    "    with start and end tokens between contents from each file.\n",
    "\n",
    "    :param directory: Path to the directory containing text files.\n",
    "    :param output_file: Name of the output file to create.\n",
    "    :param num_files_to_sample: Number of files to sample and combine.\n",
    "    :param start_token: The start token to be added before each file's content.\n",
    "    :param end_token: The end token to be added after each file's content.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # List all text files in the directory\n",
    "    all_files = [f for f in os.listdir(directory) if f.endswith('.txt')]\n",
    "    files = all_files\n",
    "\n",
    "    if sample:\n",
    "        # Sample the specified number of files\n",
    "        random.seed(seed)\n",
    "        files = random.sample(all_files, min(num_files_to_sample, len(all_files)))\n",
    "\n",
    "    # Start combining the sampled files\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, 'r') as infile:\n",
    "                # outfile.write(start_token + '\\n')\n",
    "                content = infile.read()\n",
    "                content_with_tabs = content.replace('    ', '\\t')\n",
    "                outfile.write(content_with_tabs + '\\n')\n",
    "                # outfile.write(end_token + '\\n\\n')\n",
    "\n",
    "    print(f\"Combined file created as '{output_file}' with contents from {len(files)} files.\")\n",
    "  \n",
    "# Example usage\n",
    "combine_files('dataset/raw/', 'sample_scripts.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3f31df58-4700-4380-88a8-bbb297c931df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it in to inspect it\n",
    "# data_file = 'sample_scripts.txt'\n",
    "# data_file = 'dataset/adamw.txt'\n",
    "with open('sample_scripts.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6c19f8cc-ea26-4b5b-ab62-2d22cdbc15b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  118465\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6e0b01c0-81dc-4641-83a3-792396633be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import torch\n",
      "import torch.nn.functional as F\n",
      "from torch.utils.data import Dataset, DataLoader\n",
      "from datautils import MyTrainDataset\n",
      "\n",
      "import torch.multiprocessing as mp\n",
      "from torch.utils.data.distributed import DistributedSampler\n",
      "from torch.nn.parallel import DistributedDataParallel as DDP\n",
      "from torch.distributed import init_process_group, destroy_process_group\n",
      "import os\n",
      "\n",
      "\n",
      "def ddp_setup():\n",
      "\tinit_process_group(backend=\"nccl\")\n",
      "\ttorch.cuda.set_device(int(os.environ[\"LOCAL_RANK\"]))\n",
      "\n",
      "class Trainer:\n",
      "\tdef __init__(\n",
      "\t\tself,\n",
      "\t\tmodel: torch.nn.Module,\n",
      "\t\ttrain_data: DataLoader,\n",
      "\t\toptimizer: torch.optim.Optimizer,\n",
      "\t\tsave_every: int,\n",
      "\t\tsnapshot_path: str,\n",
      "\t) -> None:\n",
      "\t\tself.gpu_id = int(os.environ[\"LOCAL_RANK\"])\n",
      "\t\tself.model = model.to(self.gpu_id)\n",
      "\t\tself.train_data = train_data\n",
      "\t\tself.optimizer = optimizer\n",
      "\t\tself.save_every = save_every\n",
      "\t\tself.epochs_run = 0\n",
      "\t\tself.snapshot_path = snapshot_path\n",
      "\t\tif os.path.exists(snapshot_path):\n",
      "\t\t\tprint(\"Loading snapshot\")\n",
      "\t\t\tself._load_snapshot(snapshot_path)\n",
      "\n",
      "\t\tse\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b72fd8ba-74d7-4040-a498-eacaa9b0e723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\t\\n !\"#$%\\'()*+,-./0123456789:<=>?@ABCDEFGHIKLMNOPRSTUVWXYZ[\\\\]_`abcdefghijklmnopqrstuvwxyz{|}'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "77b7f505-3c24-41cf-8c16-070ba7d26eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dbdd55-c84b-462a-83fa-5b9272b1e97f",
   "metadata": {},
   "source": [
    "# encoding and decoding for chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "444a70cd-2509-42c9-bdac-214c6076d9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70, 74, 77, 76, 79, 81, 2, 81, 76, 79, 64, 69]\n",
      "import torch\n"
     ]
    }
   ],
   "source": [
    "# create a mapping from characters to integers\n",
    "ch_to_idx = { ch:i for i,ch in enumerate(chars) }\n",
    "idx_to_ch = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [ch_to_idx[ch] for ch in s] # encoder: take a string, output a list of mapping idx\n",
    "decode = lambda l: ''.join([idx_to_ch[idx] for idx in l]) # decoder: take a list of index, output a string\n",
    "\n",
    "print(encode(\"import torch\"))\n",
    "print(decode(encode(\"import torch\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9f4c44dc-93a7-4184-a915-42f1d8400198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([118465]) torch.int64\n",
      "tensor([70, 74, 77, 76, 79, 81,  2, 81, 76, 79, 64, 69,  1, 70, 74, 77, 76, 79,\n",
      "        81,  2, 81, 76, 79, 64, 69, 15, 75, 75, 15, 67, 82, 75, 64, 81, 70, 76,\n",
      "        75, 62, 73,  2, 62, 80,  2, 38,  1, 67, 79, 76, 74,  2, 81, 76, 79, 64,\n",
      "        69, 15, 82, 81, 70, 73, 80, 15, 65, 62, 81, 62,  2, 70, 74, 77, 76, 79,\n",
      "        81,  2, 36, 62, 81, 62, 80, 66, 81, 13,  2, 36, 62, 81, 62, 43, 76, 62,\n",
      "        65, 66, 79,  1, 67, 79, 76, 74,  2, 65])\n"
     ]
    }
   ],
   "source": [
    "# encode the entire text dataset and store it into a torch.Tensor\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9427660-f082-46be-97d9-cd471b8aa26c",
   "metadata": {},
   "source": [
    "# train dev split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "725693c4-15e1-4d3b-a036-cb52b2b42089",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce40248d-dabc-4c5e-a2cf-8970ebfe5cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6cacc69e-43e0-4561-8475-7f7305c1203c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([70]) the target: 74\n",
      "when input is tensor([70, 74]) the target: 77\n",
      "when input is tensor([70, 74, 77]) the target: 76\n",
      "when input is tensor([70, 74, 77, 76]) the target: 79\n",
      "when input is tensor([70, 74, 77, 76, 79]) the target: 81\n",
      "when input is tensor([70, 74, 77, 76, 79, 81]) the target: 2\n",
      "when input is tensor([70, 74, 77, 76, 79, 81,  2]) the target: 81\n",
      "when input is tensor([70, 74, 77, 76, 79, 81,  2, 81]) the target: 76\n"
     ]
    }
   ],
   "source": [
    "context_length = 8\n",
    "x = train_data[:context_length]\n",
    "y = train_data[1:context_length+1]\n",
    "for t in range(context_length):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f83221-8143-46b7-812d-02eea5067558",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "08cf2024-2f73-4275-83b4-dff95ec0050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "context_length = 256\n",
    "emb_dim = 32\n",
    "max_iters = 5000\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_interval = 100\n",
    "eval_iters = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ca0020-50db-4d97-88fa-abe53f5fe019",
   "metadata": {},
   "source": [
    "# data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9ec801a0-ce4b-4011-877f-0067e665d340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([32, 256])\n",
      "tensor([[84, 76, 79,  ..., 75, 76, 74],\n",
      "        [80, 66, 80,  ..., 80, 66, 73],\n",
      "        [69, 15, 75,  ..., 79, 75,  2],\n",
      "        ...,\n",
      "        [ 9, 65, 66,  ..., 68, 82, 74],\n",
      "        [67, 66, 79,  ..., 73, 13,  2],\n",
      "        [70, 67, 86,  ..., 66, 13,  2]], device='cuda:0')\n",
      "targets:\n",
      "torch.Size([32, 256])\n",
      "tensor([[76, 79, 65,  ..., 76, 74, 70],\n",
      "        [66, 80, 60,  ..., 66, 73, 67],\n",
      "        [15, 75, 75,  ..., 75,  2, 80],\n",
      "        ...,\n",
      "        [65, 66, 67,  ..., 82, 74, 66],\n",
      "        [66, 79,  2,  ..., 13,  2, 76],\n",
      "        [67, 86,  2,  ..., 13,  2, 79]], device='cuda:0')\n",
      "----\n",
      "when input is [84] the target: 76\n",
      "when input is [84, 76] the target: 79\n",
      "when input is [84, 76, 79] the target: 65\n",
      "when input is [84, 76, 79, 65] the target: 60\n",
      "when input is [84, 76, 79, 65, 60] the target: 81\n",
      "when input is [84, 76, 79, 65, 60, 81] the target: 66\n",
      "when input is [84, 76, 79, 65, 60, 81, 66] the target: 75\n",
      "when input is [84, 76, 79, 65, 60, 81, 66, 75] the target: 80\n",
      "when input is [80] the target: 66\n",
      "when input is [80, 66] the target: 80\n",
      "when input is [80, 66, 80] the target: 60\n",
      "when input is [80, 66, 80, 60] the target: 84\n",
      "when input is [80, 66, 80, 60, 84] the target: 70\n",
      "when input is [80, 66, 80, 60, 84, 70] the target: 81\n",
      "when input is [80, 66, 80, 60, 84, 70, 81] the target: 69\n",
      "when input is [80, 66, 80, 60, 84, 70, 81, 69] the target: 9\n",
      "when input is [69] the target: 15\n",
      "when input is [69, 15] the target: 75\n",
      "when input is [69, 15, 75] the target: 75\n",
      "when input is [69, 15, 75, 75] the target: 15\n",
      "when input is [69, 15, 75, 75, 15] the target: 77\n",
      "when input is [69, 15, 75, 75, 15, 77] the target: 62\n",
      "when input is [69, 15, 75, 75, 15, 77, 62] the target: 79\n",
      "when input is [69, 15, 75, 75, 15, 77, 62, 79] the target: 62\n",
      "when input is [73] the target: 2\n",
      "when input is [73, 2] the target: 64\n",
      "when input is [73, 2, 64] the target: 69\n",
      "when input is [73, 2, 64, 69] the target: 66\n",
      "when input is [73, 2, 64, 69, 66] the target: 64\n",
      "when input is [73, 2, 64, 69, 66, 64] the target: 72\n",
      "when input is [73, 2, 64, 69, 66, 64, 72] the target: 77\n",
      "when input is [73, 2, 64, 69, 66, 64, 72, 77] the target: 76\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(111)\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    start_idxs = torch.randint(len(data) - context_length, (batch_size,))\n",
    "    context_idxs = torch.stack([data[start_idx : start_idx+context_length] for start_idx in start_idxs])\n",
    "    target_idxs = torch.stack([data[start_idx+1 : start_idx+context_length+1] for start_idx in start_idxs])\n",
    "    \n",
    "    context_idxs, target_idxs = context_idxs.to(device), target_idxs.to(device)\n",
    "    \n",
    "    return context_idxs, target_idxs\n",
    "\n",
    "context_idxs, target_idxs = get_batch('train')\n",
    "print('inputs:')\n",
    "print(context_idxs.shape)\n",
    "print(context_idxs)\n",
    "print('targets:')\n",
    "print(target_idxs.shape)\n",
    "print(target_idxs)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(4): # batch dimension\n",
    "    for step in range(8): # context length dimension\n",
    "        context = context_idxs[b, :step+1]\n",
    "        target = target_idxs[b,step]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b83ccd-440b-4cbb-a3de-819660488096",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "486d2ed1-d798-4a78-b0b1-7a04d2d5a00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b3880a56-be00-480d-a300-dfaaae9ece79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8192, 91])\n",
      "tensor(4.5222, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(111)\n",
    "\n",
    "\n",
    "class GPTLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # works as a look up table for the probability of the next char for each current char\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.position_embedding_table = nn.Embedding(context_length, emb_dim)\n",
    "        self.attention_head = MultiHeadAttention(4, emb_dim//4)\n",
    "        self.ffwd = FeedForward(emb_dim)\n",
    "        self.lm_head = nn.Linear(emb_dim, vocab_size)\n",
    "\n",
    "    def forward(self, context_idxs, target_idxs=None):\n",
    "        B, T = context_idxs.shape # num of batches; num of total steps in context_length\n",
    "\n",
    "        # context_idxs, target_idxs are both (B,T) tensor of integers\n",
    "        token_emb = self.token_embedding_table(context_idxs) # (B, T, emb_dim)\n",
    "        position_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, emb_dim)\n",
    "        x = token_emb + position_emb # (B, T, emb_dim)\n",
    "        x = self.attention_head(x) # (B, T, head_size)\n",
    "        logits = self.lm_head(x) # (B, T, vocab_size), now the feature_dim is vocab_size again\n",
    "        \n",
    "        if target_idxs is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, D = logits.shape # num of batches; num of total steps in context_length; num of feature dimension\n",
    "            logits = logits.view(B * T, D) # now D == vocab_size == number of classes\n",
    "            target_idxs = target_idxs.view(B * T)\n",
    "            loss = F.cross_entropy(logits, target_idxs)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, context_idxs, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            # trim input\n",
    "            input_idxs = context_idxs[:, -context_length:]\n",
    "            # forward\n",
    "            logits, loss = self(input_idxs)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # (B, D) tensor for the last step\n",
    "            probs = F.softmax(logits, dim=-1) # predicted_label (B, D)\n",
    "            \n",
    "            # sample from the distribution\n",
    "            # torch.multinomial: Returns a tensor where each row contains num_samples indices \n",
    "            # sampled from the multinomial probability distribution located in the corresponding row of tensor input.\n",
    "            pred_idxs = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            context_idxs = torch.cat((context_idxs, pred_idxs), dim=1) # (B, T+1)\n",
    "        return context_idxs\n",
    "\n",
    "\n",
    "class Head(nn.Module):\n",
    "    '''\n",
    "    self-attention with only one head\n",
    "    '''\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(emb_dim, head_size, bias=False)\n",
    "        self.query = nn.Linear(emb_dim, head_size, bias=False)\n",
    "        self.value = nn.Linear(emb_dim, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length, context_length)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, D = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        \n",
    "        # attention-score\n",
    "        weight = q @ k.transpose(-2,-1) * D**-0.5 # (B, T, D) @ (B, D, T) ---> (B, T, T)\n",
    "        # D**-0.5: to relief the influence of large value makes the vector after softmax looks like one-hot vector.\n",
    "\n",
    "        weight = weight.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B,T,T), the upper-right triangle will be -inf\n",
    "        weight = F.softmax(weight, dim=-1) # (B, T, T)\n",
    "\n",
    "        # weighted-aggregation of values based on the attention-score\n",
    "        v = self.value(x) # (B, T, D)\n",
    "        out = weight @ v # (B, T, T) @ (B, T, D) --------> (B, T, D)\n",
    "\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    '''\n",
    "    multiple heads fo self-attention in parallel\n",
    "    '''\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    '''\n",
    "    a simple linear layer with activation in decoder\n",
    "    '''\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(emb_dim, emb_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = GPTLanguageModel().to(device)\n",
    "logits, loss = model(context_idxs, target_idxs)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "# decode 5 batches of data, the initial start char is 'i'\n",
    "# [decode(model.generate(context_idxs=torch.full((5, 1), 75, dtype=torch.long).to(device), max_new_tokens=100)[i].tolist()) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "06bd74f5-5346-40af-b033-aa2800a905f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [1., 1., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [1., 1., 1., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [1., 1., 1., 1., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [1., 1., 1., 1., 1., -inf, -inf, -inf, -inf, -inf],\n",
      "        [1., 1., 1., 1., 1., 1., -inf, -inf, -inf, -inf],\n",
      "        [1., 1., 1., 1., 1., 1., 1., -inf, -inf, -inf],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., -inf, -inf],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., -inf],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111,\n",
      "         0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000]])\n",
      "tensor([[0.4883, 0.3293, 0.4527],\n",
      "        [0.8066, 0.9854, 0.7635],\n",
      "        [0.2121, 0.5962, 0.7260],\n",
      "        [0.2487, 0.2953, 0.1770],\n",
      "        [0.9804, 0.6896, 0.0585],\n",
      "        [0.0394, 0.3690, 0.1926],\n",
      "        [0.9254, 0.5354, 0.6169],\n",
      "        [0.4690, 0.2805, 0.6615],\n",
      "        [0.0644, 0.1840, 0.4387],\n",
      "        [0.9132, 0.8690, 0.7885]])\n",
      "tensor([[0.4883, 0.3293, 0.4527],\n",
      "        [0.6474, 0.6573, 0.6081],\n",
      "        [0.5023, 0.6369, 0.6474],\n",
      "        [0.4389, 0.5515, 0.5298],\n",
      "        [0.5472, 0.5791, 0.4356],\n",
      "        [0.4626, 0.5441, 0.3951],\n",
      "        [0.5287, 0.5429, 0.4268],\n",
      "        [0.5212, 0.5101, 0.4561],\n",
      "        [0.4705, 0.4738, 0.4542],\n",
      "        [0.5147, 0.5134, 0.4876]])\n"
     ]
    }
   ],
   "source": [
    "weight_test = torch.tril(torch.ones(10,10))\n",
    "print(weight_test)\n",
    "weight_test = weight_test.masked_fill(weight_test == 0, float('-inf'))\n",
    "print(weight_test)\n",
    "weight_test = F.softmax(weight_test, dim=-1)\n",
    "print(weight_test)\n",
    "v_test = torch.rand((10,3))\n",
    "print(v_test)\n",
    "out = weight_test @ v_test\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07188173-cb6b-4565-bca2-ea1bee2d5c3d",
   "metadata": {},
   "source": [
    "# optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7fa8e344-7697-4d9e-ad4f-1a0de5a4564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06df9566-6a45-47e1-a12f-68a738176440",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "86798e56-c560-4216-9e69-22cb753fe490",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    res = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, y = get_batch(split)\n",
    "            logits, loss = model(X, y)\n",
    "            losses[k] = loss.item()\n",
    "        res[split] = losses.mean()\n",
    "    model.train()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "696868ff-0c80-4654-b54f-143a63f74dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.5222, val loss 4.5137\n",
      "step 100: train loss 3.4105, val loss 3.3955\n",
      "step 200: train loss 3.1668, val loss 3.1641\n",
      "step 300: train loss 3.0305, val loss 3.0376\n",
      "step 400: train loss 2.9526, val loss 2.9619\n",
      "step 500: train loss 2.9018, val loss 2.9127\n",
      "step 600: train loss 2.8638, val loss 2.8882\n",
      "step 700: train loss 2.8339, val loss 2.8608\n",
      "step 800: train loss 2.8115, val loss 2.8434\n",
      "step 900: train loss 2.7946, val loss 2.8241\n",
      "step 1000: train loss 2.7769, val loss 2.8210\n",
      "step 1100: train loss 2.7641, val loss 2.7987\n",
      "step 1200: train loss 2.7569, val loss 2.7932\n",
      "step 1300: train loss 2.7442, val loss 2.7863\n",
      "step 1400: train loss 2.7359, val loss 2.7742\n",
      "step 1500: train loss 2.7271, val loss 2.7710\n",
      "step 1600: train loss 2.7166, val loss 2.7674\n",
      "step 1700: train loss 2.7061, val loss 2.7524\n",
      "step 1800: train loss 2.7005, val loss 2.7526\n",
      "step 1900: train loss 2.6925, val loss 2.7451\n",
      "step 2000: train loss 2.6851, val loss 2.7394\n",
      "step 2100: train loss 2.6774, val loss 2.7371\n",
      "step 2200: train loss 2.6755, val loss 2.7334\n",
      "step 2300: train loss 2.6659, val loss 2.7294\n",
      "step 2400: train loss 2.6587, val loss 2.7292\n",
      "step 2500: train loss 2.6566, val loss 2.7193\n",
      "step 2600: train loss 2.6495, val loss 2.7210\n",
      "step 2700: train loss 2.6474, val loss 2.7234\n",
      "step 2800: train loss 2.6444, val loss 2.7180\n",
      "step 2900: train loss 2.6407, val loss 2.7133\n",
      "step 3000: train loss 2.6364, val loss 2.7158\n",
      "step 3100: train loss 2.6286, val loss 2.7064\n",
      "step 3200: train loss 2.6299, val loss 2.7111\n",
      "step 3300: train loss 2.6256, val loss 2.7130\n",
      "step 3400: train loss 2.6193, val loss 2.7069\n",
      "step 3500: train loss 2.6153, val loss 2.7106\n",
      "step 3600: train loss 2.6173, val loss 2.7042\n",
      "step 3700: train loss 2.6154, val loss 2.7004\n",
      "step 3800: train loss 2.6116, val loss 2.7101\n",
      "step 3900: train loss 2.6084, val loss 2.7022\n",
      "step 4000: train loss 2.6034, val loss 2.7019\n",
      "step 4100: train loss 2.6038, val loss 2.7010\n",
      "step 4200: train loss 2.6047, val loss 2.6994\n",
      "step 4300: train loss 2.6012, val loss 2.7025\n",
      "step 4400: train loss 2.5947, val loss 2.6915\n",
      "step 4500: train loss 2.5927, val loss 2.6969\n",
      "step 4600: train loss 2.5898, val loss 2.6959\n",
      "step 4700: train loss 2.5868, val loss 2.6885\n",
      "step 4800: train loss 2.5878, val loss 2.6859\n",
      "step 4900: train loss 2.5835, val loss 2.6858\n",
      "step 4999: train loss 2.5804, val loss 2.6951\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for iter in range(max_iters): # increase number of steps for good results... \n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "    \n",
    "    # sample a batch of data\n",
    "    context_idxs, target_idxs = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(context_idxs, target_idxs)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "45e42c0d-e619-4f26-a15f-04ecb6c36e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import torch}\n",
      "woimportory:\n",
      "\tortal.sth 'ch}\n",
      "\t\tporarch)\n",
      "\t\tdati\n",
      "\n",
      "\n",
      "\t)\n",
      "\tdurarcBct(\n",
      "\t\td tatrgs eravorors.get or.tit at an t eportoaimeTrge):\n",
      "\n",
      "prge\" = rimpt_ata tratodenePonch.l'-00\n",
      "\n",
      "\t\t\txoderinpat(tckex'CamorudDinadeppatogr,\n",
      "\n",
      "\t\t\tb)\n",
      "\t\t\trgsde\n",
      "\ttis.s---b('rc_rgunt = ifochulicete tamorte(\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\tcoske traioumonk)\n",
      "ph()\n",
      "\n",
      "\tdelargel, %steren.tepteners.rad  ininty1)\n",
      "\t\t 3, ize\"sy), + mim t Ade, = r\n",
      "\t\tpt_ert le: rtoch.j of.ge_mt= neel_amuevinvild= 1, Uraburtylofg.mpch.ck, talorer.zerernsepe _ngerarcenlflghum_matodade= \n"
     ]
    }
   ],
   "source": [
    "print(decode(model.generate(context_idxs = torch.tensor(encode('import torch')).view(1, 12).to(device), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "35c3d71c-672a-4aab-8e83-2de2ab1d9485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[70, 74, 77, 76, 79, 81]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(encode('import')).view(1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14367d3-b4d3-4910-8185-a3ebae8fd4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d426e38c-cf24-40de-b6ed-c69f24ac60a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llm]",
   "language": "python",
   "name": "conda-env-llm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
