{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb4737e4-b920-41cd-887b-eea2cc1e9b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8877d5de-19bd-4f8d-b9ce-9d453abbc2be",
   "metadata": {},
   "source": [
    "# extract text and create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44fb714b-e291-4639-b0ed-7dd074b8ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_comment(line):\n",
    "    # Define a function to check if a line is a comment\n",
    "    line = line.strip()\n",
    "    if line.startswith('#') or line.startswith(\"'''\") or line.startswith('\"\"\"'):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def extract_non_comments(source_directory, target_directory):\n",
    "    # Process all .py files in the specified directory and subdirectories\n",
    "    for root, dirs, files in os.walk(source_directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.py'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                target_file_path = os.path.join(target_directory, file.replace('.py', '.txt'))\n",
    "                with open(file_path, 'r') as source_file, open(target_file_path, 'w') as target_file:\n",
    "                    non_comments = []\n",
    "                    comment_block = False\n",
    "                    \n",
    "                    for line in source_file:\n",
    "                        # Check for the start or end of a comment block\n",
    "                        if \"''\" in line or '\"\"\"' in line:\n",
    "                            comment_block = not comment_block\n",
    "                            continue\n",
    "                        # If it's not a comment or part of a comment block, save it\n",
    "                        if not is_comment(line) and not comment_block:\n",
    "                            non_comments.append(line)\n",
    "                        # Write non-comment lines to a target .txt file\n",
    "                    target_file.writelines(non_comments)\n",
    "\n",
    "# # Define the path to the local repository (change this to the actual path of your local repo)\n",
    "# # source_directory = '/path/to/your/local/pytorch/repo'\n",
    "# source_directory = '.'\n",
    "# # target_directory = '/path/to/your/output/directory'\n",
    "# target_directory = './dataset/'\n",
    "\n",
    "\n",
    "# # Create the target directory if it doesn't exist\n",
    "# os.makedirs(target_directory, exist_ok=True)\n",
    "\n",
    "# # Call the function to start extracting non-comment lines\n",
    "# extract_non_comments(source_directory, target_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "954bd61d-0495-4afd-b754-36969e202bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined file created as 'sample_scripts.txt' with contents from 1153 files.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def combine_files(directory, output_file, sample=False, num_files_to_sample=100, seed=111, start_token=\"<START>\", end_token=\"<END>\"):\n",
    "    \"\"\"\n",
    "    Combine content from a specified number of text files in a directory into one file, \n",
    "    with start and end tokens between contents from each file.\n",
    "\n",
    "    :param directory: Path to the directory containing text files.\n",
    "    :param output_file: Name of the output file to create.\n",
    "    :param num_files_to_sample: Number of files to sample and combine.\n",
    "    :param start_token: The start token to be added before each file's content.\n",
    "    :param end_token: The end token to be added after each file's content.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # List all text files in the directory\n",
    "    all_files = [f for f in os.listdir(directory) if f.endswith('.txt')]\n",
    "    files = all_files\n",
    "\n",
    "    if sample:\n",
    "        # Sample the specified number of files\n",
    "        random.seed(seed)\n",
    "        files = random.sample(all_files, min(num_files_to_sample, len(all_files)))\n",
    "\n",
    "    # Start combining the sampled files\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, 'r') as infile:\n",
    "                outfile.write(start_token + '\\n')\n",
    "                content = infile.read()\n",
    "                content_with_tabs = content.replace('    ', '\\t')\n",
    "                outfile.write(content_with_tabs + '\\n')\n",
    "                outfile.write(end_token + '\\n\\n')\n",
    "\n",
    "    print(f\"Combined file created as '{output_file}' with contents from {len(files)} files.\")\n",
    "\n",
    "# Example usage\n",
    "combine_files('dataset/', 'sample_scripts.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f31df58-4700-4380-88a8-bbb297c931df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it in to inspect it\n",
    "with open('sample_scripts.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c19f8cc-ea26-4b5b-ab62-2d22cdbc15b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  8518735\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e0b01c0-81dc-4641-83a3-792396633be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START>\n",
      "\n",
      "from __future__ import annotations\n",
      "\n",
      "import dataclasses\n",
      "from typing import Optional\n",
      "\n",
      "from torch.onnx._internal.diagnostics.infra.sarif import (\n",
      "\t_artifact_location,\n",
      "\t_property_bag,\n",
      ")\n",
      "\n",
      "\n",
      "@dataclasses.dataclass\n",
      "class VersionControlDetails(object):\n",
      "\n",
      "<END>\n",
      "\n",
      "<START>\n",
      "from typing import Union\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "class _InsertPoint:\n",
      "\tdef __init__(\n",
      "\t\tself,\n",
      "\t\tinsert_point_graph: torch._C.Graph,\n",
      "\t\tinsert_point: Union[torch._C.Node, torch._C.Block],\n",
      "\t):\n",
      "\t\tself.insert_point = insert_point\n",
      "\t\tself.g = insert_point_graph\n",
      "\t\tself.guard = None\n",
      "\n",
      "\tdef __enter__(self):\n",
      "\t\tself.prev_insert_point = self.g.insertPoint()\n",
      "\t\tself.g.setInsertPoint(self.insert_point)\n",
      "\n",
      "\tdef __exit__(self, *args):\n",
      "\t\tself.g.setInsertPoint(self.prev_insert_point)\n",
      "\n",
      "\n",
      "def insert_point_guard(self, insert_point: Union[torch._C.Node, torch._C.Block]):\n",
      "\treturn _InsertPoint(self, insert_point)\n",
      "\n",
      "<END>\n",
      "\n",
      "<START>\n",
      "import contextlib\n",
      "import logging\n",
      "import math\n",
      "import warnings\n",
      "from typing import Any, Callable, cast, Dict, Generator, Iterator, no_typ\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b72fd8ba-74d7-4040-a498-eacaa9b0e723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\t\\n !\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~–≤⊑⊔⊳─│└├✓'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77b7f505-3c24-41cf-8c16-070ba7d26eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dbdd55-c84b-462a-83fa-5b9272b1e97f",
   "metadata": {},
   "source": [
    "# encoding and decoding for chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "444a70cd-2509-42c9-bdac-214c6076d9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75, 79, 82, 81, 84, 86, 2, 86, 81, 84, 69, 74]\n",
      "import torch\n"
     ]
    }
   ],
   "source": [
    "# create a mapping from characters to integers\n",
    "ch_to_idx = { ch:i for i,ch in enumerate(chars) }\n",
    "idx_to_ch = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [ch_to_idx[ch] for ch in s] # encoder: take a string, output a list of mapping idx\n",
    "decode = lambda l: ''.join([idx_to_ch[idx] for idx in l]) # decoder: take a list of index, output a string\n",
    "\n",
    "print(encode(\"import torch\"))\n",
    "print(decode(encode(\"import torch\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f4c44dc-93a7-4184-a915-42f1d8400198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8518735]) torch.int64\n",
      "tensor([30, 53, 54, 35, 52, 54, 32,  1,  1, 72, 84, 81, 79,  2, 65, 65, 72, 87,\n",
      "        86, 87, 84, 71, 65, 65,  2, 75, 79, 82, 81, 84, 86,  2, 67, 80, 80, 81,\n",
      "        86, 67, 86, 75, 81, 80, 85,  1,  1, 75, 79, 82, 81, 84, 86,  2, 70, 67,\n",
      "        86, 67, 69, 78, 67, 85, 85, 71, 85,  1, 72, 84, 81, 79,  2, 86, 91, 82,\n",
      "        75, 80, 73,  2, 75, 79, 82, 81, 84, 86,  2, 49, 82, 86, 75, 81, 80, 67,\n",
      "        78,  1,  1, 72, 84, 81, 79,  2, 86, 81])\n"
     ]
    }
   ],
   "source": [
    "# encode the entire text dataset and store it into a torch.Tensor\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9427660-f082-46be-97d9-cd471b8aa26c",
   "metadata": {},
   "source": [
    "# train dev split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "725693c4-15e1-4d3b-a036-cb52b2b42089",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce40248d-dabc-4c5e-a2cf-8970ebfe5cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cacc69e-43e0-4561-8475-7f7305c1203c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([30]) the target: 53\n",
      "when input is tensor([30, 53]) the target: 54\n",
      "when input is tensor([30, 53, 54]) the target: 35\n",
      "when input is tensor([30, 53, 54, 35]) the target: 52\n",
      "when input is tensor([30, 53, 54, 35, 52]) the target: 54\n",
      "when input is tensor([30, 53, 54, 35, 52, 54]) the target: 32\n",
      "when input is tensor([30, 53, 54, 35, 52, 54, 32]) the target: 1\n",
      "when input is tensor([30, 53, 54, 35, 52, 54, 32,  1]) the target: 1\n"
     ]
    }
   ],
   "source": [
    "context_length = 8\n",
    "x = train_data[:context_length]\n",
    "y = train_data[1:context_length+1]\n",
    "for t in range(context_length):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f83221-8143-46b7-812d-02eea5067558",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08cf2024-2f73-4275-83b4-dff95ec0050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "context_length = 8\n",
    "emb_dim = 32\n",
    "max_iters = 5000\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ca0020-50db-4d97-88fa-abe53f5fe019",
   "metadata": {},
   "source": [
    "# data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ec801a0-ce4b-4011-877f-0067e665d340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([32, 8])\n",
      "tensor([[84, 11,  1,  0,  0, 84, 71, 86],\n",
      "        [67, 86, 75, 69, 79, 71, 86, 74],\n",
      "        [67, 86, 71, 80, 16, 80, 67, 86],\n",
      "        [67, 79, 71, 85,  2, 10, 89, 75],\n",
      "        [79, 65, 84, 71, 82, 78, 75, 69],\n",
      "        [14,  2, 39, 90, 82, 67, 80, 70],\n",
      "        [ 0,  0, 90, 16, 80, 67, 79, 71],\n",
      "        [14,  2, 78, 81, 69, 67, 78, 65],\n",
      "        [ 0,  0, 85, 91, 80, 69, 65, 75],\n",
      "        [ 2, 86, 81, 84, 69, 74, 16, 86],\n",
      "        [81, 87, 82, 16, 85, 75, 92, 71],\n",
      "        [ 0, 46, 49, 36, 50, 37, 41, 16],\n",
      "        [ 4, 86, 81, 84, 69, 74, 16, 67],\n",
      "        [ 4, 14,  2,  4, 71, 90, 69, 71],\n",
      "        [85, 86, 84, 75, 68, 87, 86, 71],\n",
      "        [ 2, 31,  2, 78, 75, 85, 86, 10],\n",
      "        [86,  2, 31,  2, 37, 67, 78, 78],\n",
      "        [ 4, 14,  1,  0,  4, 83, 87, 67],\n",
      "        [85, 14,  2, 87, 80, 77, 80, 81],\n",
      "        [71, 80, 85, 81, 84, 35, 84, 73],\n",
      "        [53, 54, 65, 48, 39, 58, 54, 65],\n",
      "        [75, 69, 86, 61, 86, 81, 84, 69],\n",
      "        [ 2, 85, 71, 78, 72, 16, 82, 84],\n",
      "        [67, 86, 74, 61, 28, 15, 21, 63],\n",
      "        [71, 86, 87, 84, 80,  2, 80, 81],\n",
      "        [28,  2, 41, 84, 67, 82, 74, 47],\n",
      "        [85, 85, 79, 71, 86, 74, 81, 70],\n",
      "        [21, 20, 14,  2, 21, 14,  2, 20],\n",
      "        [88, 71, 70,  2, 79, 71, 86, 67],\n",
      "        [21, 26, 22, 14,  2, 19, 24, 21],\n",
      "        [86, 82, 87, 86, 85, 61, 18, 63],\n",
      "        [78, 81, 89, 65, 85, 79, 67, 78]], device='cuda:0')\n",
      "targets:\n",
      "torch.Size([32, 8])\n",
      "tensor([[11,  1,  0,  0, 84, 71, 86, 87],\n",
      "        [86, 75, 69, 79, 71, 86, 74, 81],\n",
      "        [86, 71, 80, 16, 80, 67, 86, 75],\n",
      "        [79, 71, 85,  2, 10, 89, 75, 86],\n",
      "        [65, 84, 71, 82, 78, 75, 69, 67],\n",
      "        [ 2, 39, 90, 82, 67, 80, 70, 71],\n",
      "        [ 0, 90, 16, 80, 67, 79, 71, 28],\n",
      "        [ 2, 78, 81, 69, 67, 78, 65, 86],\n",
      "        [ 0, 85, 91, 80, 69, 65, 75, 80],\n",
      "        [86, 81, 84, 69, 74, 16, 86, 71],\n",
      "        [87, 82, 16, 85, 75, 92, 71, 10],\n",
      "        [46, 49, 36, 50, 37, 41, 16, 69],\n",
      "        [86, 81, 84, 69, 74, 16, 67, 85],\n",
      "        [14,  2,  4, 71, 90, 69, 71, 82],\n",
      "        [86, 84, 75, 68, 87, 86, 71, 65],\n",
      "        [31,  2, 78, 75, 85, 86, 10, 84],\n",
      "        [ 2, 31,  2, 37, 67, 78, 78, 40],\n",
      "        [14,  1,  0,  4, 83, 87, 67, 80],\n",
      "        [14,  2, 87, 80, 77, 80, 81, 89],\n",
      "        [80, 85, 81, 84, 35, 84, 73, 87],\n",
      "        [54, 65, 48, 39, 58, 54, 65, 40],\n",
      "        [69, 86, 61, 86, 81, 84, 69, 74],\n",
      "        [85, 71, 78, 72, 16, 82, 84, 71],\n",
      "        [86, 74, 61, 28, 15, 21, 63,  2],\n",
      "        [86, 87, 84, 80,  2, 80, 81, 70],\n",
      "        [ 2, 41, 84, 67, 82, 74, 47, 81],\n",
      "        [85, 79, 71, 86, 74, 81, 70,  1],\n",
      "        [20, 14,  2, 21, 14,  2, 20, 11],\n",
      "        [71, 70,  2, 79, 71, 86, 67, 70],\n",
      "        [26, 22, 14,  2, 19, 24, 21, 26],\n",
      "        [82, 87, 86, 85, 61, 18, 63, 16],\n",
      "        [81, 89, 65, 85, 79, 67, 78, 78]], device='cuda:0')\n",
      "----\n",
      "when input is [84] the target: 11\n",
      "when input is [84, 11] the target: 1\n",
      "when input is [84, 11, 1] the target: 0\n",
      "when input is [84, 11, 1, 0] the target: 0\n",
      "when input is [84, 11, 1, 0, 0] the target: 84\n",
      "when input is [84, 11, 1, 0, 0, 84] the target: 71\n",
      "when input is [84, 11, 1, 0, 0, 84, 71] the target: 86\n",
      "when input is [84, 11, 1, 0, 0, 84, 71, 86] the target: 87\n",
      "when input is [67] the target: 86\n",
      "when input is [67, 86] the target: 75\n",
      "when input is [67, 86, 75] the target: 69\n",
      "when input is [67, 86, 75, 69] the target: 79\n",
      "when input is [67, 86, 75, 69, 79] the target: 71\n",
      "when input is [67, 86, 75, 69, 79, 71] the target: 86\n",
      "when input is [67, 86, 75, 69, 79, 71, 86] the target: 74\n",
      "when input is [67, 86, 75, 69, 79, 71, 86, 74] the target: 81\n",
      "when input is [67] the target: 86\n",
      "when input is [67, 86] the target: 71\n",
      "when input is [67, 86, 71] the target: 80\n",
      "when input is [67, 86, 71, 80] the target: 16\n",
      "when input is [67, 86, 71, 80, 16] the target: 80\n",
      "when input is [67, 86, 71, 80, 16, 80] the target: 67\n",
      "when input is [67, 86, 71, 80, 16, 80, 67] the target: 86\n",
      "when input is [67, 86, 71, 80, 16, 80, 67, 86] the target: 75\n",
      "when input is [67] the target: 79\n",
      "when input is [67, 79] the target: 71\n",
      "when input is [67, 79, 71] the target: 85\n",
      "when input is [67, 79, 71, 85] the target: 2\n",
      "when input is [67, 79, 71, 85, 2] the target: 10\n",
      "when input is [67, 79, 71, 85, 2, 10] the target: 89\n",
      "when input is [67, 79, 71, 85, 2, 10, 89] the target: 75\n",
      "when input is [67, 79, 71, 85, 2, 10, 89, 75] the target: 86\n",
      "when input is [79] the target: 65\n",
      "when input is [79, 65] the target: 84\n",
      "when input is [79, 65, 84] the target: 71\n",
      "when input is [79, 65, 84, 71] the target: 82\n",
      "when input is [79, 65, 84, 71, 82] the target: 78\n",
      "when input is [79, 65, 84, 71, 82, 78] the target: 75\n",
      "when input is [79, 65, 84, 71, 82, 78, 75] the target: 69\n",
      "when input is [79, 65, 84, 71, 82, 78, 75, 69] the target: 67\n",
      "when input is [14] the target: 2\n",
      "when input is [14, 2] the target: 39\n",
      "when input is [14, 2, 39] the target: 90\n",
      "when input is [14, 2, 39, 90] the target: 82\n",
      "when input is [14, 2, 39, 90, 82] the target: 67\n",
      "when input is [14, 2, 39, 90, 82, 67] the target: 80\n",
      "when input is [14, 2, 39, 90, 82, 67, 80] the target: 70\n",
      "when input is [14, 2, 39, 90, 82, 67, 80, 70] the target: 71\n",
      "when input is [0] the target: 0\n",
      "when input is [0, 0] the target: 90\n",
      "when input is [0, 0, 90] the target: 16\n",
      "when input is [0, 0, 90, 16] the target: 80\n",
      "when input is [0, 0, 90, 16, 80] the target: 67\n",
      "when input is [0, 0, 90, 16, 80, 67] the target: 79\n",
      "when input is [0, 0, 90, 16, 80, 67, 79] the target: 71\n",
      "when input is [0, 0, 90, 16, 80, 67, 79, 71] the target: 28\n",
      "when input is [14] the target: 2\n",
      "when input is [14, 2] the target: 78\n",
      "when input is [14, 2, 78] the target: 81\n",
      "when input is [14, 2, 78, 81] the target: 69\n",
      "when input is [14, 2, 78, 81, 69] the target: 67\n",
      "when input is [14, 2, 78, 81, 69, 67] the target: 78\n",
      "when input is [14, 2, 78, 81, 69, 67, 78] the target: 65\n",
      "when input is [14, 2, 78, 81, 69, 67, 78, 65] the target: 86\n",
      "when input is [0] the target: 0\n",
      "when input is [0, 0] the target: 85\n",
      "when input is [0, 0, 85] the target: 91\n",
      "when input is [0, 0, 85, 91] the target: 80\n",
      "when input is [0, 0, 85, 91, 80] the target: 69\n",
      "when input is [0, 0, 85, 91, 80, 69] the target: 65\n",
      "when input is [0, 0, 85, 91, 80, 69, 65] the target: 75\n",
      "when input is [0, 0, 85, 91, 80, 69, 65, 75] the target: 80\n",
      "when input is [2] the target: 86\n",
      "when input is [2, 86] the target: 81\n",
      "when input is [2, 86, 81] the target: 84\n",
      "when input is [2, 86, 81, 84] the target: 69\n",
      "when input is [2, 86, 81, 84, 69] the target: 74\n",
      "when input is [2, 86, 81, 84, 69, 74] the target: 16\n",
      "when input is [2, 86, 81, 84, 69, 74, 16] the target: 86\n",
      "when input is [2, 86, 81, 84, 69, 74, 16, 86] the target: 71\n",
      "when input is [81] the target: 87\n",
      "when input is [81, 87] the target: 82\n",
      "when input is [81, 87, 82] the target: 16\n",
      "when input is [81, 87, 82, 16] the target: 85\n",
      "when input is [81, 87, 82, 16, 85] the target: 75\n",
      "when input is [81, 87, 82, 16, 85, 75] the target: 92\n",
      "when input is [81, 87, 82, 16, 85, 75, 92] the target: 71\n",
      "when input is [81, 87, 82, 16, 85, 75, 92, 71] the target: 10\n",
      "when input is [0] the target: 46\n",
      "when input is [0, 46] the target: 49\n",
      "when input is [0, 46, 49] the target: 36\n",
      "when input is [0, 46, 49, 36] the target: 50\n",
      "when input is [0, 46, 49, 36, 50] the target: 37\n",
      "when input is [0, 46, 49, 36, 50, 37] the target: 41\n",
      "when input is [0, 46, 49, 36, 50, 37, 41] the target: 16\n",
      "when input is [0, 46, 49, 36, 50, 37, 41, 16] the target: 69\n",
      "when input is [4] the target: 86\n",
      "when input is [4, 86] the target: 81\n",
      "when input is [4, 86, 81] the target: 84\n",
      "when input is [4, 86, 81, 84] the target: 69\n",
      "when input is [4, 86, 81, 84, 69] the target: 74\n",
      "when input is [4, 86, 81, 84, 69, 74] the target: 16\n",
      "when input is [4, 86, 81, 84, 69, 74, 16] the target: 67\n",
      "when input is [4, 86, 81, 84, 69, 74, 16, 67] the target: 85\n",
      "when input is [4] the target: 14\n",
      "when input is [4, 14] the target: 2\n",
      "when input is [4, 14, 2] the target: 4\n",
      "when input is [4, 14, 2, 4] the target: 71\n",
      "when input is [4, 14, 2, 4, 71] the target: 90\n",
      "when input is [4, 14, 2, 4, 71, 90] the target: 69\n",
      "when input is [4, 14, 2, 4, 71, 90, 69] the target: 71\n",
      "when input is [4, 14, 2, 4, 71, 90, 69, 71] the target: 82\n",
      "when input is [85] the target: 86\n",
      "when input is [85, 86] the target: 84\n",
      "when input is [85, 86, 84] the target: 75\n",
      "when input is [85, 86, 84, 75] the target: 68\n",
      "when input is [85, 86, 84, 75, 68] the target: 87\n",
      "when input is [85, 86, 84, 75, 68, 87] the target: 86\n",
      "when input is [85, 86, 84, 75, 68, 87, 86] the target: 71\n",
      "when input is [85, 86, 84, 75, 68, 87, 86, 71] the target: 65\n",
      "when input is [2] the target: 31\n",
      "when input is [2, 31] the target: 2\n",
      "when input is [2, 31, 2] the target: 78\n",
      "when input is [2, 31, 2, 78] the target: 75\n",
      "when input is [2, 31, 2, 78, 75] the target: 85\n",
      "when input is [2, 31, 2, 78, 75, 85] the target: 86\n",
      "when input is [2, 31, 2, 78, 75, 85, 86] the target: 10\n",
      "when input is [2, 31, 2, 78, 75, 85, 86, 10] the target: 84\n",
      "when input is [86] the target: 2\n",
      "when input is [86, 2] the target: 31\n",
      "when input is [86, 2, 31] the target: 2\n",
      "when input is [86, 2, 31, 2] the target: 37\n",
      "when input is [86, 2, 31, 2, 37] the target: 67\n",
      "when input is [86, 2, 31, 2, 37, 67] the target: 78\n",
      "when input is [86, 2, 31, 2, 37, 67, 78] the target: 78\n",
      "when input is [86, 2, 31, 2, 37, 67, 78, 78] the target: 40\n",
      "when input is [4] the target: 14\n",
      "when input is [4, 14] the target: 1\n",
      "when input is [4, 14, 1] the target: 0\n",
      "when input is [4, 14, 1, 0] the target: 4\n",
      "when input is [4, 14, 1, 0, 4] the target: 83\n",
      "when input is [4, 14, 1, 0, 4, 83] the target: 87\n",
      "when input is [4, 14, 1, 0, 4, 83, 87] the target: 67\n",
      "when input is [4, 14, 1, 0, 4, 83, 87, 67] the target: 80\n",
      "when input is [85] the target: 14\n",
      "when input is [85, 14] the target: 2\n",
      "when input is [85, 14, 2] the target: 87\n",
      "when input is [85, 14, 2, 87] the target: 80\n",
      "when input is [85, 14, 2, 87, 80] the target: 77\n",
      "when input is [85, 14, 2, 87, 80, 77] the target: 80\n",
      "when input is [85, 14, 2, 87, 80, 77, 80] the target: 81\n",
      "when input is [85, 14, 2, 87, 80, 77, 80, 81] the target: 89\n",
      "when input is [71] the target: 80\n",
      "when input is [71, 80] the target: 85\n",
      "when input is [71, 80, 85] the target: 81\n",
      "when input is [71, 80, 85, 81] the target: 84\n",
      "when input is [71, 80, 85, 81, 84] the target: 35\n",
      "when input is [71, 80, 85, 81, 84, 35] the target: 84\n",
      "when input is [71, 80, 85, 81, 84, 35, 84] the target: 73\n",
      "when input is [71, 80, 85, 81, 84, 35, 84, 73] the target: 87\n",
      "when input is [53] the target: 54\n",
      "when input is [53, 54] the target: 65\n",
      "when input is [53, 54, 65] the target: 48\n",
      "when input is [53, 54, 65, 48] the target: 39\n",
      "when input is [53, 54, 65, 48, 39] the target: 58\n",
      "when input is [53, 54, 65, 48, 39, 58] the target: 54\n",
      "when input is [53, 54, 65, 48, 39, 58, 54] the target: 65\n",
      "when input is [53, 54, 65, 48, 39, 58, 54, 65] the target: 40\n",
      "when input is [75] the target: 69\n",
      "when input is [75, 69] the target: 86\n",
      "when input is [75, 69, 86] the target: 61\n",
      "when input is [75, 69, 86, 61] the target: 86\n",
      "when input is [75, 69, 86, 61, 86] the target: 81\n",
      "when input is [75, 69, 86, 61, 86, 81] the target: 84\n",
      "when input is [75, 69, 86, 61, 86, 81, 84] the target: 69\n",
      "when input is [75, 69, 86, 61, 86, 81, 84, 69] the target: 74\n",
      "when input is [2] the target: 85\n",
      "when input is [2, 85] the target: 71\n",
      "when input is [2, 85, 71] the target: 78\n",
      "when input is [2, 85, 71, 78] the target: 72\n",
      "when input is [2, 85, 71, 78, 72] the target: 16\n",
      "when input is [2, 85, 71, 78, 72, 16] the target: 82\n",
      "when input is [2, 85, 71, 78, 72, 16, 82] the target: 84\n",
      "when input is [2, 85, 71, 78, 72, 16, 82, 84] the target: 71\n",
      "when input is [67] the target: 86\n",
      "when input is [67, 86] the target: 74\n",
      "when input is [67, 86, 74] the target: 61\n",
      "when input is [67, 86, 74, 61] the target: 28\n",
      "when input is [67, 86, 74, 61, 28] the target: 15\n",
      "when input is [67, 86, 74, 61, 28, 15] the target: 21\n",
      "when input is [67, 86, 74, 61, 28, 15, 21] the target: 63\n",
      "when input is [67, 86, 74, 61, 28, 15, 21, 63] the target: 2\n",
      "when input is [71] the target: 86\n",
      "when input is [71, 86] the target: 87\n",
      "when input is [71, 86, 87] the target: 84\n",
      "when input is [71, 86, 87, 84] the target: 80\n",
      "when input is [71, 86, 87, 84, 80] the target: 2\n",
      "when input is [71, 86, 87, 84, 80, 2] the target: 80\n",
      "when input is [71, 86, 87, 84, 80, 2, 80] the target: 81\n",
      "when input is [71, 86, 87, 84, 80, 2, 80, 81] the target: 70\n",
      "when input is [28] the target: 2\n",
      "when input is [28, 2] the target: 41\n",
      "when input is [28, 2, 41] the target: 84\n",
      "when input is [28, 2, 41, 84] the target: 67\n",
      "when input is [28, 2, 41, 84, 67] the target: 82\n",
      "when input is [28, 2, 41, 84, 67, 82] the target: 74\n",
      "when input is [28, 2, 41, 84, 67, 82, 74] the target: 47\n",
      "when input is [28, 2, 41, 84, 67, 82, 74, 47] the target: 81\n",
      "when input is [85] the target: 85\n",
      "when input is [85, 85] the target: 79\n",
      "when input is [85, 85, 79] the target: 71\n",
      "when input is [85, 85, 79, 71] the target: 86\n",
      "when input is [85, 85, 79, 71, 86] the target: 74\n",
      "when input is [85, 85, 79, 71, 86, 74] the target: 81\n",
      "when input is [85, 85, 79, 71, 86, 74, 81] the target: 70\n",
      "when input is [85, 85, 79, 71, 86, 74, 81, 70] the target: 1\n",
      "when input is [21] the target: 20\n",
      "when input is [21, 20] the target: 14\n",
      "when input is [21, 20, 14] the target: 2\n",
      "when input is [21, 20, 14, 2] the target: 21\n",
      "when input is [21, 20, 14, 2, 21] the target: 14\n",
      "when input is [21, 20, 14, 2, 21, 14] the target: 2\n",
      "when input is [21, 20, 14, 2, 21, 14, 2] the target: 20\n",
      "when input is [21, 20, 14, 2, 21, 14, 2, 20] the target: 11\n",
      "when input is [88] the target: 71\n",
      "when input is [88, 71] the target: 70\n",
      "when input is [88, 71, 70] the target: 2\n",
      "when input is [88, 71, 70, 2] the target: 79\n",
      "when input is [88, 71, 70, 2, 79] the target: 71\n",
      "when input is [88, 71, 70, 2, 79, 71] the target: 86\n",
      "when input is [88, 71, 70, 2, 79, 71, 86] the target: 67\n",
      "when input is [88, 71, 70, 2, 79, 71, 86, 67] the target: 70\n",
      "when input is [21] the target: 26\n",
      "when input is [21, 26] the target: 22\n",
      "when input is [21, 26, 22] the target: 14\n",
      "when input is [21, 26, 22, 14] the target: 2\n",
      "when input is [21, 26, 22, 14, 2] the target: 19\n",
      "when input is [21, 26, 22, 14, 2, 19] the target: 24\n",
      "when input is [21, 26, 22, 14, 2, 19, 24] the target: 21\n",
      "when input is [21, 26, 22, 14, 2, 19, 24, 21] the target: 26\n",
      "when input is [86] the target: 82\n",
      "when input is [86, 82] the target: 87\n",
      "when input is [86, 82, 87] the target: 86\n",
      "when input is [86, 82, 87, 86] the target: 85\n",
      "when input is [86, 82, 87, 86, 85] the target: 61\n",
      "when input is [86, 82, 87, 86, 85, 61] the target: 18\n",
      "when input is [86, 82, 87, 86, 85, 61, 18] the target: 63\n",
      "when input is [86, 82, 87, 86, 85, 61, 18, 63] the target: 16\n",
      "when input is [78] the target: 81\n",
      "when input is [78, 81] the target: 89\n",
      "when input is [78, 81, 89] the target: 65\n",
      "when input is [78, 81, 89, 65] the target: 85\n",
      "when input is [78, 81, 89, 65, 85] the target: 79\n",
      "when input is [78, 81, 89, 65, 85, 79] the target: 67\n",
      "when input is [78, 81, 89, 65, 85, 79, 67] the target: 78\n",
      "when input is [78, 81, 89, 65, 85, 79, 67, 78] the target: 78\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(111)\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    start_idxs = torch.randint(len(data) - context_length, (batch_size,))\n",
    "    context_idxs = torch.stack([data[start_idx : start_idx+context_length] for start_idx in start_idxs])\n",
    "    target_idxs = torch.stack([data[start_idx+1 : start_idx+context_length+1] for start_idx in start_idxs])\n",
    "    context_idxs, target_idxs = context_idxs.to(device), target_idxs.to(device)\n",
    "    return context_idxs, target_idxs\n",
    "\n",
    "context_idxs, target_idxs = get_batch('train')\n",
    "print('inputs:')\n",
    "print(context_idxs.shape)\n",
    "print(context_idxs)\n",
    "print('targets:')\n",
    "print(target_idxs.shape)\n",
    "print(target_idxs)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for step in range(context_length): # time dimension\n",
    "        context = context_idxs[b, :step+1]\n",
    "        target = target_idxs[b,step]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b83ccd-440b-4cbb-a3de-819660488096",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "486d2ed1-d798-4a78-b0b1-7a04d2d5a00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3880a56-be00-480d-a300-dfaaae9ece79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 107])\n",
      "tensor(4.7207, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 89\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# decode 5 batches of data, the initial start char is 'i'\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m \u001b[43m[\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_idxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m75\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 89\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# decode 5 batches of data, the initial start char is 'i'\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m [decode(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_idxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m75\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m[i]\u001b[38;5;241m.\u001b[39mtolist()) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m)]\n",
      "Cell \u001b[0;32mIn[36], line 39\u001b[0m, in \u001b[0;36mBigramLanguageModel.generate\u001b[0;34m(self, context_idxs, max_new_tokens)\u001b[0m\n\u001b[1;32m     37\u001b[0m input_idxs \u001b[38;5;241m=\u001b[39m context_idxs[:, \u001b[38;5;241m-\u001b[39mcontext_length:]\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# forward\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcontext_idxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# focus only on the last time step\u001b[39;00m\n\u001b[1;32m     41\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;66;03m# (B, D) tensor for the last step\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[36], line 18\u001b[0m, in \u001b[0;36mBigramLanguageModel.forward\u001b[0;34m(self, context_idxs, target_idxs)\u001b[0m\n\u001b[1;32m     15\u001b[0m B, T \u001b[38;5;241m=\u001b[39m context_idxs\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;66;03m# num of batches; num of total steps in context_length\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# context_idxs, target_idxs are both (B,T) tensor of integers\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m token_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_embedding_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_idxs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B, T, emb_dim)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m position_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_table(torch\u001b[38;5;241m.\u001b[39marange(T, device\u001b[38;5;241m=\u001b[39mdevice)) \u001b[38;5;66;03m# (T, emb_dim)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m x \u001b[38;5;241m=\u001b[39m token_emb \u001b[38;5;241m+\u001b[39m position_emb \u001b[38;5;66;03m# (B, T, emb_dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2227\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2228\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2230\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(111)\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # works as a look up table for the probability of the next char for each current char\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.position_embedding_table = nn.Embedding(context_length, emb_dim)\n",
    "        self.attention_head = Head(emb_dim)\n",
    "        self.lm_head = nn.Linear(emb_dim, vocab_size)\n",
    "\n",
    "    def forward(self, context_idxs, target_idxs=None):\n",
    "        B, T = context_idxs.shape # num of batches; num of total steps in context_length\n",
    "\n",
    "        # context_idxs, target_idxs are both (B,T) tensor of integers\n",
    "        token_emb = self.token_embedding_table(context_idxs) # (B, T, emb_dim)\n",
    "        position_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, emb_dim)\n",
    "        x = token_emb + position_emb # (B, T, emb_dim)\n",
    "        x = self.attention_head(x) # (B, T, head_size)\n",
    "        logits = self.lm_head(x) # (B, T, vocab_size), now the feature_dim is vocab_size again\n",
    "        \n",
    "        if target_idxs is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, D = logits.shape # num of batches; num of total steps in context_length; num of feature dimension\n",
    "            logits = logits.view(B * T, D)\n",
    "            target_idxs = target_idxs.view(B * T)\n",
    "            loss = F.cross_entropy(logits, target_idxs)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, context_idxs, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            # trim input\n",
    "            input_idxs = context_idxs[:, -context_length:]\n",
    "            # forward\n",
    "            logits, loss = self(context_idxs)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # (B, D) tensor for the last step\n",
    "            probs = F.softmax(logits, dim=-1) # predicted_label (B, D)\n",
    "            \n",
    "            # sample from the distribution\n",
    "            # torch.multinomial: Returns a tensor where each row contains num_samples indices \n",
    "            # sampled from the multinomial probability distribution located in the corresponding row of tensor input.\n",
    "            pred_idxs = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            context_idxs = torch.cat((context_idxs, pred_idxs), dim=1) # (B, T+1)\n",
    "        return context_idxs\n",
    "\n",
    "\n",
    "class Head(nn.Module):\n",
    "    '''\n",
    "    self-attention with only one head\n",
    "    '''\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(emb_dim, head_size, bias=False)\n",
    "        self.query = nn.Linear(emb_dim, head_size, bias=False)\n",
    "        self.value = nn.Linear(emb_dim, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length, context_length)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, D = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        \n",
    "        # attention-score\n",
    "        weight = q @ k.transpose(-2,-1) * D**-0.5 # (B, T, D) @ (B, D, T) ---> (B, T, T)\n",
    "        # D**-0.5: to relief the influence of large value makes the vector after softmax looks like one-hot vector.\n",
    "\n",
    "        weight = weight.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B,T,T)\n",
    "        weight = F.softmax(weight, dim=-1) # (B, T, T)\n",
    "\n",
    "        # weighted-aggregation of values based on the attention-score\n",
    "        v = self.value(x) # (B, T, D)\n",
    "        out = weight @ v # (B, T, T) @ (B, T, D) --------> (B, T, D)\n",
    "\n",
    "        return out\n",
    "\n",
    "model = BigramLanguageModel().to(device)\n",
    "logits, loss = model(context_idxs, target_idxs)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "# decode 5 batches of data, the initial start char is 'i'\n",
    "[decode(model.generate(context_idxs=torch.full((5, 1), 75, dtype=torch.long), max_new_tokens=100)[i].tolist()) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8443e3c8-f03b-41a1-8474-1500f42eb3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[75]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(['i'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07188173-cb6b-4565-bca2-ea1bee2d5c3d",
   "metadata": {},
   "source": [
    "# optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7fa8e344-7697-4d9e-ad4f-1a0de5a4564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06df9566-6a45-47e1-a12f-68a738176440",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "696868ff-0c80-4654-b54f-143a63f74dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6875393390655518\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(max_iters): # increase number of steps for good results... \n",
    "    \n",
    "    # sample a batch of data\n",
    "    context_idxs, target_idxs = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(context_idxs, target_idxs)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "45e42c0d-e619-4f26-a15f-04ecb6c36e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isuss:\n",
      "\t\tze Opt_bec_coppoturetioralf.ycl,\n",
      "\t\tduarorann id_ > = 0 TICa, ctr(): 1))) =-1  but5, 2\n",
      "\taye_1: 10.an ffrrertcrsap): det[iz= = svinnde``\\z282 lutese(1]\n",
      "\t\tifingstispurch'\n",
      "\tcke._Sctetor_l\"CLOC2, = `bsij}(t, =1,\n",
      "\t.rars_sit,│n_Upade.eUA\n",
      "\t\t\t), natT5):\n",
      "\t\tns)\n",
      "\t\tain, t: = iqus(\n",
      "\t), acbast\n",
      "\t\tscef t_eizevanatarch.t_6, gicver soistpald_pouth.obutiof4, (CUCOpteclouer n=-deamp wagndine ([pe\"NCPoasewalfat_bit, = cetr dpalas= _if, all1644, {s\"\\(ke fonde,  &# = %Qubl_fomoceingrur(p}: {Fan far_D_anvetsmewr\n"
     ]
    }
   ],
   "source": [
    "print(decode(model.generate(context_idxs = torch.full((1, 1), 75, dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4e8a4d-a831-40de-9767-e0c30d51f043",
   "metadata": {},
   "source": [
    "# self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7aea88d9-7a3b-4091-a114-d6a4440b26f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(T, T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddd727a4-fa18-4756-854a-ffc8bd1926f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(111)\n",
    "B,T,D = 4,8,32 # num of batches; num of total steps in context_length; num of feature dimension\n",
    "x = torch.randn(B,T,D)\n",
    "\n",
    "# a single Head\n",
    "head_size = 16\n",
    "key = nn.Linear(D, head_size, bias=False)\n",
    "query = nn.Linear(D, head_size, bias=False)\n",
    "value = nn.Linear(D, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "weight =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "#wei = torch.zeros((T,T))\n",
    "weight = weight.masked_fill(tril == 0, float('-inf'))\n",
    "\n",
    "weight = F.softmax(weight, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = weight @ v\n",
    "\n",
    "out.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llm]",
   "language": "python",
   "name": "conda-env-llm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
