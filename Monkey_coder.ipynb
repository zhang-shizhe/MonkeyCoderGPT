{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "eb4737e4-b920-41cd-887b-eea2cc1e9b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8877d5de-19bd-4f8d-b9ce-9d453abbc2be",
   "metadata": {},
   "source": [
    "# extract text and create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "44fb714b-e291-4639-b0ed-7dd074b8ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_comment(line):\n",
    "    # Define a function to check if a line is a comment\n",
    "    line = line.strip()\n",
    "    if line.startswith('#') or line.startswith(\"'''\") or line.startswith('\"\"\"'):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def extract_non_comments(source_directory, target_directory):\n",
    "    # Process all .py files in the specified directory and subdirectories\n",
    "    for root, dirs, files in os.walk(source_directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.py'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                target_file_path = os.path.join(target_directory, file.replace('.py', '.txt'))\n",
    "                with open(file_path, 'r') as source_file, open(target_file_path, 'w') as target_file:\n",
    "                    non_comments = []\n",
    "                    comment_block = False\n",
    "                    \n",
    "                    for line in source_file:\n",
    "                        # Check for the start or end of a comment block\n",
    "                        # if \"r'''\" in line and \"'''\" in line or 'r\"\"\"' in line and '\"\"\"' in line:\n",
    "                        #     continue\n",
    "                        # if \"'''\" in line or '\"\"\"' in line:\n",
    "                        #     comment_block = not comment_block\n",
    "                        #     continue\n",
    "                        # if \"r'''\" in line or 'r\"\"\"' in line:\n",
    "                        #     comment_block = not comment_block\n",
    "                        #     continue\n",
    "                        if line.count(\"'''\") == 1 or line.count('\"\"\"') == 1:\n",
    "                            comment_block = not comment_block\n",
    "                            continue\n",
    "                        # If it's not a comment or part of a comment block, save it\n",
    "                        if not is_comment(line) and not comment_block:\n",
    "                            non_comments.append(line)\n",
    "                        # Write non-comment lines to a target .txt file\n",
    "                    target_file.writelines(non_comments)\n",
    "\n",
    "# # Define the path to the local repository (change this to the actual path of your local repo)\n",
    "# # source_directory = '/path/to/your/local/pytorch/repo'\n",
    "source_directory = '../examples/'\n",
    "# # target_directory = '/path/to/your/output/directory'\n",
    "target_directory = './dataset/raw/'\n",
    "\n",
    "\n",
    "# # Create the target directory if it doesn't exist\n",
    "# os.makedirs(target_directory, exist_ok=True)\n",
    "\n",
    "# # Call the function to start extracting non-comment lines\n",
    "# extract_non_comments(source_directory, target_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "954bd61d-0495-4afd-b754-36969e202bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined file created as 'sample_scripts.txt' with contents from 57 files.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def combine_files(directory, output_file, sample=False, num_files_to_sample=100, seed=111, start_token=\"<START>\", end_token=\"<END>\"):\n",
    "    \"\"\"\n",
    "    Combine content from a specified number of text files in a directory into one file, \n",
    "    with start and end tokens between contents from each file.\n",
    "\n",
    "    :param directory: Path to the directory containing text files.\n",
    "    :param output_file: Name of the output file to create.\n",
    "    :param num_files_to_sample: Number of files to sample and combine.\n",
    "    :param start_token: The start token to be added before each file's content.\n",
    "    :param end_token: The end token to be added after each file's content.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # List all text files in the directory\n",
    "    all_files = [f for f in os.listdir(directory) if f.endswith('.txt')]\n",
    "    files = all_files\n",
    "\n",
    "    if sample:\n",
    "        # Sample the specified number of files\n",
    "        random.seed(seed)\n",
    "        files = random.sample(all_files, min(num_files_to_sample, len(all_files)))\n",
    "\n",
    "    # Start combining the sampled files\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, 'r') as infile:\n",
    "                # outfile.write(start_token + '\\n')\n",
    "                content = infile.read()\n",
    "                content_with_tabs = content.replace('    ', '\\t')\n",
    "                outfile.write(content_with_tabs + '\\n')\n",
    "                # outfile.write(end_token + '\\n\\n')\n",
    "\n",
    "    print(f\"Combined file created as '{output_file}' with contents from {len(files)} files.\")\n",
    "  \n",
    "# Example usage\n",
    "combine_files('dataset/raw/', 'sample_scripts.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "3f31df58-4700-4380-88a8-bbb297c931df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it in to inspect it\n",
    "# data_file = 'sample_scripts.txt'\n",
    "# data_file = 'dataset/adamw.txt'\n",
    "with open('sample_scripts.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "6c19f8cc-ea26-4b5b-ab62-2d22cdbc15b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  118465\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "6e0b01c0-81dc-4641-83a3-792396633be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import torch\n",
      "import torch.nn.functional as F\n",
      "from torch.utils.data import Dataset, DataLoader\n",
      "from datautils import MyTrainDataset\n",
      "\n",
      "import torch.multiprocessing as mp\n",
      "from torch.utils.data.distributed import DistributedSampler\n",
      "from torch.nn.parallel import DistributedDataParallel as DDP\n",
      "from torch.distributed import init_process_group, destroy_process_group\n",
      "import os\n",
      "\n",
      "\n",
      "def ddp_setup():\n",
      "\tinit_process_group(backend=\"nccl\")\n",
      "\ttorch.cuda.set_device(int(os.environ[\"LOCAL_RANK\"]))\n",
      "\n",
      "class Trainer:\n",
      "\tdef __init__(\n",
      "\t\tself,\n",
      "\t\tmodel: torch.nn.Module,\n",
      "\t\ttrain_data: DataLoader,\n",
      "\t\toptimizer: torch.optim.Optimizer,\n",
      "\t\tsave_every: int,\n",
      "\t\tsnapshot_path: str,\n",
      "\t) -> None:\n",
      "\t\tself.gpu_id = int(os.environ[\"LOCAL_RANK\"])\n",
      "\t\tself.model = model.to(self.gpu_id)\n",
      "\t\tself.train_data = train_data\n",
      "\t\tself.optimizer = optimizer\n",
      "\t\tself.save_every = save_every\n",
      "\t\tself.epochs_run = 0\n",
      "\t\tself.snapshot_path = snapshot_path\n",
      "\t\tif os.path.exists(snapshot_path):\n",
      "\t\t\tprint(\"Loading snapshot\")\n",
      "\t\t\tself._load_snapshot(snapshot_path)\n",
      "\n",
      "\t\tse\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "b72fd8ba-74d7-4040-a498-eacaa9b0e723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\t\\n !\"#$%\\'()*+,-./0123456789:<=>?@ABCDEFGHIKLMNOPRSTUVWXYZ[\\\\]_`abcdefghijklmnopqrstuvwxyz{|}'"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "77b7f505-3c24-41cf-8c16-070ba7d26eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dbdd55-c84b-462a-83fa-5b9272b1e97f",
   "metadata": {},
   "source": [
    "# encoding and decoding for chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "444a70cd-2509-42c9-bdac-214c6076d9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70, 74, 77, 76, 79, 81, 2, 81, 76, 79, 64, 69]\n",
      "import torch\n"
     ]
    }
   ],
   "source": [
    "# create a mapping from characters to integers\n",
    "ch_to_idx = { ch:i for i,ch in enumerate(chars) }\n",
    "idx_to_ch = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [ch_to_idx[ch] for ch in s] # encoder: take a string, output a list of mapping idx\n",
    "decode = lambda l: ''.join([idx_to_ch[idx] for idx in l]) # decoder: take a list of index, output a string\n",
    "\n",
    "print(encode(\"import torch\"))\n",
    "print(decode(encode(\"import torch\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "9f4c44dc-93a7-4184-a915-42f1d8400198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([118465]) torch.int64\n",
      "tensor([70, 74, 77, 76, 79, 81,  2, 81, 76, 79, 64, 69,  1, 70, 74, 77, 76, 79,\n",
      "        81,  2, 81, 76, 79, 64, 69, 15, 75, 75, 15, 67, 82, 75, 64, 81, 70, 76,\n",
      "        75, 62, 73,  2, 62, 80,  2, 38,  1, 67, 79, 76, 74,  2, 81, 76, 79, 64,\n",
      "        69, 15, 82, 81, 70, 73, 80, 15, 65, 62, 81, 62,  2, 70, 74, 77, 76, 79,\n",
      "        81,  2, 36, 62, 81, 62, 80, 66, 81, 13,  2, 36, 62, 81, 62, 43, 76, 62,\n",
      "        65, 66, 79,  1, 67, 79, 76, 74,  2, 65])\n"
     ]
    }
   ],
   "source": [
    "# encode the entire text dataset and store it into a torch.Tensor\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9427660-f082-46be-97d9-cd471b8aa26c",
   "metadata": {},
   "source": [
    "# train dev split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "725693c4-15e1-4d3b-a036-cb52b2b42089",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce40248d-dabc-4c5e-a2cf-8970ebfe5cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "6cacc69e-43e0-4561-8475-7f7305c1203c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([70]) the target: 74\n",
      "when input is tensor([70, 74]) the target: 77\n",
      "when input is tensor([70, 74, 77]) the target: 76\n",
      "when input is tensor([70, 74, 77, 76]) the target: 79\n",
      "when input is tensor([70, 74, 77, 76, 79]) the target: 81\n",
      "when input is tensor([70, 74, 77, 76, 79, 81]) the target: 2\n",
      "when input is tensor([70, 74, 77, 76, 79, 81,  2]) the target: 81\n",
      "when input is tensor([70, 74, 77, 76, 79, 81,  2, 81]) the target: 76\n"
     ]
    }
   ],
   "source": [
    "context_length = 8\n",
    "x = train_data[:context_length]\n",
    "y = train_data[1:context_length+1]\n",
    "for t in range(context_length):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f83221-8143-46b7-812d-02eea5067558",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "08cf2024-2f73-4275-83b4-dff95ec0050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "context_length = 256\n",
    "max_iters = 1000\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_interval = 100\n",
    "eval_iters = 200\n",
    "\n",
    "num_heads = 6\n",
    "emb_dim = 64 * num_heads\n",
    "num_layers = 6\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ca0020-50db-4d97-88fa-abe53f5fe019",
   "metadata": {},
   "source": [
    "# data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "9ec801a0-ce4b-4011-877f-0067e665d340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([64, 256])\n",
      "tensor([[84, 76, 79,  ..., 75, 76, 74],\n",
      "        [80, 66, 80,  ..., 80, 66, 73],\n",
      "        [69, 15, 75,  ..., 79, 75,  2],\n",
      "        ...,\n",
      "        [10,  1,  1,  ..., 86, 74, 63],\n",
      "        [13,  2, 45,  ..., 80, 86, 74],\n",
      "        [81,  2, 75,  ..., 68,  2, 62]], device='cuda:0')\n",
      "targets:\n",
      "torch.Size([64, 256])\n",
      "tensor([[76, 79, 65,  ..., 76, 74, 70],\n",
      "        [66, 80, 60,  ..., 66, 73, 67],\n",
      "        [15, 75, 75,  ..., 75,  2, 80],\n",
      "        ...,\n",
      "        [ 1,  1, 70,  ..., 74, 63, 76],\n",
      "        [ 2, 45, 76,  ..., 86, 74, 63],\n",
      "        [ 2, 75, 15,  ...,  2, 62, 80]], device='cuda:0')\n",
      "----\n",
      "when input is [84] the target: 76\n",
      "when input is [84, 76] the target: 79\n",
      "when input is [84, 76, 79] the target: 65\n",
      "when input is [84, 76, 79, 65] the target: 60\n",
      "when input is [84, 76, 79, 65, 60] the target: 81\n",
      "when input is [84, 76, 79, 65, 60, 81] the target: 66\n",
      "when input is [84, 76, 79, 65, 60, 81, 66] the target: 75\n",
      "when input is [84, 76, 79, 65, 60, 81, 66, 75] the target: 80\n",
      "when input is [80] the target: 66\n",
      "when input is [80, 66] the target: 80\n",
      "when input is [80, 66, 80] the target: 60\n",
      "when input is [80, 66, 80, 60] the target: 84\n",
      "when input is [80, 66, 80, 60, 84] the target: 70\n",
      "when input is [80, 66, 80, 60, 84, 70] the target: 81\n",
      "when input is [80, 66, 80, 60, 84, 70, 81] the target: 69\n",
      "when input is [80, 66, 80, 60, 84, 70, 81, 69] the target: 9\n",
      "when input is [69] the target: 15\n",
      "when input is [69, 15] the target: 75\n",
      "when input is [69, 15, 75] the target: 75\n",
      "when input is [69, 15, 75, 75] the target: 15\n",
      "when input is [69, 15, 75, 75, 15] the target: 77\n",
      "when input is [69, 15, 75, 75, 15, 77] the target: 62\n",
      "when input is [69, 15, 75, 75, 15, 77, 62] the target: 79\n",
      "when input is [69, 15, 75, 75, 15, 77, 62, 79] the target: 62\n",
      "when input is [73] the target: 2\n",
      "when input is [73, 2] the target: 64\n",
      "when input is [73, 2, 64] the target: 69\n",
      "when input is [73, 2, 64, 69] the target: 66\n",
      "when input is [73, 2, 64, 69, 66] the target: 64\n",
      "when input is [73, 2, 64, 69, 66, 64] the target: 72\n",
      "when input is [73, 2, 64, 69, 66, 64, 72] the target: 77\n",
      "when input is [73, 2, 64, 69, 66, 64, 72, 77] the target: 76\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(111)\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    start_idxs = torch.randint(len(data) - context_length, (batch_size,))\n",
    "    context_idxs = torch.stack([data[start_idx : start_idx+context_length] for start_idx in start_idxs])\n",
    "    target_idxs = torch.stack([data[start_idx+1 : start_idx+context_length+1] for start_idx in start_idxs])\n",
    "    \n",
    "    context_idxs, target_idxs = context_idxs.to(device), target_idxs.to(device)\n",
    "    \n",
    "    return context_idxs, target_idxs\n",
    "\n",
    "context_idxs, target_idxs = get_batch('train')\n",
    "print('inputs:')\n",
    "print(context_idxs.shape)\n",
    "print(context_idxs)\n",
    "print('targets:')\n",
    "print(target_idxs.shape)\n",
    "print(target_idxs)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(4): # batch dimension\n",
    "    for step in range(8): # context length dimension\n",
    "        context = context_idxs[b, :step+1]\n",
    "        target = target_idxs[b,step]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b83ccd-440b-4cbb-a3de-819660488096",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "486d2ed1-d798-4a78-b0b1-7a04d2d5a00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "b3880a56-be00-480d-a300-dfaaae9ece79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384, 91])\n",
      "tensor(4.9763, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(111)\n",
    "\n",
    "\n",
    "class GPTLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # works as a look up table for the probability of the next char for each current char\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.position_embedding_table = nn.Embedding(context_length, emb_dim)\n",
    "        self.blocks = nn.Sequential(*[Block(emb_dim, num_heads=num_heads) for _ in range(num_layers)])\n",
    "        self.ln_final = nn.LayerNorm(emb_dim) # the final layer norm before output\n",
    "        self.lm_head = nn.Linear(emb_dim, vocab_size)\n",
    "\n",
    "    def forward(self, context_idxs, target_idxs=None):\n",
    "        B, T = context_idxs.shape # num of batches; num of total steps in context_length\n",
    "\n",
    "        # context_idxs, target_idxs are both (B,T) tensor of integers\n",
    "        token_emb = self.token_embedding_table(context_idxs) # (B, T, emb_dim)\n",
    "        position_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, emb_dim)\n",
    "        x = token_emb + position_emb # (B, T, emb_dim)\n",
    "        x = self.blocks(x) # (B, T, head_size)\n",
    "        logits = self.lm_head(x) # (B, T, vocab_size), now the feature_dim is vocab_size again\n",
    "        \n",
    "        if target_idxs is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, D = logits.shape # num of batches; num of total steps in context_length; num of feature dimension\n",
    "            logits = logits.view(B * T, D) # now D == vocab_size == number of classes\n",
    "            target_idxs = target_idxs.view(B * T)\n",
    "            loss = F.cross_entropy(logits, target_idxs)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, context_idxs, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            # trim input\n",
    "            input_idxs = context_idxs[:, -context_length:]\n",
    "            # forward\n",
    "            logits, loss = self(input_idxs)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # (B, D) tensor for the last step\n",
    "            probs = F.softmax(logits, dim=-1) # predicted_label (B, D)\n",
    "            \n",
    "            # sample from the distribution\n",
    "            # torch.multinomial: Returns a tensor where each row contains num_samples indices \n",
    "            # sampled from the multinomial probability distribution located in the corresponding row of tensor input.\n",
    "            pred_idxs = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            context_idxs = torch.cat((context_idxs, pred_idxs), dim=1) # (B, T+1)\n",
    "        return context_idxs\n",
    "\n",
    "\n",
    "class Head(nn.Module):\n",
    "    '''\n",
    "    self-attention with only one head\n",
    "    '''\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(emb_dim, head_size, bias=False)\n",
    "        self.query = nn.Linear(emb_dim, head_size, bias=False)\n",
    "        self.value = nn.Linear(emb_dim, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length, context_length)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, D = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        \n",
    "        # attention-score\n",
    "        weight = q @ k.transpose(-2,-1) * D**-0.5 # (B, T, D) @ (B, D, T) ---> (B, T, T)\n",
    "        # D**-0.5: to relief the influence of large value makes the vector after softmax looks like one-hot vector.\n",
    "\n",
    "        weight = weight.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B,T,T), the upper-right triangle will be -inf\n",
    "        weight = F.softmax(weight, dim=-1) # (B, T, T)\n",
    "        weight = self.dropout(weight)\n",
    "\n",
    "        # weighted-aggregation of values based on the attention-score\n",
    "        v = self.value(x) # (B, T, D)\n",
    "        out = weight @ v # (B, T, T) @ (B, T, D) --------> (B, T, D)\n",
    "\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    '''\n",
    "    multiple heads fo self-attention in parallel\n",
    "    '''\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.projection = nn.Linear(emb_dim, emb_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.projection(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    '''\n",
    "    a simple linear layer with activation in decoder, + projection\n",
    "    '''\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(emb_dim, 4 * emb_dim), # the inner dimension is 4 * D, based on the original paper\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * emb_dim, emb_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    '''\n",
    "    a decoder block without cross-attentioin part\n",
    "    '''\n",
    "    def __init__(self, emb_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.head_size = emb_dim // num_heads\n",
    "        self.attention = MultiHeadAttention(num_heads, self.head_size)\n",
    "        self.ffwd = FeedForward(emb_dim)\n",
    "        self.ln1 = nn.LayerNorm(emb_dim)\n",
    "        self.ln2 = nn.LayerNorm(emb_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attention(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "model = GPTLanguageModel().to(device)\n",
    "logits, loss = model(context_idxs, target_idxs)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "# decode 5 batches of data, the initial start char is 'i'\n",
    "# [decode(model.generate(context_idxs=torch.full((5, 1), 75, dtype=torch.long).to(device), max_new_tokens=100)[i].tolist()) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "06bd74f5-5346-40af-b033-aa2800a905f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [1., 1., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [1., 1., 1., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [1., 1., 1., 1., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [1., 1., 1., 1., 1., -inf, -inf, -inf, -inf, -inf],\n",
      "        [1., 1., 1., 1., 1., 1., -inf, -inf, -inf, -inf],\n",
      "        [1., 1., 1., 1., 1., 1., 1., -inf, -inf, -inf],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., -inf, -inf],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., -inf],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111,\n",
      "         0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000]])\n",
      "tensor([[0.1157, 0.2485, 0.9113],\n",
      "        [0.0553, 0.2639, 0.1699],\n",
      "        [0.3641, 0.9834, 0.5603],\n",
      "        [0.2958, 0.3170, 0.2767],\n",
      "        [0.5954, 0.6977, 0.5031],\n",
      "        [0.6098, 0.1969, 0.1853],\n",
      "        [0.2700, 0.4689, 0.6992],\n",
      "        [0.2840, 0.2913, 0.5957],\n",
      "        [0.5312, 0.7020, 0.2222],\n",
      "        [0.6867, 0.0429, 0.2974]])\n",
      "tensor([[0.1157, 0.2485, 0.9113],\n",
      "        [0.0855, 0.2562, 0.5406],\n",
      "        [0.1784, 0.4986, 0.5472],\n",
      "        [0.2077, 0.4532, 0.4795],\n",
      "        [0.2853, 0.5021, 0.4843],\n",
      "        [0.3393, 0.4512, 0.4344],\n",
      "        [0.3294, 0.4537, 0.4723],\n",
      "        [0.3238, 0.4334, 0.4877],\n",
      "        [0.3468, 0.4633, 0.4582],\n",
      "        [0.3808, 0.4212, 0.4421]])\n"
     ]
    }
   ],
   "source": [
    "weight_test = torch.tril(torch.ones(10,10))\n",
    "print(weight_test)\n",
    "weight_test = weight_test.masked_fill(weight_test == 0, float('-inf'))\n",
    "print(weight_test)\n",
    "weight_test = F.softmax(weight_test, dim=-1)\n",
    "print(weight_test)\n",
    "v_test = torch.rand((10,3))\n",
    "print(v_test)\n",
    "out = weight_test @ v_test\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07188173-cb6b-4565-bca2-ea1bee2d5c3d",
   "metadata": {},
   "source": [
    "# optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "7fa8e344-7697-4d9e-ad4f-1a0de5a4564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06df9566-6a45-47e1-a12f-68a738176440",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "86798e56-c560-4216-9e69-22cb753fe490",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    res = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, y = get_batch(split)\n",
    "            logits, loss = model(X, y)\n",
    "            losses[k] = loss.item()\n",
    "        res[split] = losses.mean()\n",
    "    model.train()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "696868ff-0c80-4654-b54f-143a63f74dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9b0289d039416e9bb7fc90dc3704ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.9563, val loss 4.9562\n",
      "step 100: train loss 2.6412, val loss 2.7066\n",
      "step 200: train loss 2.4702, val loss 2.5987\n",
      "step 300: train loss 2.1111, val loss 2.3333\n",
      "step 400: train loss 1.6781, val loss 1.9988\n",
      "step 500: train loss 1.3750, val loss 1.8004\n",
      "step 600: train loss 1.1585, val loss 1.6911\n",
      "step 700: train loss 0.9687, val loss 1.5995\n",
      "step 800: train loss 0.8173, val loss 1.5766\n",
      "step 900: train loss 0.6938, val loss 1.5487\n",
      "step 999: train loss 0.5870, val loss 1.5305\n"
     ]
    }
   ],
   "source": [
    "for iter in tqdm(range(max_iters)): # increase number of steps for good results... \n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "    \n",
    "    # sample a batch of data\n",
    "    context_idxs, target_idxs = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(context_idxs, target_idxs)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "c14367d3-b4d3-4910-8185-a3ebae8fd4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 million parameters\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters())//1e6, 'million parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "45e42c0d-e619-4f26-a15f-04ecb6c36e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import torch\n",
      "import torch.nn.functional as F\n",
      "from torch.utils.data import Dataset, DataLoader\n",
      "from datautils import MyTrainDataset\n",
      "\n",
      "class Trainer:\n",
      "\tCatePalaclel(\n",
      "\tLar,\n",
      "\tDDataConflwionPalGral = None\n",
      "\tget__fu__worldat():\n",
      "\t\tself.val_loss = [\"MLOC\"] fulloating_probj\"] Example = squie\n",
      "\t\telf.dps_checkpointim_apth: save_aves inint = {\n",
      "\ttrain_accuda: torat_hem': Grapplending, the='storal_ccuda: \\ntrainerNe)\n",
      "\t\ttrain(\n",
      "\n",
      "\tos.parser = 0\n",
      "\tfsele N EPURLR_dar Chiswisplither\n",
      "\t\t\tp = torch.batch_size:\n",
      "\t\t\tp.sentr.izeroy_model.parames()\n",
      "\t\t\tself.upsion = 'optimizer':\n",
      "\t\t\tparint(\n",
      "\t\t\t\t'arg name, traintraing', train_trun': 000,\n",
      "\t\t\t\t    help= model, checkpdistrient1 20 (\n",
      "args)\n",
      "\n",
      "from torch.distarge import for checoin rec_tracerversing\n",
      "\n",
      "from sys.backend psinf\n",
      "\n",
      "from traced (torch.nn.Module):\n",
      "\tref in rank rangeward(0, tra.DhibFate, = mask_end=isp_checkpoin=True,\n",
      "\tnlapse=CotpLis,\n",
      "\t\t\tShePOfarS path training num:\n",
      "\t\t\tse:\n",
      "\t\t\tsnapshot = FShard2Dict,\n",
      "\t\t\t)\n",
      "\t\trprint(f\"--> checkpoint {rank}\")\n",
      "\trank_loader = 0:\n",
      "\t\"Soalder rank rank loas = valPCoselicel\", strfut_load_state_dir,\n",
      ")\n",
      "\t_rank\n",
      ")\n",
      "\n",
      "\tprint(f\"tokery log {rank}\\n\" fstave_dict raining terpc....\"\n",
      "\t\tesave_ever(\n",
      "\t\t\tfull_l\n"
     ]
    }
   ],
   "source": [
    "test_string = \"\"\"import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datautils import MyTrainDataset\n",
    "\n",
    "class Trainer:\n",
    "\"\"\"\n",
    "generated_text = decode(model.generate(\n",
    "    context_idxs = torch.tensor(encode(test_string)).view(1, len(test_string)).to(device), \n",
    "    max_new_tokens=1000)[0].tolist()\n",
    "               )\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "d426e38c-cf24-40de-b6ed-c69f24ac60a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text has been saved to monkey_text.txt\n"
     ]
    }
   ],
   "source": [
    "# save the output\n",
    "filename = 'monkey_text.txt'\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(generated_text)\n",
    "print(f\"Generated text has been saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f932fba-e8df-4b4c-92ba-661410748042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llm]",
   "language": "python",
   "name": "conda-env-llm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
