<START>

import builtins
import itertools
import logging
import math
import operator
import sys
from functools import lru_cache, update_wrapper
from typing import Optional, Type, TYPE_CHECKING, Union

from torch import (  # noqa: F401
    sym_float,
    sym_ite,
    sym_max,
    sym_min,
    sym_not,
    sym_sqrt,
    SymBool,
    SymFloat,
    SymInt,
)

from torch.fx.experimental._sym_dispatch_mode import (
    handle_sym_dispatch,
    sym_function_mode,
)

if TYPE_CHECKING:
    from torch.fx.experimental.symbolic_shapes import ShapeEnv

log = logging.getLogger(__name__)


__all__ = ["SymNode", "method_to_operator", "magic_methods", "sym_sqrt"]


SymTypes = (SymInt, SymFloat, SymBool)


def _to_symtype(t):
    if t is bool:
        return SymBool
    if t is int:
        return SymInt
    if t is float:
        return SymFloat
    return t


class SymNode:

    def __init__(
        self,
        expr,
        shape_env,
        pytype,
        hint: Optional[Union[int, float, bool]],
        constant=None,
        fx_node=None,
    ):
        self._expr = expr
        self.shape_env = shape_env
        self.pytype = pytype
        if hint is not None:
            assert type(hint) is pytype or type(hint) is _to_symtype(pytype), (
                "Cannot create SymNode of type "
                f"{pytype} with incompatible hint of type {type(hint)}"
            )
        self._hint = hint
        self.constant: Optional[Union[int, float, bool]] = constant

        self.fx_node = (
            fx_node if self.shape_env._translation_validation_enabled else None
        )

    def with_shape_env(self, shape_env: "ShapeEnv") -> "SymNode":
        return SymNode(
            self._expr, shape_env, self.pytype, self._hint, self.constant, self.fx_node
        )

    @property
    def expr(self):
        return self.shape_env.replace(self._expr)

    def _update_hint(self):
        r = self.shape_env._maybe_evaluate_static(self.expr, compute_hint=True)
        if r is not None:
            self._hint = self.pytype(r) if not isinstance(r, SymTypes) else r

    @property
    def hint(self):
        if self._hint is None:
            self._update_hint()
        return self._hint

    def has_hint(self):
        if self._hint is None:
            self._update_hint()
        return self._hint is not None

    def require_hint(self, fallback=None):
        if self._hint is None:
            self._update_hint()
        if self._hint is None:
            if fallback is not None:
                return fallback
            return self.shape_env.size_hint(self.expr)
        return self._hint

    def maybe_as_int(self):
        if self.expr.is_number:
            return int(self.expr)
        else:
            return None

    def is_int(self):
        return self.pytype is int

    def is_float(self):
        return self.pytype is float

    def is_bool(self):
        return self.pytype is bool

    def wrap_int(self, num):
        assert type(num) is int
        import sympy

        return SymNode(
            sympy.Integer(num), self.shape_env, int, num, constant=num, fx_node=num
        )

    def wrap_float(self, num):
        assert type(num) is float
        import sympy

        return SymNode(
            sympy.Float(num), self.shape_env, float, num, constant=num, fx_node=num
        )

    def wrap_bool(self, num):
        assert type(num) is bool
        import sympy

        return SymNode(
            sympy.true if num else sympy.false,
            self.shape_env,
            bool,
            num,
            constant=num,
            fx_node=num,
        )

    def clone(self):
        return self

    def str(self):
        return f"{self.expr}"

    def __str__(self):
        return self.str()

    def __repr__(self):
        return self.str()

    def abs(self) -> "SymNode":
        return self._abs()  # type: ignore[attr-defined]

    def round(self, ndigits=None) -> "SymNode":
        return self._round(ndigits)  # type: ignore[attr-defined]

    def add(self, other) -> "SymNode":
        return self._add(other)  # type: ignore[attr-defined]

    def sub(self, other) -> "SymNode":
        return self._sub(other)  # type: ignore[attr-defined]

    def mul(self, other) -> "SymNode":
        return self._mul(other)  # type: ignore[attr-defined]

    def mod(self, other) -> "SymNode":
        return self._mod(other)  # type: ignore[attr-defined]

    def pow(self, other) -> "SymNode":
        return self._pow(other)  # type: ignore[attr-defined]

    def and_(self, other) -> "SymNode":
        return self._and_(other)  # type: ignore[attr-defined]

    def or_(self, other) -> "SymNode":
        return self._or_(other)  # type: ignore[attr-defined]

    def truediv(self, other) -> "SymNode":
        return self._truediv(other)  # type: ignore[attr-defined]

    def floordiv(self, other) -> "SymNode":
        return self._floordiv(other)  # type: ignore[attr-defined]

    def lshift(self, other) -> "SymNode":
        return self._lshift(other)  # type: ignore[attr-defined]

    def rshift(self, other) -> "SymNode":
        return self._rshift(other)  # type: ignore[attr-defined]

    def sym_not(self) -> "SymNode":  # noqa: F811
        return self._sym_not()  # type: ignore[attr-defined]

    def eq(self, other) -> "SymNode":
        return self._eq(other)  # type: ignore[attr-defined]

    def ne(self, other) -> "SymNode":
        return self._ne(other)  # type: ignore[attr-defined]

    def gt(self, other) -> "SymNode":
        return self._gt(other)  # type: ignore[attr-defined]

    def lt(self, other) -> "SymNode":
        return self._lt(other)  # type: ignore[attr-defined]

    def le(self, other) -> "SymNode":
        return self._le(other)  # type: ignore[attr-defined]

    def ge(self, other) -> "SymNode":
        return self._ge(other)  # type: ignore[attr-defined]

    def floor(self) -> "SymNode":
        return self._floor()  # type: ignore[attr-defined]

    def is_integer(self) -> "SymNode":
        return self._is_integer()  # type: ignore[attr-defined]

    def sym_float(self) -> "SymNode":  # noqa: F811
        return self._sym_float()  # type: ignore[attr-defined]

    def sym_int(self) -> "SymNode":
        return self._sym_int()  # type: ignore[attr-defined]

    def ceil(self) -> "SymNode":
        return self._ceil()  # type: ignore[attr-defined]

    def neg(self) -> "SymNode":
        return self._neg()  # type: ignore[attr-defined]

    def sym_min(self, other) -> "SymNode":  # noqa: F811
        return self._sym_min(other)  # type: ignore[attr-defined]

    def sym_max(self, other) -> "SymNode":  # noqa: F811
        return self._sym_max(other)  # type: ignore[attr-defined]

    def sym_ite(self, then_val, else_val) -> "SymNode":
        return self._sym_ite(then_val, else_val)  # type: ignore[attr-defined]

    def sym_sqrt(self) -> "SymNode":
        return self._sym_sqrt()  # type: ignore[attr-defined]

    def is_contiguous(self, sizes, strides) -> "SymNode":
        return self._is_contiguous(sizes, strides)  # type: ignore[attr-defined]

    def is_channels_last_contiguous_2d(self, sizes, strides) -> "SymNode":
        return self._is_channels_last_contiguous_2d(sizes, strides)  # type: ignore[attr-defined]

    def is_channels_last_contiguous_3d(self, sizes, strides) -> "SymNode":
        return self._is_channels_last_contiguous_3d(sizes, strides)  # type: ignore[attr-defined]

    def is_channels_last_strides_2d(self, sizes, strides) -> "SymNode":
        return self._is_channels_last_strides_2d(sizes, strides)  # type: ignore[attr-defined]

    def is_channels_last_strides_3d(self, sizes, strides) -> "SymNode":
        return self._is_channels_last_strides_3d(sizes, strides)  # type: ignore[attr-defined]

    def is_non_overlapping_and_dense_indicator(self, sizes, strides) -> "SymNode":
        return self._is_non_overlapping_and_dense_indicator(sizes, strides)  # type: ignore[attr-defined]

    def sym_or(self, other):
        return self.or_(other)

    def sym_and(self, other):
        return self.and_(other)

    def is_non_overlapping_and_dense(self, sizes, strides):
        return self.is_non_overlapping_and_dense_indicator(sizes, strides).eq(to_node(self, 1))  # type: ignore[attr-defined]

    def int_(self):
        return self.guard_int("", 0)  # NB: uses Python backtrace

    def guard_int(self, file, line):
        r = self.shape_env.evaluate_expr(self.expr, self.hint, fx_node=self.fx_node)
        try:
            return int(r)
        except Exception:
            log.warning("Failed to convert to int: %s", r)
            raise

    def guard_float(self, file, line):
        r = self.shape_env.evaluate_expr(
            self.expr, self.hint, fx_node=self.fx_node, expect_rational=False
        )
        try:
            return float(r)
        except Exception:
            log.warning("Failed to convert to float: %s", r)
            raise

    def guard_bool(self, file, line):
        r = self.shape_env.evaluate_expr(self.expr, self.hint, fx_node=self.fx_node)
        try:
            return bool(r)
        except Exception:
            log.warning("Failed to convert to bool: %s", r)
            raise

    def expect_true(self, file, line):
        if self.has_hint():
            return self.guard_bool(file, line)
        return self.shape_env.defer_runtime_assert(
            self.expr, f"{file}:{line}", fx_node=self.fx_node
        )

    def expect_size(self, file, line):
        from torch.fx.experimental.symbolic_shapes import _advise_is_size

        b = self.ge(self.wrap_int(0))
        r = b.expect_true(file, line)
        if r and not self.has_hint():
            _advise_is_size(SymInt(self))
        return r

    def bool_(self):
        return self.guard_bool("", 0)

    def is_symbolic(self):
        return True

    def singleton_int(self):
        return None

    def is_constant(self):
        return False


METHOD_TO_OPERATOR = {
    "abs": operator.abs,
    "add": operator.add,
    "and": operator.and_,
    "ceil": math.ceil,
    "eq": operator.eq,
    "floor": math.floor,
    "floordiv": operator.floordiv,
    "ge": operator.ge,
    "gt": operator.gt,
    "is_integer": lambda x: x.is_integer(),
    "le": operator.le,
    "lshift": operator.lshift,
    "lt": operator.lt,
    "mod": operator.mod,
    "mul": operator.mul,
    "ne": operator.ne,
    "neg": operator.neg,
    "or": operator.or_,
    "pow": operator.pow,
    "round": builtins.round,
    "rshift": operator.rshift,
    "sub": operator.sub,
    "sym_float": sym_float,
    "sym_ite": sym_ite,
    "sym_max": sym_max,
    "sym_min": sym_min,
    "sym_not": sym_not,
    "sym_sqrt": sym_sqrt,
    "truediv": operator.truediv,
}

unary_magic_methods = {
    "abs",
    "sym_float",
    "ceil",
    "floor",
    "neg",
    "sym_sqrt",
    "sym_not",
}

unary_nonmagic_methods = {
    "is_integer",
}

unary_methods = unary_magic_methods | unary_nonmagic_methods

only_bool_magic_methods = {"and", "or", "sym_not", "sym_ite"}
bool_becomes_int_magic_methods = {"add", "sub", "mul"}
also_bool_magic_methods = {"eq"}
bool_magic_methods = only_bool_magic_methods | also_bool_magic_methods

only_float_magic_methods = {"is_integer"}


magic_methods_on_operator_with_trailing_underscore = {"and", "or"}


always_float_magic_methods = {"truediv", "sym_float", "sym_sqrt", "pow"}
always_int_magic_methods = {"ceil", "floor"}
always_bool_magic_methods = {
    "eq",
    "ne",
    "gt",
    "lt",
    "le",
    "ge",
    "and",
    "or",
    "sym_not",
    "is_non_overlapping_and_dense",
    "is_integer",
}



def _sympy_truediv(a, b):
    from torch.utils._sympy.functions import TrueDiv

    return TrueDiv(a, b)


def _sympy_floordiv(a, b):
    from torch.utils._sympy.functions import FloorDiv

    return FloorDiv(a, b)


def _sympy_mod(a, b):
    from torch.utils._sympy.functions import Mod

    return Mod(a, b)


def _sympy_pow(a, b):
    from torch.utils._sympy.functions import Pow

    return Pow(a, b)


def _sympy_and(a, b):
    import sympy

    return sympy.And(a, b)


def _sympy_or(a, b):
    import sympy

    return sympy.Or(a, b)


def _sympy_lshift(a, b):
    from torch.utils._sympy.functions import LShift

    return LShift(a, b)


def _sympy_rshift(a, b):
    from torch.utils._sympy.functions import RShift

    return RShift(a, b)


reflectable_magic_methods = {
    "add": operator.add,
    "sub": operator.sub,
    "mul": operator.mul,
    "mod": _sympy_mod,
    "pow": _sympy_pow,
    "and": _sympy_and,
    "or": _sympy_or,
    "truediv": _sympy_truediv,
    "floordiv": _sympy_floordiv,
    "lshift": _sympy_lshift,
    "rshift": _sympy_rshift,
}


def _floor_ceil_helper(a, fn):
    import sympy

    if isinstance(a, sympy.Mul):
        aa = a.args
        if len(aa) == 2 and isinstance(aa[0], sympy.Float) and aa[1].is_integer:
            coef = sympy.Integer(aa[0])
            if aa[0] == coef:  # structural equality test
                return coef * aa[1]
    if (
        isinstance(a, sympy.Float)
        and a == sympy.Integer(a)
        or isinstance(a, sympy.Integer)
    ):
        return sympy.Integer(a)
    return fn(a)


def _sympy_floor(a):
    import sympy

    return _floor_ceil_helper(a, sympy.floor)


def _sympy_ceil(a):
    import sympy

    return _floor_ceil_helper(a, sympy.ceiling)


def _sympy_eq(a, b):
    import sympy

    return sympy.Eq(a, b)


def _sympy_ne(a, b):
    import sympy

    return sympy.Ne(a, b)


def _sympy_gt(a, b):
    import sympy

    return sympy.Gt(a, b)


def _sympy_lt(a, b):
    import sympy

    return sympy.Lt(a, b)


def _sympy_le(a, b):
    import sympy

    return sympy.Le(a, b)


def _sympy_ge(a, b):
    import sympy

    return sympy.Ge(a, b)


def _sympy_min(a, b):
    import sympy

    return sympy.Min(a, b)


def _sympy_max(a, b):
    import sympy

    return sympy.Max(a, b)


def _sympy_ite(a, t, f):
    import sympy

    return sympy.Piecewise((t, a), (f, True))


def _sympy_sqrt(a):
    import sympy

    return sympy.sqrt(a)


def _sympy_abs(a):
    import sympy

    return sympy.Abs(a)


def _sympy_round(number, ndigits=None):
    from torch.utils._sympy.functions import Round, RoundDecimal

    if ndigits is None:
        return Round(number)
    else:
        return RoundDecimal(number, ndigits)


def _sympy_sym_float(a):
    return a * 1.0


def _sympy_is_integer(a):
    import sympy

    return sympy.Eq(sympy.floor(a), a)


magic_methods = {
    **reflectable_magic_methods,
    "sym_not": operator.invert,
    "eq": _sympy_eq,
    "ne": _sympy_ne,
    "gt": _sympy_gt,
    "lt": _sympy_lt,
    "le": _sympy_le,
    "ge": _sympy_ge,
    "floor": _sympy_floor,
    "sym_float": _sympy_sym_float,
    "ceil": _sympy_ceil,
    "neg": operator.neg,
    "sym_min": _sympy_min,
    "sym_max": _sympy_max,
    "sym_ite": _sympy_ite,
    "sym_sqrt": _sympy_sqrt,
    "abs": _sympy_abs,
    "round": _sympy_round,
    "is_integer": _sympy_is_integer,
}


def sympy_is_contiguous(sizes, strides):
    dim = len(sizes)
    return sympy_is_contiguous_generic(sizes, strides, list(range(dim - 1, -1, -1)))


def sympy_is_contiguous_generic(sizes, strides, dim_order):
    import sympy

    dim = len(sizes)

    if len(dim_order) != dim:
        return sympy.false

    is_contiguous = sympy.true
    z = sympy.Integer(1)
    for d in dim_order:
        is_contiguous &= sympy.Eq(sizes[d], sympy.Integer(1)) | sympy.Eq(strides[d], z)
        z *= sizes[d]
    for d in range(dim):
        is_contiguous |= sympy.Eq(sizes[d], sympy.Integer(0))
    return is_contiguous




def sympy_is_channels_last_contiguous_2d(sizes, strides):
    return sympy_is_contiguous_generic(sizes, strides, [1, 3, 2, 0])


def sympy_is_channels_last_contiguous_3d(sizes, strides):
    return sympy_is_contiguous_generic(sizes, strides, [1, 4, 3, 2, 0])


def sympy_is_channels_last_strides_generic(sizes, strides, dim_order):
    import sympy

    dim = len(sizes)

    if dim != len(dim_order):
        return sympy.false

    m = sympy.Integer(0)
    r = sympy.true

    r &= sympy.Ne(strides[1], 0)

    for d in dim_order:
        r &= sympy.Ne(sizes[d], 0) & (strides[d] >= m)
        if d == 0:
            r &= sympy.Ne(m, strides[1])
        m = strides[d] * sympy.Max(sizes[d], 1)

    return r


def sympy_is_channels_last_strides_2d(sizes, strides):
    return sympy_is_channels_last_strides_generic(sizes, strides, [1, 3, 2, 0])


def sympy_is_channels_last_strides_3d(sizes, strides):
    return sympy_is_channels_last_strides_generic(sizes, strides, [1, 4, 3, 2, 0])


def _sympy_is_non_overlapping_and_dense_indicator(sizes, strides):
    from torch.utils._sympy.functions import IsNonOverlappingAndDenseIndicator

    return IsNonOverlappingAndDenseIndicator(*sizes, *strides)


sizes_strides_methods = {
    "is_contiguous": sympy_is_contiguous,
    "is_channels_last_contiguous_2d": sympy_is_channels_last_contiguous_2d,
    "is_channels_last_contiguous_3d": sympy_is_channels_last_contiguous_3d,
    "is_channels_last_strides_2d": sympy_is_channels_last_strides_2d,
    "is_channels_last_strides_3d": sympy_is_channels_last_strides_3d,
    "is_non_overlapping_and_dense_indicator": _sympy_is_non_overlapping_and_dense_indicator,
}

alternate_impl_if_hinted_methods = {
    "sym_min": builtins.min,
    "sym_max": builtins.max,
}


def to_node(self, num):
    if isinstance(num, SymTypes):
        return num.node
    elif type(num) is bool:
        return self.wrap_bool(num)
    elif type(num) is int:
        return self.wrap_int(num)
    elif type(num) is float:
        return self.wrap_float(num)
    else:
        return NotImplemented


def wrap_node(x):
    if isinstance(x, SymNode) and x.constant is not None:
        return x.constant
    if x.is_int():
        return SymInt(x)
    elif x.is_float():
        return SymFloat(x)
    elif x.is_bool():
        return SymBool(x)
    else:
        raise AssertionError(f"unrecognized return type {x}")


def method_to_operator(method):
    return METHOD_TO_OPERATOR[method]


def _make_node_magic(method, func):
    func = lru_cache(256)(func)

    if method in magic_methods_on_operator_with_trailing_underscore:
        method_attr = f"{method}_"
    else:
        method_attr = method

    def binary_magic_impl(self, other):
        from torch.fx.experimental.symbolic_shapes import safe_expand

        op = method_to_operator(method)

        out_hint = None
        if self.hint is not None and other.hint is not None:
            out_hint = op(self.hint, other.hint)

        alternate_impl = alternate_impl_if_hinted_methods.get(method)
        if alternate_impl and out_hint is not None:
            return to_node(self, alternate_impl(wrap_node(self), wrap_node(other)))

        if sym_function_mode():
            return to_node(
                self, handle_sym_dispatch(op, (wrap_node(self), wrap_node(other)), {})
            )
        assert isinstance(other, SymNode)
        try:
            out = func(self.expr, other.expr)
        except Exception:
            log.warning("failed to eval %s(%s, %s)", method, self.expr, other.expr)
            raise
        out = safe_expand(out)
        pytype: Type
        if method in always_float_magic_methods:
            pytype = float
        elif method in always_bool_magic_methods:
            pytype = bool
        elif self.pytype is float or other.pytype is float:
            pytype = float
        else:
            pytype = self.pytype

        if (
            pytype is not None
            and out_hint is not None
            and not isinstance(out_hint, SymTypes)
        ):
            out_hint = pytype(out_hint)

        fx_node, _ = self.shape_env.create_fx_call_function(
            op, (self.fx_node, other.fx_node)
        )
        return SymNode(out, self.shape_env, pytype, out_hint, fx_node=fx_node)

    def unary_magic_impl(self):
        from torch.fx.experimental.symbolic_shapes import safe_expand

        op = method_to_operator(method)
        if sym_function_mode():
            return to_node(self, handle_sym_dispatch(op, (wrap_node(self),), {}))
        expr = self.expr
        if method == "floor" or method == "ceiling":
            expr = self.shape_env._simplify_floor_div(expr)

        try:
            out = func(expr)
        except Exception:
            log.warning("failed to eval %s(%s)", method, expr)
            raise

        out_hint = None
        if self.hint is not None:
            out_hint = op(self.hint)
        out = safe_expand(out)
        pytype: Type
        if method in always_int_magic_methods:
            pytype = int
        elif method in always_bool_magic_methods:
            pytype = bool
        elif method in always_float_magic_methods:
            pytype = float
        else:
            pytype = self.pytype

        fx_node, _ = self.shape_env.create_fx_call_function(op, (self.fx_node,))
        return SymNode(out, self.shape_env, pytype, out_hint, fx_node=fx_node)

    if method in unary_methods:
        setattr(SymNode, f"_{method_attr}", unary_magic_impl)
    elif method == "sym_ite":

        def sym_ite_impl(pred_node, then_node, else_node):
            from torch.fx.experimental.symbolic_shapes import safe_expand

            out_hint = then_node.hint if pred_node.hint else else_node.hint
            if sym_function_mode():
                return to_node(
                    pred_node,
                    handle_sym_dispatch(
                        sym_ite,
                        (
                            wrap_node(pred_node),
                            wrap_node(then_node),
                            wrap_node(else_node),
                        ),
                        {},
                    ),
                )

            try:
                out = func(pred_node.expr, then_node.expr, else_node.expr)
            except Exception:
                log.warning(
                    "failed to eval %s(%s, %s, %s)",
                    method,
                    pred_node.expr,
                    then_node.expr,
                    else_node.expr,
                )
                raise

            out = safe_expand(out)
            fx_node, _ = pred_node.shape_env.create_fx_call_function(
                sym_ite, (pred_node.fx_node, then_node.fx_node, else_node.fx_node)
            )
            return SymNode(
                out, pred_node.shape_env, then_node.pytype, out_hint, fx_node=fx_node
            )

        setattr(SymNode, f"_{method_attr}", sym_ite_impl)
    elif method == "round":

        def round_impl(self, ndigits=None):
            from torch.fx.experimental.symbolic_shapes import safe_expand

            op = builtins.round
            if sym_function_mode():
                return to_node(
                    self, handle_sym_dispatch(op, (wrap_node(self), ndigits), {})
                )

            expr = self.expr
            try:
                out = func(expr, ndigits)
            except Exception:
                log.warning("failed to eval %s(%s, ndigits=%s)", method, expr, ndigits)
                raise
            out = safe_expand(out)

            pytype = int if ndigits is None else self.pytype

            out_hint = None
            if self.hint is not None:
                out_hint = op(self.hint, ndigits)

            args = [self.fx_node]
            if ndigits is not None:
                args.append(ndigits)
            fx_node, _ = self.shape_env.create_fx_call_function(op, tuple(args))
            return SymNode(out, self.shape_env, pytype, out_hint, fx_node=fx_node)

        setattr(SymNode, f"_{method_attr}", round_impl)
    else:
        setattr(SymNode, f"_{method_attr}", binary_magic_impl)


def _make_node_sizes_strides(method, func):

    def sizes_strides_impl(self, sizes, strides):
        op = getattr(sys.modules[__name__], method)
        if sym_function_mode():
            return to_node(
                self,
                handle_sym_dispatch(
                    op,
                    ([wrap_node(s) for s in sizes], [wrap_node(s) for s in strides]),
                    {},
                ),
            )
        size_exprs = [s.expr for s in sizes]
        stride_exprs = [s.expr for s in strides]
        try:
            out = func(size_exprs, stride_exprs)
        except Exception:
            log.warning("failed to eval %s(%s, %s)", method, size_exprs, stride_exprs)
            raise

        size_hints = []
        out_hint = None
        for s in sizes:
            if s.hint is None:
                break
            size_hints.append(s.hint)
        else:
            stride_hints = []
            for s in strides:
                if s.hint is None:
                    break
                stride_hints.append(s.hint)
            else:
                out_hint = op(size_hints, stride_hints)

        pytype: Type
        if method.endswith("_indicator"):
            pytype = int
        else:
            pytype = bool
        return SymNode(out, self.shape_env, pytype, out_hint)

    setattr(SymNode, f"_{method}", sizes_strides_impl)

    def sizes_strides_user(sizes, strides):
        import sympy

        from torch.fx.experimental.symbolic_shapes import (
            eval_is_non_overlapping_and_dense,
        )

        for a in itertools.chain(sizes, strides):
            if isinstance(a, SymInt):
                return wrap_node(
                    getattr(a.node, method)(
                        [to_node(a.node, b) for b in sizes],
                        [to_node(a.node, b) for b in strides],
                    )
                )
        if method == "is_non_overlapping_and_dense_indicator":
            return eval_is_non_overlapping_and_dense(sizes, strides)
        else:
            return bool(
                func(
                    [sympy.sympify(a) for a in sizes],
                    [sympy.sympify(a) for a in strides],
                )
            )

    if not hasattr(sys.modules[__name__], method):
        setattr(sys.modules[__name__], method, sizes_strides_user)


for method, func in magic_methods.items():
    _make_node_magic(method, func)

for method, func in sizes_strides_methods.items():
    _make_node_sizes_strides(method, func)


def _make_user_magic(method, user_type):

    if method in magic_methods_on_operator_with_trailing_underscore:
        method_attr = f"{method}_"
    else:
        method_attr = method

    def get_constant(x: Union[SymInt, int, SymFloat, float, SymBool, bool]):
        if isinstance(x, (int, float, bool)):
            return x
        if isinstance(x, SymBool):
            return x.node.guard_bool("", 0)
        raise AssertionError("expect to be called with constant SymBools")

    def is_constant(x):
        if isinstance(x, (int, float, bool)):
            return True
        if isinstance(x, (SymInt, SymFloat, SymBool)):
            return x.node.is_constant()
        return False

    if method in bool_becomes_int_magic_methods:

        def promote(x):

<END>

<START>
import torch
from ._common_operator_config_utils import (
    _get_binary_op_configs,
    _get_bn_configs,
    _get_cat_config,
    _get_conv_configs,
    _get_default_op_configs,
    _get_embedding_op_configs,
    _get_fixed_qparams_op_configs,
    _get_linear_configs,
    _get_rnn_op_configs,
    _get_share_qparams_op_configs,
    _get_tensor_info_op_configs,
)
from .backend_config import BackendConfig, DTypeConfig

__all__ = [
    "get_fbgemm_backend_config",
]



fbgemm_weighted_op_quint8_dtype_config = DTypeConfig(
    input_dtype=torch.quint8,
    output_dtype=torch.quint8,
    weight_dtype=torch.qint8,
    bias_dtype=torch.float,
)

fbgemm_default_op_quint8_dtype_config = DTypeConfig(
    input_dtype=torch.quint8,
    output_dtype=torch.quint8,
)

fbgemm_default_op_fp16_dtype_config = DTypeConfig(
    input_dtype=torch.float16,
    output_dtype=torch.float16,
    weight_dtype=torch.float16,
    bias_dtype=torch.float16,
)

fbgemm_default_dynamic_int8_dtype_config = DTypeConfig(
    input_dtype=torch.quint8,
    output_dtype=torch.float,
    weight_dtype=torch.qint8,
    bias_dtype=torch.float,
    is_dynamic=True,
)

fbgemm_default_dynamic_float16_dtype_config = DTypeConfig(
    input_dtype=torch.float16,
    output_dtype=torch.float,
    weight_dtype=torch.float16,
    bias_dtype=torch.float,
    is_dynamic=True,
)

fbgemm_weight_only_quint8_dtype_config = DTypeConfig(
    input_dtype=torch.float,
    output_dtype=torch.float,
    weight_dtype=torch.quint8,
)

fbgemm_weight_only_quint4x2_dtype_config = DTypeConfig(
    input_dtype=torch.float,
    output_dtype=torch.float,
    weight_dtype=torch.quint4x2,
)



def get_fbgemm_backend_config() -> BackendConfig:
    conv_dtype_configs = [fbgemm_weighted_op_quint8_dtype_config]
    linear_dtype_configs = [
        fbgemm_weighted_op_quint8_dtype_config,
        fbgemm_default_dynamic_int8_dtype_config,
        fbgemm_default_dynamic_float16_dtype_config,
    ]
    binary_op_dtype_configs = [fbgemm_default_op_quint8_dtype_config]
    default_op_dtype_configs = [fbgemm_default_op_quint8_dtype_config]
    fixed_qparams_op_dtype_configs = [fbgemm_default_op_quint8_dtype_config]
    share_qparams_op_dtype_configs = [fbgemm_default_op_quint8_dtype_config]
    tensor_info_op_dtype_configs = [fbgemm_default_op_quint8_dtype_config]
    rnn_op_dtype_configs = [
        fbgemm_default_dynamic_int8_dtype_config,
        fbgemm_default_dynamic_float16_dtype_config,
    ]
    embedding_op_dtype_configs = [
        fbgemm_weight_only_quint8_dtype_config,
        fbgemm_weight_only_quint4x2_dtype_config,
    ]
    return BackendConfig("fbgemm") \
        .set_backend_pattern_configs(_get_conv_configs(conv_dtype_configs)) \
        .set_backend_pattern_configs(_get_linear_configs(linear_dtype_configs)) \
        .set_backend_pattern_configs(_get_binary_op_configs(binary_op_dtype_configs)) \
        .set_backend_pattern_config(_get_cat_config(default_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_default_op_configs(default_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_fixed_qparams_op_configs(fixed_qparams_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_share_qparams_op_configs(share_qparams_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_tensor_info_op_configs(tensor_info_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_bn_configs(default_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_rnn_op_configs(rnn_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_embedding_op_configs(embedding_op_dtype_configs))

<END>

<START>
import inspect
import logging

import math
import re
from typing import Dict, List

from torch._streambase import _StreamBase
from ..guards import install_guard

try:
    import numpy as np
except ModuleNotFoundError:
    np = None

import torch._C
import torch._refs
import torch.fx
import torch.nn
import torch.onnx.operators

from .. import config, polyfill, variables
from ..device_interface import get_registered_device_interfaces
from ..exc import unimplemented
from ..guards import GuardBuilder
from ..utils import (
    check_constant_args,
    check_unspec_python_args,
    has_torch_function,
    product,
    proxy_args_kwargs,
)
from .base import VariableTracker
from .ctx_manager import (
    AutocastModeVariable,
    NullContextVariable,
    TorchFunctionDisableVariable,
)
from .distributed import is_constant_pg_functions, is_from_local, ProcessGroupVariable
from .higher_order_ops import TorchHigherOrderOperatorVariable
from .lists import ListVariable, TupleVariable
from .torch_function import can_dispatch_torch_function, dispatch_torch_function

log = logging.getLogger(__name__)


REWRITE_OPS_TO_TENSOR_SIZE_METHOD = [
    torch.onnx.operators.shape_as_tensor,
    torch._shape_as_tensor,
]

constant_fold_functions = [
    torch._assert,
    torch._utils._get_device_index,
    torch.cuda.is_available,
    torch.distributed.is_available,
    torch.get_autocast_gpu_dtype,
    torch.get_default_dtype,
    torch.is_autocast_cache_enabled,
    torch.is_autocast_cpu_enabled,
    torch.is_autocast_enabled,
    torch.is_complex,
    torch.is_floating_point,
    torch.nn.functional._Reduction.get_enum,
    torch.promote_types,
    torch._C._get_privateuse1_backend_name,
]


if torch.distributed.is_available():
    constant_fold_functions.extend(
        [
            torch.distributed.is_initialized,
            torch.distributed.get_rank,
            torch.distributed.get_world_size,
        ]
    )


tracing_state_functions = {
    torch.jit.is_scripting: False,
    torch.jit.is_tracing: False,
    torch._C._get_tracing_state: None,
    torch.fx._symbolic_trace.is_fx_tracing: False,
    torch.onnx.is_in_onnx_export: False,
    torch._dynamo.external_utils.is_compiling: True,
    torch._utils.is_compiling: True,
}


class BaseTorchVariable(VariableTracker):

    def __repr__(self):
        return f"TorchCtxManagerClassVariable({self.value})"

    def call_function(
        self, tx, args: "List[VariableTracker]", kwargs: "Dict[str, VariableTracker]"
    ) -> "VariableTracker":
        from . import GradModeVariable, InferenceModeVariable, StreamVariable

        if self.value is torch.no_grad:
            if len(args) == 1 and isinstance(
                args[0], variables.functions.BaseUserFunctionVariable
            ):
                ctx = GradModeVariable.create(tx, False)
                return ctx.call_function(tx, args, kwargs)
            else:
                return GradModeVariable.create(tx, False)
        elif self.value is torch.enable_grad:
            if len(args) == 1 and isinstance(
                args[0], variables.functions.BaseUserFunctionVariable
            ):
                ctx = GradModeVariable.create(tx, True)
                return ctx.call_function(tx, args, kwargs)
            return GradModeVariable.create(tx, True)
        elif self.value is torch.set_grad_enabled and len(args) == 1:
            return GradModeVariable.create(
                tx, args[0].as_python_constant(), initialized=True
            )
        elif self.value is torch.inference_mode:
            return InferenceModeVariable.create(tx, args[0].as_python_constant())
        elif inspect.isclass(self.value) and issubclass(self.value, _StreamBase):
            from torch._dynamo.variables.builder import wrap_fx_proxy_cls

            return wrap_fx_proxy_cls(
                StreamVariable,
                tx,
                tx.output.create_proxy(
                    "call_function",
                    self.value,
                    (),
                    {},
                ),
            )
        elif self.value in [
            torch.amp.autocast_mode.autocast,
            torch.cuda.amp.autocast,
            torch.cpu.amp.autocast,
        ]:
            return AutocastModeVariable.create(self.value, args, kwargs)
        elif self.value in (
            torch.profiler.profile,
            torch.profiler.record_function,
            torch.autograd.profiler.profile,
            torch.autograd.profiler.record_function,
        ):
            log.warning("Profiler function %s will be ignored", self.value)
            return NullContextVariable()
        elif self.value is torch._C.DisableTorchFunctionSubclass:
            assert not (args or kwargs)
            return TorchFunctionDisableVariable.create(tx)


class TorchInGraphFunctionVariable(BaseTorchVariable):
Calling {str(self.value)} on only torch.SymInt arguments is not yet supported.
To support this behavior, we need to allow const-propping tensors that store symint data.
For now, dynamo will explicitly graph break when it encounters user code with this behavior.
        if self.value is torch.nn.modules.utils._ntuple:
            count = args[0].as_python_constant()
        else:
            count = self.value.__closure__[0].cell_contents
        assert isinstance(count, int)
        assert not kwargs

        def handle_ntuple(value):
            if value.has_unpack_var_sequence(tx):
                return variables.TupleVariable(
                    list(value.unpack_var_sequence(tx)),
                )
            elif value.is_python_constant():
                return variables.ConstantVariable.create(
                    torch.nn.modules.utils._ntuple(count)(value.as_python_constant()),
                )
            else:
                unimplemented(f"torch.nn.modules.utils._ntuple({value})")

        if self.value is torch.nn.modules.utils._ntuple:
            return variables.LambdaVariable(handle_ntuple)
        else:
            return handle_ntuple(args[0])

<END>

<START>

import logging
import warnings

from torch.distributed.run import get_args_parser, run


logger = logging.getLogger(__name__)


def parse_args(args):
    parser = get_args_parser()
    parser.add_argument(
        "--use-env",
        "--use_env",
        default=False,
        action="store_true",
        help="Use environment variable to pass "
        "'local rank'. For legacy reasons, the default value is False. "
        "If set to True, the script will not pass "
        "--local-rank as argument, and will instead set LOCAL_RANK.",
    )
    return parser.parse_args(args)


def launch(args):
    if args.no_python and not args.use_env:
        raise ValueError(
            "When using the '--no-python' flag,"
            " you must also set the '--use-env' flag."
        )
    run(args)


def main(args=None):
    warnings.warn(
        "The module torch.distributed.launch is deprecated\n"
        "and will be removed in future. Use torchrun.\n"
        "Note that --use-env is set by default in torchrun.\n"
        "If your script expects `--local-rank` argument to be set, please\n"
        "change it to read from `os.environ['LOCAL_RANK']` instead. See \n"
        "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n"
        "further instructions\n",
        FutureWarning,
    )
    args = parse_args(args)
    launch(args)


if __name__ == "__main__":
    main()

<END>

<START>
from collections import defaultdict
from copy import deepcopy
import torch
from typing import Any, Optional, Dict
import pytorch_lightning as pl  # type: ignore[import]

from ._data_sparstity_utils import (
    _attach_model_to_data_sparsifier,
    _log_sparsified_level,
    _get_valid_name
)


class PostTrainingDataSparsity(pl.callbacks.Callback):
    def __init__(self, data_sparsifier_class, data_sparsifier_args):
        super().__init__()
        self.data_sparsifier_class = data_sparsifier_class
        self.data_sparsifier_args = data_sparsifier_args
        self.data_sparsifier: Any = None
        self.sparsified: Optional[torch.nn.Module] = None

    def on_fit_end(self, trainer, pl_module) -> None:
        self.sparsified = deepcopy(pl_module.model).eval()
        self.data_sparsifier = self.data_sparsifier_class(**self.data_sparsifier_args)

        _attach_model_to_data_sparsifier(self.sparsified, self.data_sparsifier)

        self.data_sparsifier.step()

        self.data_sparsifier.squash_mask()  # currently squashes params for all mask

        _log_sparsified_level(self.sparsified, self.data_sparsifier)


class TrainingAwareDataSparsity(pl.callbacks.Callback):
    def __init__(self, data_sparsifier_class, data_sparsifier_args,
                 data_scheduler_class, data_scheduler_args):
        super().__init__()
        self.data_sparsifier_class = data_sparsifier_class
        self.data_sparsifier_args = data_sparsifier_args

        self.data_scheduler_class = data_scheduler_class
        self.data_scheduler_args = data_scheduler_args

        self.data_sparsifier: Any = None
        self.data_scheduler: Any = None
        self.sparsified: Optional[torch.nn.Module] = None

        self.data_sparsifier_state_dict: Any = None

    def on_train_start(self, trainer, pl_module) -> None:
        self.data_sparsifier = self.data_sparsifier_class(**self.data_sparsifier_args)
        self.sparsified = deepcopy(pl_module.model)

        _attach_model_to_data_sparsifier(self.sparsified, self.data_sparsifier)  # just to populate the base_sl in the scheduler

        args = deepcopy(self.data_scheduler_args)
        args['data_sparsifier'] = self.data_sparsifier
        self.data_scheduler = self.data_scheduler_class(**args)

    def on_train_epoch_start(self, trainer, pl_module):
        if self.data_sparsifier_state_dict is None:
            return  # probably first epoch

        self.data_sparsifier.load_state_dict(self.data_sparsifier_state_dict)

    def __create_config_based_on_state(self, pl_module):
        config: Dict = defaultdict()
        if self.data_sparsifier_state_dict is None:
            return config
        for name, _ in pl_module.model.named_parameters():
            valid_name = _get_valid_name(name)
            config[valid_name] = self.data_sparsifier.data_groups[valid_name]

        return config

    def on_train_epoch_end(self, trainer, pl_module):
        self.sparsified = deepcopy(pl_module.model)
        config = self.__create_config_based_on_state(pl_module)

        _attach_model_to_data_sparsifier(self.sparsified, self.data_sparsifier, config=config)
        self.data_sparsifier.step()
        self.data_scheduler.step()

        self.data_sparsifier_state_dict = self.data_sparsifier.state_dict()

    def on_train_end(self, trainer, pl_module):
        self.data_sparsifier.squash_mask()

<END>

<START>
from itertools import chain
from operator import getitem
import torch
import torch.nn.functional as F
from torch import nn
from torch.fx import symbolic_trace
from torch.nn.utils import parametrize
from typing import Type, Set, Dict, Callable, Tuple, Optional, Union

from torch.ao.pruning import BaseSparsifier
from .parametrization import FakeStructuredSparsity, BiasHook, module_contains_param
from .match_utils import apply_match, MatchAllNode
from .prune_functions import (
    prune_linear,
    prune_linear_linear,
    prune_linear_activation_linear,
    prune_conv2d,
    prune_conv2d_conv2d,
    prune_conv2d_activation_conv2d,
    prune_conv2d_activation_pool_conv2d,
    prune_conv2d_pool_activation_conv2d,
    prune_conv2d_pool_flatten_linear,
    prune_lstm_output_linear,
    prune_lstm_output_layernorm_linear,
)


def _get_supported_structured_pruning_modules():
    SUPPORTED_STRUCTURED_PRUNING_MODULES = {  # added to config if None given
        nn.Linear,
        nn.Conv2d,
        nn.LSTM,
    }
    return SUPPORTED_STRUCTURED_PRUNING_MODULES


def _get_supported_activation_functions():
    SUPPORTED_ACTIVATION_FUNCTIONS = {
        F.relu,
        F.rrelu,
        F.hardtanh,
        F.relu6,
        F.sigmoid,
        F.hardsigmoid,
        F.tanh,
        F.silu,
        F.mish,
        F.hardswish,
        F.elu,
        F.celu,
        F.selu,
        F.hardshrink,
        F.leaky_relu,
        F.logsigmoid,
        F.softplus,
        F.prelu,
        F.softsign,
        F.tanhshrink,
        F.gelu,
    }
    return SUPPORTED_ACTIVATION_FUNCTIONS


def _get_supported_activation_modules():
    SUPPORTED_ACTIVATION_MODULES = {
        nn.ReLU,
        nn.RReLU,
        nn.Hardtanh,
        nn.ReLU6,
        nn.Sigmoid,
        nn.Hardsigmoid,
        nn.Tanh,
        nn.SiLU,
        nn.Mish,
        nn.Hardswish,
        nn.ELU,
        nn.CELU,
        nn.SELU,
        nn.Hardshrink,
        nn.LeakyReLU,
        nn.LogSigmoid,
        nn.Softplus,
        nn.PReLU,
        nn.Softsign,
        nn.Tanhshrink,
        nn.GELU,
    }
    return SUPPORTED_ACTIVATION_MODULES


def _get_default_structured_pruning_patterns() -> Dict[
    Tuple[Union[Type[nn.Module], Callable, MatchAllNode, str], ...],
    Callable[..., None],
]:
    patterns: Dict[
        Tuple[Union[Type[nn.Module], Callable, MatchAllNode, str], ...],
        Callable[..., None],
    ] = {
        (nn.Linear, "output"): prune_linear,
        (nn.Linear, nn.Linear): prune_linear_linear,
        (nn.Conv2d, "output"): prune_conv2d,
        (nn.Conv2d, nn.Conv2d): prune_conv2d_conv2d,
        (nn.LSTM, getitem, nn.Linear): prune_lstm_output_linear,
        (nn.LSTM, getitem, nn.LayerNorm, nn.Linear): prune_lstm_output_layernorm_linear,
    }

    for activation in chain(
        _get_supported_activation_functions(), _get_supported_activation_modules()
    ):
        patterns.update(
            {
                (nn.Linear, activation, nn.Linear): prune_linear_activation_linear,
                (nn.Conv2d, activation, nn.Conv2d): prune_conv2d_activation_conv2d,
                (
                    nn.Conv2d,
                    activation,
                    nn.AvgPool2d,
                    nn.Conv2d,
                ): prune_conv2d_activation_pool_conv2d,
                (
                    nn.Conv2d,
                    activation,
                    F.avg_pool2d,
                    nn.Conv2d,
                ): prune_conv2d_activation_pool_conv2d,
                (
                    nn.Conv2d,
                    activation,
                    nn.MaxPool2d,
                    nn.Conv2d,
                ): prune_conv2d_activation_pool_conv2d,
                (
                    nn.Conv2d,
                    activation,
                    F.max_pool2d,
                    nn.Conv2d,
                ): prune_conv2d_activation_pool_conv2d,
                (
                    nn.Conv2d,
                    nn.AvgPool2d,
                    activation,
                    nn.Conv2d,
                ): prune_conv2d_pool_activation_conv2d,
                (
                    nn.Conv2d,
                    F.avg_pool2d,
                    activation,
                    nn.Conv2d,
                ): prune_conv2d_pool_activation_conv2d,
                (
                    nn.Conv2d,
                    nn.MaxPool2d,
                    activation,
                    nn.Conv2d,
                ): prune_conv2d_pool_activation_conv2d,
                (
                    nn.Conv2d,
                    F.max_pool2d,
                    activation,
                    nn.Conv2d,
                ): prune_conv2d_pool_activation_conv2d,
                (
                    nn.Conv2d,
                    nn.AdaptiveAvgPool2d,
                    nn.Flatten,
                    nn.Linear,
                ): prune_conv2d_pool_flatten_linear,
                (
                    nn.Conv2d,
                    nn.AdaptiveAvgPool2d,
                    torch.flatten,
                    nn.Linear,
                ): prune_conv2d_pool_flatten_linear,
                (
                    nn.Conv2d,
                    nn.AdaptiveMaxPool2d,
                    nn.Flatten,
                    nn.Linear,
                ): prune_conv2d_pool_flatten_linear,
                (
                    nn.Conv2d,
                    nn.AdaptiveMaxPool2d,
                    torch.flatten,
                    nn.Linear,
                ): prune_conv2d_pool_flatten_linear,
            }
        )
    return patterns


class BaseStructuredSparsifier(BaseSparsifier):

    def __init__(self, defaults, patterns=None):
        super().__init__(defaults)
        if patterns is None:
            patterns = _get_default_structured_pruning_patterns()
        self.patterns = patterns

    def make_config_from_model(
        self,
        model: nn.Module,
        SUPPORTED_MODULES: Optional[Set[Type]] = None,
    ) -> None:
        if SUPPORTED_MODULES is None:
            SUPPORTED_MODULES = _get_supported_structured_pruning_modules()
        super().make_config_from_model(model, SUPPORTED_MODULES=SUPPORTED_MODULES)

    def _prepare(self, *args, **kwargs) -> None:
        for config in self.groups:
            module = config["module"]
            tensor_name = config["tensor_name"]
            parametrization = config.get("parametrization", FakeStructuredSparsity)
            tensor = getattr(module, tensor_name)

            mask = config.get(
                "mask",
                torch.ones(tensor.shape[0], dtype=torch.bool, device=tensor.device),
            )
            self.state[config["tensor_fqn"]]["mask"] = mask
            parametrize.register_parametrization(
                module, tensor_name, parametrization(mask)
            )

            if isinstance(module, (nn.Linear, nn.Conv2d)):
                prune_bias = config.get("prune_bias", True)
                if module.bias is not None:
                    module.register_parameter(
                        "_bias", nn.Parameter(module.bias.detach())
                    )
                    module.bias = None
                    module.prune_bias = prune_bias

                module.register_forward_hook(
                    BiasHook(module.parametrizations.weight[0], prune_bias)
                )

    def prune(self) -> None:

        self.traced = symbolic_trace(self.model)
        modules = dict(self.traced.named_modules())

        for node in self.traced.graph.nodes:
            for pattern, convert_fn in self.patterns.items():
                matched = apply_match(modules, pattern, node, [])
                if matched is None:
                    continue

                first_module = modules.get(node.target)
                if (
                    first_module is not None
                    and parametrize.is_parametrized(first_module)
                    and module_contains_param(first_module, FakeStructuredSparsity)
                ):
                    convert_block = []
                    for node in matched:
                        if node.op == "call_module":
                            convert_block.append(modules.get(node.target))
                        elif node.op == "call_function":
                            convert_block.append(node.target)
                    convert_fn(*convert_block)

        for module in self.traced.modules():
            if module_contains_param(module, FakeStructuredSparsity):
                raise Exception(
                    f"Error: {module} still contains FakeStructuredSparsity parametrizations!"
                )

        self.traced.graph.lint()
        self.traced.recompile()
        return self.traced

<END>

<START>

__all__ = ['FloatFunctional', 'FXFloatFunctional', 'QFunctional']

from torch.ao.nn.quantized.modules.functional_modules import FloatFunctional
from torch.ao.nn.quantized.modules.functional_modules import FXFloatFunctional
from torch.ao.nn.quantized.modules.functional_modules import QFunctional

<END>

<START>
from dataclasses import dataclass, field
from collections import defaultdict
import copy
import torch
from torch.fx import (
    Node,
    Graph,
)
from torch.fx._compatibility import compatibility
from typing import Dict, List, Set, Any, Union, Tuple
import logging
import os

__all__ = ['SubgraphMatcher', 'InternalMatch']

def _init_logger():
    logger = logging.getLogger(__name__)

    level = os.environ.get('PYTORCH_MATCHER_LOGLEVEL', 'WARNING').upper()
    logger.setLevel(level)
    console = logging.StreamHandler()
    formatter = logging.Formatter("%(filename)s > %(message)s")
    console.setFormatter(formatter)
    console.setLevel(level)
    logger.addHandler(console)
    logger.propagate = False
    return logger

logger = _init_logger()

@compatibility(is_backward_compatible=False)
@dataclass
class InternalMatch:
    anchors: List[Node]
    nodes_map: Dict[Node, Node] = field(default_factory=dict)

    placeholder_nodes: List[Node] = field(default_factory=list)

    returning_nodes: List[Node] = field(default_factory=list)

    name_node_map: Dict[str, Node] = field(default_factory=dict)

    def __copy__(self):
        return InternalMatch(anchors=self.anchors, nodes_map=self.nodes_map.copy(),
                             placeholder_nodes=self.placeholder_nodes.copy(),
                             returning_nodes=self.returning_nodes.copy())

@compatibility(is_backward_compatible=False)
class SubgraphMatcher:
    def __init__(self, pattern: Graph,
                 match_output: bool = False,
                 match_placeholder: bool = False,
                 remove_overlapping_matches: bool = True,
                 ignore_literals: bool = False) -> None:

        self.pattern = pattern
        self.match_output = match_output
        self.match_placeholder = match_placeholder
        self.remove_overlapping_matches = remove_overlapping_matches
        self.ignore_literals = ignore_literals

        if len(pattern.nodes) == 0:
            raise ValueError("SubgraphMatcher cannot be initialized with an empty pattern")

        for node in pattern.nodes:
            if node.op != "output":
                assert len(node.users) > 0, \
                       "SubgraphMatcher cannot be initialized with an pattern with dead code"


        self.pattern_placeholder_nodes = [n for n in pattern.nodes if n.op == "placeholder"]
        output_node = next(iter(reversed(pattern.nodes)))
        self.pattern_returning_nodes: List[Node] = output_node.all_input_nodes

        self.pattern_anchors: List[Node] = []
        if match_output:
            self.pattern_anchors = [output_node]
        else:
            self.pattern_anchors = [n for n in output_node.all_input_nodes if len(n.users) == 1]

    def _match_attributes(self, pn: Node, gn: Node) -> bool:
        assert isinstance(pn.target, str), f"pn.target {pn.target} must be a string."
        assert isinstance(gn.target, str), f"gn.target {gn.target} must be a string."
        pn_value = getattr(pn.graph.owning_module, pn.target)
        gn_value = getattr(gn.graph.owning_module, gn.target)
        if type(pn_value) != type(gn_value):
            return False

        if isinstance(pn_value, torch.Tensor):
            return isinstance(gn_value, torch.Tensor)
        else:
            raise RuntimeError(f"Unsupported type {pn_value} when matching attributes")
        return False

    def _nodes_are_equal(self, pn: Node, gn: Node) -> bool:
        if not self.match_placeholder and pn.op == "placeholder":
            return True

        if pn.op == gn.op:
            if pn.op == "placeholder" or pn.op == "output":
                return True
            elif pn.op == "get_attr":
                return self._match_attributes(pn, gn)
            return pn.target == gn.target
        return False

    def _is_contained(self, nodes_map: Dict[Node, Node]) -> bool:

        lookup: Dict[Node, Node] = {gn : pn for pn, gn in nodes_map.items() if pn.op != "placeholder"}

        for gn, pn in lookup.items():
            if pn in self.pattern_returning_nodes:
                continue

            for user in gn.users:
                if user not in lookup:
                    return False
        return True

    def _remove_overlapping_matches(self, matches: List[InternalMatch]) -> List[InternalMatch]:
        non_overlapping_matches: List[InternalMatch] = list()
        nodes_matched: Set[Node] = set()

        for match in matches:
            found_overlap = False
            for pn, gn in match.nodes_map.items():
                if pn.op not in {"placeholder", "output"} and gn in nodes_matched:
                    found_overlap = True
                    break

            if not found_overlap:
                non_overlapping_matches.append(match)
                for pn, gn in match.nodes_map.items():
                    if pn.op not in {"placeholder", "output"}:
                        nodes_matched.add(gn)
        return non_overlapping_matches

    def _match_literals(self, pn: Any, gn: Any, match: InternalMatch) -> bool:
        assert not (isinstance(pn, Node) and isinstance(gn, Node)), "pn and gn cannot both be Node"

        if isinstance(pn, Node) and not isinstance(gn, Node):
            if pn.op == "placeholder":
                if pn in match.nodes_map:
                    return match.nodes_map[pn] == gn

                match.nodes_map[pn] = gn
                return True
            else:
                return False
        elif not isinstance(pn, Node) and isinstance(gn, Node):
            return False
        else:
            return type(gn) == type(pn) and gn == pn

    def _match_nodes(self, pn: Node, gn: Node, match: InternalMatch) -> bool:
        logger.info("  matching %s to %s", pn, gn)

        assert isinstance(pn, Node) and isinstance(gn, Node), str(f"pn and gn must be Node, pn: {pn}, gn: {gn}")

        if pn in match.nodes_map:
            return match.nodes_map[pn] == gn

        if gn in match.nodes_map.values():
            return False

        if not self._nodes_are_equal(pn, gn):
            return False

        saved_match = copy.copy(match)
        match.nodes_map[pn] = gn

        if pn.op == "placeholder":
            return True

        match_found = True

        def _match_args(args1: Union[List, Tuple], args2: Union[List, Tuple]) -> bool:
            if len(args1) != len(args2):
                return False

            for a1, a2 in zip(args1, args2):
                if isinstance(a1, Node) and isinstance(a2, Node):
                    matched = self._match_nodes(a1, a2, match)
                elif isinstance(a1, (list, tuple)) and isinstance(a2, (list, tuple)):
                    matched = _match_args(a1, a2)
                else:
                    matched = self._match_literals(a1, a2, match) or self.ignore_literals

                if not matched:
                    return False

            return True

        pn_args, gn_args = None, None
        if (
            (len(pn.args) != len(gn.args) or list(pn.kwargs.keys()) != list(gn.kwargs.keys())) and
            pn.op == "call_function" and
            isinstance(pn.target, torch._ops.OpOverload)
        ):
            args_schema = pn.target._schema.arguments

            def get_all_arguments(orig_args, orig_kwargs):
                all_args = []
                for i, schema in enumerate(args_schema):
                    if schema.name in orig_kwargs:
                        all_args.append(orig_kwargs[schema.name])
                    elif not schema.kwarg_only and i < len(orig_args):
                        all_args.append(orig_args[i])
                    else:
                        all_args.append(schema.default_value)
                return all_args

            pn_args = get_all_arguments(pn.args, pn.kwargs)
            gn_args = get_all_arguments(gn.args, gn.kwargs)

        elif len(pn.args) == len(gn.args) and list(pn.kwargs.keys()) == list(gn.kwargs.keys()):
            pn_args = list(pn.args)
            gn_args = list(gn.args)
            pn_args.extend(list(pn.kwargs.values()))
            gn_args.extend(list(gn.kwargs.values()))
        else:
            match_found = False

        match_found = (
            match_found and
            pn_args is not None and
            gn_args is not None and
            _match_args(pn_args, gn_args)
        )

        if not match_found:
            match = copy.copy(saved_match)
            return False

        return True

    def match(self, graph: Graph) -> List[InternalMatch]:
        from torch.fx.passes.utils.fuser_utils import validate_partition

        match_candidates: Dict[Node, List[Node]] = defaultdict(list)
        for pattern_anchor in self.pattern_anchors:
            for node in graph.nodes:
                if self._nodes_are_equal(pattern_anchor, node):
                    match_candidates[pattern_anchor].append(node)
        match_candidates_list = list(match_candidates.items())

        logger.info("Initial match_candidates_list: %s\n", match_candidates_list)

        matches: List[InternalMatch] = []

        def backtracking(anchor_index, match):
            if anchor_index == len(match_candidates_list):
                match.placeholder_nodes = [match.nodes_map[pn] for pn in self.pattern_placeholder_nodes]
                match.returning_nodes = [match.nodes_map[pn] for pn in self.pattern_returning_nodes]
                matches.append(match)

                logger.info("Found a match: %s\n", match)
                return

            pattern_anchor, candidate_nodes = match_candidates_list[anchor_index]
            saved_match = copy.copy(match)

            for node in candidate_nodes:
                logger.info("Trying to match anchor %s to %s", pattern_anchor, node)

                match_found = self._match_nodes(pattern_anchor, node, match)
                if match_found:
                    backtracking(anchor_index + 1, match)
                else:
                    logger.info("Failed to match anchor %s to %s\n", pattern_anchor, node)

                match = copy.copy(saved_match)

        match = InternalMatch(anchors=self.pattern_anchors)
        if match_candidates_list:
            backtracking(0, match)

        before = len(matches)
        matches = [match for match in matches if self._is_contained(match.nodes_map)]
        after = len(matches)
        if before != after:
            logger.info("Filtered out %s matches because they are not fully contained", before - after)

        valid_matches = []
        for match in matches:
            matched_compute_nodes = \
                [gn for pn, gn in match.nodes_map.items() if pn.op not in {"placeholder", "output"}]
            if validate_partition(matched_compute_nodes):
                valid_matches.append(match)
        if len(valid_matches) != len(matches):
            logger.info("Filtered out %s matches because \
                          matched subgraph would form a cycle if fused", len(matches) - len(valid_matches))

        if self.remove_overlapping_matches:
            before = len(valid_matches)
            matches = self._remove_overlapping_matches(valid_matches)
            after = len(matches)
            if before != after:
                logger.info("Filtered out %s matches because matched subgraphs are overlapping", before - after)

        logger.info("Matches returned: %s", matches)

        return matches

<END>

<START>

<END>

<START>
from typing import Callable, Optional, Union

import torch

from .base_structured_sparsifier import BaseStructuredSparsifier

__all__ = ["FPGMPruner"]


class FPGMPruner(BaseStructuredSparsifier):

    def __init__(
        self, sparsity_level: float = 0.5, dist: Optional[Union[Callable, int]] = None
    ):
        defaults = {
            "sparsity_level": sparsity_level,
        }

        if dist is None:
            dist = 2

        if callable(dist):
            self.dist_fn = dist
        elif dist == 1:
            self.dist_fn = lambda x: torch.cdist(x, x, p=1)
        elif dist == 2:
            self.dist_fn = lambda x: torch.cdist(x, x, p=2)
        else:
            raise NotImplementedError("Distance function is not yet implemented.")
        super().__init__(defaults=defaults)

    def _compute_distance(self, t):
        dim = 0  # prune filter (row)

        size = t.size(dim)
        slc = [slice(None)] * t.dim()

        t_flatten = [
            t[tuple(slc[:dim] + [slice(i, i + 1)] + slc[dim + 1 :])].reshape(-1)
            for i in range(size)
        ]
        t_flatten = torch.stack(t_flatten)

        dist_matrix = self.dist_fn(t_flatten)

        distance = torch.sum(torch.abs(dist_matrix), 1)

        return distance

    def update_mask(self, module, tensor_name, sparsity_level, **kwargs):
        tensor_weight = getattr(module, tensor_name)
        mask = getattr(module.parametrizations, tensor_name)[0].mask

        if sparsity_level <= 0:
            mask.data = torch.ones_like(mask).bool()
        elif sparsity_level >= 1.0:
            mask.data = torch.zeros_like(mask).bool()
        else:
            distance = self._compute_distance(tensor_weight)

            tensor_size = tensor_weight.shape[0]  # prune filter (row)
            nparams_toprune = round(sparsity_level * tensor_size)
            nparams_toprune = min(
                max(nparams_toprune, 0), tensor_size
            )  # clamp to [0, tensor_size]
            topk = torch.topk(distance, k=nparams_toprune, largest=False)
            mask[topk.indices] = False

<END>

<START>

import torch
from torch._jit_internal import Future
from torch.jit._builtins import _register_builtin

from torch.utils import set_module

set_module(Future, "torch.jit")


def fork(func, *args, **kwargs):
    return torch._C.fork(func, *args, **kwargs)


def wait(future):
    return torch._C.wait(future)


_register_builtin(wait, "aten::wait")

<END>

<START>
import dataclasses
import functools
import inspect
import sys
import typing
import weakref

from torchgen.model import FunctionSchema, OperatorName, SchemaKind, BaseType, ListType, BaseTy

import torch
import torch._C as _C
import torch.library as library
from torch._library.abstract_impl import AbstractImplCtx
from torch.library import get_ctx

from .autograd import autograd_kernel_indirection, construct_autograd_kernel


__all__ = ["custom_op", "CustomOp", "get_ctx", "AbstractImplCtx"]


SUPPORTED_DEVICE_TYPE_TO_KEY = {
    "cpu": "CPU",
    "cuda": "CUDA",
}

RESERVED_NS = {
    "prim",
    "prims",
    "aten",
    "at",
    "torch",
    "pytorch",
}


def custom_op(
    qualname: str, manual_schema: typing.Optional[str] = None
) -> typing.Callable:

    def inner(func):
        if not inspect.isfunction(func):
            raise ValueError(
                f"custom_op(...)(func): Expected `func` to be a Python "
                f"function, got: {type(func)}"
            )

        ns, name = parse_qualname(qualname)
        validate_namespace(ns)
        if func.__name__ != name:
            raise ValueError(
                f"custom_op(qualname='{qualname}', ...)(func): expected `func` "
                f"to have name '{name}' but got '{func.__name__}'. "
                f"Please either change the name of `func` or the qualname that "
                f"is passed to `custom_op`"
            )

        schema = infer_schema(func) if manual_schema is None else manual_schema
        schema_str = f"{name}{schema}"
        function_schema = FunctionSchema.parse(schema_str)
        validate_schema(function_schema)
        if manual_schema is not None:
            validate_function_matches_schema(function_schema, func)

        lib = library.Library(ns, "FRAGMENT")
        lib.define(schema_str)
        ophandle = find_ophandle_or_throw(ns, function_schema.name)
        result = CustomOp(lib, ns, function_schema, name, ophandle, _private_access=True)

        result.__name__ = func.__name__
        result.__module__ = func.__module__
        result.__doc__ = func.__doc__

        library.impl(lib, result._opname, "Autograd")(
            autograd_kernel_indirection(weakref.proxy(result))
        )

        torch._C._dispatch_set_report_error_callback(
            ophandle, functools.partial(report_error_callback, weakref.proxy(result))
        )

        return result

    return inner


global_registry: typing.Dict[str, "CustomOp"] = {}


class CustomOp:

    def __init__(self, lib, cpp_ns, schema, operator_name, ophandle, *, _private_access=False):
        super().__init__()
        if not _private_access:
            raise RuntimeError(
                "The CustomOp constructor is private and we do not guarantee "
                "BC for it. Please use custom_op(...) to create a CustomOp object"
            )
        name = f"{cpp_ns}::{operator_name}"
        self._schema = schema
        self._cpp_ns = cpp_ns
        self._lib: library.Library = lib
        self._ophandle: _C._DispatchOperatorHandle = ophandle
        self._opname: str = operator_name
        self._qualname: str = name
        self.__name__ = None  # mypy requires this
        self._impls: typing.Dict[str, typing.Optional[FuncAndLocation]] = {}
        self._registered_autograd_kernel_indirection = False

        global_registry[self._qualname] = self

    def _register_autograd_kernel_indirection(self):
        assert not self._registered_autograd_kernel_indirection
        self._lib.impl(self._opname, autograd_kernel_indirection(weakref.proxy(self)), "Autograd")
        self._registered_autograd_kernel_indirection = True

    def _register_impl(self, kind, func, stacklevel=2):
        if self._has_impl(kind):
            func_and_location = self._impls[kind]
            assert func_and_location is not None  # Pacify mypy
            location = func_and_location.location
            raise RuntimeError(
                f"Attempting to register a {kind} impl for operator {self._qualname} "
                f"that already has a {kind} impl registered from Python at "
                f"{location}. This is not supported."
            )
        frame = inspect.getframeinfo(sys._getframe(stacklevel))
        location = f"{frame.filename}:{frame.lineno}"
        self._impls[kind] = FuncAndLocation(func, location)

    def _get_impl(self, kind):
        return self._impls[kind]

    def _has_impl(self, kind):
        return kind in self._impls

    def _destroy(self):
        del self._lib

        opnamespace = getattr(torch.ops, self._cpp_ns)
        if hasattr(opnamespace, self._opname):
            delattr(opnamespace, self._opname)

        del global_registry[self._qualname]

    def __repr__(self):
        return f'<CustomOp(op="{self._qualname}")>'

    def __call__(self, *args, **kwargs):
        result = _C._dispatch_call_boxed(self._ophandle, *args, **kwargs)
        return result

    def impl(
        self, device_types: typing.Union[str, typing.Iterable[str]], _stacklevel=2,
    ) -> typing.Callable:
        if isinstance(device_types, str):
            device_types = [device_types]
        for device_type in device_types:
            validate_device_type(device_type)

        def inner(f):
            for device_type in set(device_types):
                self._check_doesnt_have_library_impl(device_type)
                self._register_impl(device_type, f, stacklevel=_stacklevel)
                dispatch_key = SUPPORTED_DEVICE_TYPE_TO_KEY[device_type]
                library.impl(self._lib, self._opname, dispatch_key)(f)
            return f

        return inner

    def _check_doesnt_have_library_impl(self, device_type):
        if self._has_impl(device_type):
            return
        key = SUPPORTED_DEVICE_TYPE_TO_KEY[device_type]
        if _C._dispatch_has_computed_kernel_for_dispatch_key(self._qualname, key):
            raise RuntimeError(
                f"impl(..., device_types={device_type}): the operator {self._qualname} "
                f"already has an implementation for this device type via a "
                f"pre-existing torch.library or TORCH_LIBRARY registration.")

    def impl_factory(self) -> typing.Callable:

        WARNING: please do not use this directly (and instead use the torch._custom_ops
        APIs). Also please see the following for a detailed guide on custom ops.
        https://docs.google.com/document/d/1aGWtgxV3HppuxQAdddyPrs74_aEntpkYt9MalnCKnhk

        An "abstract implementation" specifies the behavior of this operator on
        Tensors that carry no data. Given some input Tensors with certain properties
        (sizes/strides/storage_offset/device), it specifies what the properties of
        the output Tensors are.

        The abstract implementation has the same signature as the operator.
        It is run for both FakeTensors and meta tensors. To write an abstract
        implementation, assume that all Tensor inputs to the operator are
        regular CPU/CUDA/Meta tensors, but they do not have storage, and
        you are trying to return regular CPU/CUDA/Meta tensor(s) as output.
        The abstract implementation must consist of only PyTorch operations
        (and may not directly access the storage or data of any input or
        intermediate Tensors).

        This API is used as a decorator (see examples).

        Examples::
            >>> import numpy as np
            >>> from torch import Tensor
            >>>
            >>> # Example 1: an operator without data-dependent output shape
            >>> @custom_op('my_library::custom_linear')
            >>> def custom_linear(x: Tensor, weight: Tensor, bias: Tensor) -> Tensor:
            >>>     ...
            >>>
            >>> @custom_linear.impl_abstract()
            >>> def custom_linear_abstract(x, weight):
            >>>     assert x.dim() == 2
            >>>     assert weight.dim() == 2
            >>>     assert bias.dim() == 1
            >>>     assert x.shape[1] == weight.shape[1]
            >>>     assert weight.shape[0] == bias.shape[0]
            >>>     assert x.device == weight.device
            >>>
            >>>     return (x @ weight.t()) + bias
            >>>
            >>> # Example 2: an operator with data-dependent output shape
            >>> @custom_op('my_library::custom_nonzero')
            >>> def custom_nonzero(x: Tensor) -> Tensor:
            >>>     ...
            >>>
            >>> @custom_nonzero.impl_abstract()
            >>> def custom_nonzero_abstract(x):
            >>>     # Number of nonzero-elements is data-dependent.
            >>>     # Since we cannot peek at the data in an abstract impl,
            >>>     # we use the ctx object to construct a new symint that
            >>>     # represents the data-dependent size.
            >>>     ctx = torch._custom_op.get_ctx()
            >>>     nnz = ctx.create_unbacked_symint()
            >>>     shape = [x.dim(), nnz]
            >>>     result = x.new_empty(shape, dtype=torch.long)
            >>>     return result
            >>>
            >>> @custom_nonzero.impl(['cpu', 'cuda'])
            >>> def custom_nonzero_impl(x):
            >>>     x_np = to_numpy(x)
            >>>     res = np.stack(np.nonzero(x_np), axis=1)
            >>>     # unbacked symbolic ints in PyTorch must be >= 2, so we
            >>>     # constrain the range to at least 2
            >>>     if res.shape[0] <= 1:
            >>>         raise RuntimeError("not supported")
            >>>     return torch.tensor(res, device=x.device)


        Please see impl_backward for more details.

        WARNING: if you're a user, please do not use this directly
        (instead use the torch._custom_ops APIs).
        Also please see the following for a detailed guide on custom ops.
        https://docs.google.com/document/d/1aGWtgxV3HppuxQAdddyPrs74_aEntpkYt9MalnCKnhk

        In order for the CustomOp to work with autograd, you need to register
        a backward formula. There are two pieces to this:
        1. You must give us a function to specify what to save for backward.
           Call this the "save for backward" function.
        2. You must give us a function that computes gradients. Call this the
           "backward" function.

        Use `impl_save_for_backward` to define a "save for backward" function
        that specifies what gets saved for backward. The function should accept
        two arguments ``(inputs, output)`` and return the quantities to be saved
        for backward.

        During runtime, when you call the CustomOp, PyTorch will invoke the
        "save for backward" function with the inputs and output of the CustomOp.

        Use `impl_backward` to define the "backward" function. The backward
        function must accept ``(ctx, saved, *grads)``:
        - ``ctx`` is a context object where we may provide information
        - ``saved`` is exactly what gets returned from the "save for backward"
          function
        - ``grads`` is one or more gradients. The number of gradients matches
          the number of outputs of the CustomOp.

        The backward function must return a dict that maps the name of
        an input to the CustomOp to its corresponding gradient. All inputs that
        were declared to be Tensors in the CustomOp definition must be accounted
        for in the dict. The gradient may be a Tensor or None.


<END>

<START>



<END>

<START>

__all__ = ['LayerNorm', 'GroupNorm', 'InstanceNorm1d', 'InstanceNorm2d', 'InstanceNorm3d']

from torch.ao.nn.quantized.modules.normalization import LayerNorm
from torch.ao.nn.quantized.modules.normalization import GroupNorm
from torch.ao.nn.quantized.modules.normalization import InstanceNorm1d
from torch.ao.nn.quantized.modules.normalization import InstanceNorm2d
from torch.ao.nn.quantized.modules.normalization import InstanceNorm3d

<END>

<START>
import copy
import functools
import inspect
import itertools
import logging
import os
import sys
import warnings
import weakref
from collections import defaultdict, deque
from contextlib import contextmanager
from dataclasses import dataclass, fields, is_dataclass
from enum import auto, Enum
from typing import Any, Callable, List, Optional, Type

import torch
import torch.distributed as dist
from torch.autograd import Function, Variable
from torch.distributed.algorithms.join import Join, Joinable, JoinHook

from torch.utils._pytree import tree_flatten, tree_unflatten

RPC_AVAILABLE = False
if dist.is_available():
    from torch.distributed.distributed_c10d import (
        _get_default_group,
        _rank_not_in_group,
        ReduceOp,
    )
    from torch.distributed.utils import (
        _alloc_storage,
        _cast_forward_inputs,
        _free_storage,
        _sync_module_states,
        _to_kwargs,
        _verify_param_shape_across_processes,
    )
if torch.distributed.rpc.is_available():
    RPC_AVAILABLE = True
    from torch.distributed.rpc import RRef

from torch._utils import _get_device_index

from ..modules import Module
from .scatter_gather import gather, scatter_kwargs  # noqa: F401

__all__ = ["DistributedDataParallel"]

logger = logging.getLogger(__name__)


@dataclass
class _MixedPrecision:

    param_dtype: Optional[torch.dtype] = None
    reduce_dtype: Optional[torch.dtype] = None
    buffer_dtype: Optional[torch.dtype] = None


def _cast_buffers(mixed_precision_config, root_module):
    for param in root_module.parameters():
        if hasattr(param, "_ddp_ignored") and param._ddp_ignored:
            continue

        if not hasattr(param, "_mp_param"):
            param._mp_param = torch.zeros_like(
                param,
                device=param.device,
                dtype=mixed_precision_config.param_dtype,
                requires_grad=param.requires_grad,
            )
            _free_storage(param._mp_param)
            param._fp_param = param.data


def _tree_flatten_with_rref(output):
    output_is_rref = RPC_AVAILABLE and isinstance(output, RRef)
    if output_is_rref:
        output_tensor_list, treespec = tree_flatten(output.local_value())
    else:
        output_tensor_list, treespec = tree_flatten(output)
    return output_tensor_list, treespec, output_is_rref


def _tree_unflatten_with_rref(output, treespec, output_is_rref):
    output = tree_unflatten(output, treespec)
    if output_is_rref:
        output = RRef(output)
    return output


def _find_tensors(obj):
        assert isinstance(ddp, DistributedDataParallel), (
            "DDP join hook requires passing in a DistributedDataParallel "
            "instance as the state"
        )
        assert ddp.logger is not None
        ddp.logger._set_uneven_input_join()
        self.ddp = ddp
        self.ddp._divide_by_initial_world_size = divide_by_initial_world_size
        super().__init__()

    def main_hook(self):
        self.ddp._sync_final_model(is_last_joiner)


class DistributedDataParallel(Module, Joinable):

    _active_ddp_module = None

    def __init__(
        self,
        module,
        device_ids=None,
        output_device=None,
        dim=0,
        broadcast_buffers=True,
        process_group=None,
        bucket_cap_mb=25,
        find_unused_parameters=False,
        check_reduction=False,
        gradient_as_bucket_view=False,
        static_graph=False,
        delay_all_reduce_named_params=None,
        param_to_hook_all_reduce=None,
        mixed_precision: Optional[_MixedPrecision] = None,
        device_mesh=None,
    ):
        super().__init__()
        Joinable.__init__(self)
        self.logger = None
        if bool(delay_all_reduce_named_params is not None) != bool(
            param_to_hook_all_reduce is not None
        ):
            self._log_and_throw(
                ValueError,
                "delay_all_reduce_named_params and param_to_hook_all_reduce "
                "need to be set at the same time.",
            )

        self._delay_all_reduce_params = []
        if hasattr(module, "_ddp_params_and_buffers_to_ignore"):
            self.parameters_to_ignore = set(module._ddp_params_and_buffers_to_ignore)
        else:
            self.parameters_to_ignore = set()
        if delay_all_reduce_named_params is not None:
            for name, param in delay_all_reduce_named_params:
                self.parameters_to_ignore.add(name)
                self._delay_all_reduce_params.append(param)

        self._module_parameters = [
            p
            for n, p in module.named_parameters()
            if n not in self.parameters_to_ignore
        ]
        if not any(p.requires_grad for p in self._module_parameters):
            if len(self._delay_all_reduce_params):
                logger.info("Delay the AllReduce of all parameters.")
            else:
                self._log_and_throw(
                    RuntimeError,
                    "DistributedDataParallel is not needed when a module "
                    "doesn't have any parameter that requires a gradient.",
                )

        if device_ids is not None and len(device_ids) > 1:
            self._log_and_throw(
                ValueError,
                "device_ids can only be None or contain a single element.",
            )

        self.is_multi_device_module = (
            len({p.device for p in self._module_parameters}) > 1
        )
        distinct_device_types = {
            p.device.type for p in self._module_parameters if p.device is not None
        }
        if len(distinct_device_types) != 1:
            self._log_and_throw(
                ValueError,
                "DistributedDataParallel's input module must be on "
                f"the same type of devices, but input module parameters locate in {distinct_device_types}.",
            )

        self.device_type = next(iter(distinct_device_types))

        if (
            device_ids is None
            or len(device_ids) == 0  # For backward compatibility.
            or self.device_type == "cpu"
            or self.is_multi_device_module
        ):
            if device_ids or output_device:
                self._log_and_throw(
                    ValueError,
                    "DistributedDataParallel device_ids and output_device arguments "
                    "only work with single-device/multiple-device GPU modules or CPU modules, "
                    "but got device_ids {}, output_device {}, and module parameters {}.".format(
                        device_ids,
                        output_device,
                        {p.device for p in self._module_parameters},
                    ),
                )

            self.device_ids = None
            self.output_device = None
        else:
            self.device_ids = [_get_device_index(x, True) for x in device_ids]

            if output_device is None:
                output_device = device_ids[0]

            self.output_device = _get_device_index(output_device, True)

        if process_group and device_mesh is not None:
            raise RuntimeError(
                "Cannot specify both process_group and device_mesh arguments."
            )
        elif process_group is None and device_mesh is None:
            self.process_group = _get_default_group()
        elif device_mesh is None:
            self.process_group = process_group
        else:
            if device_mesh.ndim != 1:
                raise RuntimeError(
                    f"Only 1D device mesh is supported, but got {device_mesh}."
                )
            self.device_mesh = device_mesh
            self.process_group = device_mesh.get_group(mesh_dim=0)

        self.static_graph = False
        self.dim = dim
        self.module = module
        self.device = next(iter(self._module_parameters)).device
        self.broadcast_buffers = broadcast_buffers
        self.find_unused_parameters = find_unused_parameters
        self.require_backward_grad_sync = True
        self.require_forward_param_sync = True
        self.gradient_as_bucket_view = gradient_as_bucket_view
        self.mixed_precision = mixed_precision
        if self.mixed_precision is not None:
            logger.warning("Received mixed precision config %s", self.mixed_precision)

        if check_reduction:
            warnings.warn(
                "The `check_reduction` argument in `DistributedDataParallel` "
                "module is deprecated. Please avoid using it."
            )

        for param in self._module_parameters:
            if isinstance(param, torch.nn.parameter.UninitializedParameter):
                self._log_and_throw(
                    RuntimeError,
                    "Modules with uninitialized parameters can't be used with `DistributedDataParallel`. "
                    "Run a dummy forward pass to correctly initialize the modules",
                )
        self.broadcast_bucket_size = int(250 * 1024 * 1024)

        self.bucket_bytes_cap = int(bucket_cap_mb * 1024 * 1024)
        self.use_side_stream_for_tensor_copies = (
            os.environ.get("PYTORCH_DDP_USE_SIDE_STREAM", "1") == "1"
        )

        self._delay_grad_buffer = None
        self._delay_grad_views: List[torch.Tensor] = []
        self._delay_all_reduce_all_params = False
        if len(self._delay_all_reduce_params) != 0:
            self._register_delay_all_reduce_hook(
                bucket_cap_mb=bucket_cap_mb,
                param_to_hook_all_reduce=param_to_hook_all_reduce,
                device_ids=device_ids,
            )
            if self._delay_all_reduce_all_params:
                return

        parameters, expect_sparse_gradient = self._build_params_for_reducer()
        _verify_param_shape_across_processes(self.process_group, parameters)
        _sync_module_states(
            module=self.module,
            process_group=self.process_group,
            broadcast_bucket_size=self.broadcast_bucket_size,
            src=0,
            params_and_buffers_to_ignore=self.parameters_to_ignore,
            broadcast_buffers=self.broadcast_buffers,
        )
        param_to_name_mapping = self._build_debug_param_to_name_mapping(parameters)

        self._ddp_init_helper(
            parameters,
            expect_sparse_gradient,
            param_to_name_mapping,
            static_graph,
        )
        if self.mixed_precision is not None:
            _setup_mixed_precision_params(self.mixed_precision, self.module)
            _cast_buffers(self.mixed_precision, self.module)
            self._mp_stream = torch.cuda.Stream()
            self._submodule_to_event = defaultdict(deque)  # type: ignore[var-annotated]
            self.module.register_forward_pre_hook(
                self._root_copy_hook, prepend=False, with_kwargs=True
            )
            for module in self.module.modules():
                module.register_forward_pre_hook(
                    self._module_wait_for_copy_hook,
                    prepend=False,
                    with_kwargs=True,
                )
            from torch.distributed.algorithms.ddp_comm_hooks.mixed_precision_hooks import (
                _AllreduceUpcastHookState,
                _reducer_allreduce_and_upcast_hook,
            )

            upcast_hook_state = _AllreduceUpcastHookState(
                ddp_weakref=weakref.ref(self),
                upcast_stream=torch.cuda.Stream(),
            )
            self.register_comm_hook(
                upcast_hook_state,
                _reducer_allreduce_and_upcast_hook,
            )
            self.reducer._set_mixed_precision_param_dtype(  # type: ignore[attr-defined]
                self.mixed_precision.param_dtype
            )

        self._has_rebuilt_buckets = False

        if static_graph:
            self._set_static_graph()

        self._lazy_init_ran = False

    def _delayed_all_reduce_hook(self, grad):
        world_size = dist.get_world_size(self.process_group)

        self._delay_grad_buffer.div_(world_size)  # type: ignore[union-attr]
        _ = dist.all_reduce(
            self._delay_grad_buffer, group=self.process_group, async_op=True
        )
        return grad

    def _register_delay_all_reduce_hook(
        self,
        bucket_cap_mb,
        param_to_hook_all_reduce,
        device_ids,
    ):
        device = torch.device("cpu") if device_ids is None else device_ids[0]
        self._delay_grad_buffer = torch.zeros(
            sum([p.numel() for p in self._delay_all_reduce_params]),
            device=device,
        )

        detached_params = [p.detach() for p in self._delay_all_reduce_params]
        dist._broadcast_coalesced(self.process_group, detached_params, bucket_cap_mb, 0)

        param_to_hook_all_reduce.register_hook(self._delayed_all_reduce_hook)

        offset = 0
        for param in self._delay_all_reduce_params:
            grad_view = self._delay_grad_buffer[offset : (offset + param.numel())].view(
                param.shape
            )
            self._delay_grad_views.append(grad_view)
            offset = offset + param.numel()

        for module_name, module in self.module.named_modules():
            for param_name, param in module.named_parameters(recurse=False):
                if param.requires_grad:
                    full_name = f"{module_name}.{param_name}"
                    if full_name not in self.parameters_to_ignore:
                        return
        self._delay_all_reduce_all_params = True

    def _setup_in_backward_optimizers(self):
        if any(hasattr(p, "_in_backward_optimizers") for p in self._module_parameters):
            torch._C._log_api_usage_once("ddp.optimizer_in_backward")
            param_to_handle_map = (
                dist.optim.apply_optimizer_in_backward.param_to_optim_hook_handle_map
            )
            for p in self._module_parameters:
                for handle in param_to_handle_map.get(p, []):
                    handle.remove()

            ddp_weakref = weakref.ref(self)
            from torch.distributed.algorithms.ddp_comm_hooks.optimizer_overlap_hooks import (
                _apply_optim_in_backward_hook,
            )

            self.register_comm_hook(
                ddp_weakref,
                _apply_optim_in_backward_hook(
                    gradient_is_bucket_view=self.gradient_as_bucket_view
                ),
            )

            self.reducer._set_optimizer_in_backward()  # type: ignore[attr-defined]

    def _fire_reducer_autograd_hook(self, idx, *unused):
        self.reducer._autograd_hook(idx)  # type: ignore[attr-defined]

    def _root_copy_hook(self, *args: Any, **kwargs: Any) -> None:
        self._submodule_to_event = defaultdict(deque)  # type: ignore[var-annotated]
        with torch.cuda.stream(self._mp_stream):
            for submodule in self.module.modules():
                for param in submodule.parameters(recurse=False):
                    if hasattr(param, "_ddp_ignored") and param._ddp_ignored:
                        continue
                    _alloc_storage(param._mp_param, param.size())
                    with torch.no_grad():
                        param._mp_param.copy_(param.data)
                        if param.grad is not None:
                            param.grad.data = param.grad.to(
                                self.mixed_precision.param_dtype  # type: ignore[union-attr]
                            )
                    param.data = param._mp_param
                copy_event = torch.cuda.Event()
                copy_event.record()
                self._submodule_to_event[submodule].append(copy_event)

    def _module_wait_for_copy_hook(
        self,
        module,
        *args: Any,
        **kwargs: Any,
    ) -> None:
        DDP init helper function to manage parameters, grad hooks, logging, and SyncBatchNorm.

        Initialization helper function that does the following:
        (1) bucketing the parameters for reductions
        (2) resetting the bucketing states
        (3) registering the grad hooks
        (4) Logging construction-time DDP logging data
        (5) passing a handle of DDP to SyncBatchNorm Layer
        Assign self.module.named_buffers to self.modules_buffers.

        Assigns module buffers to self.modules_buffers which are then used to
        broadcast across ranks when broadcast_buffers=True. Note that this
        must be called every time buffers need to be synced because buffers can
        be reassigned by user module,
        see https://github.com/pytorch/pytorch/issues/63916.

        def model_parameters(m):
            ps = (
                m._former_parameters.values()
                if hasattr(m, "_former_parameters")
                else m.parameters(recurse=False)
            )
            yield from ps

        for mod in m.modules() if recurse else [m]:
            yield from model_parameters(mod)

    def _check_default_group(self):
        pickle_not_supported = False
        try:
            if self.process_group != _get_default_group():
                pickle_not_supported = True
        except RuntimeError:
            pickle_not_supported = True

        if pickle_not_supported:
            self._log_and_throw(
                RuntimeError,
                "DDP Pickling/Unpickling are only supported "
                "when using DDP with the default process "
                "group. That is, when you have called "
                "init_process_group and have not passed "
                "process_group argument to DDP constructor",
            )

    @contextmanager
    def no_sync(self):
        old_require_backward_grad_sync = self.require_backward_grad_sync
        self.require_backward_grad_sync = False
        try:
            yield
        finally:
            self.require_backward_grad_sync = old_require_backward_grad_sync

    @classmethod
    def _get_active_ddp_module(cls):
        Context manager for training with uneven inputs across processes in DDP.

        This context manager will keep track of already-joined DDP processes,
        and "shadow" the forward and backward passes by inserting collective
        communication operations to match with the ones created by non-joined
        DDP processes. This will ensure each collective call has a corresponding
        call by already-joined DDP processes, preventing hangs or errors that
        would otherwise happen when training with uneven inputs across
        processes. Alternatively, if the flag ``throw_on_early_termination`` is
        specified to be ``True``, all trainers will throw an error once one rank
        runs out of inputs, allowing these errors to be caught and handled
        according to application logic.

        Once all DDP processes have joined, the context manager will broadcast
        the model corresponding to the last joined process to all processes to
        ensure the model is the same across all processes
        (which is guaranteed by DDP).

        To use this to enable training with uneven inputs across processes,
        simply wrap this context manager around your training loop. No further
        modifications to the model or data loading is required.

        .. warning::
            If the model or training loop this context manager is wrapped around
            has additional distributed collective operations, such as
            ``SyncBatchNorm`` in the model's forward pass, then the flag
            ``throw_on_early_termination`` must be enabled. This is because this
            context manager is not aware of non-DDP collective communication.
            This flag will cause all ranks to throw when any one rank
            exhausts inputs, allowing these errors to be caught and recovered
            from across all ranks.

        Args:
            divide_by_initial_world_size (bool): If ``True``, will divide
                gradients by the initial ``world_size`` DDP training was launched
                with. If ``False``, will compute the effective world size
                (number of ranks that have not depleted their inputs yet) and
                divide gradients by that during allreduce. Set
                ``divide_by_initial_world_size=True`` to ensure every input
                sample including the uneven inputs have equal weight in terms of
                how much they contribute to the global gradient. This is
                achieved by always dividing the gradient by the initial
                ``world_size`` even when we encounter uneven inputs. If you set
                this to ``False``, we divide the gradient by the remaining
                number of nodes. This ensures parity with training on a smaller
                ``world_size`` although it also means the uneven inputs would
                contribute more towards the global gradient. Typically, you
                would want to set this to ``True`` for cases where the last few
                inputs of your training job are uneven. In extreme cases, where
                there is a large discrepancy in the number of inputs, setting
                this to ``False`` might provide better results.
            enable (bool): Whether to enable uneven input detection or not. Pass
                in ``enable=False`` to disable in cases where you know that
                inputs are even across participating processes. Default is
                ``True``.
            throw_on_early_termination (bool): Whether to throw an error
                or continue training when at least one rank has exhausted
                inputs. If ``True``, will throw upon the first rank reaching end
                of data. If ``False``, will continue training with a smaller
                effective world size until all ranks are joined. Note that if
                this flag is specified, then the flag
                ``divide_by_initial_world_size`` would be ignored. Default
                is ``False``.


        Example::

            >>> # xdoctest: +SKIP("Distributed")
            >>> import torch
            >>> import torch.distributed as dist
            >>> import os
            >>> import torch.multiprocessing as mp
            >>> import torch.nn as nn
            >>> # On each spawned worker
            >>> def worker(rank):
            >>>     dist.init_process_group("nccl", rank=rank, world_size=2)
            >>>     torch.cuda.set_device(rank)
            >>>     model = nn.Linear(1, 1, bias=False).to(rank)
            >>>     model = torch.nn.parallel.DistributedDataParallel(
            >>>         model, device_ids=[rank], output_device=rank
            >>>     )
            >>>     # Rank 1 gets one more input than rank 0.
            >>>     inputs = [torch.tensor([1]).float() for _ in range(10 + rank)]
            >>>     with model.join():
            >>>         for _ in range(5):
            >>>             for inp in inputs:
            >>>                 loss = model(inp).sum()
            >>>                 loss.backward()
            >>>     # Without the join() API, the below synchronization will hang
            >>>     # blocking for rank 1's allreduce to complete.
            >>>     torch.cuda.synchronize(device=rank)
        DDP join hook enables training on uneven inputs by mirroring communications in forward and backward passes.

        Arguments:
            kwargs (dict): a :class:`dict` containing any keyword arguments
                to modify the behavior of the join hook at run time; all
                :class:`Joinable` instances sharing the same join context
                manager are forwarded the same value for ``kwargs``.

        The hook supports the following keyword arguments:
            divide_by_initial_world_size (bool, optional):
                If ``True``, then gradients are divided by the initial world
                size that DDP was launched with.
                If ``False``, then gradients are divided by the effective world
                size (i.e. the number of non-joined processes), meaning that
                the uneven inputs contribute more toward the global gradient.
                Typically, this should be set to ``True`` if the degree of
                unevenness is small but can be set to ``False`` in extreme
                cases for possibly better results.
                Default is ``True``.
        Allow custom registration of hooks that define how buffer are synchronized across ranks.

        The hook takes in an optional state and is passed in a Dict[str, Tensor]
        corresponding to buffer names and the buffers, and can run arbitrary reductions
        on buffers as opposed to DDP's default broadcast from rank 0. This is useful for
        example if a counter needs to be summed or averaged across ranks every iteration.

        Args:
            state (Any): Optional state that is passed to the hook.
            hook (Callable): Callable with the following signature:
                         ``hook(state: object, bucket: dist.GradBucket) -> torch.futures.Future[torch.Tensor]``
            comm_hook_location (_BufferCommHookLocation): Enum value indicating
                            where to run the hook.
                            _BufferCommHookLocation.PRE_FORWARD means that the
                            hook will run _before_ the forward pass, and
                            _BufferCommHookLocation.POST_FORWARD means that the
                            hook will run _after_ the forward pass.

            NOTE: To maximize performance, users can return a
                List[torch.futures.Future] from their hook, and DDP will
                install and await these hooks appropriately at the end of
                the backward pass. This will ensure all buffers are
                synchronized by the end of the backward pass. If this
                setting is used, it is recommended to pass
                comm_hook_location=_BufferCommHookLocation.POST_FORWARD,
                which will trigger the hook after the forward pass.
                If _BufferCommHookLocation.PRE_FORWARD is used, users must
                ensure appropriate synchronization when manipulating GPU
                buffers in the forward pass.
        Register communication hook for user-defined DDP aggregation of gradients across multiple workers.

        This hook would be very useful for researchers to try out new ideas. For
        example, this hook can be used to implement several algorithms like GossipGrad
        and gradient compression which involve different communication strategies for
        parameter syncs while running Distributed DataParallel training.

        Args:
            state (object): Passed to the hook to maintain any state information during the training process.
                            Examples include error feedback in gradient compression,
                            peers to communicate with next in GossipGrad, etc.

                            It is locally stored by each worker
                            and shared by all the gradient tensors on the worker.
            hook (Callable): Callable with the following signature:
                             ``hook(state: object, bucket: dist.GradBucket) -> torch.futures.Future[torch.Tensor]``:

                             This function is called once the bucket is ready. The
                             hook can perform whatever processing is needed and return
                             a Future indicating completion of any async work (ex: allreduce).
                             If the hook doesn't perform any communication, it still
                             must return a completed Future. The Future should hold the
                             new value of grad bucket's tensors. Once a bucket is ready,
                             c10d reducer would call this hook and use the tensors returned
                             by the Future and copy grads to individual parameters.
                             Note that the future's return type must be a single tensor.

                             We also provide an API called ``get_future`` to retrieve a
                             Future associated with the completion of ``c10d.ProcessGroup.Work``.
                             ``get_future`` is currently supported for NCCL and also supported for most
                             operations on GLOO and MPI, except for peer to peer operations (send/recv).

        .. warning ::
            Grad bucket's tensors will not be predivided by world_size. User is responsible
            to divide by the world_size in case of operations like allreduce.

        .. warning ::
            DDP communication hook can only be registered once and should be registered
            before calling backward.

        .. warning ::
            The Future object that hook returns should contain a single tensor
            that has the same shape with the tensors inside grad bucket.

        .. warning ::
            ``get_future`` API supports NCCL, and partially GLOO and MPI backends (no support
            for peer-to-peer operations like send/recv) and will return a ``torch.futures.Future``.

        Example::
            Below is an example of a noop hook that returns the same tensor.

            >>> # xdoctest: +SKIP('undefined name')
            >>> def noop(state: object, bucket: dist.GradBucket) -> torch.futures.Future[torch.Tensor]:
            >>>     fut = torch.futures.Future()
            >>>     fut.set_result(bucket.buffer())
            >>>     return fut
            >>> ddp.register_comm_hook(state=None, hook=noop)

        Example::
            Below is an example of a Parallel SGD algorithm where gradients are encoded before
            allreduce, and then decoded after allreduce.

            >>> # xdoctest: +SKIP('undefined name')
            >>> def encode_and_decode(state: object, bucket: dist.GradBucket) -> torch.futures.Future[torch.Tensor]:
            >>>     encoded_tensor = encode(bucket.buffer())  # encode gradients
            >>>     fut = torch.distributed.all_reduce(encoded_tensor).get_future()
            >>>     # Define the then callback to decode.
            >>>     def decode(fut):
            >>>         decoded_tensor = decode(fut.value()[0])  # decode gradients
            >>>         return decoded_tensor
            >>>     return fut.then(decode)
            >>> ddp.register_comm_hook(state=None, hook=encode_and_decode)
        Register a built-in communication hook that specifies how DDP aggregates gradients across multiple workers.

        The built-in hooks aim to provide efficient C++ implementations for certain hooks,
        which might not be as efficient if implemented in Python using a Python communication hook.

        Args:
            comm_hook_type (dist.BuiltinCommHookType): type of communication hook, such as ALLREDUCE, FP16_COMPRESS, etc.

        .. warning ::
            DDP communication hook can only be registered once and should be registered
            before calling backward.

        Example::
            Below is an example of a FP16 compression where gradients are
            compressed into 16-bit floating-point numbers before allreduce, and
            then decompressed after allreduce.

            >>> # xdoctest: +SKIP('undefined name')
            >>> ddp._register_builtin_comm_hook(dist.BuiltinCommHookType.FP16_COMPRESS)

        Register an optimizer in DDP to optimize parameter immediately after its gradient reduction.

        Registers an optimizer with DDP such that the optimization for a
        parameter will run immediately when that parameter's gradient is
        finished with reduction, instead of waiting for all parameters'
        gradients to finish reduction. This can result in a training speedup
        depending on your workload since the optimizer can run while gradient
        reduction for other parameters are still ongoing. In addition, this has
        the potential to reduce peak memory consumption during training, as it
        only needs to load the per-parameter optimizer states of a single
        parameter at a time, instead of loading all per-parameter optimizer
        states at once.

        Args:
            optim (Type): a ``torch.optim.Optimizer`` class to be registered
            as a fused optimizer.
            *args (Sequence[Any]): Arguments to forward to `optim`.
            optim_params (Optional[Iterable[torch.Tensor]]): Set of parameters
            to optimize, similar to `params` argument of traditional `torch.optim`
            Optimizers. If this is omitted, all DDP model parameters will be
            optimized.
            **kwargs: (Dict[str, Any]): Keyword arguments to forward to `optim`.

        .. warning ::
            _register_fused_optim should only be called once on a DDP instance,
            and registering multiple fused optimizers for the same DDP model
            is not currently supported. Please ping
            https://github.com/pytorch/pytorch/issues/71595 if this is necessary
            for your use case.

        .. warning ::
            _register_fused_optim and register_comm_hook currently do not
            compose together, meaning that custom DDP communication hooks are
            not supported with overlapped optimizers. Please ping
            https://github.com/pytorch/pytorch/issues/71595 if this is necessary
            for your use case.

        .. warning ::
            Gradient accumulation and DDP `no_sync` are currently not supported
            with overlapped optimizer. Please ping
            https://github.com/pytorch/pytorch/issues/71595 if this is necessary
            for your use case.

        Example::

            >>> # xdoctest: +SKIP("No rendezvous handler")
            >>> torch.distributed.init_process_group(backend='nccl', world_size=4, init_method='...')
            >>> net = torch.nn.parallel.DistributedDataParallel(model, pg)
            >>> lr = 1e-2
            >>> betas = (0.9, 0.99)
            >>> eps = 1e-6
            >>> net._register_fused_optim(torch.optim.Adam, lr, betas=betas, eps=eps)
            >>> # Example with subset of parameters
            >>> params_to_opt = [list(net.parameters())[0]]
            >>> net._register_fused_optim(
            ...   torch.optim.Adam, lr, optim_params=params_to_opt,  betas=betas, eps=eps
            ... )
        Broadcasts buffers from rank 0 to rest of workers.

        If bufs, bucket_size are None, default values self.modules_buffers
        and self.broadcast_bucket_size are used instead.
        for param in (
            module.parameters() if not named_params else module.named_parameters()
        ):
            if not hasattr(param, "_ddp_ignored"):
                yield param

    @staticmethod
    def _set_params_and_buffers_to_ignore_for_model(
        module, params_and_buffers_to_ignore
    ):
        module._ddp_params_and_buffers_to_ignore = params_and_buffers_to_ignore
        for name, param in module.named_parameters():
            if name in params_and_buffers_to_ignore:
                param._ddp_ignored = True
        for name, buffer in module.named_buffers():
            if name in params_and_buffers_to_ignore:
                buffer._ddp_ignored = True

    def _get_ddp_logging_data(self):
        assert self.logger is not None
        ddp_logging_data = self.logger._get_ddp_logging_data()
        return {**ddp_logging_data.strs_map, **ddp_logging_data.ints_map}

    def _set_ddp_runtime_logging_sample_rate(self, sample_rate):
        if sample_rate < 1:
            self._log_and_throw(
                ValueError,
                "DDP runtime logging sample rate should be equal or greater than 1",
            )
        self.reducer._set_ddp_runtime_logging_sample_rate(sample_rate)

    def _set_static_graph(self):
        if self.static_graph:
            warnings.warn(
                "You've set static_graph to be True, no need to set it again."
            )
            return
        self.static_graph = True
        self._static_graph_delay_allreduce_enqueued = False
        self.reducer._set_static_graph()
        assert self.logger is not None
        self.logger._set_static_graph()
        if self.find_unused_parameters:
            warnings.warn(
                "You passed find_unused_parameters=true to DistributedDataParallel, "
                "`_set_static_graph` will detect unused parameters automatically, so "
                "you do not need to set find_unused_parameters=true, just be sure these "
                "unused parameters will not change during training loop while calling "
                "`_set_static_graph`."
            )

    def _remove_autograd_hooks(self):
        Check if the reducer has processed all buckets and finalized the backward appropriately.

        It is useful to call this method after calling .backward() in your training loop
        in order to avoid subsequent hard to debug errors down the road due to the
        reducer not finalizing backward.
        Dynamically updates the process group for DDP so that we can shrink/expand DDP
        world size without having to reinitialize DDP.

        NOTE: If you are using custom communications hooks via, register_comm_hook,
        you need to update the process groups for those hooks separately.

<END>

<START>
from abc import abstractmethod
import tempfile
import unittest

from copy import deepcopy
from functools import reduce, partial
from itertools import product
from operator import mul


import torch
import torch.cuda
import torch.nn as nn
import torch.nn.functional as F
from torch.nn import _reduction as _Reduction
from torch.testing._internal.common_utils import TestCase, to_gpu, freeze_rng_state, is_iterable, \
    gradcheck, gradgradcheck, set_default_dtype
from torch.testing._internal.common_cuda import TEST_CUDA, SM90OrLater
from torch.autograd.gradcheck import _get_numerical_jacobian, _iter_tensors
from torch.autograd import Variable
from torch.types import _TensorOrTensors
import torch.backends.cudnn

from typing import Dict, Callable, Tuple, List, Sequence, Union, Any

TemporaryFile = tempfile.TemporaryFile
PRECISION = 1e-5


def get_reduction(m):
    result = getattr(m, 'reduction', None)
    if result is None:
        result = _Reduction.legacy_get_string(getattr(m, 'sizeAverage', None), True, emit_warning=False)
    assert result is not None
    return result


def get_weight(m):
    result = getattr(m, 'weight', None)
    if result is not None:
        return result
    return getattr(m, 'weights', None)



module_tests = [
    dict(
        module_name='Linear',
        constructor_args=(10, 8),
        cpp_constructor_args='torch::nn::LinearOptions(10, 8)',
        input_size=(4, 10),
        reference_fn=lambda i, p, _: torch.mm(i, p[0].t()) + p[1].view(1, -1).expand(4, 8),
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Linear',
        constructor_args=(10, 8, False),
        cpp_constructor_args='torch::nn::LinearOptions(10, 8).bias(false)',
        input_size=(4, 10),
        desc='no_bias',
        reference_fn=lambda i, p, _: torch.mm(i, p[0].t()),
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        module_name='RReLU',
        input_size=(1, 2, 2),
        test_cuda=False,
        default_dtype=torch.double,
    ),
    dict(
        module_name='RReLU',
        constructor_args=(0.1, 0.9),
        cpp_constructor_args='torch::nn::RReLUOptions().lower(0.1).upper(0.9)',
        input_size=(4, 4, 5),
        desc='with_up_down',
        test_cuda=False,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Flatten',
        input_size=(2, 3, 4, 5),
        reference_fn=lambda i, *_: torch.flatten(i, 1),
        default_dtype=torch.double,
    ),
    dict(
        module_name='CrossMapLRN2d',
        constructor_args=(5, 5e-3, 1e-3, 2),
        cpp_constructor_args='torch::nn::CrossMapLRN2dOptions(5).alpha(5e-3).beta(1e-3).k(2)',
        input_size=(2, 3, 6, 6),
        check_gradgrad=False,
        check_batched_grad=False,
        default_dtype=torch.double,
    ),
]


def _rand_tensor_non_equal(*size):
    total = reduce(mul, size, 1)
    return torch.randperm(total).view(*size).double()


def wrap_functional(fn, **kwargs):
    class FunctionalModule(nn.Module):
        def forward(self, *args):
            return fn(*args, **kwargs)
    return FunctionalModule


def poissonnllloss_no_reduce_test():
    t = torch.randn(10, 10)
    return dict(
        fullname='PoissonNLLLoss_no_reduce',
        constructor=wrap_functional(
            lambda i: F.poisson_nll_loss(i, t.type_as(i), reduction='none')),
        cpp_function_call='F::poisson_nll_loss('
                          'i, t.to(i.options()), F::PoissonNLLLossFuncOptions().reduction(torch::kNone))',
        input_fn=lambda: torch.rand(10, 10),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_: i.exp() - t.mul(i),
        pickle=False,
        default_dtype=torch.double)


def bceloss_no_reduce_test():
    t = Variable(torch.randn(15, 10).gt(0).to(torch.double))
    return dict(
        fullname='BCELoss_no_reduce',
        constructor=wrap_functional(
            lambda i: F.binary_cross_entropy(i, t.type_as(i), reduction='none')),
        cpp_function_call='F::binary_cross_entropy('
                          'i, t.to(i.options()), F::BinaryCrossEntropyFuncOptions().reduction(torch::kNone))',
        input_fn=lambda: torch.rand(15, 10).clamp_(2.8e-2, 1 - 2.8e-2),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_: -(t * i.log() + (1 - t) * (1 - i).log()),
        pickle=False,
        precision=7e-4,
        default_dtype=torch.double)


def bceloss_no_reduce_scalar_test():
    t = torch.randn(()).gt(0).to(torch.double)
    return dict(
        fullname='BCELoss_no_reduce_scalar',
        constructor=wrap_functional(
            lambda i: F.binary_cross_entropy(i, t.type_as(i), reduction='none')),
        cpp_function_call='F::binary_cross_entropy('
                          'i, t.to(i.options()), F::BinaryCrossEntropyFuncOptions().reduction(torch::kNone))',
        input_fn=lambda: torch.rand(()).clamp_(2.8e-2, 1 - 2.8e-2),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_: -(t * i.log() + (1 - t) * (1 - i).log()),
        pickle=False,
        default_dtype=torch.double)


def bceloss_weights_no_reduce_test():
    t = Variable(torch.randn(15, 10, dtype=torch.double).gt(0).to(torch.double))
    weights = torch.rand(10, dtype=torch.double)
    return dict(
        fullname='BCELoss_weights_no_reduce',
        constructor=wrap_functional(
            lambda i: F.binary_cross_entropy(i, t.type_as(i),
                                             weight=weights.type_as(i), reduction='none')),
        cpp_function_call='F::binary_cross_entropy('
                          'i, t.to(i.options()), '
                          'F::BinaryCrossEntropyFuncOptions().weight(weights.to(i.options())).reduction(torch::kNone))',
        input_fn=lambda: torch.rand(15, 10).clamp_(2.8e-2, 1 - 2.8e-2),
        cpp_var_map={'i': '_get_input()', 't': t, 'weights': weights},
        reference_fn=lambda i, p, m: -(t * i.log() + (1 - t) * (1 - i).log()) * weights,
        pickle=False,
        precision=3e-4,
        default_dtype=torch.double,
    )


def bceloss_weights_no_reduce_scalar_test():
    t = torch.randn(()).gt(0).to(torch.double)
    weights = torch.rand((), dtype=torch.double)
    return dict(
        fullname='BCELoss_weights_no_reduce_scalar',
        constructor=wrap_functional(
            lambda i: F.binary_cross_entropy(i, t.type_as(i),
                                             weight=weights.type_as(i), reduction='none')),
        cpp_var_map={'i': '_get_input()', 't': t, 'weights': weights},
        input_fn=lambda: torch.rand(()).clamp_(2.8e-2, 1 - 2.8e-2),
        reference_fn=lambda i, *_: -(t * i.log() + (1 - t) * (1 - i).log()) * weights,
        pickle=False,
        default_dtype=torch.double,
    )


def bce_with_logistic_legacy_enum_test():
    t = Variable(torch.randn(15, 10).gt(0).to(torch.double))
    sigmoid = nn.Sigmoid()
    return dict(
        fullname='BCEWithLogitsLoss_legacy_enum',
        constructor=wrap_functional(
            lambda i: F.binary_cross_entropy_with_logits(i, t.type_as(i), reduce=False)),
        input_fn=lambda: torch.rand(15, 10).clamp_(2.8e-2, 1 - 2.8e-2),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_: -(t * sigmoid(i).log() + (1 - t) * (1 - sigmoid(i)).log()),
        check_gradgrad=False,
        pickle=False,
        default_dtype=torch.double,
    )


def bce_with_logistic_no_reduce_test():
    t = Variable(torch.randn(15, 10).gt(0).to(torch.double))
    sigmoid = nn.Sigmoid()
    return dict(
        fullname='BCEWithLogitsLoss_no_reduce',
        constructor=wrap_functional(
            lambda i: F.binary_cross_entropy_with_logits(i, t.type_as(i), reduction='none')),
        input_fn=lambda: torch.rand(15, 10).clamp_(2.8e-2, 1 - 2.8e-2),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_: -(t * sigmoid(i).log() + (1 - t) * (1 - sigmoid(i)).log()),
        check_gradgrad=False,
        pickle=False,
        default_dtype=torch.double,
    )


def bce_with_logistic_no_reduce_scalar_test():
    t = torch.randn(()).gt(0).to(torch.double)
    sigmoid = nn.Sigmoid()
    return dict(
        fullname='BCEWithLogitsLoss_no_reduce_scalar',
        constructor=wrap_functional(
            lambda i: F.binary_cross_entropy_with_logits(i, t.type_as(i), reduction='none')),
        input_fn=lambda: torch.rand(()).clamp_(2.8e-2, 1 - 2.8e-2),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_: -(t * sigmoid(i).log() + (1 - t) * (1 - sigmoid(i)).log()),
        check_gradgrad=False,
        pickle=False,
        default_dtype=torch.double,
    )


def kldivloss_with_target_no_reduce_test():
    t = torch.rand(10, 10, dtype=torch.double)
    return dict(
        fullname='KLDivLoss_with_target_no_reduce',
        constructor=wrap_functional(
            lambda i: F.kl_div(i, t.type_as(i), reduction='none')),
        cpp_function_call='F::kl_div(i, t.to(i.options()), F::KLDivFuncOptions().reduction(torch::kNone))',
        input_fn=lambda: torch.rand(10, 10).log(),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['KLDivLoss'](i, t.type_as(i), reduction='none'),
        supports_forward_ad=True,
        pickle=False,
        default_dtype=torch.double)


def kldivloss_no_reduce_test():
    t = torch.rand(10, 10, dtype=torch.double)
    return dict(
        fullname='KLDivLoss_no_reduce',
        constructor=wrap_functional(
            lambda i: F.kl_div(i, t.type_as(i), reduction='none')),
        cpp_function_call='F::kl_div(i, t.to(i.options()), F::KLDivFuncOptions().reduction(torch::kNone))',
        input_fn=lambda: torch.rand(10, 10).log(),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['KLDivLoss'](i, t.type_as(i), reduction='none'),
        supports_forward_ad=True,
        pickle=False,
        default_dtype=torch.double,
    )


def kldivloss_no_reduce_scalar_test():
    t = torch.rand((), dtype=torch.double)
    return dict(
        fullname='KLDivLoss_no_reduce_scalar',
        constructor=wrap_functional(
            lambda i: F.kl_div(i, t.type_as(i), reduction='none')),
        cpp_function_call='F::kl_div(i, t.to(i.options()), F::KLDivFuncOptions().reduction(torch::kNone))',
        input_fn=lambda: torch.rand(()).log(),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['KLDivLoss'](i, t.type_as(i), reduction='none'),
        supports_forward_ad=True,
        pickle=False,
        default_dtype=torch.double)


def kldivloss_with_log_target_no_reduce_test():
    t = torch.rand(10, 10, dtype=torch.double).log()
    return dict(
        fullname='KLDivLoss_with_log_target_no_reduce',
        constructor=wrap_functional(
            lambda i: F.kl_div(i, t.type_as(i), reduction='none', log_target=True)),
        cpp_function_call='F::kl_div(i, t.to(i.options()), F::KLDivFuncOptions().reduction(torch::kNone).log_target(true))',
        input_fn=lambda: torch.rand(10, 10).log(),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['KLDivLoss_log_target'](i, t.type_as(i), reduction='none'),
        supports_forward_ad=True,
        pickle=False,
        default_dtype=torch.double)


def kldivloss_no_reduce_log_target_test():
    t = torch.rand(10, 10, dtype=torch.double).log()
    return dict(
        fullname='KLDivLoss_no_reduce_log_target',
        constructor=wrap_functional(
            lambda i: F.kl_div(i, t.type_as(i), reduction='none', log_target=True)),
        cpp_function_call='F::kl_div(i, t.to(i.options()), F::KLDivFuncOptions().reduction(torch::kNone).log_target(true))',
        input_fn=lambda: torch.rand(10, 10).log(),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['KLDivLoss_log_target'](i, t.type_as(i), reduction='none'),
        supports_forward_ad=True,
        pickle=False,
        default_dtype=torch.double,
    )


def kldivloss_no_reduce_scalar_log_target_test():
    t = torch.rand((), dtype=torch.double).log()
    return dict(
        fullname='KLDivLoss_no_reduce_scalar_log_target',
        constructor=wrap_functional(
            lambda i: F.kl_div(i, t.type_as(i), reduction='none', log_target=True)),
        cpp_function_call='F::kl_div(i, t.to(i.options()), F::KLDivFuncOptions().reduction(torch::kNone).log_target(true))',
        input_fn=lambda: torch.rand(()).log(),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['KLDivLoss_log_target'](i, t.type_as(i), reduction='none'),
        supports_forward_ad=True,
        pickle=False,
        default_dtype=torch.double)


def l1loss_no_reduce_test():
    t = torch.randn(2, 3, 4, dtype=torch.double)
    return dict(
        fullname='L1Loss_no_reduce',
        constructor=wrap_functional(
            lambda i: F.l1_loss(i, t.type_as(i), reduction='none')),
        cpp_function_call='F::l1_loss(i, t.to(i.options()), F::L1LossFuncOptions().reduction(torch::kNone))',
        input_fn=lambda: torch.randn(2, 3, 4),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_: (i - t.type_as(i)).abs(),
        supports_forward_ad=True,
        pickle=False,
        default_dtype=torch.double)


def l1loss_no_reduce_complex_test():
    t = torch.randn(2, 3, 4, dtype=torch.cdouble)
    return dict(
        fullname='L1Loss_no_reduce_complex',
        constructor=wrap_functional(
            lambda i: F.l1_loss(i, t.type_as(i), reduction='none')),
        cpp_function_call='F::l1_loss(i, t.to(i.options()), F::L1LossFuncOptions().reduction(torch::kNone))',
        input_fn=lambda: torch.randn(2, 3, 4, dtype=torch.cdouble),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_: (i - t.type_as(i)).abs(),
        supports_forward_ad=True,
        pickle=False)


def l1loss_no_reduce_scalar_test():
    t = torch.randn((), dtype=torch.double)
    return dict(
        fullname='L1Loss_no_reduce_scalar',
        constructor=wrap_functional(
            lambda i: F.l1_loss(i, t.type_as(i), reduction='none')),
        cpp_function_call='F::l1_loss(i, t.to(i.options()), F::L1LossFuncOptions().reduction(torch::kNone))',
        input_fn=lambda: torch.randn(()),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_: (i - t.type_as(i)).abs(),
        supports_forward_ad=True,
        pickle=False,
        default_dtype=torch.double)


def mseloss_no_reduce_test():
    input_size = (2, 3, 4, 5)
    target = torch.randn(*input_size, dtype=torch.double)
    return dict(
        fullname='MSELoss_no_reduce',
        constructor=wrap_functional(
            lambda i: F.mse_loss(i, target.type_as(i), reduction='none')),
        cpp_function_call='F::mse_loss(i, target.to(i.options()), F::MSELossFuncOptions().reduction(torch::kNone))',
        input_size=input_size,
        cpp_var_map={'i': '_get_input()', 'target': target},
        reference_fn=lambda i, *_: (i - target).pow(2),
        supports_forward_ad=True,
        pickle=False,
        default_dtype=torch.double)


def mseloss_no_reduce_scalar_test():
    input_size = ()
    target = torch.randn(input_size, dtype=torch.double)
    return dict(
        fullname='MSELoss_no_reduce_scalar',
        constructor=wrap_functional(
            lambda i: F.mse_loss(i, target.type_as(i), reduction='none')),
        cpp_function_call='F::mse_loss(i, target.to(i.options()), F::MSELossFuncOptions().reduction(torch::kNone))',
        input_size=input_size,
        cpp_var_map={'i': '_get_input()', 'target': target},
        reference_fn=lambda i, *_: (i - target).pow(2),
        supports_forward_ad=True,
        pickle=False,
        default_dtype=torch.double)


def nllloss_no_reduce_test():
    t = Variable(torch.empty(15).uniform_().mul(10).floor().long())
    kwargs = {'reduction': 'none'}
    return dict(
        fullname='NLLLoss_no_reduce',
        constructor=wrap_functional(
            lambda i: F.nll_loss(i, t.type_as(i).long(), reduction=kwargs['reduction'])),
        input_fn=lambda: torch.rand(15, 10).log(),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['NLLLoss'](i, t.type_as(i).long(), **kwargs),
        pickle=False,
        default_dtype=torch.double)


def nllloss_no_reduce_ignore_index_test():
    t = Variable(torch.empty(15).uniform_().mul(10).floor().long())
    kwargs: Dict[str, Union[int, str]] = {'ignore_index': 2, 'reduction': 'none'}
    return dict(
        fullname='NLLLoss_no_reduce_ignore_index',
        constructor=wrap_functional(
            lambda i: F.nll_loss(i, t.type_as(i).long(), ignore_index=int(kwargs['ignore_index']),
                                 reduction=str(kwargs['reduction']))),
        input_fn=lambda: torch.rand(15, 10).log(),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['NLLLoss'](i, t.type_as(i).long(), **kwargs),
        pickle=False,
        default_dtype=torch.double)


def nllloss_no_reduce_weights_test():
    t = Variable(torch.empty(15).uniform_().mul(10).floor().long())
    weight = torch.rand(10)

    def kwargs(i):
        return {'weight': weight.type_as(i), 'reduction': 'none'}

    return dict(
        fullname='NLLLoss_no_reduce_weights',
        constructor=wrap_functional(
            lambda i: F.nll_loss(i, t.type_as(i).long(), **kwargs(i))),
        input_fn=lambda: torch.rand(15, 10).add(1e-2).log(),
        cpp_var_map={'i': '_get_input()', 't': t, 'weight': weight},
        reference_fn=lambda i, *_:
            loss_reference_fns['NLLLoss'](i, t.type_as(i).long(), **kwargs(i)),
        pickle=False,
        default_dtype=torch.double)


def nllloss_no_reduce_weights_ignore_index_test():
    t = Variable(torch.empty(15).uniform_().mul(10).floor().long())
    weight = torch.rand(10)

    def kwargs(i):
        return {'weight': weight.type_as(i), 'reduction': 'none',
                'ignore_index': 2}

    return dict(
        fullname='NLLLoss_no_reduce_weights_ignore_index',
        constructor=wrap_functional(
            lambda i: F.nll_loss(i, t.type_as(i).long(), **kwargs(i.data))),
        input_fn=lambda: torch.rand(15, 10).add(1e-2).log(),
        cpp_var_map={'i': '_get_input()', 't': t, 'weight': weight},
        reference_fn=lambda i, *_:
            loss_reference_fns['NLLLoss'](i, t.type_as(i).long(), **kwargs(i)),
        pickle=False,
        default_dtype=torch.double)


def nllloss_no_reduce_weights_ignore_index_neg_test():
    t = Variable(torch.empty(15).uniform_().mul(10).floor().long())
    weight = torch.rand(10)

    def kwargs(i):
        return {'weight': weight.type_as(i), 'reduction': 'none',
                'ignore_index': -1}

    return dict(
        fullname='NLLLoss_no_reduce_weights_ignore_index_neg',
        constructor=wrap_functional(
            lambda i: F.nll_loss(i, t.type_as(i).long(), **kwargs(i))),
        input=torch.rand(15, 10, dtype=torch.double).add(1e-2).log(),
        cpp_var_map={'i': '_get_input()', 't': t, 'weight': weight},
        reference_fn=lambda i, *_:
            loss_reference_fns['NLLLoss'](i, t.type_as(i).long(), **kwargs(i)),
        pickle=False,
        default_dtype=torch.double)


def nllloss2d_no_reduce_test():
    t = Variable(torch.rand(2, 5, 5).mul(3).floor().long())
    kwargs = {'reduction': 'none'}
    return dict(
        fullname='NLLLoss2d_no_reduce',
        constructor=wrap_functional(
            lambda i: F.nll_loss(i, t.type_as(i).long(), reduction=kwargs['reduction'])),
        input_fn=lambda: torch.rand(2, 3, 5, 5).log(),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['NLLLossNd'](i, t.type_as(i).long(), **kwargs),
        pickle=False,
        default_dtype=torch.double)


def nllloss2d_no_reduce_ignore_index_test():
    t = Variable(torch.rand(2, 5, 5).mul(3).floor().long())
    kwargs: Dict[str, Union[int, str]] = {'ignore_index': 1, 'reduction': 'none'}
    return dict(
        fullname='NLLLoss2d_no_reduce_ignore_index',
        constructor=wrap_functional(
            lambda i: F.nll_loss(i, t.type_as(i).long(), ignore_index=int(kwargs['ignore_index']),
                                 reduction=str(kwargs['reduction']))),
        input_fn=lambda: torch.rand(2, 3, 5, 5).log(),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['NLLLossNd'](i, t.type_as(i).long(), **kwargs),
        pickle=False,
        default_dtype=torch.double)


def nllloss2d_no_reduce_weights_test():
    t = Variable(torch.rand(2, 5, 5).mul(3).floor().long())
    weight = torch.rand(3)

    def kwargs(i):
        return {'weight': weight.type_as(i), 'reduction': 'none'}

    return dict(
        fullname='NLLLoss2d_no_reduce_weights',
        constructor=wrap_functional(
            lambda i: F.nll_loss(i, t.type_as(i).long(), **kwargs(i))),
        input_fn=lambda: torch.rand(2, 3, 5, 5).log(),
        cpp_var_map={'i': '_get_input()', 't': t, 'weight': weight},
        reference_fn=lambda i, *_:
            loss_reference_fns['NLLLossNd'](i, t.type_as(i).long(), **kwargs(i)),
        pickle=False,
        default_dtype=torch.double)


def nlllossNd_no_reduce_test():
    t = Variable(torch.rand(2, 5, 5, 2, 2).mul(3).floor().long())
    kwargs = {'reduction': 'none'}
    return dict(
        fullname='NLLLossNd_no_reduce',
        constructor=wrap_functional(
            lambda i: F.nll_loss(i, t.type_as(i).long(), reduction=kwargs['reduction'])),
        input_fn=lambda: torch.rand(2, 3, 5, 5, 2, 2).log(),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['NLLLossNd'](i, t.type_as(i).long(), **kwargs),
        pickle=False,
        default_dtype=torch.double)


def nlllossNd_no_reduce_ignore_index_test():
    t = Variable(torch.rand(2, 5, 5, 2, 2).mul(3).floor().long())
    kwargs: Dict[str, Union[int, str]] = {'ignore_index': 1, 'reduction': 'none'}
    return dict(
        fullname='NLLLossNd_no_reduce_ignore_index',
        constructor=wrap_functional(
            lambda i: F.nll_loss(i, t.type_as(i).long(), ignore_index=int(kwargs['ignore_index']),
                                 reduction=str(kwargs['reduction']))),
        input_fn=lambda: torch.rand(2, 3, 5, 5, 2, 2).log(),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['NLLLossNd'](i, t.type_as(i).long(), **kwargs),
        pickle=False,
        default_dtype=torch.double)


def nlllossNd_no_reduce_weights_test():
    t = Variable(torch.rand(2, 5, 5, 2, 2).mul(3).floor().long())
    weight = torch.rand(3)

    def kwargs(i):
        return {'weight': weight.type_as(i), 'reduction': 'none'}

    return dict(
        fullname='NLLLossNd_no_reduce_weights',
        constructor=wrap_functional(
            lambda i: F.nll_loss(i, t.type_as(i).long(), **kwargs(i))),
        input_fn=lambda: torch.rand(2, 3, 5, 5, 2, 2).log(),
        cpp_var_map={'i': '_get_input()', 't': t, 'weight': weight},
        reference_fn=lambda i, *_:
            loss_reference_fns['NLLLossNd'](i, t.type_as(i).long(), **kwargs(i)),
        pickle=False,
        default_dtype=torch.double)


def smoothl1loss_no_reduce_test():
    t = torch.randn(2, 3, 4, dtype=torch.double)
    return dict(
        fullname='SmoothL1Loss_no_reduce',
        constructor=wrap_functional(
            lambda i: F.smooth_l1_loss(i, t.type_as(i), reduction='none')),
        input_fn=lambda: torch.randn(2, 3, 4),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['SmoothL1Loss'](i, t.type_as(i), reduction='none'),
        supports_forward_ad=True,
        pickle=False,
        default_dtype=torch.double)


def smoothl1loss_no_reduce_scalar_test():
    t = torch.randn((), dtype=torch.double)
    return dict(
        fullname='SmoothL1Loss_no_reduce_scalar',
        constructor=wrap_functional(
            lambda i: F.smooth_l1_loss(i, t.type_as(i), reduction='none')),
        input_fn=lambda: torch.randn(()),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['SmoothL1Loss'](i, t.type_as(i), reduction='none'),
        supports_forward_ad=True,
        pickle=False,
        default_dtype=torch.double)


def smoothl1loss_beta_test():
    t = torch.randn(2, 3, 4, dtype=torch.double)
    return dict(
        fullname='SmoothL1Loss_beta',
        constructor=wrap_functional(
            lambda i: F.smooth_l1_loss(i, t.type_as(i), reduction='none', beta=0.5)),
        input_fn=lambda: torch.randn(2, 3, 4),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['SmoothL1Loss'](i, t.type_as(i), reduction='none', beta=0.5),
        supports_forward_ad=True,
        pickle=False,
        default_dtype=torch.double)


def smoothl1loss_zero_beta_test():
    t = torch.randn(2, 3, 4, dtype=torch.double)
    return dict(
        fullname='SmoothL1Loss_zero_beta',
        constructor=wrap_functional(
            lambda i: F.smooth_l1_loss(i, t.type_as(i), reduction='none', beta=0)),
        input_fn=lambda: torch.randn(2, 3, 4),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['SmoothL1Loss'](i, t.type_as(i), reduction='none', beta=0),
        supports_forward_ad=True,
        pickle=False,
        default_dtype=torch.double)


def huberloss_delta_test():
    t = torch.randn(2, 3, 4)
    return dict(
        fullname='HuberLoss_delta',
        constructor=wrap_functional(
            lambda i: F.huber_loss(i, t.type_as(i), reduction='none', delta=0.5)),
        input_fn=lambda: torch.randn(2, 3, 4),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['HuberLoss'](i, t.type_as(i), reduction='none', delta=0.5),
        supports_forward_ad=True,
        pickle=False,
        default_dtype=torch.double)


def multilabelmarginloss_0d_no_reduce_test():
    t = torch.zeros(()).long()
    return dict(
        fullname='MultiLabelMarginLoss_0d_no_reduce',
        constructor=wrap_functional(
            lambda i: F.multilabel_margin_loss(i, t.type_as(i).long(), reduction='none')),
        input_fn=lambda: torch.randn(()),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['MultiLabelMarginLoss'](i, t.data.type_as(i).long(), reduction='none'),
        check_sum_reduction=True,
        check_gradgrad=False,
        pickle=False)


def multilabelmarginloss_1d_no_reduce_test():
    t = Variable(torch.rand(10).mul(10).floor().long())
    return dict(
        fullname='MultiLabelMarginLoss_1d_no_reduce',
        constructor=wrap_functional(
            lambda i: F.multilabel_margin_loss(i, t.type_as(i).long(), reduction='none')),
        input_fn=lambda: torch.randn(10),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['MultiLabelMarginLoss'](i, t.data.type_as(i).long(), reduction='none'),
        check_sum_reduction=True,
        check_gradgrad=False,
        pickle=False,
        default_dtype=torch.double)


def multilabelmarginloss_index_neg_test():
    t = Variable(torch.clamp(torch.rand(5, 10).add(-.5).mul(20).floor().long(), min=-1))
    return dict(
        fullname='MultiLabelMarginLoss_index_neg',
        constructor=wrap_functional(
            lambda i: F.multilabel_margin_loss(i, t.type_as(i).long(), reduction='none')),
        input_fn=lambda: torch.randn(5, 10),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['MultiLabelMarginLoss'](i, t.data.type_as(i).long(), reduction='none'),
        check_sum_reduction=True,
        check_gradgrad=False,
        pickle=False,
        default_dtype=torch.double)


def multilabelmarginloss_no_reduce_test():
    t = Variable(torch.rand(5, 10).mul(10).floor().long())
    return dict(
        fullname='MultiLabelMarginLoss_no_reduce',
        constructor=wrap_functional(
            lambda i: F.multilabel_margin_loss(i, t.type_as(i).long(), reduction='none')),
        input_fn=lambda: torch.randn(5, 10),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['MultiLabelMarginLoss'](i, t.data.type_as(i).long(), reduction='none'),
        check_sum_reduction=True,
        check_gradgrad=False,
        pickle=False,
        default_dtype=torch.double)


def hingeembeddingloss_no_reduce_test():
    t = Variable(torch.randn(10).gt(0).to(torch.double).mul_(2).sub(1))
    return dict(
        fullname='HingeEmbeddingLoss_no_reduce',
        constructor=wrap_functional(
            lambda i: F.hinge_embedding_loss(i, t.type_as(i), reduction='none')),
        input_fn=lambda: torch.randn(10),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['HingeEmbeddingLoss'](i, t.type_as(i), reduction='none'),
        check_sum_reduction=True,
        pickle=False,
        default_dtype=torch.double)


def hingeembeddingloss_margin_no_reduce_test():
    t = Variable(torch.randn(10).gt(0).to(torch.double).mul_(2).sub(1))
    return dict(
        fullname='HingeEmbeddingLoss_margin_no_reduce',
        constructor=wrap_functional(
            lambda i: F.hinge_embedding_loss(i, t.type_as(i), margin=0.5, reduction='none')),
        input_fn=lambda: torch.randn(10),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['HingeEmbeddingLoss'](i, t.type_as(i), margin=0.5, reduction='none'),
        check_sum_reduction=True,
        pickle=False,
        default_dtype=torch.double)


def softmarginloss_no_reduce_test():
    t = torch.randn(5, 5, dtype=torch.double)
    return dict(
        fullname='SoftMarginLoss_no_reduce',
        constructor=wrap_functional(
            lambda i: F.soft_margin_loss(i, t.type_as(i), reduction='none')),
        input_fn=lambda: torch.randn(5, 5),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['SoftMarginLoss'](i, t.type_as(i), reduction='none'),
        supports_forward_ad=True,
        pickle=False,
        default_dtype=torch.double)


def multilabelsoftmarginloss_no_reduce_test():
    t = torch.rand(5, 10).mul(2).floor()
    return dict(
        fullname='MultiLabelSoftMarginLoss_no_reduce',
        constructor=wrap_functional(
            lambda i: F.multilabel_soft_margin_loss(i, t.type_as(i), reduction='none')),
        input_fn=lambda: torch.randn(5, 10),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            (-(t * i.sigmoid().log() + (1 - t) * (-i).sigmoid().log())).sum(dim=1) / i.size(1),
        check_gradgrad=False,
        pickle=False,
        default_dtype=torch.double)


def multilabelsoftmarginloss_weights_no_reduce_test():
    t = torch.rand(5, 10).mul(2).floor()
    weights = torch.rand(10)
    return dict(
        fullname='MultiLabelSoftMarginLoss_weights_no_reduce',
        constructor=wrap_functional(
            lambda i: F.multilabel_soft_margin_loss(i, t.type_as(i),
                                                    weight=weights.type_as(i), reduction='none')),
        input_fn=lambda: torch.randn(5, 10),
        cpp_var_map={'i': '_get_input()', 't': t, 'weights': weights},
        reference_fn=lambda i, *_:
            (-(t * i.sigmoid().log() + (1 - t) * (-i).sigmoid().log()) * weights).sum(dim=1) / i.size(1),
        check_sum_reduction=True,
        check_gradgrad=False,
        pickle=False,
        default_dtype=torch.double)


def multimarginloss_no_reduce_test():
    t = torch.rand(5).mul(8).floor().long()
    return dict(
        fullname='MultiMarginLoss_no_reduce',
        constructor=wrap_functional(
            lambda i: F.multi_margin_loss(i, t.type_as(i).long(), reduction='none')),
        input_fn=lambda: torch.randn(5, 10),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['MultiMarginLoss'](i, t.data.type_as(i).long(), reduction='none'),
        check_sum_reduction=True,
        check_gradgrad=False,
        pickle=False,
        default_dtype=torch.double)


def multimarginloss_1d_no_reduce_test():
    t = torch.rand(1).mul(8).floor().long()
    return dict(
        fullname='MultiMarginLoss_1d_no_reduce',
        constructor=wrap_functional(
            lambda i: F.multi_margin_loss(i, t.type_as(i).long(), reduction='none')),
        input_fn=lambda: torch.randn(10),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['MultiMarginLoss'](i, t.data.type_as(i).long(), reduction='none'),
        check_sum_reduction=True,
        check_gradgrad=False,
        pickle=False,
        default_dtype=torch.double)


def multimarginloss_1d_input_0d_target_no_reduce_test():
    t = torch.rand(()).mul(8).floor().long()
    return dict(
        fullname='multimarginloss_1d_input_0d_target_no_reduce',
        constructor=wrap_functional(
            lambda i: F.multi_margin_loss(i, t.type_as(i).long(), reduction='none')),
        input_fn=lambda: torch.randn(10),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['MultiMarginLoss'](i, t.data.type_as(i).long(), reduction='none'),
        check_sum_reduction=True,
        check_gradgrad=False,
        pickle=False,
        default_dtype=torch.double)


def multimarginloss_p_no_reduce_test():
    t = torch.rand(5).mul(8).floor().long()
    return dict(
        fullname='MultiMarginLoss_p_no_reduce',
        constructor=wrap_functional(
            lambda i: F.multi_margin_loss(i, t.type_as(i).long(), p=2, reduction='none')),
        input_fn=lambda: torch.randn(5, 10).clamp_(1e-2, 1 - 1e-2),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['MultiMarginLoss'](i, t.data.type_as(i).long(), p=2, reduction='none'),
        check_sum_reduction=True,
        check_gradgrad=False,
        pickle=False,
        default_dtype=torch.double)


def multimarginloss_margin_no_reduce_test():
    t = torch.rand(5).mul(8).floor().long()
    return dict(
        fullname='MultiMarginLoss_margin_no_reduce',
        constructor=wrap_functional(
            lambda i: F.multi_margin_loss(i, t.type_as(i).long(), margin=0.5, reduction='none')),
        input_fn=lambda: torch.randn(5, 10),
        cpp_var_map={'i': '_get_input()', 't': t},
        reference_fn=lambda i, *_:
            loss_reference_fns['MultiMarginLoss'](i, t.data.type_as(i).long(),
                                                  margin=0.5, reduction='none'),
        check_sum_reduction=True,
        check_gradgrad=False,
        pickle=False,
        default_dtype=torch.double)


def multimarginloss_weights_no_reduce_test():
    t = torch.rand(5).mul(8).floor().long()
    weights = torch.rand(10, dtype=torch.double)
    return dict(
        fullname='MultiMarginLoss_weights_no_reduce',
        constructor=wrap_functional(
            lambda i: F.multi_margin_loss(i, t.type_as(i).long(), weight=weights.type_as(i),
                                          reduction='none')),
        input_fn=lambda: torch.randn(5, 10),
        cpp_var_map={'i': '_get_input()', 't': t, 'weights': weights},
        reference_fn=lambda i, *_:
            loss_reference_fns['MultiMarginLoss'](i, t.data.type_as(i).long(),
                                                  weight=weights, reduction='none'),
        check_sum_reduction=True,
        check_gradgrad=False,
        pickle=False,
        default_dtype=torch.double)


def single_batch_reference_fn(input, parameters, module):
    def unsqueeze_inp(inp):
        if isinstance(inp, (list, tuple)):
            return [t.unsqueeze(0) for t in inp]
        return inp.unsqueeze(0)

    single_batch_input = unsqueeze_inp(input)
    single_batch_input = [single_batch_input] if isinstance(single_batch_input, torch.Tensor) else single_batch_input
    with freeze_rng_state():
        return module(*single_batch_input).squeeze(0)


new_module_tests = [
    poissonnllloss_no_reduce_test(),
    bceloss_no_reduce_test(),
    bceloss_weights_no_reduce_test(),
    bce_with_logistic_legacy_enum_test(),
    bce_with_logistic_no_reduce_test(),
    bceloss_no_reduce_scalar_test(),
    bceloss_weights_no_reduce_scalar_test(),
    bce_with_logistic_no_reduce_scalar_test(),
    kldivloss_with_target_no_reduce_test(),
    kldivloss_no_reduce_test(),
    kldivloss_no_reduce_scalar_test(),
    kldivloss_with_log_target_no_reduce_test(),
    kldivloss_no_reduce_log_target_test(),
    kldivloss_no_reduce_scalar_log_target_test(),
    l1loss_no_reduce_test(),
    l1loss_no_reduce_complex_test(),
    l1loss_no_reduce_scalar_test(),
    mseloss_no_reduce_test(),
    mseloss_no_reduce_scalar_test(),
    nllloss_no_reduce_test(),
    nllloss_no_reduce_ignore_index_test(),
    nllloss_no_reduce_weights_test(),
    nllloss_no_reduce_weights_ignore_index_test(),
    nllloss_no_reduce_weights_ignore_index_neg_test(),
    nllloss2d_no_reduce_test(),
    nllloss2d_no_reduce_weights_test(),
    nllloss2d_no_reduce_ignore_index_test(),
    nlllossNd_no_reduce_test(),
    nlllossNd_no_reduce_weights_test(),
    nlllossNd_no_reduce_ignore_index_test(),
    smoothl1loss_no_reduce_test(),
    smoothl1loss_no_reduce_scalar_test(),
    smoothl1loss_beta_test(),
    smoothl1loss_zero_beta_test(),
    huberloss_delta_test(),
    multilabelmarginloss_0d_no_reduce_test(),
    multilabelmarginloss_1d_no_reduce_test(),
    multilabelmarginloss_index_neg_test(),
    multilabelmarginloss_no_reduce_test(),
    hingeembeddingloss_no_reduce_test(),
    hingeembeddingloss_margin_no_reduce_test(),
    softmarginloss_no_reduce_test(),
    multilabelsoftmarginloss_no_reduce_test(),
    multilabelsoftmarginloss_weights_no_reduce_test(),
    multimarginloss_no_reduce_test(),
    multimarginloss_1d_no_reduce_test(),
    multimarginloss_1d_input_0d_target_no_reduce_test(),
    multimarginloss_p_no_reduce_test(),
    multimarginloss_margin_no_reduce_test(),
    multimarginloss_weights_no_reduce_test(),
    dict(
        module_name='Conv1d',
        constructor_args=(4, 5, 3),
        cpp_constructor_args='torch::nn::Conv1dOptions(4, 5, 3)',
        input_size=(2, 4, 10),
        cudnn=True,
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Conv1d',
        constructor_args=(4, 5, 3, 2),
        cpp_constructor_args='torch::nn::Conv1dOptions(4, 5, 3).stride(2)',
        input_size=(2, 4, 10),
        cudnn=True,
        desc='stride',
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Conv1d',
        constructor_args=(4, 5, 3, 1, 1),
        cpp_constructor_args='torch::nn::Conv1dOptions(4, 5, 3).stride(1).padding(1)',
        input_size=(2, 4, 10),
        cudnn=True,
        desc='pad1',
        with_tf32=True,
        tf32_precision=0.01,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Conv1d',
        constructor_args=(4, 5, 5, 1, 2),
        cpp_constructor_args='torch::nn::Conv1dOptions(4, 5, 5).stride(1).padding(2)',
        input_size=(2, 4, 10),
        cudnn=True,
        desc='pad2',
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Conv1d',
        constructor_args=(4, 4, 3, 1, 1),
        cpp_constructor_args='torch::nn::Conv1dOptions(4, 4, 3).stride(1).padding(1)',
        input_size=(1, 4, 1),
        cudnn=True,
        desc='pad1size1',
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Conv1d',
        constructor_args=(4, 4, 5, 1, 2),
        cpp_constructor_args='torch::nn::Conv1dOptions(4, 4, 5).stride(1).padding(2)',
        input_size=(1, 4, 1),
        cudnn=True,
        desc='pad2size1',
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Conv1d',
        constructor_args=(4, 5, 3),
        cpp_constructor_args='torch::nn::Conv1dOptions(4, 5, 3)',
        input_size=(0, 4, 10),
        cudnn=True,
        desc='zero_batch',
        with_tf32=True,
        tf32_precision=0.005,
    ),
    dict(
        fullname='Conv1d_dilated',
        constructor=lambda: nn.Conv1d(4, 5, kernel_size=3, dilation=2),
        cpp_constructor_args='torch::nn::Conv1dOptions(4, 5, 3).dilation(2)',
        input_size=(2, 4, 10),
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Conv1d_groups',
        constructor=lambda: nn.Conv1d(4, 6, kernel_size=3, groups=2),
        cpp_constructor_args='torch::nn::Conv1dOptions(4, 6, 3).groups(2)',
        input_size=(2, 4, 6),
        cudnn=True,
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Conv1d_pad_valid',
        constructor=lambda: nn.Conv1d(4, 5, 3, padding="valid"),
        cpp_constructor_args='torch::nn::Conv1dOptions(4, 5, 3).padding(torch::kValid)',
        input_size=(2, 4, 10),
        cudnn=True,
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Conv1d_pad_same',
        constructor=lambda: nn.Conv1d(4, 5, 3, padding="same"),
        cpp_constructor_args='torch::nn::Conv1dOptions(4, 5, 3).padding(torch::kSame)',
        input_size=(2, 4, 10),
        cudnn=True,
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Conv1d_pad_same2',
        constructor=lambda: nn.Conv1d(4, 5, 4, padding="same"),
        cpp_constructor_args='torch::nn::Conv1dOptions(4, 5, 4).padding(torch::kSame)',
        input_size=(2, 4, 10),
        cudnn=True,
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Conv1d_pad_same_dilated',
        constructor=lambda: nn.Conv1d(4, 5, 4, padding="same", dilation=2),
        cpp_constructor_args='torch::nn::Conv1dOptions(4, 5, 3).padding(torch::kSame).dilation(2)',
        input_size=(2, 4, 10),
        cudnn=True,
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        fullname='ConvTranspose1d',
        constructor=lambda: nn.ConvTranspose1d(3, 4, kernel_size=3, stride=(3,), padding=1, output_padding=(1,)),
        cpp_constructor_args='torch::nn::ConvTranspose1dOptions(3, 4, 3).stride(3).padding(1).output_padding(1)',
        cudnn=True,
        input_size=(1, 3, 7),
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        module_name='ConvTranspose1d',
        constructor_args=(3, 4, 3, 2, 1, 1, 1, False),
        input_size=(1, 3, 6),
        cudnn=True,
        desc='no_bias',
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        module_name='ConvTranspose1d',
        constructor_args=(3, 4, 3, 2, 1, 1, 1, True, 2),
        input_size=(1, 3, 6),
        cudnn=True,
        desc='dilated',
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        fullname='ConvTranspose1d_groups',
        constructor=lambda: nn.ConvTranspose1d(4, 6, 3, stride=(3,), padding=1, output_padding=(1,), groups=2),
        cudnn=True,
        input_size=(2, 4, 7),
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Conv2d',
        constructor_args=(3, 4, (3, 2)),
        cpp_constructor_args='torch::nn::Conv2dOptions(3, 4, {3, 2})',
        input_size=(2, 3, 7, 5),
        cudnn=True,
        check_with_long_tensor=True,
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Conv2d',
        constructor_args=(3, 4, (3, 3), (2, 2)),
        cpp_constructor_args='torch::nn::Conv2dOptions(3, 4, {3, 3}).stride({2, 2})',
        input_size=(2, 3, 6, 6),
        cudnn=True,
        desc='strided',
        check_with_long_tensor=True,
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Conv2d',
        constructor_args=(3, 4, (3, 3), (2, 2), (1, 1)),
        cpp_constructor_args='torch::nn::Conv2dOptions(3, 4, {3, 3}).stride({2, 2}).padding({1, 1})',
        input_size=(2, 3, 6, 6),
        cudnn=True,
        desc='padding',
        check_with_long_tensor=True,
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Conv2d',
        constructor_args=(3, 2, (3, 3), (2, 2), (1, 1), (2, 2)),
        cpp_constructor_args='torch::nn::Conv2dOptions(3, 2, {3, 3}).stride({2, 2}).padding({1, 1}).dilation({2, 2})',
        input_size=(2, 3, 8, 8),
        cudnn=True,
        desc='dilated',
        check_with_long_tensor=True,
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Conv2d',
        constructor_args=(3, 4, (3, 2), 1, 0, 1, 1, False),
        input_size=(2, 3, 6, 5),
        cudnn=True,
        desc='no_bias',
        check_with_long_tensor=True,
        with_tf32=True,
        tf32_precision=0.015,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Conv2d',
        constructor_args=(3, 4, (3, 2)),
        cpp_constructor_args='torch::nn::Conv2dOptions(3, 4, {3, 2})',
        input_size=(0, 3, 7, 5),
        cudnn=True,
        desc='zero_batch',
        check_with_long_tensor=True,
        with_tf32=True,
    ),
    dict(
        fullname='Conv2d_groups',
        constructor=lambda: nn.Conv2d(4, 6, (3, 2), groups=2),
        cpp_constructor_args='torch::nn::Conv2dOptions(4, 6, {3, 2}).groups(2)',
        input_size=(2, 4, 6, 5),
        cudnn=True,
        check_with_long_tensor=True,
        with_tf32=True,
        tf32_precision=0.015,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Conv2d_groups_thnn',
        constructor=lambda: nn.Conv2d(4, 6, (3, 2), groups=2),
        cpp_constructor_args='torch::nn::Conv2dOptions(4, 6, {3, 2}).groups(2)',
        input_size=(2, 4, 6, 5),
        check_with_long_tensor=True,
        with_tf32=True,
        tf32_precision=0.015,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Conv2d_pad_valid',
        constructor=lambda: nn.Conv2d(2, 4, (3, 4), padding="valid"),
        cpp_constructor_args='torch::nn::Conv2dOptions(2, 4, {3, 4}).padding(torch::kValid)',
        input_size=(2, 2, 6, 5),
        cudnn=True,
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Conv2d_pad_same',
        constructor=lambda: nn.Conv2d(2, 4, (3, 4), padding="same"),
        cpp_constructor_args='torch::nn::Conv2dOptions(2, 4, {3, 4}).padding(torch::kSame)',
        input_size=(2, 2, 6, 5),
        cudnn=True,
        with_tf32=True,
        tf32_precision=0.01,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Conv2d_pad_same_dilated',
        constructor=lambda: nn.Conv2d(2, 4, (3, 4), padding="same", dilation=2),
        cpp_constructor_args='torch::nn::Conv2dOptions(2, 4, {3, 4}).padding(torch::kSame).dilation(2)',
        input_size=(2, 2, 6, 5),
        cudnn=True,
        with_tf32=True,
        tf32_precision=0.01,
        default_dtype=torch.double,
    ),
    dict(
        module_name='ConvTranspose2d',
        constructor_args=(3, 4, 3, (3, 2), 1, (1, 1)),
        cudnn=True,
        input_size=(1, 3, 7, 6),
        check_with_long_tensor=True,
        with_tf32=True,
        tf32_precision=0.01,
        default_dtype=torch.double,
    ),
    dict(
        module_name='ConvTranspose2d',
        constructor_args=(3, 4, 3, (2, 3), 1, (1, 1), 1, False, (2, 2)),
        input_size=(1, 3, 6, 7),
        cudnn=True,
        desc='dilated',
        check_with_long_tensor=True,
        with_tf32=True,
        tf32_precision=0.01,
        default_dtype=torch.double,
    ),
    dict(
        module_name='ConvTranspose2d',
        constructor_args=(3, 4, 3, (2, 3), 1, (1, 1), 1, False),
        input_size=(1, 3, 6, 7),
        cudnn=True,
        desc='no_bias',
        check_with_long_tensor=True,
        with_tf32=True,
        tf32_precision=0.01,
        default_dtype=torch.double,
    ),
    dict(
        fullname='ConvTranspose2d_groups',
        constructor=lambda: nn.ConvTranspose2d(2, 4, (2, 3), groups=2),
        cpp_constructor_args='torch::nn::ConvTranspose2dOptions(2, 4, {2, 3}).groups(2)',
        input_size=(1, 2, 4, 5),
        cudnn=True,
        check_with_long_tensor=True,
        with_tf32=True,
        tf32_precision=0.01,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Conv2d_depthwise',
        constructor=lambda: nn.Conv2d(4, 4, (3, 3), groups=4),
        cpp_constructor_args='torch::nn::Conv2dOptions(4, 4, {3, 3}).groups(4)',
        input_size=(2, 4, 6, 6),
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Conv2d_depthwise_with_multiplier',
        constructor=lambda: nn.Conv2d(4, 8, (3, 3), groups=4),
        cpp_constructor_args='torch::nn::Conv2dOptions(4, 8, {3, 3}).groups(4)',
        input_size=(2, 4, 6, 6),
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Conv2d_depthwise_strided',
        constructor=lambda: nn.Conv2d(4, 4, (3, 3), stride=(2, 2), groups=4),
        cpp_constructor_args='torch::nn::Conv2dOptions(4, 4, {3, 3}).stride({2, 2}).groups(4)',
        input_size=(2, 4, 6, 6),
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Conv2d_depthwise_padded',
        constructor=lambda: nn.Conv2d(4, 4, (3, 3), padding=(1, 1), groups=4),
        cpp_constructor_args='torch::nn::Conv2dOptions(4, 4, {3, 3}).padding({1, 1}).groups(4)',
        input_size=(2, 4, 6, 6),
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Conv2d_depthwise_dilated',
        constructor=lambda: nn.Conv2d(4, 4, (2, 2), dilation=(2, 2), groups=4),
        cpp_constructor_args='torch::nn::Conv2dOptions(4, 4, {2, 2}).dilation({2, 2}).groups(4)',
        input_size=(2, 4, 5, 5),
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Conv3d',
        constructor_args=(2, 3, (2, 3, 2)),
        cpp_constructor_args='torch::nn::Conv3dOptions(2, 3, {2, 3, 2})',
        input_size=(1, 2, 4, 5, 4),
        cudnn=True,
        check_with_long_tensor=True,
        with_tf32=True,
        tf32_precision=0.05,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Conv3d',
        constructor_args=(2, 3, (2, 3, 4), 1, 0, 1, 1, False),
        input_size=(1, 2, 3, 4, 5),
        cudnn=True,
        desc='no_bias',
        check_with_long_tensor=True,
        with_tf32=True,
        tf32_precision=0.05,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Conv3d',
        constructor_args=(2, 3, (1, 1, 1), 1, 0, 1, 1, False),
        input_size=(1, 2, 3, 4, 5),
        cudnn=True,
        desc='1x1x1_no_bias',
        check_with_long_tensor=False,
        with_tf32=True,
        tf32_precision=0.05,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Conv3d',
        constructor_args=(3, 4, 2, 2),
        cpp_constructor_args='torch::nn::Conv3dOptions(3, 4, 2).stride(2)',
        input_size=(2, 3, 5, 5, 5),
        cudnn=True,
        desc='stride',
        check_with_long_tensor=True,
        with_tf32=True,
        tf32_precision=0.05,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Conv3d',
        constructor_args=(3, 4, 2, 2, 1),
        cpp_constructor_args='torch::nn::Conv3dOptions(3, 4, 2).stride(2).padding(1)',
        input_size=(2, 3, 5, 5, 5),
        cudnn=True,
        desc='stride_padding',
        check_with_long_tensor=True,
        with_tf32=True,
        tf32_precision=0.05,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Conv3d',
        constructor_args=(3, 4, (2, 3, 4)),
        cpp_constructor_args='torch::nn::Conv3dOptions(3, 4, {2, 3, 4})',
        input_size=(0, 3, 3, 4, 5),
        cudnn=True,
        check_with_long_tensor=True,
        desc='zero_batch',
        with_tf32=True,
    ),
    dict(
        fullname='Conv3d_groups',
        constructor=lambda: nn.Conv3d(2, 4, kernel_size=3, groups=2),
        cpp_constructor_args='torch::nn::Conv3dOptions(2, 4, 3).groups(2)',
        input_size=(1, 2, 4, 5, 4),
        cudnn=True,
        check_with_long_tensor=True,
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Conv3d_dilated',
        constructor=lambda: nn.Conv3d(3, 4, kernel_size=2, dilation=2),
        cpp_constructor_args='torch::nn::Conv3dOptions(3, 4, 2).dilation(2)',
        input_size=(2, 3, 5, 5, 5),
        with_tf32=True,
        tf32_precision=0.05,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Conv3d_dilated_strided',
        constructor=lambda: nn.Conv3d(3, 4, kernel_size=2, dilation=2, stride=2),
        cpp_constructor_args='torch::nn::Conv3dOptions(3, 4, 2).dilation(2).stride(2)',
        input_size=(2, 3, 5, 5, 5),
        with_tf32=True,
        tf32_precision=0.05,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Conv3d_pad_valid',
        constructor=lambda: nn.Conv3d(3, 4, (2, 3, 4), padding="valid"),
        cpp_constructor_args='torch::nn::Conv3dOptions(3, 4, {2, 3, 4}).padding(torch::kValid)',
        input_size=(2, 3, 6, 5, 4),
        cudnn=True,
        with_tf32=True,
        tf32_precision=0.05,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Conv3d_pad_same',
        constructor=lambda: nn.Conv3d(3, 4, (2, 3, 4), padding="same"),
        cpp_constructor_args='torch::nn::Conv3dOptions(3, 4, {2, 3, 4}).padding(torch::kSame)',
        input_size=(2, 3, 6, 5, 4),
        cudnn=True,
        with_tf32=True,
        tf32_precision=0.05,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Conv3d_pad_same_dilated',
        constructor=lambda: nn.Conv3d(3, 4, (2, 3, 4), padding="same", dilation=2),
        cpp_constructor_args='torch::nn::Conv3dOptions(3, 4, {2, 3, 4}).padding(torch::kSame).dilation(2)',
        input_size=(2, 3, 6, 5, 4),
        cudnn=True,
        with_tf32=True,
        tf32_precision=0.05,
        default_dtype=torch.double,
    ),
    dict(
        module_name='ConvTranspose3d',
        constructor_args=(2, 3, (2, 3, 2)),
        cpp_constructor_args='torch::nn::ConvTranspose3dOptions(2, 3, {2, 3, 2})',
        cudnn=True,
        input_size=(1, 2, 4, 5, 4),
        with_tf32=True,
        tf32_precision=0.05,
        default_dtype=torch.double,
    ),
    dict(
        module_name='ConvTranspose3d',
        constructor_args=(2, 3, (2, 3, 2), 1, 0, 0, 1, True, (2, 2, 2)),
        cudnn=True,
        input_size=(1, 2, 4, 5, 4),
        desc='dilated',
        with_tf32=True,
        tf32_precision=0.05,
        default_dtype=torch.double,
    ),
    dict(
        module_name='ReplicationPad3d',
        constructor_args=((1, 2, 3, 3, 2, 1),),
        cpp_constructor_args='torch::nn::ReplicationPad3dOptions({1, 2, 3, 3, 2, 1})',
        input_size=(2, 3, 2, 2, 2),
        default_dtype=torch.double,
    ),
    dict(
        module_name='ReplicationPad3d',
        constructor_args=((1, 2, 3, 3, 2, 1),),
        cpp_constructor_args='torch::nn::ReplicationPad3dOptions({1, 2, 3, 3, 2, 1})',
        input_size=(3, 2, 2, 2),
        reference_fn=single_batch_reference_fn,
        desc='no_batch_dim',
        default_dtype=torch.double,
    ),
    dict(
        module_name='ReplicationPad3d',
        constructor_args=((1, 2, 3, 3, 2, 1),),
        cpp_constructor_args='torch::nn::ReplicationPad3dOptions({1, 2, 3, 3, 2, 1})',
        input_fn=lambda: torch.rand(2, 3, 2, 2, 2, dtype=torch.complex128, requires_grad=True),
        skip_half=True,
        desc='complex'
    ),
    dict(
        module_name='Embedding',
        constructor_args=(4, 3),
        cpp_constructor_args='torch::nn::EmbeddingOptions(4, 3)',
        input_fn=lambda: torch.empty(2, 3, dtype=torch.long).random_(4),
        check_gradgrad=False,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Embedding',
        constructor_args=(4, 3),
        cpp_constructor_args='torch::nn::EmbeddingOptions(4, 3)',
        input_fn=lambda: torch.empty(1, 512, dtype=torch.long).random_(4).expand(7, 512),
        check_gradgrad=False,
        desc='discontiguous',
        default_dtype=torch.double,
    ),
    dict(
        module_name='EmbeddingBag',
        constructor_args=(4, 3),
        cpp_constructor_args='torch::nn::EmbeddingBagOptions(4, 3)',
        input_fn=lambda: torch.empty(2, 3, dtype=torch.long).random_(4),
        check_gradgrad=False,
        desc='mean',
        default_dtype=torch.double,
    ),
    dict(
        module_name='EmbeddingBag',
        constructor_args=(4, 3),
        cpp_constructor_args='torch::nn::EmbeddingBagOptions(4, 3)',
        input_fn=lambda: torch.empty(1, 512, dtype=torch.long).random_(4).expand(7, 512),
        check_gradgrad=False,
        desc='discontiguous',
        default_dtype=torch.double,
    ),
    dict(
        module_name='EmbeddingBag',
        constructor_args=(4, 3, None, 2., False, 'sum'),
        input_fn=lambda: torch.empty(2, 3, dtype=torch.long).random_(4),
        check_gradgrad=False,
        desc='sum',
        default_dtype=torch.double,
    ),
    dict(
        module_name='EmbeddingBag',
        constructor_args=(4, 3, None, 2., False, 'max'),
        input_fn=lambda: torch.empty(2, 3, dtype=torch.long).random_(4),
        check_gradgrad=False,
        desc='max',
        default_dtype=torch.double,
    ),
    dict(
        fullname='EmbeddingBag_mean_padding_idx',
        constructor=lambda: nn.EmbeddingBag(4, 3, padding_idx=1),
        cpp_constructor_args='torch::nn::EmbeddingBagOptions(4, 3).padding_idx(1)',
        input_fn=lambda: torch.stack([torch.randperm(3), torch.randperm(3)]),
        check_gradgrad=False,
        default_dtype=torch.double,
    ),
    dict(
        fullname='EmbeddingBag_sum_padding_idx',
        constructor=lambda: nn.EmbeddingBag(4, 3, None, 2., False, 'sum', padding_idx=1),
        input_fn=lambda: torch.stack([torch.randperm(3), torch.randperm(3)]),
        check_gradgrad=False,
        default_dtype=torch.double,
    ),
    dict(
        fullname='EmbeddingBag_max_padding_idx',
        constructor=lambda: nn.EmbeddingBag(4, 3, None, 2., False, 'max', padding_idx=1),
        input_fn=lambda: torch.stack([torch.randperm(3), torch.randperm(3)]),
        check_gradgrad=False,
        default_dtype=torch.double,
    ),
    dict(
        fullname='EmbeddingBag_sparse',
        constructor=lambda: nn.EmbeddingBag(4, 3, sparse=True, dtype=torch.double),
        cpp_constructor_args='torch::nn::EmbeddingBagOptions(4, 3).sparse(true)._weight(torch::rand({4, 3}).to(torch::kFloat64))',
        input_fn=lambda: torch.randperm(2).repeat(1, 2),
        check_gradgrad=False,
        has_sparse_gradients=True,
    ),
    dict(
        constructor=lambda: nn.Embedding(4, 3, dtype=torch.double, sparse=True),
        cpp_constructor_args='torch::nn::EmbeddingOptions(4, 3).sparse(true)._weight(torch::rand({4, 3}).to(torch::kFloat64))',
        input_fn=lambda: torch.randperm(2).repeat(1, 2),
        fullname='Embedding_sparse',
        check_gradgrad=False,
        has_sparse_gradients=True,
    ),
    dict(
        module_name='PixelShuffle',
        constructor_args=(3,),
        cpp_constructor_args='torch::nn::PixelShuffleOptions(3)',
        input_size=(1, 9, 4, 4),
        default_dtype=torch.double,
    ),
    dict(
        module_name='PixelUnshuffle',
        constructor_args=(3,),
        cpp_constructor_args='torch::nn::PixelUnshuffleOptions(3)',
        input_size=(1, 1, 12, 12),
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=12, scale_factor=None, mode='nearest'),
        input_size=(1, 2, 4),
        fullname='interpolate_nearest_1d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=12, scale_factor=None, mode='nearest'),
        input_size=(0, 2, 4),
        fullname='interpolate_nearest_1d_zero_dim',
        pickle=False,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=(12, ), scale_factor=None, mode='nearest'),
        input_size=(1, 2, 3),
        fullname='interpolate_nearest_tuple_1d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=None, scale_factor=4., mode='nearest'),
        input_size=(1, 2, 4),
        fullname='interpolate_nearest_scale_1d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=12, scale_factor=None, mode='linear', align_corners=False),
        input_size=(1, 2, 4),
        fullname='interpolate_linear_1d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=(4, ), scale_factor=None, mode='linear', align_corners=False),
        input_size=(1, 2, 3),
        fullname='interpolate_linear_tuple_1d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=None, scale_factor=4., mode='linear', align_corners=False),
        input_size=(1, 2, 4),
        fullname='interpolate_linear_scale_1d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=12, scale_factor=None, mode='linear', align_corners=False),
        input_size=(0, 2, 4),
        fullname='interpolate_linear_1d_zero_dim',
        pickle=False,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=12, scale_factor=None, mode='linear', align_corners=True),
        input_size=(1, 2, 4),
        fullname='interpolate_linear_1d_align_corners',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=None, scale_factor=4., mode='linear', align_corners=True),
        input_size=(1, 2, 4),
        fullname='interpolate_linear_scale_1d_align_corners',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=2, scale_factor=None, mode='nearest'),
        input_size=(1, 128, 1, 1),
        fullname='interpolate_nearest_2d_launch_configs',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=12, scale_factor=None, mode='nearest'),
        input_size=(1, 2, 4, 4),
        fullname='interpolate_nearest_2d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=(12, 16), scale_factor=None, mode='nearest'),
        input_size=(1, 2, 3, 4),
        fullname='interpolate_nearest_tuple_2d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=None, scale_factor=4., mode='nearest'),
        input_size=(1, 2, 4, 4),
        fullname='interpolate_nearest_scale_2d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=12, scale_factor=None, mode='nearest'),
        input_size=(0, 2, 4, 4),
        fullname='interpolate_nearest_2d_zero_dim',
        pickle=False,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=12, scale_factor=None, mode='bilinear', align_corners=False),
        input_size=(1, 2, 4, 4),
        fullname='interpolate_bilinear_2d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=12, scale_factor=None, mode='bilinear', align_corners=False),
        input_size=(0, 2, 4, 4),
        fullname='interpolate_bilinear_2d_zero_dim',
        pickle=False,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=(4, 6), scale_factor=None,
                                    mode='bilinear', align_corners=False),
        input_size=(1, 2, 2, 3),
        fullname='interpolate_bilinear_tuple_2d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=None, scale_factor=4.,
                                    mode='bilinear', align_corners=False),
        input_size=(1, 2, 4, 4),
        fullname='interpolate_bilinear_scale_2d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=None, scale_factor=(2., 2.),
                                    mode='bilinear', align_corners=False),
        input_size=(1, 2, 4, 4),
        fullname='interpolate_bilinear_scale_tuple_shared_2d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=None, scale_factor=(2., 1.),
                                    mode='bilinear', align_corners=False),
        input_size=(1, 2, 4, 4),
        fullname='interpolate_bilinear_scale_tuple_skewed_2d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=(4, 6), scale_factor=None, mode='bilinear', align_corners=True),
        input_size=(1, 2, 4, 4),
        fullname='interpolate_bilinear_tuple_2d_align_corners',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=None, scale_factor=(2., 1.),
                                    mode='bilinear', align_corners=True),
        input_size=(1, 2, 4, 4),
        fullname='interpolate_bilinear_scale_tuple_skewed_2d_align_corners',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=12, scale_factor=None, mode='bicubic', align_corners=False),
        input_size=(1, 2, 4, 4),
        fullname='interpolate_bicubic_2d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=12, scale_factor=None, mode='bicubic', align_corners=False),
        input_size=(0, 2, 4, 4),
        fullname='interpolate_bicubic_2d_zero_dim',
        pickle=False,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=(4, 6), scale_factor=None,
                                    mode='bicubic', align_corners=False),
        input_size=(1, 2, 2, 3),
        fullname='interpolate_bicubic_tuple_2d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=None, scale_factor=4., mode='bicubic', align_corners=False),
        input_size=(1, 2, 4, 4),
        fullname='interpolate_bicubic_scale_2d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=None, scale_factor=(2., 2.),
                                    mode='bicubic', align_corners=False),
        input_size=(1, 2, 4, 4),
        fullname='interpolate_bicubic_scale_tuple_shared_2d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=None, scale_factor=(2., 1.),
                                    mode='bicubic', align_corners=False),
        input_size=(1, 2, 4, 4),
        fullname='interpolate_bicubic_scale_tuple_skewed_2d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=(4, 6), scale_factor=None, mode='bicubic', align_corners=True),
        input_size=(1, 2, 4, 4),
        fullname='interpolate_bicubic_tuple_2d_align_corners',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=None, scale_factor=(2., 1.),
                                    mode='bicubic', align_corners=True),
        input_size=(1, 2, 4, 4),
        fullname='interpolate_bicubic_scale_tuple_skewed_2d_align_corners',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=12, scale_factor=None, mode='nearest'),
        input_size=(1, 2, 4, 4, 4),
        fullname='interpolate_nearest_3d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=12, scale_factor=None, mode='nearest'),
        input_size=(0, 2, 4, 4, 4),
        fullname='interpolate_nearest_3d_zero_dim',
        pickle=False,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=(12, 16, 16), scale_factor=None, mode='nearest'),
        input_size=(1, 2, 3, 4, 4),
        fullname='interpolate_nearest_tuple_3d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=None, scale_factor=4., mode='nearest'),
        input_size=(1, 2, 4, 4, 4),
        fullname='interpolate_nearest_scale_3d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=12, scale_factor=None, mode='trilinear', align_corners=False),
        input_size=(1, 2, 4, 4, 4),
        fullname='interpolate_trilinear_3d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=12, scale_factor=None, mode='trilinear', align_corners=False),
        input_size=(0, 2, 4, 4, 4),
        fullname='interpolate_trilinear_3d_zero_dim',
        pickle=False,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=(4, 6, 6),
                                    scale_factor=None, mode='trilinear', align_corners=False),
        input_size=(1, 2, 2, 3, 3),
        fullname='interpolate_trilinear_tuple_3d',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=None, scale_factor=3., mode='trilinear', align_corners=False),
        input_size=(1, 2, 3, 4, 5),
        fullname='interpolate_trilinear_scale_3d',
        precision=3e-4,
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=(4, 6, 6), scale_factor=None,
                                    mode='trilinear', align_corners=True),
        input_size=(1, 2, 2, 3, 3),
        fullname='interpolate_trilinear_tuple_3d_align_corners',
        pickle=False,
        default_dtype=torch.double
    ),
    dict(
        constructor=wrap_functional(F.interpolate, size=None, scale_factor=3., mode='trilinear', align_corners=True),
        input_size=(1, 2, 3, 4, 4),
        fullname='interpolate_trilinear_scale_3d_align_corners',
        precision=3e-4,
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.softmax, dim=-1),
        cpp_options_args='F::SoftmaxFuncOptions(-1)',
        input_size=(2, 128),  # trigger the last-dim algo in CUDA
        fullname='softmax_lastdim',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.softmax, dim=1, dtype=torch.float64),
        cpp_options_args='F::SoftmaxFuncOptions(1).dtype(torch::kFloat64)',
        input_size=(2, 128),
        fullname='softmax_lastdim_dtype',
        pickle=False,
        test_cuda=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.softmax, dim=1),
        cpp_options_args='F::SoftmaxFuncOptions(1)',
        input_size=(2, 128, 2, 2),  # trigger special case of spatial CUDA algo
        fullname='softmax_spatial_special',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.softmax, dim=1),
        cpp_options_args='F::SoftmaxFuncOptions(1)',
        input_size=(2, 2, 4, 4),  # regular spatial algorithm
        fullname='softmax_spatial',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.softmax, dim=1, dtype=torch.float64),
        cpp_options_args='F::SoftmaxFuncOptions(1).dtype(torch::kFloat64)',
        input_size=(2, 2, 4, 4),  # regular spatial algorithm
        fullname='softmax_spatial_dtype',
        pickle=False,
        test_cuda=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.softmax, dim=0),
        cpp_options_args='F::SoftmaxFuncOptions(0)',
        input_size=(2, 3, 4, 5),
        fullname='softmax_functional_dim0',
        test_cuda=False,
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.softmax, dim=3),
        cpp_options_args='F::SoftmaxFuncOptions(3)',
        input_size=(2, 3, 4, 5),
        fullname='softmax_functional_dim3',
        test_cuda=False,
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.softmax, dim=-1),
        cpp_options_args='F::SoftmaxFuncOptions(-1)',
        input_size=(),
        fullname='softmax_functional_scalar',
        test_cuda=False,
        pickle=False,
    ),
    dict(
        constructor=wrap_functional(F.log_softmax, dim=-1),
        cpp_options_args='F::LogSoftmaxFuncOptions(-1)',
        input_size=(2, 128),  # trigger the last-dim algo in CUDA
        fullname='log_softmax_lastdim',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.log_softmax, dim=1),
        cpp_options_args='F::LogSoftmaxFuncOptions(1)',
        input_size=(2, 128, 2, 2),  # trigger special case of spatial CUDA algo
        fullname='log_softmax_spatial_special',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.log_softmax, dim=1),
        cpp_options_args='F::LogSoftmaxFuncOptions(1)',
        input_size=(2, 2, 4, 4),  # regular spatial algorithm
        fullname='log_softmax_spatial',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.log_softmax, dim=0),
        cpp_options_args='F::LogSoftmaxFuncOptions(0)',
        input_size=(2, 3, 4, 5),
        fullname='log_softmax_dim0',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.log_softmax, dim=3),
        cpp_options_args='F::LogSoftmaxFuncOptions(3)',
        input_size=(2, 3, 4, 5),
        fullname='log_softmax_dim3',
        pickle=False,
        default_dtype=torch.double,
    ),
    dict(
        constructor=wrap_functional(F.log_softmax, dim=0),
        cpp_options_args='F::LogSoftmaxFuncOptions(0)',
        input_size=(),
        fullname='log_softmax_scalar',
        pickle=False,
    ),
    dict(
        fullname='Unfold',
        constructor=lambda: nn.Unfold((2, 2), (1, 1), (0, 0), (1, 1)),
        cpp_constructor_args='torch::nn::UnfoldOptions({2, 2}).dilation({1, 1}).padding({0, 0}).stride({1, 1})',
        input_size=(2, 4, 3, 3),
        check_gradgrad=False,
        test_cuda=True,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Fold',
        constructor=lambda: nn.Fold((3, 3), (2, 2), (1, 1), (0, 0), (1, 1)),
        cpp_constructor_args='torch::nn::FoldOptions({3, 3}, {2, 2}).dilation({1, 1}).padding({0, 0}).stride({1, 1})',
        input_size=(2, 16, 4),
        check_gradgrad=False,
        test_cuda=True,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Fold_no_batch_dim_input',
        constructor=lambda: nn.Fold((3, 3), (2, 2), (1, 1), (0, 0), (1, 1)),
        cpp_constructor_args='torch::nn::FoldOptions({3, 3}, {2, 2}).dilation({1, 1}).padding({0, 0}).stride({1, 1})',
        input_size=(16, 4),
        check_gradgrad=False,
        ref=single_batch_reference_fn,
        test_cuda=True,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Unfold_int_input',
        constructor=lambda: nn.Unfold(2, 1, 0, 1),
        cpp_constructor_args='torch::nn::UnfoldOptions(2).dilation(1).padding(0).stride(1)',
        input_size=(2, 4, 3, 3),
        check_gradgrad=False,
        test_cuda=True,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Fold_int_input',
        constructor=lambda: nn.Fold(3, 2, 1, 0, 1),
        cpp_constructor_args='torch::nn::FoldOptions(3, 2).dilation(1).padding(0).stride(1)',
        input_size=(2, 16, 4),
        check_gradgrad=False,
        test_cuda=True,
        default_dtype=torch.double,
    ),
    dict(
        fullname='Fold_no_batch_dim_int_input',
        constructor=lambda: nn.Fold(3, 2, 1, 0, 1),
        cpp_constructor_args='torch::nn::FoldOptions(3, 2).dilation(1).padding(0).stride(1)',
        input_size=(16, 4),
        ref=single_batch_reference_fn,
        check_gradgrad=False,
        test_cuda=True,
        default_dtype=torch.double,
    ),
    dict(
        module_name='RReLU',
        constructor_args=(0.1, 0.9),
        cpp_constructor_args='torch::nn::RReLUOptions().lower(0.1).upper(0.9)',
        input_size=(),
        desc='with_up_down_scalar',
        test_cuda=False,
        default_dtype=torch.double,
    ),
    dict(
        module_name='PairwiseDistance',
        input_fn=lambda: (torch.randn(10, 8), torch.randn(10, 8)),
        default_dtype=torch.double,
    ),
    dict(
        module_name='PairwiseDistance',
        input_fn=lambda: (torch.randn(10, 1), torch.randn(10, 8)),
        desc='broadcast_lhs',
        default_dtype=torch.double,
    ),
    dict(
        module_name='PairwiseDistance',
        input_fn=lambda: (torch.randn(10, 8), torch.randn(1, 8)),
        desc='broadcast_rhs',
        default_dtype=torch.double,
    ),
    dict(
        module_name='PairwiseDistance',
        constructor_args=(1.5, 1e-05, True),
        cpp_constructor_args='torch::nn::PairwiseDistanceOptions().p(1.5).eps(1e-05).keepdim(true)',
        input_fn=lambda: (torch.randn(10, 8), torch.randn(10, 8)),
        desc='with_non_default_args',
        default_dtype=torch.double,
    ),
    dict(
        module_name='PairwiseDistance',
        input_fn=lambda: (torch.randn(8), torch.randn(8)),
        reference_fn=single_batch_reference_fn,
        desc='no_batch_dim',
        default_dtype=torch.double,
    ),
    dict(
        module_name='TransformerEncoderLayer',
        constructor_args=(4, 2, 16, 0.0),
        input_size=(2, 3, 4),
        desc='relu_activation',
        with_tf32=True,
        tf32_precision=0.1,
        check_batched_grad=False,
        check_gradgrad=False,
        default_dtype=torch.double,
    ),
    dict(
        module_name='TransformerEncoderLayer',
        constructor_args=(4, 2, 8, 0.0, F.gelu),
        input_size=(2, 3, 4),
        check_gradgrad=False,
        desc='gelu_activation',
        with_tf32=True,
        tf32_precision=0.08 if SM90OrLater else 0.05,
        default_dtype=torch.double,
    ),
    dict(
        module_name='TransformerDecoderLayer',
        constructor_args=(4, 2, 8, 0.0),
        input_fn=lambda: (torch.rand(3, 3, 4), torch.rand(2, 3, 4)),
        check_gradgrad=False,
        desc='relu_activation',
        with_tf32=True,
        tf32_precision=0.05,
        default_dtype=torch.double,
    ),
    dict(
        module_name='TransformerDecoderLayer',
        constructor_args=(4, 2, 8, 0.0, F.gelu),
        input_fn=lambda: (torch.rand(3, 3, 4), torch.rand(2, 3, 4)),
        check_gradgrad=False,
        desc='gelu_activation',
        with_tf32=True,
        tf32_precision=0.05,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Transformer',
        constructor_args=(4, 2, 2, 2, 8, 0.0, F.relu),
        input_fn=lambda:(torch.rand(3, 3, 4), torch.rand(2, 3, 4), torch.rand(3, 3)),
        check_gradgrad=False,
        desc='multilayer_coder',
        with_tf32=True,
        tf32_precision=0.05 if SM90OrLater else 0.03,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Linear',
        constructor_args=(3, 5),
        cpp_constructor_args='torch::nn::LinearOptions(3, 5)',
        input_fn=lambda: torch.rand(3),
        reference_fn=lambda i, p, _: torch.mm(i.view(1, -1), p[0].t()).view(-1) + p[1],
        desc="no_batch_dim",
        with_tf32=True,
        tf32_precision=0.005,
        default_dtype=torch.double,
    ),
    dict(
        module_name='Flatten',
        cpp_constructor_args='torch::nn::FlattenOptions().start_dim(-3).end_dim(-1)',
        constructor_args=(-3, -1),
        input_size=(3, 4, 5),
        reference_fn=single_batch_reference_fn,
        desc="no_batch_dim",
        default_dtype=torch.double,
    ),
    dict(
        module_name='Unflatten',
        cpp_constructor_args='torch::nn::UnflattenOptions(-2, {2, 2})',
        constructor_args=(-2, torch.Size([2, 2])),
        input_size=(3, 4, 5),
        reference_fn=single_batch_reference_fn,
        desc="no_batch_dim",
        default_dtype=torch.double,
    ),
    dict(
        module_name='LayerNorm',
        constructor_args=([56, 56, 56], 1e-5, False),
        cpp_constructor_args='torch::nn::LayerNormOptions({56, 56, 56}).eps(1e-5).elementwise_affine(false)',
        input_size=(4, 56, 56, 56),
        cudnn=True,
        check_eval=True,
        gradcheck_fast_mode=True,
        check_half=True,
        desc='3d_no_affine_large_feature',
    ),
]

for padding_mode, cpp_padding_mode in zip(
        ['reflect', 'circular', 'replicate', 'zeros'],
        ['torch::kReflect', 'torch::kCircular', 'torch::kReplicate', 'torch::kZeros']):
    for d in (1, 2, 3):
        if d == 3 and padding_mode == 'reflect':
            continue
        padding = tuple(range(1, d + 1))
        cpp_padding = '{' + ', '.join(map(str, padding)) + '}'
        input_size = (2, 2) + (4,) * d
        output_size = (2, 3) + tuple(p + 1 for p in padding)  # simplified from `(4 + 2 * p - 3) // 2 + 1`
        new_module_tests.append(
            dict(
                module_name=f'Conv{d}d',
                constructor_args=(2, 3, 3, 2, padding, 1, 1, True, padding_mode),
                input_size=input_size,
                output_size=output_size,
                cudnn=True,
                desc=f'{padding_mode}_stride2_pad2',
                with_tf32=True,
                tf32_precision=0.05,
                default_dtype=torch.double,
            ),
        )

non_linear_activations_no_batch = [
    'ELU', 'Hardshrink', 'Hardsigmoid', 'Hardtanh', 'Hardswish', 'LeakyReLU',
    'LogSigmoid', 'PReLU', 'ReLU', 'ReLU6', 'RReLU', 'SELU', 'CELU', 'GELU', 'GLU',
    'Sigmoid', 'SiLU', 'Mish', 'Softplus', 'Softshrink', 'Softsign', 'Tanh',
    'Tanhshrink', 'Threshold'
]
non_linear_activations_extra_info: Dict[str, dict] = {
    'CELU': {'constructor_args': (2.,), 'default_dtype': torch.double},
    'Threshold': {'constructor_args': (2., 1.)},
    'Hardsigmoid': {'check_gradgrad': False, 'check_jit': False, 'default_dtype': torch.double},
    'Hardswish': {'check_gradgrad': False, 'check_jit': False, 'default_dtype': torch.double},
    'RReLU': {'test_cuda': False, 'default_dtype': torch.double},
    'ELU': {'default_dtype': torch.double},
    'GELU': {'default_dtype': torch.double},
    'GLU': {'default_dtype': torch.double},
    'Hardshrink': {'default_dtype': torch.double},
    'Hardtanh': {'default_dtype': torch.double},
    'LeakyReLU': {'default_dtype': torch.double},
    'LogSigmoid': {'default_dtype': torch.double},
    'Mish': {'default_dtype': torch.double},
    'PReLU': {'default_dtype': torch.double},
    'ReLU6': {'default_dtype': torch.double},
    'ReLU': {'default_dtype': torch.double},
    'SELU': {'default_dtype': torch.double},
    'SiLU': {'default_dtype': torch.double},
    'Sigmoid': {'default_dtype': torch.double},
    'Softplus': {'default_dtype': torch.double},
    'Softshrink': {'default_dtype': torch.double},
    'Softsign': {'default_dtype': torch.double},
    'Tanh': {'default_dtype': torch.double},
    'Tanhshrink': {'default_dtype': torch.double},
}
for non_linear_activation in non_linear_activations_no_batch:
    activation_test_info = dict(
        module_name=non_linear_activation,
        input_size=(4,),
        reference_fn=single_batch_reference_fn,
        desc='no_batch_dim',
        test_cpp_api_parity=False,
    )
    extra_info = non_linear_activations_extra_info.get(non_linear_activation, {})
    activation_test_info.update(extra_info)
    new_module_tests.append(activation_test_info)


def kldivloss_reference(input, target, reduction='mean', log_target=False):
    if log_target:
        result = torch.exp(target) * (target - input)
    else:
        result = target * (target.log() - input)
    if reduction == 'mean':
        return result.mean()
    elif reduction == 'sum':
        return result.sum()
    elif reduction == 'batchmean' and result.dim() != 0:
        return result.sum() / result.size(0)
    return result


def nlllossNd_reference(input, target, weight=None, ignore_index=-100,
                        reduction='mean'):
    assert input.dim() >= 3
    N = input.size(0)
    C = input.size(1)
    out_size = (N,) + input.size()[2:]
    output = torch.zeros(out_size).type_as(input)

    if weight is None:
        weight = torch.ones(C).type_as(input)
    total_weight = 0
    for tup in product(*[range(size) for size in out_size]):
        t_nx = target[tup]
        norm = 0. if ignore_index == t_nx else weight[t_nx].item()
        input_index = list(tup)
        input_index.insert(1, t_nx)
        output[tup] = -input[tuple(input_index)] * norm
        total_weight += norm

    if reduction == 'mean':
        return output.sum() / total_weight
    elif reduction == 'sum':
        return output.sum()
    return output


def cross_entropy_loss_prob_target_reference(input, target, weight=None, reduction='mean',
                                             label_smoothing=0.0):
    assert input.dim() >= 2

    input = torch.log_softmax(input, 1)
    C = input.size(1)
    if weight is None:
        weight = torch.ones(C).type_as(input)
    weight = weight.view(1, C, *(1 for _ in input.shape[2:]))

    if label_smoothing > 0.0:
        assert label_smoothing <= 1.0
        target = (target * (1 - label_smoothing) + label_smoothing / C)

    output = -(input * target * weight).sum(dim=1)
    if reduction == 'mean':
        return output.mean()
    elif reduction == 'sum':
        return output.sum()
    return output


def cross_entropy_loss_indices_target_reference(input, target, weight=None, ignore_index=-100,
                                                reduction='mean', label_smoothing=0.0):
    log_softmax_input = torch.log_softmax(input, 1)
    nllloss = F.nll_loss(
        log_softmax_input,
        target,
        weight,
        ignore_index=ignore_index,
        reduction=reduction)

    if label_smoothing == 0.0:
        return nllloss

    assert 0.0 < label_smoothing <= 1.0

    input = torch.log_softmax(input, 1)
    C = input.size(1)
    if weight is not None:
        input = input * weight.view(1, C, *(1 for _ in input.shape[2:]))

    smooth_loss = -torch.sum(input, 1)

    ignore_mask = target == ignore_index
    smooth_loss.masked_fill_(ignore_mask, 0.0)

    if reduction == 'mean':
        if weight is not None:
            ret = torch.sum(smooth_loss) / weight.gather(0, target.masked_select(ignore_mask.logical_not()).flatten()).sum()
        else:
            ret = torch.mean(smooth_loss.masked_select(ignore_mask.logical_not()))
    elif reduction == 'sum':
        ret = torch.sum(smooth_loss)
    else:
        ret = smooth_loss

    return (1 - label_smoothing) * nllloss + ret * (label_smoothing / C)


def cross_entropy_loss_reference(input, target, weight=None, ignore_index=-100, reduction='mean',
                                 label_smoothing=0.0):
    if input.shape == target.shape:
        return cross_entropy_loss_prob_target_reference(
            input,
            target,
            weight=weight,
            reduction=reduction,
            label_smoothing=label_smoothing)
    else:
        return cross_entropy_loss_indices_target_reference(
            input, target, weight=weight, reduction=reduction,
            ignore_index=ignore_index, label_smoothing=label_smoothing
        )


def nllloss_reference(input, target, weight=None, ignore_index=-100,
                      reduction='mean'):

    def nll_loss_helper(input, target, weight, ignore_index):
        if target == ignore_index:
            return (0, 0)
        norm = 1 if weight is None else weight[target]
        result = -input[target] * norm
        return (result, norm)

    losses_and_weights = [nll_loss_helper(i, t, weight, ignore_index)
                          for i, t in zip(input, target)]
    losses, weights = zip(*losses_and_weights)
    losses_tensor = input.new_tensor(losses)
    if reduction == 'mean':
        return sum(losses_tensor) / sum(weights)
    elif reduction == 'sum':
        return sum(losses_tensor)
    else:
        return losses_tensor


def smoothl1loss_reference(input, target, reduction='mean', beta=1.0):
    abs_diff = (input - target).abs()
    ge_beta_mask = (abs_diff >= beta).type_as(abs_diff)
    lt_beta_mask = (abs_diff < beta).type_as(abs_diff)
    if beta == 0:
        output = abs_diff
    else:
        output = ge_beta_mask * (abs_diff - 0.5 * beta) + lt_beta_mask * 0.5 * (abs_diff ** 2) / beta
    if reduction == 'mean':
        return output.mean()
    elif reduction == 'sum':
        return output.sum()
    return output


def huberloss_reference(input, target, reduction='mean', delta=1.0):
    abs_diff = (input - target).abs()
    ge_delta_mask = (abs_diff >= delta)
    lt_delta_mask = (abs_diff < delta)
    output = ge_delta_mask * delta * (abs_diff - 0.5 * delta) + lt_delta_mask * 0.5 * (abs_diff ** 2)
    if reduction == 'mean':
        return output.mean()
    elif reduction == 'sum':
        return output.sum()
    return output


def _multilabelmarginloss_reference(input, target):
    targets = []
    for target_index in target:
        if target_index < 0:
            break
        targets.append(target_index)

    sum = 0
    for target_index in targets:
        for i in range(0, len(input)):
            if i not in targets:
                sum += max(0, 1 - input[target_index] + input[i])

    return sum


def multilabelmarginloss_reference(input, target, reduction='mean'):
    input_dim = input.dim()
    if input.dim() < 2:
        assert target.dim() < 2
        input = input.unsqueeze(0) if input.dim() == 1 else input.unsqueeze(0).unsqueeze(0)
        target = target.unsqueeze(0) if target.dim() == 1 else target.unsqueeze(0).unsqueeze(0)

    n = input.size(0)
    dim = input.size(1)
    output = input.new(n).zero_()
    for i in range(0, n):
        output[i] = _multilabelmarginloss_reference(input[i], target[i])

    if reduction == 'mean':
        return output.mean() / dim
    elif reduction == 'sum':
        return output.sum() / dim
    elif input_dim < 2:
        return output.squeeze() / dim
    else:
        return output / dim


def hingeembeddingloss_reference(input, target, margin=1.0, reduction='mean'):
    margin_clamp = (margin - input).clamp(min=0).type_as(input)
    output = torch.where(target == 1, input, margin_clamp)

    if reduction == 'mean':
        return output.mean()
    elif reduction == 'sum':
        return output.sum()
    return output


def softmarginloss_reference(input, target, reduction='mean'):
    output = (1 + (-input * target).exp()).log()

    if reduction == 'mean':
        return output.mean()
    elif reduction == 'sum':
        return output.sum()
    return output


def _multimarginloss_reference(input, target_idx, p, margin, weight):
    if weight is None:
        weight = input.new(len(input)).fill_(1)

    output = 0
    for i in range(0, len(input)):
        if i != target_idx:
            output += weight[target_idx] * (max(0, (margin - input[target_idx] + input[i])) ** p)
    return output


def multimarginloss_reference(input, target, p=1, margin=1, weight=None, reduction='mean'):
    if input.dim() < 2:
        input = input.unsqueeze(0) if input.dim() == 1 else input.unsqueeze(0).unsqueeze(0)

    target_dim = target.dim()
    if target.dim() == 0:
        target = target.unsqueeze(0)

    n = input.size(0)
    dim = input.size(1)
    output = input.new(n)
    for x in range(0, n):
        output[x] = _multimarginloss_reference(input[x], target[x], p, margin, weight)

    if reduction == 'mean':
        return output.mean() / dim
    elif reduction == 'sum':
        return output.sum() / dim
    elif target_dim == 0:
        return output.squeeze(0) / dim
    return output / dim


def cosineembeddingloss_reference(input1, input2, target, margin=0, reduction='mean'):
    def _cos(a, b):
        cos = a.new(a.size(0))
        for i in range(0, a.size(0)):
            cos[i] = (a[i] * b[i]).sum() / ((((a[i] * a[i]).sum() + 1e-12) * ((b[i] * b[i]).sum() + 1e-12)) ** 0.5)
        return cos

    output = torch.where(target == 1, 1 - _cos(input1, input2), (_cos(input1, input2) - margin).clamp(min=0))

    if reduction == 'mean':
        return output.mean()
    elif reduction == 'sum':
        return output.sum()
    return output


def tripletmarginloss_reference(anchor, positive, negative, margin=1.0, p=2, eps=1e-6, swap=False,
                                reduction='mean'):
    d_p = torch.pairwise_distance(anchor, positive, p, eps)
    d_n = torch.pairwise_distance(anchor, negative, p, eps)
    if swap:
        d_s = torch.pairwise_distance(positive, negative, p, eps)
        d_n = torch.min(d_n, d_s)

    output = torch.clamp(margin + d_p - d_n, min=0.0)
    if reduction == 'mean':
        return output.mean()
    elif reduction == 'sum':
        return output.sum()
    return output


def marginrankingloss_reference(input1, input2, target, margin=0, reduction='mean'):
    output = (-target * (input1 - input2) + margin).clamp(min=0)
    if reduction == 'mean':
        return output.mean()
    elif reduction == 'sum':
        return output.sum()
    return output


def ctcloss_reference(log_probs, targets, input_lengths, target_lengths, blank=0, reduction='mean'):
    input_lengths = torch.as_tensor(input_lengths, dtype=torch.long)
    target_lengths = torch.as_tensor(target_lengths, dtype=torch.long)
    dt = log_probs.dtype
    log_probs = log_probs.double()  # we need the accuracy as we are not in logspace
    targets = targets.long()
    cum_target_lengths = target_lengths.cumsum(0)
    losses = []
    for i in range(log_probs.size(1)):
        input_length = input_lengths[i].item()
        target_length = target_lengths[i].item()
        cum_target_length = cum_target_lengths[i].item()
        targets_prime = targets.new_full((2 * target_length + 1,), blank)
        if targets.dim() == 2:
            targets_prime[1::2] = targets[i, :target_length]
        else:
            targets_prime[1::2] = targets[cum_target_length - target_length:cum_target_length]
        probs = log_probs[:input_length, i].exp()
        alpha = log_probs.new_zeros((target_length * 2 + 1,))
        alpha[0] = probs[0, blank]
        alpha[1] = probs[0, targets_prime[1]]
        mask_third = (targets_prime[:-2] != targets_prime[2:])
        for t in range(1, input_length):
            alpha_next = alpha.clone()
            alpha_next[1:] += alpha[:-1]
            alpha_next[2:] += torch.where(mask_third, alpha[:-2], alpha.new_zeros(1))
            alpha = probs[t, targets_prime] * alpha_next
        losses.append(-alpha[-2:].sum().log()[None])
    output = torch.cat(losses, 0)
    if reduction == 'mean':
        output = (output / target_lengths.to(dtype=output.dtype, device=output.device)).mean()
    elif reduction == 'sum':
        output = output.sum()
    output = output.to(dt)
    return output


loss_reference_fns: Dict['str', Callable] = {
    'KLDivLoss': kldivloss_reference,
    'KLDivLoss_log_target': partial(kldivloss_reference, log_target=True),
    'NLLLoss': nllloss_reference,
    'NLLLossNd': nlllossNd_reference,
    'SmoothL1Loss': smoothl1loss_reference,
    'HuberLoss': huberloss_reference,
    'MultiLabelMarginLoss': multilabelmarginloss_reference,
    'HingeEmbeddingLoss': hingeembeddingloss_reference,
    'SoftMarginLoss': softmarginloss_reference,
    'MultiMarginLoss': multimarginloss_reference,
    'CosineEmbeddingLoss': cosineembeddingloss_reference,
    'TripletMarginLoss': tripletmarginloss_reference,
    'MarginRankingLoss': marginrankingloss_reference,
    'CTCLoss': ctcloss_reference,
    'CrossEntropyLoss': cross_entropy_loss_reference
}


criterion_tests = []


def single_batch_reference_criterion_fn(*args):
    criterion = args[-1]

    def unsqueeze_inp(inp):
        if isinstance(inp, (list, tuple)):
            return [t.unsqueeze(0) for t in inp]
        return inp.unsqueeze(0)

    def flatten(xs):
        result = []
        if isinstance(xs, (list, tuple)):
            for x in xs:
                result.extend(flatten(x))
        else:
            result.append(xs)
        return result

    single_batch_input_args = flatten([unsqueeze_inp(input) for input in args[:-1]])

    output = criterion(*single_batch_input_args)
    reduction = get_reduction(criterion)

    if reduction == 'none':
        return output.squeeze(0)
    return output


regression_criterion_no_batch = [
    'L1Loss', 'MSELoss', 'PoissonNLLLoss', 'HuberLoss', 'SmoothL1Loss'
]
reductions = ['none', 'mean', 'sum']
for name, reduction in product(regression_criterion_no_batch, reductions):
    regression_test_info = dict(
        fullname=f"{name}_no_batch_dim_{reduction}",
        constructor=lambda *args, name=name: getattr(nn, name)(reduction=reduction),
        input_size=(3, ),
        target_size=(3, ),
        reference_fn=single_batch_reference_criterion_fn,
        test_cpp_api_parity=False,
        default_dtype=torch.double,
    )
    criterion_tests.append(regression_test_info)


for reduction in reductions:
    regression_test_info = dict(
        fullname=f"KLDivLoss_no_batch_dim_{reduction}",
        constructor=lambda: nn.KLDivLoss(reduction=reduction),
        input_fn=lambda: torch.rand((3,)).log(),
        target_fn=lambda: torch.rand((3,)),
        reference_fn=single_batch_reference_criterion_fn,
        test_cpp_api_parity=False,
        default_dtype=torch.double,
    )
    criterion_tests.append(regression_test_info)


classification_criterion_no_batch = [
    (
        'BCELoss',
        lambda: torch.sigmoid(torch.randn(9, dtype=torch.double)),
        lambda: torch.randn(9, dtype=torch.double).gt(0).to(torch.double)
    ),
    ('BCEWithLogitsLoss', lambda: torch.randn(9, dtype=torch.double), lambda: torch.randn(9, dtype=torch.double)),
    ('HingeEmbeddingLoss', lambda: torch.randn(9, dtype=torch.double), lambda: torch.tensor([-1, 1, 1] * 3)),
    ('MultiLabelMarginLoss', lambda: torch.randn(4, dtype=torch.double), lambda: torch.tensor([3, 0, -1, 1])),
    ('SoftMarginLoss', lambda: torch.randn(9, dtype=torch.double), lambda: torch.tensor([-1, 1, 1] * 3)),
    ('NLLLoss', lambda: F.log_softmax(torch.randn(3, dtype=torch.double), dim=0), lambda: torch.tensor(1)),
    (
        'CosineEmbeddingLoss',
        lambda: (torch.randn(9, dtype=torch.double), torch.randn(9, dtype=torch.double)),
        lambda: torch.tensor(1, dtype=torch.double)
    ),
    ('MarginRankingLoss', lambda: (torch.randn(()), torch.randn(())), lambda: torch.randn(()).sign()),
    (
        'TripletMarginLoss',
        lambda: (torch.randn(9, dtype=torch.double), torch.randn(9, dtype=torch.double)),
        lambda: torch.randn(9, dtype=torch.double)
    ),
    ('MultiLabelSoftMarginLoss', lambda: torch.randn(9, dtype=torch.double), lambda: torch.randn(9)),
]
classification_criterion_no_batch_extra_info: Dict[str, dict] = {
    'MultiLabelMarginLoss': {'check_gradgrad': False},
}
classification_cpp_parity = {
    'BCELoss': False,
    'BCEWithLogitsLoss': False,
    'HingeEmbeddingLoss': False,
    'NLLLoss': False,
    'SoftMarginLoss': False,
}
reductions = ['none', 'mean', 'sum']
for (name, input_fn, target_fn), reduction in product(classification_criterion_no_batch,
                                                      reductions):
    classification_test_info = dict(
        fullname=f"{name}_no_batch_dim_{reduction}",
        constructor=lambda *args, name=name: getattr(nn, name)(reduction=reduction),
        input_fn=lambda f=input_fn: f(),
        target_fn=lambda f=target_fn: f(),
        reference_fn=single_batch_reference_criterion_fn,
        test_cpp_api_parity=True,
        has_parity=classification_cpp_parity.get(name, True)
    )
    extra_info = classification_criterion_no_batch_extra_info.get(name, {})
    classification_test_info.update(extra_info)
    criterion_tests.append(classification_test_info)


class NNTestCase(TestCase):

    @abstractmethod
    def _forward(self, *args, **kwargs):
        raise NotImplementedError

    @abstractmethod
    def _get_parameters(self, module: nn.Module) -> Tuple[List[nn.Parameter], List[nn.Parameter]]:
        raise NotImplementedError

    @abstractmethod
    def _zero_grad_parameters(self, module: nn.Module) -> None:
        raise NotImplementedError

    @abstractmethod
    def _backward(self, module: nn.Module,
                  input: _TensorOrTensors, output: torch.Tensor,
                  grad_output: Union[torch.Tensor, Sequence[torch.Tensor]],
                  create_graph: bool = False):
        raise NotImplementedError

    def _jacobian(self, input, num_out):
        if isinstance(input, tuple):
            return tuple(self._jacobian(elem, num_out) for elem in input)
        elif isinstance(input, list):
            return [self._jacobian(elem, num_out) for elem in input]
        else:
            return torch.zeros(input.nelement(), num_out)

    def _flatten_tensors(self, x):
        if isinstance(x, torch.Tensor):
            if x.is_sparse:
                return x.to_dense().view(-1)
            else:
                return x.view(-1)
        else:
            return tuple(self._flatten_tensors(a) for a in x)

    def _zero_grad_input(self, input):
        if isinstance(input, torch.Tensor):
            if input.requires_grad and input.grad is not None:
                input.grad.zero_()
                input.grad.detach_()
        else:
            for i in input:
                self._zero_grad_input(i)

    def _analytical_jacobian(self, module, input: _TensorOrTensors, jacobian_input=True, jacobian_parameters=True):
        output = self._forward(module, input)
        output_size = output.nelement()

        if jacobian_input:
            jacobian_inp = self._jacobian(input, output_size)
            flat_jacobian_input = list(_iter_tensors(jacobian_inp))

        if jacobian_parameters:
            num_param = sum(p.numel() for p in self._get_parameters(module)[0])
            jacobian_param = torch.zeros(num_param, output_size)

        for i in range(output_size):
            param, d_param = self._get_parameters(module)
            d_param = [torch.zeros_like(p) if d is None else d for (p, d) in zip(param, d_param)]

            d_out = torch.zeros_like(output)
            flat_d_out = d_out.view(-1)
            flat_d_out[i] = 1

            if jacobian_parameters:
                self._zero_grad_parameters(module)
            if jacobian_input:
                self._zero_grad_input(input)
            d_input = self._backward(module, input, output, d_out)

            if jacobian_input:
                for jacobian_x, d_x in zip(flat_jacobian_input, _iter_tensors(d_input)):
                    jacobian_x[:, i] = d_x.contiguous().view(-1)
            if jacobian_parameters:
                jacobian_param[:, i] = torch.cat(self._flatten_tensors(d_param), 0)

        res: Tuple[torch.Tensor, ...] = tuple()
        if jacobian_input:
            res += jacobian_inp,
        if jacobian_parameters:
            res += jacobian_param,

        return res

    def _numerical_jacobian(self, module, input: _TensorOrTensors, jacobian_input=True, jacobian_parameters=True):
        def fw(*input):
            return self._forward(module, input).detach()

        res: Tuple[torch.Tensor, ...] = tuple()
        if jacobian_input:
            res += _get_numerical_jacobian(fw, input, eps=1e-6),
        if jacobian_parameters:
            param, _ = self._get_parameters(module)
            to_cat = []
            for p in param:
                jacobian = _get_numerical_jacobian(fw, input, target=p, eps=1e-6)
                to_cat.append(jacobian[0][0])
            res += (torch.cat(to_cat, 0),)
        return res

    def check_jacobian(self, module, input: _TensorOrTensors, jacobian_input=True):
        jacobian_parameters = bool(self._get_parameters(module)[0])
        analytical = self._analytical_jacobian(module, input, jacobian_input, jacobian_parameters)
        numerical = self._numerical_jacobian(module, input, jacobian_input, jacobian_parameters)
        analytical_t = list(_iter_tensors(analytical))
        numerical_t = list(_iter_tensors(numerical))

        differences = []
        for a, n in zip(analytical_t, numerical_t):
            if a.numel() != 0:
                differences.append(a.add(n, alpha=-1).abs().max())
        if len(differences) > 0:
            self.assertLessEqual(max(differences), PRECISION)  # type: ignore[type-var]


class TestBase:

    _required_arg_names = {'constructor_args', 'input', 'extra_args'}


<END>

<START>
import copy
from queue import SimpleQueue
from typing import List, Dict, Tuple

import torch.fx
from torch.fx.graph_module import GraphModule
from torch.fx.graph import Graph
from torch.fx.node import Node
from torch.fx.passes.tools_common import NodeList, NodeSet, legalize_graph
from torch.fx.passes.utils import lift_subgraph_as_module
from torch.fx._compatibility import compatibility

@compatibility(is_backward_compatible=False)
def topo_sort(nodes: NodeList) -> NodeList:
    indegree_map = {node : 0 for node in nodes}
    candidates: SimpleQueue = SimpleQueue()

    for node in nodes:
        for n in node.all_input_nodes:
            if n in indegree_map:
                indegree_map[node] += 1
        if indegree_map[node] == 0:
            candidates.put(node)

    sorted_nodes: NodeList = list()
    while not candidates.empty():
        node = candidates.get()
        sorted_nodes.append(node)

        for n in node.users:
            if n in indegree_map:
                indegree_map[n] -= 1
                if indegree_map[n] == 0:
                    candidates.put(n)

    assert len(nodes) == len(sorted_nodes), "topological sorted nodes doesn't have same length as input nodes"

    return sorted_nodes


@compatibility(is_backward_compatible=False)
def validate_partition(partition: NodeList) -> bool:

    partition_set = set(partition)

    outputs: NodeList = list()
    for node in partition_set:
        for user_node in node.users:
            if user_node not in partition_set:
                outputs.append(user_node)

    def bfs_find_cycle(root_nodes: NodeList) -> bool:
        visited: NodeSet = set()

        queue: NodeList = root_nodes
        while queue:
            current = queue.pop()
            visited.add(current)
            if current in partition_set:
                return True
            for user_node in current.users:
                if user_node in visited:
                    continue
                queue.append(user_node)
        return False

    if bfs_find_cycle(outputs):
        return False

    return True


@compatibility(is_backward_compatible=False)
def fuse_as_graphmodule(gm: GraphModule,
                        nodes: NodeList,
                        module_name: str) -> Tuple[GraphModule, Tuple[Node, ...], Tuple[Node, ...]]:



    for node in nodes:
        assert node.graph.owning_module is gm, f"{node} doesn't belong to passed in graph module {gm._get_name()}"
        assert not node._erased, f"{node} has been removed from owning graph"
        assert node in gm.graph.nodes, f"{node} is not found in graph module {gm._get_name()}"

    assert validate_partition(nodes), "Invalid partition, found dependency cycles"

    subgraph = Graph()

    node_to_placeholder: Dict[Node, Node] = {}  # mapping of nodes from old graph to placeholder in new graph
    node_map: Dict[Node, Node] = {}       # mapping of nodes from old graph to new graph

    def remap_inputs(x):
        if x.op == "get_attr":
            pass

        if x in nodes:
            return node_map[x]

        if x not in node_to_placeholder:
            placeholder_node = subgraph.placeholder(x.name, type_expr=x.type)
            placeholder_node.meta = copy.copy(x.meta)
            node_to_placeholder[x] = placeholder_node

        return node_to_placeholder[x]

    for node in nodes:
        new_node = subgraph.node_copy(node, remap_inputs)
        node_map[node] = new_node

    output_mapping: Dict[Node, Node] = {}  # mapping from old output to new outputs

    for node in nodes:
        for user_node in node.users:
            if user_node not in nodes:
                output_mapping[node] = node_map[node]

    outs = tuple(output_mapping.values())

    subgraph.output(outs[0] if len(outs) == 1 else outs)

    subgraph.lint()
    fused_gm: GraphModule
    fused_gm, _ = lift_subgraph_as_module(gm, subgraph, comp_name="", class_name=module_name)

    original_inputs: Tuple[Node, ...] = tuple(node_to_placeholder.keys())

    original_outputs: Tuple[Node, ...] = tuple(output_mapping.keys())

    return fused_gm, original_inputs, original_outputs


@compatibility(is_backward_compatible=False)
def insert_subgm(gm: GraphModule, sub_gm: GraphModule, orig_inputs: Tuple[Node, ...], orig_outputs: Tuple[Node, ...]):
    submodule_name = sub_gm.__class__.__name__
    gm.add_submodule(submodule_name, sub_gm)

    module_node = gm.graph.call_module(
        submodule_name,
        args=orig_inputs,
        kwargs=None)

    if len(orig_outputs) == 1:
        orig_outputs[0].replace_all_uses_with(module_node, propagate_meta=True)
    else:
        for i, orig_output in enumerate(orig_outputs):
            proxy_out = torch.fx.Proxy(module_node)[i].node  # type: ignore[index]
            orig_output.replace_all_uses_with(proxy_out, propagate_meta=True)
    return gm

@compatibility(is_backward_compatible=False)
def erase_nodes(gm: GraphModule, nodes: NodeList):

    for node in reversed(nodes):
        gm.graph.erase_node(node)


@compatibility(is_backward_compatible=False)
def fuse_by_partitions(gm: GraphModule, partitions: List[NodeList]) -> GraphModule:
    for partition_id, nodes in enumerate(partitions):
        sorted_nodes = topo_sort(nodes)

        submodule_name = "fused_" + str(partition_id)
        sub_gm, orig_inputs, orig_outputs = fuse_as_graphmodule(gm, sorted_nodes, submodule_name)

        insert_subgm(gm, sub_gm, orig_inputs, orig_outputs)

        erase_nodes(gm, sorted_nodes)

    legalize_graph(gm)

    return gm

<END>

<START>
from ._ops import OpOverload
from typing import Any, Optional, Set, List
import traceback
import torch
import weakref
import functools
import inspect
import re
import sys

__all__ = [
    'Library',
    'impl',
    'define',
    'fallthrough_kernel',
    'impl_abstract',
    'get_ctx',
]

_impls: Set[str] = set()
_defs: Set[str] = set()

_reserved_namespaces = ['prim']

def fallthrough_kernel():
    raise NotImplementedError("fallthrough_kernel() should never be called.")

class Library:
    def __init__(self, ns, kind, dispatch_key=""):
        if kind not in ('IMPL', 'DEF', 'FRAGMENT'):
            raise ValueError("Unsupported kind: ", kind)

        if ns in _reserved_namespaces and (kind == "DEF" or kind == 'FRAGMENT'):
            raise ValueError(ns, " is a reserved namespace. Please try creating a library with another name.")

        frame = traceback.extract_stack(limit=3)[0]
        filename, lineno = frame.filename, frame.lineno
        self.m: Optional[Any] = torch._C._dispatch_library(kind, ns, dispatch_key, filename, lineno)
        self.ns = ns
        self._op_defs: Set[str] = set()
        self._op_impls: Set[str] = set()
        self._registration_handles: List["torch._library.utils.RegistrationHandle"] = []
        self.kind = kind
        self.dispatch_key = dispatch_key
        weakref.finalize(self, _del_library, _impls, self._op_impls, _defs, self._op_defs, self._registration_handles)

    def __repr__(self):
        return f"Library(kind={self.kind}, ns={self.ns}, dispatch_key={self.dispatch_key})>"

    def define(self, schema, alias_analysis="", *, tags=()):
        if alias_analysis not in ["", "FROM_SCHEMA", "CONSERVATIVE"]:
            raise RuntimeError(f"Invalid alias_analysis type {alias_analysis}")
        assert self.m is not None
        if isinstance(tags, torch.Tag):
            tags = (tags,)
        result = self.m.define(schema, alias_analysis, tuple(tags))
        qualname = self.ns + "::" + schema.split("(")[0]
        self._op_defs.add(qualname)
        _defs.add(qualname)
        return result


        Args:
            op_name: operator name (along with the overload) or OpOverload object.
            fn: function that's the operator implementation for the input dispatch key or :func:`~fallthrough_kernel`
                to register a fallthrough.
            dispatch_key: dispatch key that the input function should be registered for. By default, it uses
                          the dispatch key that the library was created with.

        Example::
            >>> my_lib = Library("aten", "IMPL")
            >>> def div_cpu(self, other):
            >>>     return self * (1 / other)
            >>> my_lib.impl("div.Tensor", div_cpu, "CPU")
            dispatch_key = self.dispatch_key

        if isinstance(op_name, str):
            name = op_name
        elif isinstance(op_name, OpOverload):
            name = op_name._schema.name
            overload_name = op_name._schema.overload_name

    In PyTorch, defining an op (short for "operator") is a two step-process:
    - we need to define the op (by providing an operator name and schema)
    - we need to implement behavior for how the operator interacts with
    various PyTorch subsystems, like CPU/CUDA Tensors, Autograd, etc.

    This entrypoint defines the custom operator (the first step)
    you must then perform the second step by calling various
    ``impl_*`` APIs, like :func:`torch.library.impl` or
    :func:`torch.library.impl_abstract`.

    Args:
        qualname (str): The qualified name for the operator. Should be
            a string that looks like "namespace::name", e.g. "aten::sin".
            Operators in PyTorch need a namespace to
            avoid name collisions; a given operator may only be created once.
            If you are writing a Python library, we recommend the namespace to
            be the name of your top-level module.
        schema (str): The schema of the operator. E.g. "(Tensor x) -> Tensor"
            for an op that accepts one Tensor and returns one Tensor. It does
            not contain the operator name (that is passed in ``qualname``).
        lib (Optional[Library]): If provided, the lifetime of this operator
            will be tied to the lifetime of the Library object.
        tags (Tag | Sequence[Tag]): one or more torch.Tag to apply to this
            operator. Tagging an operator changes the operator's behavior
            under various PyTorch subsystems; please read the docs for the
            torch.Tag carefully before applying it.

    Example::
        >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_LIBRARY)
        >>> import torch
        >>> import numpy as np
        >>>
        >>> # Define the operator
        >>> torch.library.define("mylib::sin", "(Tensor x) -> Tensor")
        >>>
        >>> # Add implementations for the operator
        >>> @torch.library.impl("mylibrary::sin", "cpu")
        >>> def f(x):
        >>>     return torch.from_numpy(np.sin(x.numpy()))
        >>>
        >>> # Call the new operator from torch.ops.
        >>> x = torch.randn(3)
        >>> y = torch.ops.mylib.sin(x)
        >>> assert torch.allclose(y, x)

    We're keeping this around for BC reasons

    You may pass "default" for ``types`` to register this implementation as the
    default implementation for ALL device types.
    Please only use this if the implementation truly supports all device types;
    for example, this is true if it is a composition of built-in PyTorch operators.

    Some valid types are: "cpu", "cuda", "xla", "mps", "ipu", "xpu".

    Args:
        qualname (str): Should be a string that looks like "namespace::operator_name".
        types (str | Sequence[str]): The device types to register an impl to.
        lib (Optional[Library]): If provided, the lifetime of this registration
            will be tied to the lifetime of the Library object.

    Examples:
        >>> import torch
        >>> import numpy as np
        >>>
        >>> # Define the operator
        >>> torch.library.define("mylibrary::sin", "(Tensor x) -> Tensor")
        >>>
        >>> # Add implementations for the cpu device
        >>> @torch.library.impl("mylibrary::sin", "cpu")
        >>> def f(x):
        >>>     return torch.from_numpy(np.sin(x.numpy()))
        >>>
        >>> x = torch.randn(3)
        >>> y = torch.ops.mylibrary.sin(x)
        >>> assert torch.allclose(y, x.sin())
    def wrap(f):
        lib.impl(name, f, dispatch_key)
        return f
    return wrap



def impl_abstract(qualname, func=None, *, lib=None, _stacklevel=1):
    source = torch._library.utils.get_source(_stacklevel + 1)
    frame = sys._getframe(_stacklevel)
    caller_module = inspect.getmodule(frame)
    caller_module_name = None if caller_module is None else caller_module.__name__

    if caller_module_name is not None and caller_module_name.startswith("torchvision."):
        caller_module_name = None

    def inner(func):
        entry = torch._library.simple_registry.singleton.find(qualname)
        if caller_module_name is not None:
            func_to_register = _check_pystubs_once(func, qualname, caller_module_name)
        else:
            func_to_register = func

        handle = entry.abstract_impl.register(func_to_register, source)
        if lib is not None:
            lib._registration_handles.append(handle)
        return func

    if func is None:
        return inner
    return inner(func)


def _check_pystubs_once(func, qualname, actual_module_name):
    checked = False

    def inner(*args, **kwargs):
        nonlocal checked
        if checked:
            return func(*args, **kwargs)

        op = torch._library.utils.lookup_op(qualname)
        if op._defined_in_python:
            checked = True
            return func(*args, **kwargs)

        maybe_pystub = torch._C._dispatch_pystub(
            op._schema.name,
            op._schema.overload_name)
        if not maybe_pystub:
            raise RuntimeError(
                f"Operator '{qualname}' was defined in C++ and has a Python "
                f"abstract impl. In this situation, it is required to have a "
                f"C++ `m.impl_abstract_pystub` call, but we could not find one."
                f"Please add a call to `m.impl_abstract_pystub(\"{actual_module_name}\");` "
                f"to the C++ TORCH_LIBRARY block the operator was "
                f"defined in.")
        pystub_module = maybe_pystub[0]
        if actual_module_name != pystub_module:
            raise RuntimeError(
                f"Operator '{qualname}' specified that its python abstract impl "
                f"is in the Python module '{pystub_module}' but it was actually found "
                f"in '{actual_module_name}'. Please either move the abstract impl "
                f"or correct the m.impl_abstract_pystub call.")
        checked = True
        return func(*args, **kwargs)
    return inner


def get_ctx() -> "torch._library.abstract_impl.AbstractImplCtx":
    return torch._library.abstract_impl.global_ctx_getter()

<END>

<START>
from typing import Dict

import torch
from torch.distributions import constraints
from torch.distributions.distribution import Distribution
from torch.distributions.independent import Independent
from torch.distributions.transforms import ComposeTransform, Transform
from torch.distributions.utils import _sum_rightmost

__all__ = ["TransformedDistribution"]


class TransformedDistribution(Distribution):
    arg_constraints: Dict[str, constraints.Constraint] = {}

    def __init__(self, base_distribution, transforms, validate_args=None):
        if isinstance(transforms, Transform):
            self.transforms = [
                transforms,
            ]
        elif isinstance(transforms, list):
            if not all(isinstance(t, Transform) for t in transforms):
                raise ValueError(
                    "transforms must be a Transform or a list of Transforms"
                )
            self.transforms = transforms
        else:
            raise ValueError(
                f"transforms must be a Transform or list, but was {transforms}"
            )

        base_shape = base_distribution.batch_shape + base_distribution.event_shape
        base_event_dim = len(base_distribution.event_shape)
        transform = ComposeTransform(self.transforms)
        if len(base_shape) < transform.domain.event_dim:
            raise ValueError(
                "base_distribution needs to have shape with size at least {}, but got {}.".format(
                    transform.domain.event_dim, base_shape
                )
            )
        forward_shape = transform.forward_shape(base_shape)
        expanded_base_shape = transform.inverse_shape(forward_shape)
        if base_shape != expanded_base_shape:
            base_batch_shape = expanded_base_shape[
                : len(expanded_base_shape) - base_event_dim
            ]
            base_distribution = base_distribution.expand(base_batch_shape)
        reinterpreted_batch_ndims = transform.domain.event_dim - base_event_dim
        if reinterpreted_batch_ndims > 0:
            base_distribution = Independent(
                base_distribution, reinterpreted_batch_ndims
            )
        self.base_dist = base_distribution

        transform_change_in_event_dim = (
            transform.codomain.event_dim - transform.domain.event_dim
        )
        event_dim = max(
            transform.codomain.event_dim,  # the transform is coupled
            base_event_dim + transform_change_in_event_dim,  # the base dist is coupled
        )
        assert len(forward_shape) >= event_dim
        cut = len(forward_shape) - event_dim
        batch_shape = forward_shape[:cut]
        event_shape = forward_shape[cut:]
        super().__init__(batch_shape, event_shape, validate_args=validate_args)

    def expand(self, batch_shape, _instance=None):
        new = self._get_checked_instance(TransformedDistribution, _instance)
        batch_shape = torch.Size(batch_shape)
        shape = batch_shape + self.event_shape
        for t in reversed(self.transforms):
            shape = t.inverse_shape(shape)
        base_batch_shape = shape[: len(shape) - len(self.base_dist.event_shape)]
        new.base_dist = self.base_dist.expand(base_batch_shape)
        new.transforms = self.transforms
        super(TransformedDistribution, new).__init__(
            batch_shape, self.event_shape, validate_args=False
        )
        new._validate_args = self._validate_args
        return new

    @constraints.dependent_property(is_discrete=False)
    def support(self):
        if not self.transforms:
            return self.base_dist.support
        support = self.transforms[-1].codomain
        if len(self.event_shape) > support.event_dim:
            support = constraints.independent(
                support, len(self.event_shape) - support.event_dim
            )
        return support

    @property
    def has_rsample(self):
        return self.base_dist.has_rsample

    def sample(self, sample_shape=torch.Size()):
        with torch.no_grad():
            x = self.base_dist.sample(sample_shape)
            for transform in self.transforms:
                x = transform(x)
            return x

    def rsample(self, sample_shape=torch.Size()):
        x = self.base_dist.rsample(sample_shape)
        for transform in self.transforms:
            x = transform(x)
        return x

    def log_prob(self, value):
        if self._validate_args:
            self._validate_sample(value)
        event_dim = len(self.event_shape)
        log_prob = 0.0
        y = value
        for transform in reversed(self.transforms):
            x = transform.inv(y)
            event_dim += transform.domain.event_dim - transform.codomain.event_dim
            log_prob = log_prob - _sum_rightmost(
                transform.log_abs_det_jacobian(x, y),
                event_dim - transform.domain.event_dim,
            )
            y = x

        log_prob = log_prob + _sum_rightmost(
            self.base_dist.log_prob(y), event_dim - len(self.base_dist.event_shape)
        )
        return log_prob

    def _monotonize_cdf(self, value):
        sign = 1
        for transform in self.transforms:
            sign = sign * transform.sign
        if isinstance(sign, int) and sign == 1:
            return value
        return sign * (value - 0.5) + 0.5

    def cdf(self, value):
        for transform in self.transforms[::-1]:
            value = transform.inv(value)
        if self._validate_args:
            self.base_dist._validate_sample(value)
        value = self.base_dist.cdf(value)
        value = self._monotonize_cdf(value)
        return value

    def icdf(self, value):
        value = self._monotonize_cdf(value)
        value = self.base_dist.icdf(value)
        for transform in self.transforms:
            value = transform(value)
        return value

<END>

<START>
import os
import sys
import unittest
from typing import Dict, List, Type

from torch.testing._internal.common_distributed import MultiProcessTestCase
from torch.testing._internal.common_utils import (
    TEST_WITH_DEV_DBG_ASAN,
    find_free_port,
    IS_SANDCASTLE,
)
from torch.testing._internal.distributed.ddp_under_dist_autograd_test import (
    CudaDdpComparisonTest,
    DdpComparisonTest,
    DdpUnderDistAutogradTest,
)
from torch.testing._internal.distributed.pipe_with_ddp_test import (
    PipeWithDDPTest,
)
from torch.testing._internal.distributed.nn.api.remote_module_test import (
    CudaRemoteModuleTest,
    RemoteModuleTest,
    ThreeWorkersRemoteModuleTest,
)
from torch.testing._internal.distributed.rpc.dist_autograd_test import (
    DistAutogradTest,
    CudaDistAutogradTest,
    FaultyAgentDistAutogradTest,
    TensorPipeAgentDistAutogradTest,
    TensorPipeCudaDistAutogradTest
)
from torch.testing._internal.distributed.rpc.dist_optimizer_test import (
    DistOptimizerTest,
)
from torch.testing._internal.distributed.rpc.jit.dist_autograd_test import (
    JitDistAutogradTest,
)
from torch.testing._internal.distributed.rpc.jit.rpc_test import JitRpcTest
from torch.testing._internal.distributed.rpc.jit.rpc_test_faulty import (
    JitFaultyAgentRpcTest,
)
from torch.testing._internal.distributed.rpc.rpc_agent_test_fixture import (
    RpcAgentTestFixture,
)
from torch.testing._internal.distributed.rpc.faulty_agent_rpc_test import (
    FaultyAgentRpcTest,
)
from torch.testing._internal.distributed.rpc.rpc_test import (
    CudaRpcTest,
    RpcTest,
    TensorPipeAgentRpcTest,
    TensorPipeAgentCudaRpcTest,
)
from torch.testing._internal.distributed.rpc.examples.parameter_server_test import ParameterServerTest
from torch.testing._internal.distributed.rpc.examples.reinforcement_learning_rpc_test import (
    ReinforcementLearningRpcTest,
)


def _check_and_set_tcp_init():
    use_tcp_init = os.environ.get("RPC_INIT_WITH_TCP", None)
    if use_tcp_init == "1":
        os.environ["MASTER_ADDR"] = '127.0.0.1'
        os.environ["MASTER_PORT"] = str(find_free_port())

def _check_and_unset_tcp_init():
    use_tcp_init = os.environ.get("RPC_INIT_WITH_TCP", None)
    if use_tcp_init == "1":
        del os.environ["MASTER_ADDR"]
        del os.environ["MASTER_PORT"]


@unittest.skipIf(
    TEST_WITH_DEV_DBG_ASAN, "Skip ASAN as torch + multiprocessing spawn have known issues"
)
class SpawnHelper(MultiProcessTestCase):
    def setUp(self):
        super().setUp()
        _check_and_set_tcp_init()
        self._spawn_processes()

    def tearDown(self):
        _check_and_unset_tcp_init()
        super().tearDown()


GENERIC_TESTS = [
    RpcTest,
    ParameterServerTest,
    DistAutogradTest,
    DistOptimizerTest,
    JitRpcTest,
    JitDistAutogradTest,
    RemoteModuleTest,
    ThreeWorkersRemoteModuleTest,
    DdpUnderDistAutogradTest,
    DdpComparisonTest,
    ReinforcementLearningRpcTest,
]
GENERIC_CUDA_TESTS = [
    CudaRpcTest,
    CudaDistAutogradTest,
    CudaRemoteModuleTest,
    CudaDdpComparisonTest,
    PipeWithDDPTest,
]


TENSORPIPE_TESTS = [
    TensorPipeAgentRpcTest,
    TensorPipeAgentDistAutogradTest,
]
TENSORPIPE_CUDA_TESTS = [
    TensorPipeAgentCudaRpcTest,
    TensorPipeCudaDistAutogradTest,
]


FAULTY_AGENT_TESTS = [
    FaultyAgentRpcTest,
    FaultyAgentDistAutogradTest,
    JitFaultyAgentRpcTest,
]


def generate_tests(
    prefix: str,
    mixin: Type[RpcAgentTestFixture],
    tests: List[Type[RpcAgentTestFixture]],
    module_name: str,
) -> Dict[str, Type[RpcAgentTestFixture]]:
    ret: Dict[str, Type[RpcAgentTestFixture]] = {}
    for test_class in tests:
        if IS_SANDCASTLE and TEST_WITH_DEV_DBG_ASAN:
            print(
                f'Skipping test {test_class} on sandcastle for the following reason: '
                'Skip dev-asan as torch + multiprocessing spawn have known issues', file=sys.stderr)
            continue

        name = f"{prefix}{test_class.__name__}"
        class_ = type(name, (test_class, mixin, SpawnHelper), {})
        class_.__module__ = module_name
        ret[name] = class_
    return ret

<END>

<START>
import re

import torch._C as C




class PythonDispatcher:
    namespace = "__test__"
    name = "foo"
    runtime_keys = [
        "CPU", "AutogradCPU",
        "FPGA", "AutogradOther",
        "XLA", "AutogradXLA",
        "Lazy", "AutogradLazy",
    ]
    alias_keys = [
        "CompositeExplicitAutograd",
        "Autograd",
        "CompositeImplicitAutograd",
    ]
    supported_keys = runtime_keys + alias_keys

    def __init__(self):
        C._dispatch_check_invariants(self.name)  # type: ignore[attr-defined]
        self.ref = C._dispatch_library("FRAGMENT", self.namespace, "")
        self.ref.def_("foo(Tensor x) -> Tensor")


    def keys(self):
        return self.supported_keys


    def register(self, dispatchKeys):
        if len(set(dispatchKeys)) != len(dispatchKeys):
            raise RuntimeError(
                f"Overriden is not allowed but found duplicates in {dispatchKeys}."
            )
        if (
            "CompositeImplicitAutograd" in dispatchKeys
            and "CompositeExplicitAutograd" in dispatchKeys
        ):
            raise RuntimeError(
                "Registration to both CompositeImplicitAutograd and CompositeExplicitAutograd is not allowed."
            )
        for key in dispatchKeys:
            if key not in self.supported_keys:
                raise RuntimeError(
                    f"{key} is not supported, please select a dispatch key in {self.supported_keys}."
                )
            self.ref.impl_t_t("foo", dispatch=key, debug="fn_" + key)


    def _format_line(self, key, kernel):
        return f"{key:<15} {kernel}\n"


    def _format_header(self, header):
        s += self._format_line("key", "kernel")
        s += "---------------------------\n"
        return s


    def rawRegistrations(self):
        return C._dispatch_dump(f"{self.namespace}::{self.name}")  # type: ignore[attr-defined]


    def rawDispatchTable(self):
        return C._dispatch_dump_table(f"{self.namespace}::{self.name}")  # type: ignore[attr-defined]


    def registrations(self):
        output = self._format_header("Registered Kernels")
        state = self.rawRegistrations()
        state_entries = state.split("\n")
        for line in state_entries:
            first = line.split(":")[0]
            if any(first.startswith(k) for k in self.supported_keys):
                kernel = line.split("::")[0].split(" ")[1]
                output += self._format_line(first, kernel)
        return output


    def dispatchTable(self):
        output = self._format_header("Computed Dispatch Table")
        table = self.rawDispatchTable()
        table_entries = table.split("\n")
        regex = re.compile(r"registered at .*FallbackKernel\.cpp.*(\[)")
        for line in table_entries:
            k = line.split(":")[0]
            if k in self.runtime_keys:
                entry = regex.sub("[", line)
                output += self._format_line(k, entry.split(": ")[1])
        return output

<END>

<START>
import gc

import torch
from torch.utils import _pytree
from ._utils import _dummy_type

if not hasattr(torch._C, "_CudaStreamBase"):
    torch._C.__dict__["_CUDAGraph"] = _dummy_type("_CUDAGraph")
    torch._C.__dict__["_graph_pool_handle"] = _dummy_type("_graph_pool_handle")
    torch._C.__dict__["_cuda_isCurrentStreamCapturing"] = _dummy_type(
        "_cuda_isCurrentStreamCapturing"
    )

from torch._C import (  # noqa: F401
    _cuda_isCurrentStreamCapturing,
    _CUDAGraph,
    _graph_pool_handle,
)


def is_current_stream_capturing():
    return _cuda_isCurrentStreamCapturing()


def graph_pool_handle():
    return _graph_pool_handle()


class CUDAGraph(torch._C._CUDAGraph):

    def __new__(cls):
        return super().__new__(cls)

    def capture_begin(self, pool=None, capture_error_mode="global"):
        super().capture_begin(pool=pool, capture_error_mode=capture_error_mode)

    def capture_end(self):
        super().capture_end()

    def replay(self):
        super().reset()

    def pool(self):
        return super().pool()

    def enable_debug_mode(self):
        Arguments:
            debug_path (required): Path to dump the graph to.

        Calls a debugging function to dump the graph if the debugging is
        enabled via CUDAGraph.enable_debug_mode()

    See :ref:`CUDA Graphs <cuda-graph-semantics>` for a general introduction,
    detailed use, and constraints.

    Arguments:
        cuda_graph (torch.cuda.CUDAGraph): Graph object used for capture.
        pool (optional): Opaque token (returned by a call to :func:`~torch.cuda.graph_pool_handle()` or
            :meth:`other_Graph_instance.pool()<torch.cuda.CUDAGraph.pool>`) hinting this graph's capture
            may share memory from the specified pool. See :ref:`Graph memory management<graph-memory-management>`.
        stream (torch.cuda.Stream, optional): If supplied, will be set as the current stream in the context.
            If not supplied, ``graph`` sets its own internal side stream as the current stream in the context.
        capture_error_mode (str, optional): specifies the cudaStreamCaptureMode for the graph capture stream.
            Can be "global", "thread_local" or "relaxed". During cuda graph capture, some actions, such as cudaMalloc,
            may be unsafe. "global" will error on actions in other threads, "thread_local" will only error for
            actions in the current thread, and "relaxed" will not error on actions. Do NOT change this setting
            unless you're familiar with `cudaStreamCaptureMode <https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g9d0535d93a214cbf126835257b16ba85>`_

    .. note::
        For effective memory sharing, if you pass a ``pool`` used by a previous capture and the previous capture
        used an explicit ``stream`` argument, you should pass the same ``stream`` argument to this capture.

    .. warning::
        This API is in beta and may change in future releases.

    .. _cudaStreamCaptureMode:
        https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g9d0535d93a214cbf126835257b16ba85

    Each graphed callable's forward pass runs its source callable's
    forward CUDA work as a CUDA graph inside a single autograd node.

    The graphed callable's forward pass also appends
    a backward node to the autograd graph. During backward, this node runs the
    callable's backward work as a CUDA graph.

    Therefore, each graphed callable should be a drop-in replacement for its source callable
    in an autograd-enabled training loop.

    See :ref:`Partial-network capture<partial-network-capture>` for detailed use and constraints.

    If you pass a tuple of several callables, their captures will use the same memory pool.
    See :ref:`Graph memory management<graph-memory-management>` for when this is appropriate.

    Arguments:
        callables (torch.nn.Module or Python function, or tuple of these): Callable or callables to graph.
            See :ref:`Graph memory management<graph-memory-management>` for when passing a tuple of callables
            is appropriate.  If you pass a tuple of callables, their order in the tuple must be the same order
            they'll run in the live workload.
        sample_args (tuple of Tensors, or tuple of tuples of Tensors): Samples args for each callable.
            If a single callable was passed, ``sample_args`` must be a single tuple of argument Tensors.
            If a tuple of callables was passed, ``sample_args`` must be tuple of tuples of argument Tensors.
        num_warmup_iters (int): The number of warmup iterations. Currently, ``DataDistributedParallel`` needs
            11 iterations for warm up. Default: ``3``.
        allow_unused_input (bool): If False, specifying inputs that were not used when computing outputs
            (and therefore their grad is always zero) is an error. Defaults to False.

    .. note::
        The ``requires_grad`` state of each Tensor in ``sample_args`` must match the state
        that's expected for the corresponding real input in the training loop.

    .. warning::
        This API is in beta and may change in future releases.

    .. warning::
        ``sample_args`` for each callable must contain only Tensors. Other types are not allowed.

    .. warning::
        Returned callables do not support higher order differentiation (e.g., double backward).

    .. warning::
        In any :class:`~torch.nn.Module` passed to :func:`~make_graphed_callables`, only parameters
        may be trainable. Buffers must have ``requires_grad=False``.

    .. warning::
        After you pass a :class:`torch.nn.Module` through :func:`~make_graphed_callables`,
        you may not add or remove any of that Module's parameters or buffers.

    .. warning::
        :class:`torch.nn.Module`\s passed to :func:`~torch.cuda.make_graphed_callables` must not have module hooks
        registered on them at the time they are passed. However, registering hooks on modules *after* passing them
        through :func:`~torch.cuda.make_graphed_callables` is allowed.

    .. warning::
        When running a graphed callable, you must pass its arguments in the same order and format
        they appeared in that callable's ``sample_args``.

    .. warning::
        The automatic mixed precision is supported in :func:`~torch.cuda.make_graphed_callables` only with disabled
        caching. The context manager `torch.cuda.amp.autocast()` must have `cache_enabled=False`.

<END>

<START>
from functools import partial
import torch
import torch.nn.functional as F
from .expanded_weights_impl import implements_per_sample_grads
from .expanded_weights_utils import \
    forward_helper, set_grad_sample_if_exists, standard_kwargs, unpack_expanded_weight_or_tensor
from typing import List, Optional

@implements_per_sample_grads(F.instance_norm)
class InstanceNormPerSampleGrad(torch.autograd.Function):
    @staticmethod
    def forward(ctx, kwarg_names, _, *expanded_args_and_kwargs):
        instance_norm = partial(torch.instance_norm, cudnn_enabled=True)
        expanded_args, expanded_kwargs = standard_kwargs(kwarg_names, expanded_args_and_kwargs)
        output = forward_helper(instance_norm, expanded_args, expanded_kwargs)
        ctx.input = expanded_args[0]
        ctx.running_mean, ctx.running_var = expanded_kwargs['running_mean'], expanded_kwargs['running_var']
        ctx.weight, ctx.bias, ctx.eps = expanded_kwargs['weight'], expanded_kwargs['bias'], expanded_kwargs['eps']
        return output


    @staticmethod
    def backward(ctx, grad_output):
        input, running_mean, running_var = ctx.input, ctx.running_mean, ctx.running_var
        weight, bias, eps = ctx.weight, ctx.bias, ctx.eps

        results: List[Optional[torch.Tensor]] = []
        results.append(None)  # for kwarg names
        results.append(None)  # for op reference
        if input.requires_grad:
            b = input.shape[0]
            c = input.shape[1]
            new_shape = (1, b * c, *input.shape[2:])

            weight_ = unpack_expanded_weight_or_tensor(weight, lambda orig_weight: orig_weight.repeat(b))
            running_mean_ = running_mean.repeat(b) if running_mean is not None else None
            running_var_ = running_var.repeat(b) if running_var is not None else None
            input_reshaped = input.contiguous().view(new_shape)
            grad_output_reshaped = grad_output.contiguous().view(new_shape)
            mean = torch.mean(input_reshaped, (0,) + tuple(range(2, input.dim())), False)
            var = torch.var(input_reshaped, (0,) + tuple(range(2, input.dim())), keepdim=False, unbiased=False)
            rstd = 1 / torch.sqrt(var + eps)

            res = torch.ops.aten.native_batch_norm_backward(
                grad_output_reshaped, input_reshaped, weight_, running_mean_, running_var_,
                mean, rstd, True, eps, (True, False, False))
            results.append(res[0].reshape(input.shape))
        else:
            results.append(None)

        results = results + [None] * 7

        set_grad_sample_if_exists(weight,
                                  lambda _: torch.einsum("ni...->ni", F.instance_norm(input, eps=eps) * grad_output))
        set_grad_sample_if_exists(bias, lambda _: torch.einsum("ni...->ni", grad_output))
        return tuple(results)

<END>

<START>
import collections
import contextlib
import dataclasses
import functools
import inspect
import operator
import os
import re
from itertools import chain, count
from typing import Any, Dict, List, Optional, Set, Tuple, Union

import sympy
from sympy import Expr

import torch
from torch._dynamo.utils import counters, dynamo_timed
from torch._inductor.codecache import get_cpp_wrapper_cubin_path_name
from torch.fx.experimental.symbolic_shapes import free_unbacked_symbols, SymTypes

from torch.fx.node import _get_qualified_name
from torch.utils._sympy.singleton_int import SingletonInt

from .. import codecache, config, ir
from ..codecache import CudaKernelParamCache
from ..ir import ComputedBuffer, InputBuffer, ReinterpretView
from ..triton_heuristics import grid as default_grid
from ..utils import (
    cache_on_self,
    get_benchmark_name,
    LineContext,
    sympy_product,
    sympy_str,
)
from ..virtualized import V
from .common import CodeGen, DeferredLine, IndentedBuffer, PythonPrinter
from .triton_utils import config_of, signature_to_meta


pexpr = PythonPrinter().doprint


def buffer_reuse_key(node: ir.Buffer):
    return (
        node.get_device(),
        node.get_dtype(),
        sympy_str(V.graph.sizevars.simplify(node.layout.storage_size())),
    )


def is_int(s: str):
    if s and s[-1] == "L":
        s = s[:-1]
    try:
        int(s)
    except ValueError:
        return False
    except TypeError:
        return False
    return True


def is_float(s: str):
    try:
        float(s)
    except ValueError:
        return False
    return True


def convert_arg_type(arg: torch.Argument):
    from .cpp import CONTAINER_PYTHON_TO_CPP, PYTHON_TO_CPP

    python_type = repr(arg.real_type)  # type: ignore[attr-defined]

    if python_type == "Tensor":
        if arg.alias_info is not None and arg.alias_info.is_write:
            return f"at::{python_type}&"
        else:
            return f"at::{python_type} const&"

    if python_type in PYTHON_TO_CPP:
        cpp_type = PYTHON_TO_CPP[python_type]
        return cpp_type

    for py_container, cpp_container in CONTAINER_PYTHON_TO_CPP.items():
        container_match = re.findall(py_container + r"\[([a-zA-Z_]+)]", python_type)
        if len(container_match) == 1:
            contained_type = container_match[0]
            assert (
                contained_type in PYTHON_TO_CPP
            ), f"unsupported {py_container} type in convert_arg_type: {contained_type}"
            cpp_contained_type = PYTHON_TO_CPP[contained_type]
            return f"{cpp_container}<{cpp_contained_type}>"

    raise AssertionError(f"unsupport python_type: {python_type}")


def convert_return_type(ret: torch.Argument):
    python_type = repr(ret.real_type)  # type: ignore[attr-defined]
    python_to_cpp = {
        "Tensor": "at::Tensor",
        "List[Tensor]": "std::vector<at::Tensor>",
    }

    cpp_type = python_to_cpp.get(python_type, None)
    assert cpp_type is not None, f"NYI return type: {python_type}"
    if python_type == "Tensor" and ret.alias_info is not None:
        cpp_type += "&"
    return cpp_type


def get_cpp_op_schema(kernel):
    args = kernel._schema.arguments
    returns = kernel._schema.returns

    num_returns = len(returns)
    assert num_returns > 0, "must have at least one return value"

    if num_returns == 1:
        cpp_return_value = convert_return_type(returns[0])
    elif num_returns > 1:
        tuple_returns = ", ".join([convert_return_type(r) for r in returns])
        cpp_return_value = f"std::tuple<{tuple_returns}>"

    cpp_arg_type = [f"{convert_arg_type(arg)} {arg.name}" for arg in args]
    return f"{cpp_return_value}({', '.join(cpp_arg_type)})"


def user_defined_kernel_grid_fn_code(name, configs, grids):
    output = IndentedBuffer()

    fn_name = f"grid_wrapper_for_{name}"
    output.writeline(f"def {fn_name}(meta):")
    with output.indent():
        if len(grids) == 1:
            output.writeline(f"return {grids[0]}")
        else:
            assert len(grids) > 1
            assert len(grids) == len(configs)
            seen = set()
            for grid, c in zip(grids, configs):
                guards = [f"meta['{name}'] == {val}" for name, val in c.kwargs.items()]
                guards = " and ".join(guards)
                statement = f"if {guards}: return {grid}"
                if statement in seen:
                    continue
                seen.add(statement)
                output.writeline(statement)

    return fn_name, output.getvalue()


@dataclasses.dataclass
class SymbolicCallArg:
    inner: Any
    inner_expr: sympy.Expr

    def __str__(self):
        return str(self.inner)


MAX_STACK_ALLOCATION_SIZE = 1024 * 100


class MemoryPlanningState:
    def __init__(self):
        super().__init__()
        self.reuse_pool: Dict[Any, List[FreeIfNotReusedLine]] = collections.defaultdict(
            list
        )
        self.total_allocated_buffer_size: int = 0

    def __contains__(self, key):
        return bool(self.reuse_pool.get(key, None))

    def pop(self, key) -> "FreeIfNotReusedLine":
        item = self.reuse_pool[key].pop()
        assert not item.is_reused
        return item

    def push(self, key, item: "FreeIfNotReusedLine"):
        assert not item.is_reused
        self.reuse_pool[key].append(item)


@dataclasses.dataclass
class EnterDeviceContextManagerLine:
    device_idx: int
    last_seen_device_guard_index: Optional[int]

    def codegen(self, code: IndentedBuffer, device_cm_stack: contextlib.ExitStack):
        if V.graph.cpp_wrapper:
            code.writeline("\n")
            if V.graph.aot_mode:
                if self.last_seen_device_guard_index is None:
                    if config.aot_inductor.abi_compatible:
                        code.writeline(
                            "AOTICudaStreamGuard stream_guard(stream, this->device_idx_);"
                        )
                    else:
                        code.writeline(
                            "at::cuda::CUDAStreamGuard stream_guard("
                            + "at::cuda::getStreamFromExternal(stream, this->device_idx_));"
                        )
                else:
                    assert (
                        self.last_seen_device_guard_index == self.device_idx
                    ), "AOTInductor only supports running on one CUDA device"
            else:
                if self.last_seen_device_guard_index is None:
                    code.writeline(
                        f"at::cuda::CUDAGuard device_guard({self.device_idx});"
                    )
                else:
                    code.writeline(f"device_guard.set_index({self.device_idx});")
        else:
            code.writeline(f"with {V.graph.device_ops.device_guard(self.device_idx)}:")
            device_cm_stack.enter_context(code.indent())
            code.writeline(V.graph.device_ops.set_device(self.device_idx))


class ExitDeviceContextManagerLine:
    def codegen(self, code: IndentedBuffer, device_cm_stack: contextlib.ExitStack):
        if not V.graph.cpp_wrapper:
            device_cm_stack.close()


@dataclasses.dataclass
class MemoryPlanningLine:
    wrapper: "WrapperCodeGen"

    def plan(self, state: MemoryPlanningState) -> "MemoryPlanningLine":
        pass

    def __str__(self):
        args: List[str] = []
        for field in dataclasses.fields(self):
            if field.name == "wrapper":
                continue
            val = getattr(self, field.name)
            args.append(
                f"{field.name}={val.get_name() if field.type is ir.Buffer else val}"
            )
        return f"{type(self).__name__}({', '.join(args)})"


@dataclasses.dataclass
class AllocateLine(MemoryPlanningLine):
    node: ir.Buffer

    def plan(self, state: MemoryPlanningState):
        if self.node.get_name() in V.graph.removed_buffers:
            return NullLine(self.wrapper)

        key = buffer_reuse_key(self.node)
        if config.allow_buffer_reuse and key in state:
            free_line = state.pop(key)
            free_line.is_reused = True
            return ReuseLine(self.wrapper, free_line.node, self.node)

        if self.node.get_device().type == "cpu":
            static_shape = self.wrapper.static_shape_for_buffer_or_none(self.node)
            if static_shape is not None:
                state.total_allocated_buffer_size += int(
                    functools.reduce(operator.mul, static_shape, 1)
                )

        return self

    def codegen(self, code: IndentedBuffer):
        assert self.node.get_name() not in V.graph.removed_buffers
        line = self.wrapper.make_buffer_allocation(self.node)
        code.writeline(line)


@dataclasses.dataclass
class FreeIfNotReusedLine(MemoryPlanningLine):
    node: ir.Buffer
    is_reused: bool = False

    def plan(self, state: MemoryPlanningState):
        if isinstance(self.node.layout, (ir.AliasedLayout, ir.MultiOutputLayout)):
            return self
        assert not self.is_reused
        if self.node.get_name() in V.graph.removed_buffers:
            return NullLine(self.wrapper)
        if config.allow_buffer_reuse:
            state.push(buffer_reuse_key(self.node), self)
        return self

    def codegen(self, code: IndentedBuffer):
        assert self.node.get_name() not in V.graph.removed_buffers
        if not self.is_reused:
            code.writeline(self.wrapper.make_buffer_free(self.node))


@dataclasses.dataclass
class ReuseLine(MemoryPlanningLine):
    node: ir.Buffer
    reused_as: ir.Buffer
    delete_old: bool = True

    def plan(self, state: MemoryPlanningState):
        if self.node.get_name() in V.graph.removed_buffers:
            assert self.reused_as.get_name() in V.graph.removed_buffers
            return NullLine(self.wrapper)
        assert self.reused_as.get_name() not in V.graph.removed_buffers
        return self

    def codegen(self, code: IndentedBuffer):
        assert self.node.get_name() not in V.graph.removed_buffers
        assert self.reused_as.get_name() not in V.graph.removed_buffers
        code.writeline(
            self.wrapper.make_buffer_reuse(self.node, self.reused_as, self.delete_old)
        )


class NullLine(MemoryPlanningLine):
    pass


class WrapperCodeGen(CodeGen):

    def __init__(self):
        super().__init__()
        self._names_iter = count()
        self.header = IndentedBuffer()
        self.prefix = IndentedBuffer()
        self.suffix = IndentedBuffer()
        self.wrapper_call = IndentedBuffer()
        self.src_to_kernel = {}
        self.kenel_numel_expr = set()
        self.lines = []
        self.declare = ""
        self.declare_maybe_reference = ""
        self.ending = ""
        self.open_bracket = "["
        self.closed_bracket = "]"
        self.comment = "#"
        self.namespace = ""
        self.none_str = "None"
        self.size = "size()"
        self.stride = "stride()"
        self.last_seen_device_guard_index = None
        self.supports_intermediate_hooks = True
        self.expr_printer = pexpr
        self.user_defined_kernel_cache: Dict[Tuple[Any, ...], str] = {}
        self.unbacked_symbol_decls = set()
        self.allow_stack_allocation = None
        self.stack_allocated_buffers = {}

        self.write_header()
        self.write_prefix()

        if not V.graph.aot_mode:
            for name, hashed in V.graph.constant_reprs.items():
                self.write_constant(name, hashed)

        self.allocated = set()
        self.freed: Set[str] = set()

        self.reuses = dict()

        self.write_get_raw_stream = functools.lru_cache(None)(  # type: ignore[assignment]
            self.write_get_raw_stream
        )

        @functools.lru_cache(None)
        def add_import_once(line):
            self.header.writeline(line)

        self.add_import_once = add_import_once
        self._metas = {}

    def write_constant(self, name, hashed):
        self.header.writeline(f"{name} = None  # {hashed}")

    def write_header(self):
        self.header.splice(
        )

    @cache_on_self
    def write_triton_header_once(self):
        self.header.splice(
                V.graph.device_ops.import_get_raw_stream_as("get_raw_stream")
            )
        )

    def add_meta_once(self, meta):
        meta = repr(meta)
        if meta not in self._metas:
            var = f"meta{len(self._metas)}"
            self._metas[meta] = var
            self.header.writeline(f"{var} = {meta}")
        return self._metas[meta]

    @cache_on_self
    def get_output_refs(self):
        return [x.codegen_reference(self.wrapper_call) for x in V.graph.graph_outputs]

    def mark_output_type(self):
        return

    def codegen_input_size_asserts(self):
        for name, buf in V.graph.graph_inputs.items():
            if isinstance(buf, sympy.Expr):
                continue

            if sympy_product(buf.get_size()) == 0:
                continue
            size = self.codegen_shape_tuple(buf.get_size())
            stride = self.codegen_shape_tuple(buf.get_stride())
            self.prefix.writeline(f"assert_size_stride({name}, {size}, {stride})")

    def write_prefix(self):
        self.prefix.splice(
        )
        with self.prefix.indent():
            if config.triton.debug_sync_graph:
                self.prefix.writeline(V.graph.device_ops.synchronize())
            inp_len = len(V.graph.graph_inputs.keys())
            if inp_len != 0:

        @functools.lru_cache(None)
        def sizeof(name):
            self.codegen_input_size_var_decl(code, name)
            return f"{name}_size"

        @functools.lru_cache(None)
        def strideof(name):
            self.codegen_input_stride_var_decl(code, name)
            return f"{name}_stride"

        needed = V.graph.sizevars.free_symbols()

        def is_expr(x):
            return isinstance(x[1], sympy.Expr)

        graph_inputs_expr = list(filter(is_expr, graph_inputs.items()))
        graph_inputs_tensors = list(
            filter(lambda x: not is_expr(x), graph_inputs.items())
        )

        for name, shape in graph_inputs_expr:
            shape = V.graph.sizevars.simplify(shape)
            if shape in needed:
                needed.remove(shape)
                code.writeline(f"{self.declare}{shape} = {name}{self.ending}")

        for name, value in graph_inputs_tensors:
            shapes = value.get_size()
            for dim, shape in enumerate(shapes):
                shape = V.graph.sizevars.simplify(shape)
                if shape in needed:
                    needed.remove(shape)
                    code.writeline(
                        f"{self.declare}{shape} = {sizeof(name)}[{dim}]{self.ending}"
                    )

        for name, value in graph_inputs_tensors:
            shapes = value.get_stride()
            for dim, shape in enumerate(shapes):
                shape = V.graph.sizevars.simplify(shape)
                if shape in needed:
                    needed.remove(shape)
                    code.writeline(
                        f"{self.declare}{shape} = {strideof(name)}[{dim}]{self.ending}"
                    )

    def append_precomputed_sizes_to_prefix(self):
        with self.prefix.indent():
            for sym, expr in V.graph.sizevars.inv_precomputed_replacements.items():
                self.prefix.writeline(
                    f"{self.declare}{sym} = {self.expr_printer(expr)}{self.ending}"
                )

    def finalize_prefix(self):
        pass

    def codegen_python_sizevar(self, x: Expr) -> str:
        return pexpr(V.graph.sizevars.simplify(x))

    def codegen_sizevar(self, x: Expr) -> str:
        return self.codegen_python_sizevar(x)

    def codegen_tuple_access(self, basename: str, name: str, index: str) -> str:
        return f"{basename}[{index}]"

    def codegen_python_shape_tuple(self, shape: Tuple[Expr, ...]) -> str:
        parts = list(map(self.codegen_python_sizevar, shape))
        if len(parts) == 0:
            return "()"
        if len(parts) == 1:
            return f"({parts[0]}, )"
        return f"({', '.join(parts)})"

    def codegen_shape_tuple(self, shape: Tuple[Expr, ...]) -> str:
        return self.codegen_python_shape_tuple(shape)

    def codegen_alloc_from_pool(self, name, offset, dtype, shape, stride) -> str:
        return "alloc_from_pool({})".format(
            ", ".join(
                [
                    name,
                    pexpr(offset),  # bytes not numel
                    str(dtype),
                    self.codegen_shape_tuple(shape),
                    self.codegen_shape_tuple(stride),
                ]
            )
        )

    def codegen_reinterpret_view(self, data, size, stride, offset, writer) -> str:
        size = self.codegen_shape_tuple(size)
        stride = self.codegen_shape_tuple(stride)
        offset = self.codegen_sizevar(offset)
        return f"reinterpret_tensor({data.get_name()}, {size}, {stride}, {offset})"

    def codegen_device_copy(self, src, dst):
        self.writeline(f"{dst}.copy_({src})")

    def codegen_multi_output(self, name, value):
        self.writeline(f"{self.declare}{name} = {value}{self.ending}")

    def codegen_dynamic_scalar(self, node):
        (data,) = (t.codegen_reference() for t in node.inputs)
        if node.is_bool:
            self.writeline(f"{node.sym} = 1 if {data}.item() else 0")
        else:
            self.writeline(f"{node.sym} = {data}.item()")
        self.writeline(f"{node.get_name()} = None")

    def benchmark_compiled_module(self, output):
        def add_fake_input(name, shape, stride, device, dtype):
            output.writeline(
                f"{name} = rand_strided("
                f"{self.codegen_python_shape_tuple(shape)}, "
                f"{self.codegen_python_shape_tuple(stride)}, "
                f"device='{device}', dtype={dtype})"
            )

        def add_expr_input(name, val):
            output.writeline(f"{name} = {val}")

        output.writelines(
            ["", "", "def benchmark_compiled_module(times=10, repeat=10):"]
        )
        with output.indent():
            output.splice(
                strip=True,
            )

            for name, value in V.graph.constants.items():
                output.writeline(f"global {name}")
                add_fake_input(
                    name, value.size(), value.stride(), value.device, value.dtype
                )

            for name, value in V.graph.graph_inputs.items():
                if isinstance(value, sympy.Symbol) and isinstance(
                    V.graph.sizevars.var_to_val.get(value, None), SingletonInt
                ):
                    continue
                if isinstance(value, sympy.Expr):  # Don't need to add symbolic
                    add_expr_input(name, V.graph.sizevars.size_hint(value))
                else:
                    shape = [V.graph.sizevars.size_hint(x) for x in value.get_size()]
                    stride = [V.graph.sizevars.size_hint(x) for x in value.get_stride()]
                    add_fake_input(
                        name, shape, stride, value.get_device(), value.get_dtype()
                    )

            call_str = f"call([{', '.join(V.graph.graph_inputs.keys())}])"
            output.writeline(f"fn = lambda: {call_str}")
            output.writeline("return print_performance(fn, times=times, repeat=repeat)")

    def add_benchmark_harness(self, output):
        if not config.benchmark_harness:
            return

        self.benchmark_compiled_module(output)

        output.writelines(["", "", 'if __name__ == "__main__":'])
        with output.indent():
            output.writelines(
                [
                    "from torch._inductor.wrapper_benchmark import compiled_module_main",
                    f"compiled_module_main('{get_benchmark_name()}', benchmark_compiled_module)",
                ]
            )

    def define_kernel(
        self, name: str, kernel: str, metadata: Optional[str] = None, cuda=True
    ):
        metadata_comment = f"{metadata}\n" if metadata else ""
        self.header.splice(f"\n\n{metadata_comment}{name} = {kernel}")

    def define_user_defined_triton_kernel(self, kernel, configs, kwargs):
        original_name = kernel.__name__

        cache_key = [id(kernel.fn)]
        for arg in kwargs.values():
            if isinstance(arg, (ir.Buffer, ir.ReinterpretView)):
                cache_key.append(arg.get_dtype())
            elif len(configs) > 0:
                cache_key.append(arg)
        cache_key = tuple(cache_key)

        if cache_key in self.user_defined_kernel_cache:
            return self.user_defined_kernel_cache[cache_key]

        name = f"{original_name}_{len(self.user_defined_kernel_cache)}"
        self.user_defined_kernel_cache[cache_key] = name

        compile_wrapper = IndentedBuffer()
            import triton
            import triton.language as tl
            from torch._inductor.utils import instance_descriptor
            from torch._inductor.triton_heuristics import user_autotune
            @user_autotune(
                configs={configs!r},
                inductor_meta={inductor_meta!r},
                triton_meta={triton_meta!r},
                filename=__file__
            )
            @triton.jit
        _, lineno = inspect.getsourcelines(kernel.fn)
        srcfile = inspect.getsourcefile(kernel.fn)
        metadata = f"# Original path: {srcfile}:{lineno}"
        self.define_kernel(
            name,
            compile_wrapper.getvalue(),
            metadata,
        )
        return name

    def generate_numel_expr(self, kernel_name: str, tree):
        expr = f"{kernel_name}_{tree.prefix}numel"
        if expr not in self.kenel_numel_expr:
            self.kenel_numel_expr.add(expr)
            self.writeline(
                f"{self.declare}{expr} = {self.expr_printer(tree.numel)}{self.ending}"
            )
        else:
            self.writeline(f"{expr} = {self.expr_printer(tree.numel)}{self.ending}")
        return SymbolicCallArg(expr, tree.numel)

    def wrap_kernel_call(self, name, call_args):
        return f"{name}({', '.join(call_args)}){self.ending}"

    def generate_profiler_mark_wrapper_call(self, stack):
        self.wrapper_call.writeline("from torch.profiler import record_function")
        self.wrapper_call.writeline(
            f"with record_function('graph_{V.graph.graph_id}_inductor_wrapper_call'):"
        )
        stack.enter_context(self.wrapper_call.indent())

    def generate_start_graph(self):
        self.wrapper_call.writeline("start_graph()")

    def generate_end_graph(self):
        self.wrapper_call.writeline("end_graph()")

    def generate_default_grid(self, name: str, grid_args: List[Any]):
        return grid_args

    def generate_kernel_call(
        self,
        name,
        call_args,
        grid=None,
        device_index=None,
        cuda=True,
        triton=True,
    ):
        if cuda:
            call_args_str = ", ".join(pexpr(item) for item in call_args)
            stream_name = self.write_get_raw_stream(
                V.graph.scheduler.current_device.index
            )
            if triton:
                grid_str = ", ".join(pexpr(item) for item in grid)
                self.writeline(
                    f"{name}.run({call_args_str}, grid=grid({grid_str}), stream={stream_name})"
                )
            else:
                stream_ptr = f"c_void_p({stream_name})"
                self.writeline(f"{name}.{name}({call_args_str}, {stream_ptr})")
        else:
            self.writeline(self.wrap_kernel_call(name, call_args))

    def writeline(self, line):
        self.lines.append(line)

    def enter_context(self, ctx):
        self.lines.append(LineContext(ctx))

    def val_to_cpp_arg_str(self, type_, val, is_legacy_abi) -> str:
        raise NotImplementedError()

    def val_to_arg_str(self, s):
        if isinstance(s, SymTypes):
            return pexpr(sympy.expand(repr(s)))
        elif isinstance(s, sympy.Expr):
            return pexpr(s)
        elif isinstance(s, (tuple, list)):

            @dataclasses.dataclass
            class Shim:
                ref: Any

                def __repr__(self):
                    return self.ref

            return repr(type(s)(Shim(self.val_to_arg_str(a)) for a in s))
        elif isinstance(s, torch._ops.OpOverload):
            return _get_qualified_name(s)
        elif isinstance(s, (ComputedBuffer, InputBuffer, ReinterpretView)):
            return s.codegen_reference()
        else:
            return repr(s)

    def make_buffer_allocation(self, buffer):
        device = buffer.get_device()
        dtype = buffer.get_dtype()
        shape = tuple(buffer.get_size())
        stride = tuple(buffer.get_stride())
        return self.make_allocation(buffer.get_name(), device, dtype, shape, stride)

    def make_allocation(self, name, device, dtype, shape, stride):
        try:
            expected = tuple(ir.make_contiguous_strides_for(shape))
        except Exception:  # cannot determine truth value of Relational
            expected = None
        if stride == expected:
            return (
                f"{name} = empty("
                f"{self.codegen_shape_tuple(shape)}, "
                f"device='{device.type}', dtype={dtype})"
            )
        else:
            return (
                f"{name} = empty_strided("
                f"{self.codegen_shape_tuple(shape)}, "
                f"{self.codegen_shape_tuple(stride)}, "
                f"device='{device.type}', dtype={dtype})"
            )

    def make_tensor_alias(self, new_name, old_name, comment=""):
        return f"{self.declare}{new_name} = {old_name}{self.ending}  {self.comment} {comment}"

    def make_buffer_free(self, buffer):
        return f"del {buffer.get_name()}"

    def make_free_by_names(self, names_to_del: List[str]):
        return f"del {', '.join(name for name in names_to_del)}"

    def codegen_exact_buffer_reuse(self, old_name: str, new_name: str, del_line: str):
        return f"{self.declare_maybe_reference}{new_name} = {old_name}{del_line}{self.ending}  {self.comment} reuse"

    def make_buffer_reuse(self, old, new, delete_old: bool):
        assert old.get_dtype() == new.get_dtype()
        old_name = old.get_name()
        new_name = new.get_name()
        del_line = ";"
        if old_name not in V.graph.get_output_names() and delete_old:
            del_line = f"; {self.make_buffer_free(old)}"

        if old.get_size() == new.get_size() and old.get_stride() == new.get_stride():
            if old_name in self.stack_allocated_buffers:
                self.stack_allocated_buffers[new_name] = new
            return self.codegen_exact_buffer_reuse(old_name, new_name, del_line)

        reinterpret_view = self.codegen_reinterpret_view(
            old, new.get_size(), new.get_stride(), 0, self.wrapper_call
        )
        if reinterpret_view in self.stack_allocated_buffers:
            self.stack_allocated_buffers[new_name] = new
        return f"{self.declare_maybe_reference}{new_name} = {reinterpret_view}{del_line}  {self.comment} reuse"

    def codegen_deferred_allocation(self, name, layout):
        self.writeline(
            DeferredLine(
                name,
                f"{self.declare_maybe_reference}{name} = {layout.view.codegen_reference()}{self.ending}  "
                f"{self.comment} alias",
            )
        )

    def codegen_allocation(self, buffer):
        assert (
            buffer.get_workspace_size() == 0
        ), "Only support zero workspace size for now!"

        name = buffer.get_name()

        if name in V.graph.removed_buffers or name in self.allocated:
            return
        self.allocated.add(name)
        if isinstance(
            buffer,
            (ir.ExternKernelAlloc, ir.MultiOutput),
        ):
            return

        layout = buffer.get_layout()
        if isinstance(layout, ir.MutationLayout):
            return
        if isinstance(layout, ir.AliasedLayout):
            assert isinstance(
                layout.view, ir.ReinterpretView
            ), f"unexpected {type(layout.view)}: {layout.view}"
            self.codegen_allocation(layout.view.data)
            self.codegen_deferred_allocation(name, layout)
            return

        self.writeline(AllocateLine(self, buffer))

    def codegen_free(self, buffer):
        assert (
            buffer.get_workspace_size() == 0
        ), "Only support zero workspace size for now!"

        name = buffer.get_name()

        if isinstance(buffer, ir.InputBuffer):
            self.writeline(self.make_buffer_free(buffer))
            return

        if not self.can_reuse(buffer):
            return
        self.freed.add(name)

        self.writeline(FreeIfNotReusedLine(self, buffer))

    def can_reuse(self, input_buffer, output_buffer=None):
        name = input_buffer.get_name()
        if (
            name in V.graph.removed_buffers
            or name in V.graph.graph_inputs
            or name in V.graph.constants
            or name in V.graph.never_reuse_buffers
            or name in self.freed
        ):
            return False

        return True

    def did_reuse(self, buffer, reused_buffer):
        return (
            buffer.get_name() in self.reuses
            and self.reuses[buffer.get_name()] == reused_buffer.get_name()
        )

    def codegen_inplace_reuse(self, input_buffer, output_buffer):
        assert buffer_reuse_key(input_buffer) == buffer_reuse_key(output_buffer)
        self.codegen_allocation(input_buffer)
        self.freed.add(input_buffer.get_name())
        self.allocated.add(output_buffer.get_name())
        self.reuses[output_buffer.get_name()] = input_buffer.get_name()
        self.writeline(ReuseLine(self, input_buffer, output_buffer))

    def codegen_unbacked_symbol_decl(self, symbol):
        name = str(symbol)
        if name in self.unbacked_symbol_decls:
            return name
        else:
            self.unbacked_symbol_decls.add(name)
            return self.declare + name

    @staticmethod
    def statically_known_int_or_none(x):
        try:
            val = V.graph._shape_env._maybe_evaluate_static(x)
            return int(x)
        except Exception:
            return None

    @staticmethod
    def statically_known_list_of_ints_or_none(lst):
        result = []
        for x in lst:
            num = WrapperCodeGen.statically_known_int_or_none(x)
            if num is None:
                return None
            result.append(num)
        return result

    @staticmethod
    def is_statically_known_list_of_ints(lst):
        return WrapperCodeGen.statically_known_list_of_ints_or_none(lst) is not None

    @staticmethod
    def static_shape_for_buffer_or_none(buffer):
        return WrapperCodeGen.statically_known_list_of_ints_or_none(buffer.get_size())

    @staticmethod
    def can_prove_buffer_has_static_shape(buffer):
        return WrapperCodeGen.static_shape_for_buffer_or_none(buffer) is not None


class CppWrapperCodeGen(WrapperCodeGen):

    def __init__(self):
        super().__init__()

        self.declare = "auto "
        self.declare_maybe_reference = "decltype(auto) "
        self.ending = ";"
        self.open_bracket = "{"
        self.closed_bracket = "}"
        self.comment = "//"
        self.namespace = "at::"
        self.none_str = "at::Tensor()"
        self.extern_call_ops = set()
        self.size = "sizes()"
        self.stride = "strides()"
        self.call_func_name = "inductor_entry_cpp"
        self.cuda = False
        self.supports_intermediate_hooks = False
        self.outputs_need_copy = set()
        self.kernel_callsite_id = count()
        self.int_array_id = count()  # for int array local variable declarations
        self.declared_int_array_vars = set()
        self.tmp_tensor_id = count()  # for tmp tensor local variable declarations
        self.arg_var_id = count()
        self.used_cached_dtypes = set()
        self.cached_output_id = count()

        from .cpp import cexpr, CppPrinter

        self.expr_printer = cexpr

        class GridExprCppPrinter(CppPrinter):
            def _print_FloorDiv(self, expr):
                x, div = expr.args
                x = self.paren(self.doprint(x))
                div = self.paren(self.doprint(div))
                assert expr.is_integer, "Expect integers in GridExprPrinter"
                return f"({x}/{div})"

        self.grid_expr_printer = GridExprCppPrinter().doprint

    def generate_kernel_call(
        self,
        name,
        call_args,
        grid=None,
        device_index=None,
        cuda=True,
        triton=True,
    ):
        if cuda:
            return super().generate_kernel_call(
                name, call_args, grid, device_index, cuda, triton
            )
        else:
            if V.graph.aot_mode and config.aot_inductor.abi_compatible:
                from .cpp import DTYPE_TO_CPP

                new_args = []
                for arg in call_args:
                    var_name = f"var_{next(self.arg_var_id)}"
                    self.writeline(f"auto* {var_name} = get_data_ptr_wrapper({arg});")
                    dtype = V.graph.get_dtype(arg)
                    cpp_dtype = DTYPE_TO_CPP[dtype]
                    new_args.append(f"({cpp_dtype}*)({var_name})")
                self.writeline(self.wrap_kernel_call(name, new_args))
            else:
                self.writeline(self.wrap_kernel_call(name, call_args))

    def write_constant(self, name, hashed):
        self.header.writeline(f"// {name} {hashed}")

    def write_header(self):
        if V.graph.aot_mode:
            for header_cpp_file in ("interface.cpp", "implementation.cpp"):
                with open(
                    os.path.join(
                        os.path.dirname(__file__), "aoti_runtime", header_cpp_file
                    )
                ) as f:
                    self.header.splice(f.read())
        else:
            self.header.splice(

            [[maybe_unused]] static int64_t align(int64_t nbytes) {{
              return (nbytes + {ALIGN_BYTES} - 1) & -{ALIGN_BYTES};
            }}

    @staticmethod
    def get_input_cpp_type(input):
        assert config.use_minimal_arrayref_interface
        from .cpp import DTYPE_TO_CPP

        if isinstance(input, sympy.Expr):
            from ..graph import may_get_constant_buffer_dtype

            dtype = may_get_constant_buffer_dtype(input)
            assert dtype is not None, f"Failed to get the dtype of sympy.Expr: {input}"
            return DTYPE_TO_CPP[dtype]
        return f"ArrayRefTensor<{DTYPE_TO_CPP[input.get_dtype()]}>"

    def write_wrapper_decl(self):
        inputs_len = len(V.graph.graph_inputs.keys())
        if V.graph.aot_mode:
            if config.use_minimal_arrayref_interface:
                from .cpp import DTYPE_TO_CPP

                input_cpp_types = ", ".join(
                    f"{CppWrapperCodeGen.get_input_cpp_type(x)}"
                    for x in V.graph.graph_inputs.values()
                )

                output_arrayref_types = ", ".join(
                    f"ArrayRefTensor<{DTYPE_TO_CPP[x.get_dtype()]}>"
                    for x in V.graph.graph_outputs
                )

                self.prefix.splice(
                )

            if config.use_minimal_arrayref_interface:
                self.prefix.splice(
                )
                self.suffix.splice(run_impl_proto)
                self.suffix.splice(
                )

                self.suffix.splice(
                )
            else:
                self.prefix.splice(run_impl_proto)
        else:
            self.prefix.splice(
                                auto inputs = steal_from_raw_handles_to_raii_handles(input_handles, num_inputs());
                                auto inputs = alloc_tensors_by_stealing_from_handles(input_handles, num_inputs());
                            py::gil_scoped_release release;
                        )
                    else:
                        self.prefix.writeline(
                            f"auto {constants_key} = *tensor_handle_to_tensor_pointer("
        // Generated code example
        AOTInductorModel::AOTInductorModel()
            : AOTInductorModelBase(4, 1) {
        inputs_info_[0].name = "input0";
        inputs_info_[0].dtype = "torch.float16";
        ...
        constants_info_[0].name = "L__self___weight";
        constants_info_[0].dtype = at::kFloat;
        constants_info_[0].offset = 0;
        constants_info_[0].data_size = 8192;
        constants_info_[0].shape = {64, 32};
        constants_info_[0].stride = {32, 1};
        ...
        outputs_info_[0].name = "output0";
        outputs_info_[0].dtype = "torch.float16";
        }
            AOTInductorModel::AOTInductorModel(std::shared_ptr<ConstantMap> constants_map,
                                               std::shared_ptr<std::vector<ConstantHandle>> constants_array,
                                               std::optional<std::string> cubin_dir)
                : AOTInductorModelBase({num_inputs}, {num_outputs}, {num_constants}, cubin_dir) {{
                self.prefix.writeline(
                    f"constants_info_[{idx}].dtype = static_cast<int32_t>({self.codegen_dtype(tensor.dtype)});"
                )
                self.prefix.writeline(
                    f"constants_info_[{idx}].offset = {tensor.storage_offset()};"
                )
                self.prefix.writeline(
                    f"constants_info_[{idx}].data_size = {tensor.untyped_storage().nbytes()};"
                )

                size_str = ", ".join([str(s) for s in tensor.size()])
                self.prefix.writeline(f"constants_info_[{idx}].shape = {{{size_str}}};")

                stride_str = ", ".join([str(s) for s in tensor.stride()])
                self.prefix.writeline(
                    f"constants_info_[{idx}].stride = {{{stride_str}}};"
                )

            self.prefix.writeline("update_constants_map(std::move(constants_map));")
            self.prefix.writeline("update_constants_array(std::move(constants_array));")

            def escape_string(x):
                return (
                    x.replace("\\", "\\\\")
                    .replace('"', '\\"')
                    .replace("\n", "\\n")
                    .replace("\t", "\\t")
                )

            self.prefix.writeline(
                f'in_spec_ = "{escape_string(config.aot_inductor.serialized_in_spec)}";'
            )
            self.prefix.writeline(
                f'out_spec_ = "{escape_string(config.aot_inductor.serialized_out_spec)}";'
            )

            for idx, output in enumerate(V.graph.graph_outputs):
                assert not isinstance(
                    output, sympy.Expr
                ), f"output {name=} cannot be symbolic"
                name = f"output{idx}"
                self.write_input_output_info("outputs_info_", idx, name)

            self.prefix.writeline(
                "this->kernels_ = std::make_unique<AOTInductorModelKernels>();"
            )

        self.prefix.writeline("}")

    def generate(self, is_inference):
        if V.graph.aot_mode:
            self.codegen_model_kernels()
            self.codegen_model_constructor()
        self.write_wrapper_decl()
        return super().generate(is_inference)

    def finalize_prefix(self):
        cached_dtypes_buffer = IndentedBuffer()
        if config.aot_inductor.abi_compatible:
            for dtype in self.used_cached_dtypes:
                cached_dtypes_buffer.writeline(f"CACHE_TORCH_DTYPE({dtype});")
        cached_dtypes_buffer.splice(self.prefix)
        self.prefix = cached_dtypes_buffer

    def define_kernel(
        self, name: str, kernel: str, metadata: Optional[str] = None, cuda=False
    ):
        self.header.splice(f"\n{kernel}\n")

    def generate_return(self, output_refs):
        if V.graph.aot_mode:
            cst_names = V.graph.constants.keys()
            arr_iface = config.use_minimal_arrayref_interface  # For brevity.

            def use_thread_local_cached_output_tensor(idx, output):
                cached_output_name = f"cached_output_{next(self.cached_output_id)}"
                cache_type = "Array" if arr_iface else "Tensor"
                self.wrapper_call.writeline(
                    f"thread_local ThreadLocalCachedOutput{cache_type}<std::decay_t<decltype({output})>> "
                    f"{cached_output_name}({output});"
                )
                if arr_iface:
                    self.wrapper_call.writeline(
                        f"{cached_output_name}.copy_data_from({output});"
                    )
                    output_entry = f"std::get<{idx}>(output_arrayref_tensors)"
                    element_type = f"std::decay_t<decltype({output_entry}.data()[0])>"
                    self.wrapper_call.writeline(
                        f"{output_entry} = {cached_output_name}.arrayref_tensor<{element_type}>();"
                    )
                else:
                    self.wrapper_call.writeline(
                        f"{cached_output_name}.copy_data_from({output});"
                    )
                    self.wrapper_call.writeline(
                        f"AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_new_uninitialized_tensor(&output_handles[{idx}]));"
                    )
                    self.wrapper_call.writeline(
                        f"AOTI_TORCH_ERROR_CODE_CHECK(aoti_torch_assign_tensors({cached_output_name}.tensor(), "
                        f"output_handles[{idx}]));"
                    )

            if arr_iface:
                self.wrapper_call.writeline(
                    "AOTInductorModelOutputs output_arrayref_tensors;"
                )
            for idx, output in enumerate(output_refs):
                if config.aot_inductor.abi_compatible:
                    output_is_tensor_handle_expr = (
                        f"std::is_same_v<std::decay_t<decltype({output})>,"
                        "RAIIAtenTensorHandle> || "
                        f"std::is_same_v<std::decay_t<decltype({output})>,"
                        "AtenTensorHandle> || "
                        f"std::is_same_v<std::decay_t<decltype({output})>,"
                        "ConstantHandle>"
                    )
                    self.wrapper_call.writeline(
                        f"if constexpr ({output_is_tensor_handle_expr}) {{"
                    )
                    with self.wrapper_call.indent():
                        if config.use_minimal_arrayref_interface:
                            cached_output_name = (
                                f"cached_output_{next(self.cached_output_id)}"
                            )
                            output_value_type = f"std::decay_t<decltype(std::get<{idx}>(output_arrayref_tensors).data()[0])>"
                            self.wrapper_call.writeline(
                                f"thread_local RAIIAtenTensorHandle {cached_output_name};"
                            )
                            if output in cst_names:
                                self.wrapper_call.writeline(
                                    f"AtenTensorHandle {cached_output_name}_tmp;"
                                )
                                self.wrapper_call.writeline(
                                    f"aoti_torch_clone({output}, &{cached_output_name}_tmp);"
                                )
                                self.wrapper_call.writeline(
                                    f"{cached_output_name} = {cached_output_name}_tmp;"
                                )
                            else:
                                self.wrapper_call.writeline(
                                    f"{cached_output_name} = {output}.release();"
                                )
                            self.wrapper_call.writeline(
                                f"convert_handle_to_arrayref_tensor({cached_output_name}, "
                                f"std::get<{idx}>(output_arrayref_tensors));"
                            )
                        else:
                            if output in cst_names:
                                self.wrapper_call.writeline(
                                    f"aoti_torch_clone({output}, &output_handles[{idx}]);"
                                )
                            else:
                                self.wrapper_call.writeline(
                                    f"output_handles[{idx}] = {output}.release();"
                                )
                    self.wrapper_call.writeline("} else {")
                    with self.wrapper_call.indent():
                        use_thread_local_cached_output_tensor(idx, output)
                    self.wrapper_call.writeline("}")

                else:
                    assert (
                        not arr_iface
                    ), "minimal ArrayRef interface is only supported in ABI-compatible mode"
                    if output in cst_names:
                        output_expr = f"{output}.clone()"
                    else:
                        output_expr = output
                    self.wrapper_call.writeline(
                        f"output_handles[{idx}] = reinterpret_cast<AtenTensorHandle>("
                        + f"new at::Tensor({output_expr}));"
                    )
            if arr_iface:
                self.wrapper_call.writeline("return output_arrayref_tensors;")

        else:
            self.wrapper_call.writeline(f"return {{{', '.join(output_refs)}}};\n}}")

    def generate_before_suffix(self, result):
        if V.graph.aot_mode:
            result.writeline("} // AOTInductorModel::run_impl")

    def generate_end(self, result):
        if V.graph.aot_mode:
            result.writeline("} // namespace aot_inductor")
            result.writeline("} // namespace torch")
            return

            module = CppWrapperCodeCache.load(cpp_wrapper_src, '{self.call_func_name}', '{wrapper_call_hash}', {self.cuda})
                    outputs = f(args_tensor)
                    return {outputs_str}
                    constants_tensor = {constants_str}
                    args_tensor.extend(constants_tensor)
            def _wrap_func(f):
                def g(args):
                    {args_str}
                    {return_str}
                return g
            call = _wrap_func(module.{self.call_func_name})
    Generates cpp wrapper for running on GPU and calls CUDA kernels
            do {                                               \\
                CUresult code = EXPR;                          \\
                const char *msg;                               \\
                cuGetErrorString(code, &msg);                  \\
                if (code != CUDA_SUCCESS) {                    \\
                    throw std::runtime_error(                  \\
                        std::string("CUDA driver error: ") +   \\
                        std::string(msg));                     \\
                }                                              \\
            } while (0);

            namespace {

            struct Grid {
                Grid(uint32_t x, uint32_t y, uint32_t z)
                  : grid_x(x), grid_y(y), grid_z(z) {}
                uint32_t grid_x;
                uint32_t grid_y;
                uint32_t grid_z;

                bool is_non_zero() {
                    return grid_x > 0 && grid_y > 0 && grid_z > 0;
                }
            };

            }  // anonymous namespace

            static inline CUfunction loadKernel(
                    std::string filePath,
                    const std::string &funcName,
                    uint32_t sharedMemBytes,
                    const std::optional<std::string> &cubinDir = std::nullopt) {
                if (cubinDir) {
                    std::filesystem::path p1{*cubinDir};
                    std::filesystem::path p2{filePath};
                    filePath = (p1 / p2.filename()).string();
                }

                CUmodule mod;
                CUfunction func;
                CUDA_DRIVER_CHECK(cuModuleLoad(&mod, filePath.c_str()));
                CUDA_DRIVER_CHECK(cuModuleGetFunction(&func, mod, funcName.c_str()));
                if (sharedMemBytes > 0) {
                    CUDA_DRIVER_CHECK(cuFuncSetAttribute(
                        func,
                        CU_FUNC_ATTRIBUTE_MAX_DYNAMIC_SHARED_SIZE_BYTES,
                        sharedMemBytes
                    ))
                }
                return func;
            }

            static inline void launchKernel(
                    CUfunction func,
                    uint32_t gridX,
                    uint32_t gridY,
                    uint32_t gridZ,
                    uint32_t numWarps,
                    uint32_t sharedMemBytes,
                    void* args[],
                    cudaStream_t stream) {
                CUDA_DRIVER_CHECK(cuLaunchKernel(
                    func, gridX, gridY, gridZ, 32*numWarps, 1, 1, sharedMemBytes, stream, args, nullptr
                ));
            }
            )
            self.writeline("}")
        else:
            self.writeline(f"if ({name} == nullptr) {{")
            self.writeline(
        Generate grid configs for launching a CUDA kernel using the grid
        function from triton_heuristics.

<END>

<START>
import torch

from torch._export.db.case import export_case


@export_case(
    example_inputs=(torch.ones(3, 2, 2),),
    tags={"python.control-flow"},
)
class StaticIf(torch.nn.Module):

    def __init__(self):
        super().__init__()

    def forward(self, x):
        if len(x.shape) == 3:
            return x + torch.ones(1, 1, 1)

        return x

<END>

<START>
import torch
from torch.fx import Node
from torch.fx._compatibility import compatibility
from torch._subclasses.fake_tensor import FakeTensorMode, FakeTensor
from torch.utils._pytree import tree_map_only
from torch.utils import _pytree as pytree
from torch.multiprocessing.reductions import StorageWeakRef

import _operator
from enum import Enum
import itertools
from typing import Set, Dict
from collections import defaultdict

__all__ = ['reinplace']

class _ViewType(Enum):
    NonView = 0
    SingleOutputView = 1
    MultiOutputView = 2

def _is_view_op(tgt):
    if tgt is not None and isinstance(tgt, torch._ops.OpOverload):
        schema = tgt._schema
        if len(schema.arguments) > 0:
            first_arg = schema.arguments[0]
            return first_arg.alias_info is not None and not first_arg.alias_info.is_write

def _get_view_type(tgt) -> _ViewType:
    if tgt is not None and isinstance(tgt, torch._ops.OpOverload):
        schema = tgt._schema
        if len(schema.arguments) > 0:
            first_arg = schema.arguments[0]
            if first_arg.alias_info is not None and not first_arg.alias_info.is_write:
                if '*' in first_arg.alias_info.after_set:
                    return _ViewType.MultiOutputView
                else:
                    return _ViewType.SingleOutputView
    return _ViewType.NonView


@compatibility(is_backward_compatible=False)
class _FunctionalizationMetadataProp(torch.fx.Interpreter):

    def run_node(self, node: Node):
        self.node_counter += 1
        result = super().run_node(node)
        node.meta['fake_result'] = result
        node.meta['node_idx'] = self.node_counter

        node_args = node.args
        if node.target is torch.ops.aten.copy_.default:
            node_args = node_args[1:]

        if node.op == 'call_function':
            view_type = _get_view_type(node.target)
            if view_type == _ViewType.SingleOutputView:
                assert isinstance(node.args[0], Node)
                node.meta['view_of'] = node.args[0]
            elif view_type == _ViewType.MultiOutputView:
                self.multi_output_view_nodes[node] = node.args[0]

            elif node.target is _operator.getitem:
                list_arg = node.args[0]
                maybe_base_of_view = self.multi_output_view_nodes.get(list_arg, None)
                if maybe_base_of_view is not None:
                    assert isinstance(maybe_base_of_view, Node)
                    node.meta['view_of'] = maybe_base_of_view

        if 'view_of' in node.meta:
            assert isinstance(node.meta['fake_result'], FakeTensor)
            assert isinstance(node.meta['view_of'].meta['fake_result'], FakeTensor)
            view_storage = StorageWeakRef(node.meta['fake_result']._typed_storage())
            base_storage = StorageWeakRef(node.meta['view_of'].meta['fake_result']._typed_storage())
            assert view_storage == base_storage
        return result



    def propagate(self, *args):
        self.multi_output_view_nodes = {}
        self.node_counter = -1

        with FakeTensorMode() as mode:
            fake_args = [mode.from_tensor(a) for a in args]
            return super().run(*fake_args)

def _schemas_match(functional_schema, inplace_schema):
    names_match = inplace_schema.name.endswith("_") and inplace_schema.name[:-1] == functional_schema.name
    arg_types_match = len(functional_schema.arguments) == len(inplace_schema.arguments) and all(
        a1.type == a2.type for a1, a2 in zip(functional_schema.arguments, inplace_schema.arguments))
    assert inplace_schema.arguments[0].alias_info is not None and inplace_schema.arguments[0].alias_info.is_write
    assert all(a.alias_info is None for a in inplace_schema.arguments[1:])
    return names_match and arg_types_match

def _maybe_get_inplace_op(op):
    if not isinstance(op, torch._ops.OpOverload):
        return None
    if _is_view_op(op):
        return None
    op_namespace = op.__module__.split(".")[-1]
    op_base_name = op.overloadpacket.__name__
    maybe_namespace_module = getattr(torch.ops, op_namespace)
    maybe_inplace_op = None if maybe_namespace_module is None else getattr(maybe_namespace_module, f'{op_base_name}_', None)
    if maybe_inplace_op is None:
        return None

    inplace_overloads = [
        getattr(maybe_inplace_op, overload_name) for overload_name in maybe_inplace_op.overloads()
    ]
    inplace_overloads_with_matching_schemas = [
        f
        for f in inplace_overloads
        if _schemas_match(op._schema, f._schema)
    ]
    if len(inplace_overloads_with_matching_schemas) == 0:
        return None
    assert len(inplace_overloads_with_matching_schemas) == 1
    inplace_op = inplace_overloads_with_matching_schemas[0]
    return inplace_op

_VIEW_INVERSE_MAP = {
    torch.ops.aten.diagonal_scatter.default: torch.ops.aten.diagonal.default,
    torch.ops.aten.select_scatter.default: torch.ops.aten.select.int,
    torch.ops.aten.slice_scatter.default: torch.ops.aten.slice.Tensor,
    torch.ops.aten.as_strided_scatter.default: torch.ops.aten.as_strided.default,
}

def _get_all_later_node_usages(tensor_aliases: Set[Node], op_index: int):
    def _add_if_tensor(x, set_):
        if isinstance(x, FakeTensor):
            set_.add(StorageWeakRef(x._typed_storage()))

    nodes_used_after = set()
    for t in tensor_aliases:
        usage_nodes = t.users
        for n in usage_nodes:
            if 'node_idx' not in n.meta or n.meta['node_idx'] <= op_index:
                continue
            if n in tensor_aliases:
                if isinstance(n.target, torch._ops.OpOverload) or n.target == _operator.getitem:
                    continue
            nodes_used_after.add(n)
    return nodes_used_after

def _get_view_inverse_node_usages(later_node_usages: Set[Node], self_aliases: Set[Node]) -> Set[Node]:
    def matching_view_metadata(a, b):
        return a.size() == b.size() and \
            a.stride() == b.stride() and \
            a.storage_offset() == b.storage_offset()

    view_inverse_nodes = set()
    for n in sorted(later_node_usages, key=lambda x: x.meta['node_idx']):
        if n.target not in _VIEW_INVERSE_MAP:
            continue
        base = n.args[0]
        mutated_view = n.args[1]
        assert isinstance(base, Node)
        assert isinstance(base.meta['fake_result'], FakeTensor)
        assert isinstance(mutated_view, Node)
        assert isinstance(mutated_view.meta['fake_result'], FakeTensor)
        original_view = _VIEW_INVERSE_MAP[n.target]
        for self_alias in self_aliases:
            if 'view_of' not in self_alias.meta:
                continue
            self_alias_base = self_alias.meta['view_of']
            try:
                view_replay_metadata = original_view(self_alias_base.meta['fake_result'], *n.args[2:], **n.kwargs)
                expected_metadata = self_alias.meta['fake_result']
                if matching_view_metadata(self_alias_base.meta['fake_result'], base.meta['fake_result']) and \
                        matching_view_metadata(view_replay_metadata, expected_metadata):
                    view_inverse_nodes.add(n)
            except Exception:
                continue

    return view_inverse_nodes


@compatibility(is_backward_compatible=True)
def reinplace(gm, *sample_args):
    _FunctionalizationMetadataProp(gm).propagate(*sample_args)



    input_storages = {
        StorageWeakRef(
            node.meta['fake_result']._typed_storage()
        ) for node in gm.graph.nodes if node.op == 'placeholder'}


    storage_to_nodes: Dict[StorageWeakRef, Set[Node]] = defaultdict(set)
    for n in gm.graph.nodes:
        if 'fake_result' in n.meta:
            def _add_to_map(x):
                if isinstance(x, FakeTensor):
                    storage_to_nodes[StorageWeakRef(x._typed_storage())].add(n)
            pytree.tree_map_(_add_to_map, n.meta['fake_result'])

    all_later_view_inverse_nodes_to_delete = set()
    for idx, node in enumerate(gm.graph.nodes):
        if node.op == 'call_function':

            if not isinstance(node.target, torch._ops.OpOverload):
                continue
            if len(node.target._schema.arguments) < 1:
                continue
            if type(node.target._schema.arguments[0].type) != torch.TensorType:
                continue

            self_arg = node.args[0]
            self_flattened = pytree.tree_leaves(self_arg.meta['fake_result'])
            node_flattened = pytree.tree_leaves(node.meta['fake_result'])
            self_has_wrong_metadata = False
            if len(self_flattened) == len(node_flattened):
                for self_meta, node_meta in zip(self_flattened, node_flattened):
                    if self_meta.numel() != node_meta.numel():
                        self_has_wrong_metadata = True
                    if self_meta.dtype != node_meta.dtype:
                        self_has_wrong_metadata = True
                    if torch._debug_has_internal_overlap(self_meta) == 1:
                        self_has_wrong_metadata = True
            if self_has_wrong_metadata and node.target != torch.ops.aten.resize.default:
                continue

            self_arg_name = self_arg.name
            self_arg_storage = StorageWeakRef(self_arg.meta['fake_result']._typed_storage())
            if self_arg_storage in input_storages:
                continue
            if len([x for x in node.args if x is self_arg]) > 1:
                continue

            self_arg_storage = StorageWeakRef(self_arg.meta['fake_result']._typed_storage())
            self_aliases = storage_to_nodes[self_arg_storage]

            later_node_usages = _get_all_later_node_usages(self_aliases, node.meta['node_idx'])
            later_view_inverse_node_usages = _get_view_inverse_node_usages(later_node_usages, self_aliases)

            can_reinplace = len(later_node_usages - later_view_inverse_node_usages) == 0
            if not can_reinplace:
                continue

            if node.target in _VIEW_INVERSE_MAP and node not in all_later_view_inverse_nodes_to_delete:
                view_op = _VIEW_INVERSE_MAP[node.target]
                with gm.graph.inserting_before(node):
                    mutated_slice_node = node.args[1]
                    remaining_slice_args = node.args[2:]
                    slice_node = gm.graph.create_node(
                        'call_function', view_op, (self_arg,) + tuple(remaining_slice_args), node.kwargs)
                    copy_node = gm.graph.create_node(
                        'call_function', torch.ops.aten.copy_.default, (slice_node, mutated_slice_node,), {})
                all_later_view_inverse_nodes_to_delete.add(node)


            else:
                maybe_inplace_op = _maybe_get_inplace_op(node.target)
                if maybe_inplace_op is None:
                    continue
                node.target = maybe_inplace_op

            curr_node_storage = StorageWeakRef(node.meta['fake_result']._typed_storage())
            storage_to_nodes[self_arg_storage].update(storage_to_nodes[curr_node_storage])
            storage_to_nodes[curr_node_storage].update(storage_to_nodes[self_arg_storage])

            all_later_view_inverse_nodes_to_delete.update(later_view_inverse_node_usages)

            for old in itertools.chain([node], later_view_inverse_node_usages):
                new = old.args[0]
                nodes_to_update = [n for n in old.users if n.meta['node_idx'] > node.meta['node_idx']]
                for node_to_update in nodes_to_update:
                    new_args = []
                    args = node_to_update.args

                    def replace_arg(a):
                        if a == old:
                            return new
                        return a

                    node_to_update.args = tree_map_only(Node, replace_arg, node_to_update.args)
                    node_to_update.kwargs = tree_map_only(Node, replace_arg, node_to_update.kwargs)

                    old_flattened_res = pytree.tree_leaves(old.meta['fake_result'])
                    node_flattened_res = pytree.tree_leaves(node_to_update.meta['fake_result'])

                    old_res_storage = {
                        StorageWeakRef(
                            x._typed_storage()
                        ) for x in old_flattened_res if isinstance(x, FakeTensor)}
                    node_res_storage = {
                        StorageWeakRef(
                            x._typed_storage()
                        ) for x in node_flattened_res if isinstance(x, FakeTensor)}

                    if len(old_res_storage) == 1 and len(node_res_storage) == 1 and old_res_storage == node_res_storage:
                        new_flattened_res = pytree.tree_leaves(new.meta['fake_result'])
                        new_res_storage = {
                            StorageWeakRef(
                                x._typed_storage()
                            ) for x in new_flattened_res if isinstance(x, FakeTensor)}
                        assert len(new_res_storage) == 1
                        (old_ref,) = old_res_storage
                        (new_ref,) = new_res_storage
                        (node_ref,) = node_res_storage
                        storage_to_nodes[node_ref].update(storage_to_nodes[new_ref])
                        storage_to_nodes[new_ref].update(storage_to_nodes[node_ref])

    for to_delete in all_later_view_inverse_nodes_to_delete:
        gm.graph.erase_node(to_delete)


    gm.recompile()
    return gm

<END>

<START>
import argparse
import copy
import functools
import logging
import os
import shutil
import sys
import textwrap
from importlib import import_module
from typing import Union

import torch
import torch.fx as fx

from torch._dynamo.debug_utils import (
    AccuracyError,
    backend_accuracy_fails,
    BUCK_CMD_PREFIX,
    BuckTargetWriter,
    extra_imports,
    generate_config_string,
    helper_for_dump_minify,
    InputReader,
    InputWriter,
    minifier_dir,
    NNModuleToString,
    NopInputReader,
    run_fwd_maybe_bwd,
    same_two_models,
)
from torch.fx.experimental.symbolic_shapes import fx_placeholder_targets
from torch.hub import tqdm

from .. import config
from ..backends.registry import lookup_backend, register_debug_backend
from ..debug_utils import clone_inputs_retaining_gradness

log = logging.getLogger(__name__)


inductor_config = import_module("torch._inductor.config")
use_buck = inductor_config.is_fbcode()



def wrap_backend_debug(unconfigured_compiler_fn, compiler_name: str):

    @functools.wraps(unconfigured_compiler_fn)
    def debug_wrapper(gm, example_inputs, **kwargs):
        compiler_fn = functools.partial(unconfigured_compiler_fn, **kwargs)
        assert config.repro_after in ("dynamo", "aot", None)

        if config.repro_after == "dynamo":

            def add_paths(exc):
                exc.minifier_path = os.path.join(minifier_dir(), "minifier_launcher.py")
                if use_buck:
                    exc.buck_command = " ".join(
                        BUCK_CMD_PREFIX
                        + [BuckTargetWriter(exc.minifier_path).cmd_line_path]
                    )

            if config.repro_level == 3:
                dump_to_minify_after_dynamo(gm, example_inputs, compiler_name)

            if config.repro_level == 4:
                compiled_gm = compiler_fn(copy.deepcopy(gm), example_inputs)
                if backend_accuracy_fails(gm, example_inputs, compiler_fn):
                    log.warning(
                        "Accuracy failed for the TorchDynamo produced graph. Creating script to minify the error."
                    )
                    dump_to_minify_after_dynamo(
                        fx.GraphModule(gm, copy.deepcopy(gm.graph)),
                        example_inputs,
                        compiler_name,
                    )
                    exc = AccuracyError("Bad accuracy detected.")
                    add_paths(exc)
                    raise exc
            else:
                try:
                    compiled_gm = compiler_fn(copy.deepcopy(gm), example_inputs)
                    run_fwd_maybe_bwd(compiled_gm, example_inputs)
                except Exception as exc:
                    log.warning(
                        "Compiled Fx GraphModule failed. Creating script to minify the error."
                    )
                    if config.repro_level == 1:
                        dump_state_fn = functools.partial(
                            dump_backend_state, compiler_name=compiler_name
                        )
                        dump_state_fn(
                            fx.GraphModule(gm, copy.deepcopy(gm.graph)), example_inputs
                        )
                    elif config.repro_level == 2:
                        dump_to_minify_after_dynamo(
                            fx.GraphModule(gm, copy.deepcopy(gm.graph)),
                            example_inputs,
                            compiler_name,
                        )
                    add_paths(exc)
                    raise
        else:
            compiled_gm = compiler_fn(gm, example_inputs)

        return compiled_gm

    debug_wrapper._torchdynamo_orig_callable = unconfigured_compiler_fn  # type: ignore[attr-defined]
    if hasattr(unconfigured_compiler_fn, "compiler_name"):
        debug_wrapper.__name__ = unconfigured_compiler_fn.compiler_name
    if hasattr(unconfigured_compiler_fn, "get_compiler_config"):
        debug_wrapper.get_compiler_config = unconfigured_compiler_fn.get_compiler_config  # type: ignore[attr-defined]
    return debug_wrapper




def generate_dynamo_fx_repro_string(
    gm,
    args,
    compiler_name,
    check_accuracy=False,
    *,
    stable_output=False,
    save_dir=None,
    command="run",
):

    model_str = NNModuleToString.convert(gm)

    writer = InputWriter(save_dir, stable_hash=True)
    for placeholder, arg in zip(fx_placeholder_targets(gm), args):
        if isinstance(arg, (int, torch.SymInt)):
            writer.symint(placeholder, arg)
        elif isinstance(arg, torch.Tensor):
            writer.tensor(placeholder, arg)
        else:
            raise TypeError(f"arg is neither SymInt/int nor torch.Tensor, {arg}")
    load_args = "\n".join(writer.lines())

    return textwrap.dedent(
    )


def dump_backend_repro_as_file(gm, args, compiler_name, check_accuracy=False):
    curdir = os.getcwd()
    subdir = os.path.join(os.getcwd(), "checkpoints")
    if not os.path.exists(subdir):
        os.makedirs(subdir, exist_ok=True)
    file_name = os.path.join(subdir, f"minified_{len(gm.graph.nodes)}_nodes.py")
    log.warning(
        "Writing checkpoint with %s nodes to %s", len(gm.graph.nodes), file_name
    )

    with open(file_name, "w") as fd:
        fd.write(
            generate_dynamo_fx_repro_string(
                gm, args, compiler_name, check_accuracy, save_dir=subdir
            )
        )
    latest_repro = os.path.join(curdir, "repro.py")
    log.warning("Copying %s to %s for convenience", file_name, latest_repro)

    if use_buck:
        BuckTargetWriter(latest_repro).write()

    shutil.copyfile(file_name, latest_repro)


def dump_backend_state(gm, args, compiler_name, check_accuracy=False):
    assert NNModuleToString.can_convert_to_string(gm)
    return dump_backend_repro_as_file(gm, args, compiler_name, check_accuracy)




def dump_to_minify_after_dynamo(gm, args, compiler_name):
    subdir = os.path.join(minifier_dir(), "checkpoints")
    if not os.path.exists(subdir):
        os.makedirs(subdir, exist_ok=True)
    helper_for_dump_minify(
        generate_dynamo_fx_repro_string(
            gm,
            args,
            compiler_name,
            check_accuracy=config.repro_level == 4,
            save_dir=subdir,
            command="minify",
        )
    )




@register_debug_backend
def dynamo_minifier_backend(gm, example_inputs, compiler_name):
    from functorch.compile import minifier

    compiler_fn = lookup_backend(compiler_name)

    example_inputs = [
        i.node.hint if isinstance(i, torch.SymInt) else i for i in example_inputs
    ]

    try:
        compiled_gm = compiler_fn(gm, example_inputs)
        run_fwd_maybe_bwd(compiled_gm, example_inputs)
        raise ValueError("No issue was detected")
    except Exception as exc:
        orig_failure = str(exc)
        log.warning(
            "Compiled Fx GraphModule failed. Creating script to minify the error."
        )
        dump_state_fn = functools.partial(
            dump_backend_state, compiler_name=compiler_name
        )
        dump_state_fn(fx.GraphModule(gm, copy.deepcopy(gm.graph)), example_inputs)
        fails_fn = functools.partial(
            backend_fails,
            compiler_fn=compiler_fn,
            orig_failure=orig_failure,
        )
        minifier(
            gm,
            example_inputs,
            module_fails=fails_fn,
            dump_state=dump_state_fn,
        )
    return gm


@register_debug_backend
def dynamo_accuracy_minifier_backend(gm, example_inputs, compiler_name):
    from functorch.compile import minifier

    compiler_fn = lookup_backend(compiler_name)

    gm.eval()

    if backend_accuracy_fails(
        gm, example_inputs, compiler_fn, only_fwd=config.repro_forward_only
    ):
        log.warning("Accuracy failed for the TorchDynamo produced graph")
        dump_state_fn = functools.partial(
            dump_backend_state, compiler_name=compiler_name, check_accuracy=True
        )
        fails_fn = functools.partial(
            backend_accuracy_fails,
            compiler_fn=compiler_fn,
            only_fwd=config.repro_forward_only,
        )
        dump_state_fn(fx.GraphModule(gm, copy.deepcopy(gm.graph)), example_inputs)
        minifier(
            gm,
            example_inputs,
            module_fails=fails_fn,
            dump_state=dump_state_fn,
        )
    else:
        log.error("Input graph does not fail accuracy testing")
    return gm


def backend_fails(gm, example_inputs, compiler_fn, orig_failure):
    from difflib import SequenceMatcher

    try:
        run_fwd_maybe_bwd(gm, clone_inputs_retaining_gradness(example_inputs))
        compiled_gm = compiler_fn(gm, example_inputs)
        run_fwd_maybe_bwd(compiled_gm, clone_inputs_retaining_gradness(example_inputs))
        return False
    except Exception as e:
        new_failure = str(e)
        if SequenceMatcher(None, orig_failure, new_failure).ratio() > 0.5:
            return True
        return False




def run_load_args(options, mod, load_args):
    if not hasattr(load_args, "_version"):
        log.warning(
            "load_args does not have a _version attribute, please file a bug to PyTorch "
            "and describe how you generate this repro script"
        )
    else:
        if load_args._version > 0:
            log.warning(
                "load_args is version %s, but this version of PyTorch only supports "
                "version 0.  We will try to run it anyway but there may be an incompatibility; "
                "if so, try upgrading your version of PyTorch.",
                load_args._version,
            )

    nop_reader = NopInputReader()
    load_args(nop_reader)

    with tqdm(desc="Loading inputs", total=nop_reader.total) as pbar:
        input_reader = InputReader(save_dir=options.save_dir, pbar=pbar)
        load_args(input_reader)
        args = input_reader.args

    return args


def repro_minify(options, mod, load_args):
    args = run_load_args(options, mod, load_args)

    if not options.accuracy:
        compiler_fn = lookup_backend("dynamo_minifier_backend")
    else:
        compiler_fn = lookup_backend("dynamo_accuracy_minifier_backend")

    if options.backend is None:
        raise RuntimeError(
            "Compiler name is None - this likely means that a custom compiler "
            "was called by torchdynamo. Please remove this error, import your "
            "custom compiler function, and replace the backend=None "
            "line in run_repro to backend=<my_imported_custom_function>"
        )

    dynamo_minifier_backend = functools.partial(
        compiler_fn,
        compiler_name=options.backend,
    )
    opt_mod = torch._dynamo.optimize(dynamo_minifier_backend)(mod)

    with torch.cuda.amp.autocast(enabled=options.autocast):
        opt_mod(*args)


def repro_run(options, mod, load_args):
    opt_mod = torch._dynamo.optimize(options.backend)(mod)

    if options.accuracy != "":
        mod.eval()
        opt_mod.eval()

        with torch.cuda.amp.autocast(enabled=options.autocast):
            args = run_load_args(options, mod, load_args)
            assert same_two_models(mod, mod, args), "Eager itself failed"
            if not same_two_models(mod, opt_mod, args):
                raise AccuracyError("Dynamo failed")
    else:
        with torch.cuda.amp.autocast(enabled=options.autocast):
            args = run_load_args(options, mod, load_args)
            ref = run_fwd_maybe_bwd(
                mod, args, only_fwd=options.only_fwd, disable_clone=True
            )
            del args

            args = run_load_args(options, mod, load_args)
            res = run_fwd_maybe_bwd(
                opt_mod, args, only_fwd=options.only_fwd, disable_clone=True
            )


def run_repro(
    mod,
    load_args,
    *,
    command="run",
    accuracy: Union[bool, str] = "",
    save_dir=None,
    autocast=False,
    backend="inductor",
    **kwargs,
):
    for k in kwargs:
        log.warning(
            "Unrecognized kwarg %s; perhaps this repro was made on a newer version of PyTorch",
            k,
        )

    if accuracy is True:
        accuracy = "accuracy"
    elif accuracy is False:
        accuracy = ""

    parser = argparse.ArgumentParser(
        formatter_class=argparse.RawTextHelpFormatter,
    )

    def common_flags(parser):
        accuracy_group = parser.add_mutually_exclusive_group()
        accuracy_group.add_argument(
            "--no-accuracy",
            dest="accuracy",
            action="store_const",
            const="",
            default=accuracy,
            help="do not test accuracy, just run the module and see if it errors",
        )
        accuracy_group.add_argument(
            "--accuracy",
            action="store_const",
            const="accuracy",
            default=accuracy,
            help="test accuracy",
        )
        parser.add_argument(
            "--save-dir",
            type=str,
            default=save_dir,
            metavar="DIR",
            help="directory where saved inputs live",
        )
        parser.add_argument(
            "--no-save-dir",
            dest="save_dir",
            action="store_const",
            const=None,
            help="don't use any directory for saved inputs",
        )
        parser.add_argument(
            "--no-isolate",
            dest="isolate",
            action="store_false",
            default=False,
            help="no isolate (doesn't do anything for after_dynamo)",
        )
        parser.add_argument(
            "--autocast",
            default=autocast,
            action="store_true",
            help="use torch.cuda.amp.autocast",
        )
        parser.add_argument(
            "--no-autocast",
            dest="autocast",
            action="store_false",
            help="don't use torch.cuda.amp.autocast",
        )
        parser.add_argument(
            "--backend",
            type=str,
            default=backend,
            metavar="BACKEND",
            help="torch.compile backend to use",
        )

    subparsers = parser.add_subparsers(
        dest="command", metavar="{run,minify}", required=True
    )

    parser_run = subparsers.add_parser(
        "run",
        help="just run the repro",
    )
    common_flags(parser_run)
    parser_run.add_argument(
        "--only-fwd",
        action="store_true",
        help="don't run backwards compilation for testing",
    )

    parser_minify = subparsers.add_parser(
        "minify", help="run the minifier on the repro"
    )
    common_flags(parser_minify)

    args = None
    if len(sys.argv) <= 1:
        args = [command, *sys.argv[1:]]

    options = parser.parse_args(args)
    COMMAND_FNS = {
        "minify": repro_minify,
        "run": repro_run,
    }
    COMMAND_FNS[options.command](options, mod, load_args)

<END>

<START>
import gc
import sys
from typing import Any, Dict, List, NamedTuple, Optional, Tuple
import types
import weakref
import json
from tempfile import NamedTemporaryFile
import torch
from torch.cuda._memory_viz import _frames_fmt, _block_extra
import atexit
import logging
logger = logging.getLogger(__name__)

def observe_garbage(observer):
    enabled = True

    def disable():
        nonlocal enabled
        enabled = False
    atexit.register(disable)

    def gc_callback(phase, info):
        nonlocal enabled
        if not enabled:
            return
        if phase == "start":
            gc.set_debug(gc.DEBUG_SAVEALL)
        elif phase == "stop":
            orig_trace = sys.getprofile()
            self_return = [False]

            def do_collect(*args, **kwargs):
                nonlocal enabled
                if not self_return[0]:
                    self_return[0] = True
                else:
                    sys.setprofile(orig_trace)
                    enabled = False
                    try:
                        if info['generation'] != 2:
                            gc.collect()
                        observer(gc.garbage)
                        gc.garbage.clear()
                        gc.set_debug(0)
                        before = torch.cuda.memory_allocated()
                        gc.collect()
                        after = torch.cuda.memory_allocated()
                        if before != after:
                            logger.warning("CUDA Memory changed during GC, %d bytes freed.", before - after)
                    finally:
                        enabled = True
                if orig_trace is not None:
                    return orig_trace(*args, **kwargs)
            sys.setprofile(do_collect)

    gc.callbacks.append(gc_callback)

    def remove():
        gc.callbacks.remove(gc_callback)
    return remove


def _get_cell_type():
    def f(x=None):
        return lambda: x
    return type(f().__closure__[0])

CellType = _get_cell_type()

def annotated_references(obj):
    references: Dict[int, List[str]] = {}

    def add_reference(name, obj):
        references.setdefault(id(obj), []).append(name)

    def add_attrs(*attrs):
        for attr in attrs:
            if hasattr(obj, attr):
                add_reference(attr, getattr(obj, attr))

    def add_cell_references():
        try:
            add_attrs("cell_contents")
        except ValueError:
            pass

    def add_function_references():
        add_attrs("__defaults__",
                  "__closure__",
                  "__globals__",
                  "__code__",
                  "__name__",
                  "__module__",
                  "__doc__"
                  "__qualname__",
                  "__annotations__",
                  "__kwdefaults__")


    def add_sequence_references():
        for position, item in enumerate(obj):
            add_reference(f"[{position}]", item)

    def add_dict_references():
        for key, value in obj.items():
            add_reference("key", key)
            add_reference(f"[{repr(key)}]", value)

    def add_set_references():
        for elt in obj:
            add_reference("element", elt)

    def add_bound_method_references():
        add_attrs("__self__", "__func__", "im_class")

    def add_weakref_references():
        if type(obj) is weakref.ref:
            referents = gc.get_referents(obj)
            if len(referents) == 1:
                target = referents[0]
                add_reference("__callback__", target)


    def add_frame_references():
        f_locals = obj.f_locals
        add_attrs("f_back", "f_code", "f_builtins", "f_globals", "f_trace", "f_locals")
        if type(f_locals) is dict:
            for name, local in obj.f_locals.items():
                add_reference(f"local {name}", local)

    def add_getset_descriptor_references():
        add_attrs("__objclass__", "__name__", "__doc__")

    type_based_references = {
        tuple: add_sequence_references,
        list: add_sequence_references,
        dict: add_dict_references,
        set: add_set_references,
        frozenset: add_set_references,
        types.FunctionType: add_function_references,
        types.FrameType: add_frame_references,
        CellType: add_cell_references,
        types.MethodType: add_bound_method_references,
        weakref.ref: add_weakref_references,
        types.GetSetDescriptorType: add_getset_descriptor_references,
    }

    for type_ in type(obj).__mro__:
        if type_ in type_based_references:
            type_based_references[type_]()

    add_attrs("__dict__", "__class__")
    if isinstance(obj, type):
        add_attrs("__mro__")

    return references



BASE_TYPES = (int, float, complex, type(None), str, bytes)
FRAME_FILENAME_LIMIT = 32

def object_annotation(obj):

    def format_sequence(obj):
        body = ','.join(repr(x) if isinstance(x, BASE_TYPES) else type(x).__name__ for i, x in zip(range(8), obj))
        if len(obj) > 8:
            body = f'{body}, ...{len(obj) - 8}'
        return body

    if isinstance(obj, BASE_TYPES):
        return repr(obj)
    if type(obj).__name__ == 'function':
        return f"function\n{obj.__name__}"
    elif isinstance(obj, types.MethodType):
        try:
            func_name = obj.__func__.__qualname__
        except AttributeError:
            func_name = "<anonymous>"
        return f"instancemethod\n{func_name}"
    elif isinstance(obj, list):
        return f"[{format_sequence(obj)}]"
    elif isinstance(obj, tuple):
        return f"({format_sequence(obj)})"
    elif isinstance(obj, dict):
        return f"dict[{len(obj)}]"
    elif isinstance(obj, types.ModuleType):
        return f"module\n{obj.__name__}"
    elif isinstance(obj, type):
        return f"type\n{obj.__name__}"
    elif isinstance(obj, weakref.ref):
        referent = obj()
        if referent is None:
            return "weakref (dead referent)"
        else:
            return f"weakref to id 0x{id(referent):x}"
    elif isinstance(obj, types.FrameType):
        filename = obj.f_code.co_filename
        if len(filename) > FRAME_FILENAME_LIMIT:
            filename = "..." + filename[-(FRAME_FILENAME_LIMIT - 3):]
        return f"frame\n{filename}:{obj.f_lineno}"
    else:
        return f"object\n{type(obj).__module__}.{type(obj).__name__}"



class Node(NamedTuple):
    label: str
    context: Optional[str]
    root: bool
    referrents: List[Tuple[str, int]]

def create_graph(objects, *, context=None, filter=None):
    if context is None:
        context = cuda_allocation_context()
    if filter is None:
        filter = is_cuda_tensor

    nodes = [Node(object_annotation(obj), context(obj), filter(obj), []) for obj in objects]
    node_referrers: List[List[int]] = [[] for obj in objects]

    id_to_node = {id(obj): i for i, obj in enumerate(objects)}
    for obj in objects:
        fidx = id_to_node[id(obj)]
        f = nodes[fidx]
        references = annotated_references(obj)
        for referrent in gc.get_referents(obj):
            rid = id(referrent)
            tidx = id_to_node.get(rid, None)
            if tidx is None:
                continue
            t = nodes[tidx]
            labels = references.get(rid, ["?"])
            node_referrers[tidx].append(fidx)
            for label in labels:
                f.referrents.append((label, tidx))

    to_search = [i for i, n in enumerate(nodes) if n.root]
    to_keep = set()
    while to_search:
        idx = to_search.pop()
        if idx in to_keep:
            continue
        to_keep.add(idx)
        referrers = node_referrers[idx]
        to_search.extend(referrers)
    id_to_filtered_id: Dict[int, int] = {}
    filtered: List[Any] = []
    for i, n in enumerate(nodes):
        if i in to_keep:
            id_to_filtered_id[i] = len(id_to_filtered_id)
            filtered.append(n)
    for n in filtered:
        n.referrents[:] = [(label, id_to_filtered_id[idx])
                           for (label, idx) in n.referrents
                           if idx in id_to_filtered_id]
    return filtered

def escape(n):
    return json.dumps(n)


def is_cuda_tensor(obj):
    return isinstance(obj, torch.Tensor) and obj.is_cuda

def cuda_allocation_context():
    snapshot = torch.cuda.memory._snapshot()
    addr_to_frame = {}
    for seg in snapshot['segments']:
        addr = seg['address']
        for blk in seg['blocks']:
            if blk['state'] == 'active_allocated':
                frames, real_size = _block_extra(blk)
                addr_to_frame[addr] = frames
            addr += blk['size']

    def object_context(obj):
        if is_cuda_tensor(obj):
            addr = obj.untyped_storage().data_ptr()
            frames = addr_to_frame.get(addr)
            if frames is not None:
                return '\n'.join(_frames_fmt(frames, full_filename=True))
        return None
    return object_context

def to_dot(nodes):
    lines = ["digraph GraphName {", "node [shape=rect];", 'rankdir=LR;']
    for i, n in enumerate(nodes):
        lines.append(f'{i} [label={escape(n.label)}, color={ "red" if n.root else "black"}];')

    for i, f in enumerate(nodes):
        for label, j in f.referrents:
            lines.append(f'{i} -> {j} [label = {escape(label)}]')
    lines.append("}\n")
    return '\n'.join(lines)

def to_html(nodes):
    listeners = []
    for i, n in enumerate(nodes):
        if n.context is None:
            continue
        s = _listener_template.format(id=str(i + 1), stack=escape(f'{n.label}:\n{n.context}'))
        listeners.append(s)
    dot = to_dot(nodes)
    return _template.replace('$DOT', repr(dot)).replace('$LISTENERS', '\n'.join(listeners))

def observe_tensor_cycles(callback):
    torch.cuda.memory._record_memory_history(max_entries=100000)

    def observer(garbage):
        if garbage:
            if not any(is_cuda_tensor(obj) for obj in garbage):
                logger.info("No CUDA Tensors found in garbage")
                return
            callback(to_html(create_graph(garbage)))
    return observe_garbage(observer)


def warn_tensor_cycles():
    logger.info("Watching Python reference cycles for CUDA Tensors.")

    def write_and_log(html):
        with NamedTemporaryFile('w', suffix='.html', delete=False) as f:
            f.write(html)
            logger.warning('Reference cycle includes a CUDA Tensor see visualization of cycle %s', f.name)
    return observe_tensor_cycles(write_and_log)

<END>

<START>
import logging
import math
from typing import Optional, Tuple

import torch
import torch.nn
import torch.nn.functional as F
from torch.backends.cuda import (
    can_use_efficient_attention,
    can_use_flash_attention,
    flash_sdp_enabled,
    math_sdp_enabled,
    mem_efficient_sdp_enabled,
    SDPAParams,
    SDPBackend,
)

from .nested_tensor import buffer_from_jagged, NestedTensor, ViewNestedFromBuffer

log = logging.getLogger(__name__)


def _validate_sdpa_input(
    query: torch.Tensor,
    key: torch.Tensor,
    value: torch.Tensor,
    attn_mask: Optional[torch.Tensor] = None,
    dropout_p=0.0,
    is_causal=False,
    scale=None,
):
    if (
        not isinstance(query, NestedTensor)
        or not isinstance(key, NestedTensor)
        or not isinstance(value, NestedTensor)
    ):
        raise ValueError(
            f"Expected query, key, and value to be nested tensors, "
            f"but got query.is_nested: {query.is_nested}, key.is_nested: {key.is_nested}, "
            f"and value.is_nested: {value.is_nested} instead."
        )
    if query.dtype != key.dtype or query.dtype != value.dtype:
        raise ValueError(
            f"Expected query, key, and value to have the same dtype, "
            f"but got query.dtype: {query.dtype}, key.dtype: {key.dtype}, "
            f"and value.dtype: {value.dtype} instead."
        )
    if query.device != key.device or query.device != value.device:
        raise ValueError(
            f"Expected query, key, and value to have the same device type, "
            f"but got query.device: {query.device}, key.device: {key.device}, "
            f"and value.device: {value.device} instead."
        )
    if query.dim() < 2 or key.dim() < 2 or value.dim() < 2:
        raise ValueError(
            f"Expected query, key, and value to all be  at least 2 dimensional, but got query.dim: "
            f"{query.dim()}, key.dim: {key.dim()} and value.dim: {value.dim()} instead."
        )
    if query._ragged_idx != key._ragged_idx or query._ragged_idx != value._ragged_idx:
        raise ValueError(
            f"Expected query, key, and value to all be ragged on the same dimension, but got ragged "
            f"dims {query._ragged_idx}, {key._ragged_idx}, and {value._ragged_idx}, respectively."
        )
    if attn_mask is not None:
        raise ValueError("Masks are not yet supported!")
        if attn_mask.dtype != torch.bool and attn_mask.dtype != query.dtype:
            raise ValueError(
                f"Expected attn_mask dtype to be bool or to match query dtype, but got attn_mask.dtype: "
                f"{attn_mask.dtype}, and query.dtype: {query.dtype} instead."
            )


def _check_batch_size_nested(params: SDPAParams, debug=False) -> bool:
    q_batch_size = params.query.size(0)
    k_batch_size = params.key.size(0)
    v_batch_size = params.value.size(0)

    return q_batch_size == k_batch_size and q_batch_size == v_batch_size


def _check_head_dim_size_flash_nested(params: SDPAParams, debug=False) -> bool:
    max_size = 256
    query_size_last = params.query.size(-1)
    key_size_last = params.key.size(-1)
    value_size_last = params.value.size(-1)
    same_head_dim_size = (
        query_size_last == key_size_last and query_size_last == value_size_last
    )
    if not (
        same_head_dim_size
        and (query_size_last % 8 == 0)
        and (query_size_last <= max_size)
    ):
        if debug:
            log.warning(
                "For NestedTensor inputs, Flash attention requires q,k,v to have the same "
                "last dimension and to be a multiple of 8 and less than or equal to 256. "
                "Got Query.size(-1): %d, Key.size(-1): %d, Value.size(-1): %d instead.",
                query_size_last,
                key_size_last,
                value_size_last,
            )
        return False
    return True


def _check_for_seq_len_0_and_consistent_head_dim_nested_helper(
    param: torch.Tensor, param_name: str, debug=False
) -> bool:
    assert isinstance(param, NestedTensor), "param should be a jagged NT"

    if param._ragged_idx == 1:
        if debug:
            log.warning(
                "Fused kernels do not support ragged num_head_dims, %s has a ragged num_heads.",
                param_name,
            )
        return False

    if param._min_seqlen == 0:
        if debug:
            log.warning(
                "Fused kernels do not support seq_len == 0, %s has a seq len of 0.",
                param_name,
            )
        return False

    return True


def _try_broadcast_param_size(q_size, k_size, v_size, param_name, debug=False) -> bool:
    max_size = max(q_size, k_size, v_size)
    if (
        (q_size != max_size and q_size != 1)
        or (k_size != max_size and k_size != 1)
        or (v_size != max_size and v_size != 1)
    ):
        if debug:
            log.warning(
                "Both fused kernels require query, key and value to have broadcastable %s, "
                "got Query %s %d, Key %s %d, Value %s %d instead.",
                param_name,
                param_name,
                q_size,
                param_name,
                k_size,
                param_name,
                v_size,
            )
        return False
    return True


def _check_for_seq_len_0_nested(params: SDPAParams, debug=False) -> bool:
    q_is_safe = (
        _check_for_seq_len_0_and_consistent_head_dim_nested_helper(
            params.query, "query", debug
        )
        if params.query.is_nested
        else True
    )
    if not q_is_safe:
        return False

    k_is_safe = (
        _check_for_seq_len_0_and_consistent_head_dim_nested_helper(
            params.key, "key", debug
        )
        if params.key.is_nested
        else True
    )
    if not k_is_safe:
        return False

    v_is_safe = (
        _check_for_seq_len_0_and_consistent_head_dim_nested_helper(
            params.value, "value", debug
        )
        if params.value.is_nested
        else True
    )
    if not v_is_safe:
        return False

    q_num_heads = params.query.size(1)
    k_num_heads = params.key.size(1)
    v_num_heads = params.value.size(1)
    same_num_heads = q_num_heads == k_num_heads and q_num_heads == v_num_heads

    if not same_num_heads:
        if (
            params.query.requires_grad
            or params.key.requires_grad
            or params.value.requires_grad
        ):
            if debug:
                log.warning(
                    "Both fused kernels do not support training with broadcasted NT inputs."
                )
            return False
        return _try_broadcast_param_size(
            q_num_heads, k_num_heads, v_num_heads, "num heads", debug
        )
    return True


def _can_use_flash_sdpa_jagged(params: SDPAParams, debug=False) -> bool:
    constraints = (
        _check_batch_size_nested,
        _check_head_dim_size_flash_nested,
        _check_for_seq_len_0_nested,
    )
    for constraint in constraints:
        if not constraint(params, debug):
            return False
    return True


def _can_use_efficient_sdpa_jagged(params: SDPAParams, debug=False) -> bool:
    constraints = (
        _check_batch_size_nested,
        _check_for_seq_len_0_nested,
    )
    for constraint in constraints:
        if not constraint(params, debug):
            return False
    return True


def _can_use_math_sdpa_jagged(params: SDPAParams, debug=False) -> bool:
    if (
        not params.query.transpose(1, 2).is_contiguous()
        or not params.key.transpose(1, 2).is_contiguous()
        or not params.value.transpose(1, 2).is_contiguous()
    ):
        if debug:
            log.warning(
                "If inputs are nested tensors they must be contiguous after transposing."
            )
        return False
    if params.is_causal:
        if debug:
            log.warning(
                "Nested tensors for query / key are not supported when is_causal=True."
            )
        return False
    return True


def _select_sdp_backend(query, key, value, attn_mask, dropout, is_causal):
    if (
        not flash_sdp_enabled()
        and not mem_efficient_sdp_enabled()
        and not math_sdp_enabled()
    ):
        return SDPBackend.ERROR

    ordering = (
        SDPBackend.FLASH_ATTENTION,
        SDPBackend.EFFICIENT_ATTENTION,
        SDPBackend.MATH,
    )

    params = SDPAParams(query, key, value, attn_mask, dropout, is_causal)

    for backend in ordering:
        if backend == SDPBackend.FLASH_ATTENTION:
            if can_use_flash_attention(params) and _can_use_flash_sdpa_jagged(params):
                return SDPBackend.FLASH_ATTENTION
        if backend == SDPBackend.EFFICIENT_ATTENTION:
            if can_use_efficient_attention(params) and _can_use_efficient_sdpa_jagged(
                params
            ):
                return SDPBackend.EFFICIENT_ATTENTION
        if backend == SDPBackend.MATH:
            if math_sdp_enabled() and _can_use_math_sdpa_jagged(params):
                return SDPBackend.MATH

    log.warning("Memory efficient kernel not used because:")
    can_use_efficient_attention(params, debug=True)
    _can_use_efficient_sdpa_jagged(params, debug=True)
    log.warning("Flash attention kernel not used because:")
    can_use_flash_attention(params, debug=True)
    _can_use_flash_sdpa_jagged(params, debug=True)
    log.warning("Math attention kernel not used because:")
    _can_use_math_sdpa_jagged(params, debug=True)
    return SDPBackend.ERROR


def _cumulative_and_max_seq_len_nnz(qkv: torch.Tensor) -> Tuple[torch.Tensor, int, int]:

    if not isinstance(qkv, NestedTensor):
        raise ValueError("QKV must be nested for flash cumulative_seq_len calculation.")

    if qkv.lengths() is None:
        cumulative_seqlen = qkv.offsets().to(dtype=torch.int32, device=qkv.device)
        max_seqlen = qkv._max_seqlen
        n_elem = qkv.values().shape[0]
    else:
        cumulative_seqlen = (
            qkv.lengths().cumsum(0).to(dtype=torch.int32, device=qkv.device)
        )
        batch_size = qkv.size(0)
        max_seqlen = qkv._max_seqlen
        n_elem = int(cumulative_seqlen[-1].item())
    return cumulative_seqlen, max_seqlen, n_elem


def _is_safe_to_get_storage_as_tensor(tensor: torch.Tensor):

    assert isinstance(tensor, NestedTensor)
    offsets = tensor.offsets()
    strides = tensor._stride

    n_tensors = offsets.size(0) - 1
    if n_tensors <= 1:
        return True

    prev_stride = strides[1]
    for stride in strides[2:]:
        if prev_stride <= stride:
            return False
        prev_stride = stride

    return True


def _view_as_dense(
    tensor: torch.Tensor, Nnz: int, num_heads: int, head_dim: int
) -> torch.Tensor:
    if tensor.is_nested:
        return buffer_from_jagged(tensor)
    return tensor.view(Nnz, num_heads, head_dim)




















def _sdpa_nested_preprocessing(query, key, value):
    q_batch_size = query.size(0)
    k_batch_size = key.size(0)
    v_batch_size = value.size(0)

    q_num_heads = query.size(1)
    k_num_heads = key.size(1)
    v_num_heads = value.size(1)

    if not (q_batch_size == k_batch_size and q_batch_size == v_batch_size) or not (
        q_num_heads == k_num_heads and k_num_heads == v_num_heads
    ):
        raise RuntimeError(
            "This path is currently not implemented for jagged layout NT."
        )

    num_heads = query.size(1)
    head_dim_qk = query.size(3)
    head_dim_v = value.size(3)
    q_t = query.transpose(1, 2)
    k_t = key.transpose(1, 2)
    v_t = value.transpose(1, 2)

    (
        cumulative_sequence_length_q,
        max_seqlen_batch_q,
        Nnz_q,
    ) = _cumulative_and_max_seq_len_nnz(q_t)
    (
        cumulative_sequence_length_kv,
        max_seqlen_batch_kv,
        Nnz_kv,
    ) = _cumulative_and_max_seq_len_nnz(k_t)


    if not q_t.is_contiguous() and not _is_safe_to_get_storage_as_tensor(q_t):
        q_t = q_t.contiguous()
    if not k_t.is_contiguous() and not _is_safe_to_get_storage_as_tensor(k_t):
        k_t = k_t.contiguous()
    if not v_t.is_contiguous() and not _is_safe_to_get_storage_as_tensor(v_t):
        v_t = v_t.contiguous()

    query_buffer_reshaped = _view_as_dense(q_t, Nnz_q, num_heads, head_dim_qk)
    key_buffer_reshaped = _view_as_dense(k_t, Nnz_kv, num_heads, head_dim_qk)
    value_buffer_reshaped = _view_as_dense(v_t, Nnz_kv, num_heads, head_dim_v)

    output_nt_info = {
        "offsets": q_t.offsets(),
        "_max_seqlen": q_t._max_seqlen,
        "_min_seqlen": q_t._min_seqlen,
    }

    return (
        query_buffer_reshaped,
        key_buffer_reshaped,
        value_buffer_reshaped,
        cumulative_sequence_length_q,
        cumulative_sequence_length_kv,
        max_seqlen_batch_q,
        max_seqlen_batch_kv,
        output_nt_info,
    )


def _pad_last_dim(
    tensor: torch.Tensor, alignment_size: int, slice: bool
) -> torch.Tensor:
    last_dim_size = tensor.size(-1)
    if last_dim_size % alignment_size == 0:
        return tensor
    pad_count = alignment_size - (last_dim_size % alignment_size)
    tensor = torch.nn.functional.pad(tensor, [0, pad_count])
    if slice:
        return tensor[..., 0:last_dim_size]
    return tensor


def _calculate_scale(query, scale):
    softmax_scale = scale if scale is not None else math.sqrt(1.0 / query.size(-1))
    return softmax_scale


def _post_process_flash_output(out: torch.Tensor, og_size):
    if not out.is_nested and out.size(-1) != og_size:
        out = out[..., 0:og_size]
    return out


def jagged_scaled_dot_product_attention(
    query: torch.Tensor,
    key: torch.Tensor,
    value: torch.Tensor,
    attn_mask: Optional[torch.Tensor] = None,
    dropout_p=0.0,
    is_causal=False,
    scale=None,
):
    _validate_sdpa_input(query, key, value, attn_mask, dropout_p, is_causal, scale)
    assert (
        isinstance(query, NestedTensor)
        and isinstance(key, NestedTensor)
        and isinstance(value, NestedTensor)
    )

    if query.dim() > 3 and key.dim() > 3 and value.dim() > 3 and query._ragged_idx == 1:
        from torch.nested._internal.ops import extract_kwargs

        output = F.scaled_dot_product_attention(
            query._values,
            key._values,
            value._values,
            attn_mask=(
                attn_mask._values if isinstance(attn_mask, NestedTensor) else attn_mask
            ),
            dropout_p=dropout_p,
            is_causal=is_causal,
            scale=scale,
        )

        return NestedTensor(output, **extract_kwargs(query))

    compute_logsumexp = query.requires_grad or key.requires_grad or value.requires_grad

    backend_choice = _select_sdp_backend(
        query, key, value, attn_mask, dropout_p, is_causal
    )

    if backend_choice == SDPBackend.FLASH_ATTENTION:
        og_size = query.size(-1)
        query_padded = _pad_last_dim(query, 8, False)
        key_padded = _pad_last_dim(key, 8, False)
        value_padded = _pad_last_dim(value, 8, False)
        og_scale = _calculate_scale(query, scale)
        (
            query_buffer_reshaped,
            key_buffer_reshaped,
            value_buffer_reshaped,
            cumulative_sequence_length_q,
            cumulative_sequence_length_kv,
            max_seqlen_batch_q,
            max_seqlen_batch_kv,
            output_nt_info,
        ) = _sdpa_nested_preprocessing(query_padded, key_padded, value_padded)

        (
            attention,
            logsumexp,
            philox_seed,
            philox_offset,
            debug_attn_mask,
        ) = torch.ops.aten._flash_attention_forward(
            query_buffer_reshaped,
            key_buffer_reshaped,
            value_buffer_reshaped,
            cumulative_sequence_length_q,
            cumulative_sequence_length_kv,
            max_seqlen_batch_q,
            max_seqlen_batch_kv,
            dropout_p,
            is_causal,
            False,
            scale=og_scale,
        )
        attention = ViewNestedFromBuffer.apply(
            attention.squeeze(0), output_nt_info["offsets"]
        ).transpose(1, 2)
        return _post_process_flash_output(attention, og_size)
    elif backend_choice == SDPBackend.EFFICIENT_ATTENTION:
        (
            query_reshaped,
            key_reshaped,
            value_reshaped,
            cumulative_sequence_length_q,
            cumulative_sequence_length_kv,
            max_seqlen_batch_q,
            max_seqlen_batch_kv,
            output_nt_info,
        ) = _sdpa_nested_preprocessing(query, key, value)
        (
            attention,
            log_sumexp,
            seed,
            offset,
            max_seqlen_q,
            max_seqlen_batch_kv,
        ) = torch.ops.aten._efficient_attention_forward(
            query_reshaped.unsqueeze(0),
            key_reshaped.unsqueeze(0),
            value_reshaped.unsqueeze(0),
            None,
            cumulative_sequence_length_q,
            cumulative_sequence_length_kv,
            max_seqlen_batch_q,
            max_seqlen_batch_kv,
            dropout_p,
            int(is_causal),
            compute_logsumexp,
            scale=scale,
        )

        return ViewNestedFromBuffer.apply(
            attention.squeeze(0), output_nt_info["offsets"]
        ).transpose(1, 2)
    elif backend_choice == SDPBackend.MATH:
        return torch._scaled_dot_product_attention_math(
            query, key, value, attn_mask, dropout_p, is_causal, scale=scale
        )[0]
    else:
        raise RuntimeError(
            "No viable backend for scaled_dot_product_attention was found."
        )

<END>

<START>
    Optimize a torch script module for mobile deployment.

    Args:
        script_module: An instance of torch script module with type of ScriptModule.
        optimization_blocklist: A set with type of MobileOptimizerType. When set is not passed,
            optimization method will run all the optimizer pass; otherwise, optimizer
            method will run the optimization pass that is not included inside optimization_blocklist.
        preserved_methods: A list of methods that needed to be preserved when freeze_module pass is invoked
        backend: Device type to use for running the result model ('CPU'(default), 'Vulkan' or 'Metal').
    Returns:
        A new optimized torch script module
    Generate a list of lints for a given torch script module.

    Args:
        script_module: An instance of torch script module with type of ScriptModule.

    Returns:
        lint_map: A list of dictionary that contains modules lints

<END>

<START>
from numbers import Number

import torch
from torch import nan
from torch.distributions import constraints
from torch.distributions.distribution import Distribution
from torch.distributions.gamma import Gamma
from torch.distributions.utils import broadcast_all

__all__ = ["FisherSnedecor"]


class FisherSnedecor(Distribution):
    arg_constraints = {"df1": constraints.positive, "df2": constraints.positive}
    support = constraints.positive
    has_rsample = True

    def __init__(self, df1, df2, validate_args=None):
        self.df1, self.df2 = broadcast_all(df1, df2)
        self._gamma1 = Gamma(self.df1 * 0.5, self.df1)
        self._gamma2 = Gamma(self.df2 * 0.5, self.df2)

        if isinstance(df1, Number) and isinstance(df2, Number):
            batch_shape = torch.Size()
        else:
            batch_shape = self.df1.size()
        super().__init__(batch_shape, validate_args=validate_args)

    def expand(self, batch_shape, _instance=None):
        new = self._get_checked_instance(FisherSnedecor, _instance)
        batch_shape = torch.Size(batch_shape)
        new.df1 = self.df1.expand(batch_shape)
        new.df2 = self.df2.expand(batch_shape)
        new._gamma1 = self._gamma1.expand(batch_shape)
        new._gamma2 = self._gamma2.expand(batch_shape)
        super(FisherSnedecor, new).__init__(batch_shape, validate_args=False)
        new._validate_args = self._validate_args
        return new

    @property
    def mean(self):
        df2 = self.df2.clone(memory_format=torch.contiguous_format)
        df2[df2 <= 2] = nan
        return df2 / (df2 - 2)

    @property
    def mode(self):
        mode = (self.df1 - 2) / self.df1 * self.df2 / (self.df2 + 2)
        mode[self.df1 <= 2] = nan
        return mode

    @property
    def variance(self):
        df2 = self.df2.clone(memory_format=torch.contiguous_format)
        df2[df2 <= 4] = nan
        return (
            2
            * df2.pow(2)
            * (self.df1 + df2 - 2)
            / (self.df1 * (df2 - 2).pow(2) * (df2 - 4))
        )

    def rsample(self, sample_shape=torch.Size(())):
        shape = self._extended_shape(sample_shape)
        X1 = self._gamma1.rsample(sample_shape).view(shape)
        X2 = self._gamma2.rsample(sample_shape).view(shape)
        tiny = torch.finfo(X2.dtype).tiny
        X2.clamp_(min=tiny)
        Y = X1 / X2
        Y.clamp_(min=tiny)
        return Y

    def log_prob(self, value):
        if self._validate_args:
            self._validate_sample(value)
        ct1 = self.df1 * 0.5
        ct2 = self.df2 * 0.5
        ct3 = self.df1 / self.df2
        t1 = (ct1 + ct2).lgamma() - ct1.lgamma() - ct2.lgamma()
        t2 = ct1 * ct3.log() + (ct1 - 1) * torch.log(value)
        t3 = (ct1 + ct2) * torch.log1p(ct3 * value)
        return t1 + t2 - t3

<END>

<START>
from typing import Dict, List, Optional, Tuple

import torch
import torch.optim._functional as F

from torch import Tensor

__all__: List[str] = []

@torch.jit.script
class _FunctionalAdamax:
    def __init__(
        self,
        params: List[Tensor],
        lr: float = 1e-3,
        betas: Tuple[float, float] = (0.9, 0.999),
        eps: float = 1e-8,
        weight_decay: float = 0.0,
        foreach: bool = False,
        maximize: bool = False,
        _allow_empty_param_list: bool = False,
    ):
        if not 0.0 <= lr:
            raise ValueError(f"Invalid learning rate: {lr}")
        if not 0.0 <= eps:
            raise ValueError(f"Invalid epsilon value: {eps}")
        if not 0.0 <= betas[0] < 1.0:
            raise ValueError(f"Invalid beta parameter at index 0: {betas[0]}")
        if not 0.0 <= betas[1] < 1.0:
            raise ValueError(f"Invalid beta parameter at index 1: {betas[1]}")
        if not 0.0 <= weight_decay:
            raise ValueError(f"Invalid weight_decay value: {weight_decay}")

        self.defaults = {
            "lr": lr,
            "eps": eps,
            "beta1": betas[0],
            "beta2": betas[1],
            "weight_decay": weight_decay,
        }
        self.foreach = foreach
        self.maximize = maximize
        self.state = torch.jit.annotate(Dict[torch.Tensor, Dict[str, torch.Tensor]], {})

        if len(params) == 0 and not _allow_empty_param_list:
            raise ValueError("optimizer got an empty parameter list")

        self.param_group = {"params": params}

    def step(self, gradients: List[Optional[Tensor]]):
        params = self.param_group["params"]
        params_with_grad = []
        grads = []
        exp_avgs = []
        exp_infs = []
        state_steps: List[Tensor] = []

        if len(params) != len(gradients):
            raise ValueError(
                "the gradients passed in does not equal to the size of the parameters!"
                + f"Params length: {len(params)}. "
                + f"Gradients length: {len(gradients)}"
            )

        has_complex = False
        for param, gradient in zip(self.param_group["params"], gradients):
            if gradient is not None:
                has_complex |= torch.is_complex(param)
                params_with_grad.append(param)
                grads.append(gradient)
                if param not in self.state:
                    self.state[param] = {}
                    state = self.state[param]
                    state["step"] = torch.tensor(0.0)
                    state["exp_avg"] = torch.zeros_like(
                        param, memory_format=torch.preserve_format
                    )
                    state["exp_inf"] = torch.zeros_like(
                        param, memory_format=torch.preserve_format
                    )

                state = self.state[param]

                exp_avgs.append(state["exp_avg"])
                exp_infs.append(state["exp_inf"])
                state_steps.append(state["step"])

        with torch.no_grad():
            F.adamax(
                params_with_grad,
                grads,
                exp_avgs,
                exp_infs,
                state_steps,
                eps=self.defaults["eps"],
                beta1=self.defaults["beta1"],
                beta2=self.defaults["beta2"],
                lr=self.defaults["lr"],
                weight_decay=self.defaults["weight_decay"],
                foreach=self.foreach,
                maximize=self.maximize,
                has_complex=has_complex,
            )

<END>

<START>
__all__ = ["shutdown", "get_worker_info", "remote", "rpc_sync",
           "rpc_async", "RRef", "AllGatherStates", "method_factory", "new_method"]

import collections
import contextlib
import functools
import inspect
import logging
import threading
from typing import Dict, Generic, TypeVar, Set, Any, TYPE_CHECKING

import torch
from torch.futures import Future

from torch._C._distributed_rpc import (
    PyRRef,
    RemoteProfilerManager,
    WorkerInfo,
    TensorPipeAgent,
    get_rpc_timeout,
    _cleanup_python_rpc_handler,
    _delete_all_user_and_unforked_owner_rrefs,
    _destroy_rref_context,
    _get_current_rpc_agent,
    _invoke_remote_builtin,
    _invoke_remote_python_udf,
    _invoke_remote_torchscript,
    _invoke_rpc_builtin,
    _invoke_rpc_python_udf,
    _invoke_rpc_torchscript,
    _is_current_rpc_agent_set,
    _reset_current_rpc_agent,
    _set_and_start_rpc_agent,
)

from .internal import (
    PythonUDF,
    RPCExecMode,
    _internal_rpc_pickler,
    _build_rpc_profiling_key,
)

from .constants import DEFAULT_SHUTDOWN_TIMEOUT, UNSET_RPC_TIMEOUT

from ._utils import _group_membership_management, _update_group_membership

logger = logging.getLogger(__name__)

_ignore_rref_leak = True
_default_pickler = _internal_rpc_pickler

@contextlib.contextmanager
def _use_rpc_pickler(rpc_pickler):
    global _default_pickler
    _default_pickler = rpc_pickler
    try:
        yield
    finally:
        _default_pickler = _internal_rpc_pickler


def _require_initialized(func):
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        if not _is_current_rpc_agent_set():
            raise RuntimeError(
                "RPC has not been initialized. Call "
                "torch.distributed.rpc.init_rpc first."
            )
        return func(*args, **kwargs)

    return wrapper


class AllGatherStates:
    def __init__(self):
        self.gathered_objects = {}
        self.proceed_signal = threading.Event()


_ALL_WORKER_NAMES: Set[Any] = set()
_all_gather_dict_lock = threading.RLock()
_all_gather_sequence_id: Dict[str, int] = {}
_all_gather_sequence_id_to_states: collections.defaultdict = collections.defaultdict(AllGatherStates)


def _init_rpc_states(agent):
    worker_infos = agent.get_worker_infos()
    global _ALL_WORKER_NAMES
    _ALL_WORKER_NAMES = {worker_info.name for worker_info in worker_infos}

    if not _is_current_rpc_agent_set():
        _set_and_start_rpc_agent(agent)


def _gather_to_leader(sequence_id, worker_name, obj, worker_names=None):
    with _all_gather_dict_lock:
        if not worker_names:
            worker_names = _ALL_WORKER_NAMES
            assert (
                worker_name in worker_names
            ), f"{worker_name} is not expected by leader."
        states = _all_gather_sequence_id_to_states[sequence_id]
        assert (
            worker_name not in states.gathered_objects
        ), f"{worker_name} reported intent sequence id {sequence_id} twice. "
        states.gathered_objects[worker_name] = obj
        if worker_names == set(states.gathered_objects.keys()):
            states.proceed_signal.set()


def _broadcast_to_followers(sequence_id, objects_map):
    with _all_gather_dict_lock:
        states = _all_gather_sequence_id_to_states[sequence_id]

    assert (
        not states.proceed_signal.is_set()
    ), f"Termination signal sequence id {sequence_id} got set twice."
    states.gathered_objects = objects_map
    states.proceed_signal.set()

_thread_local_var = threading.local()


@contextlib.contextmanager
def _wait_all():
    _thread_local_var.future_list = []
    try:
        yield
    finally:
        try:
            torch.futures.wait_all(_thread_local_var.future_list)
        finally:
            del _thread_local_var.future_list


@_require_initialized
def _all_gather(obj, worker_names=None, timeout: float = UNSET_RPC_TIMEOUT):
    if not worker_names:
        assert (
            _ALL_WORKER_NAMES is not None
        ), "`_ALL_WORKER_NAMES` is not initialized for `def _all_gather`."
        worker_names = _ALL_WORKER_NAMES
    leader_name = min(worker_names)

    self_name = _get_current_rpc_agent().get_worker_info().name

    with _all_gather_dict_lock:
        concat_names = "".join(sorted(worker_names))
        sequence_num = _all_gather_sequence_id.get(concat_names, 0)
        _all_gather_sequence_id[concat_names] = sequence_num + 1
        sequence_id = concat_names + str(sequence_num)

    is_leader = leader_name == self_name

    if timeout == UNSET_RPC_TIMEOUT:
        rpc_timeout = get_rpc_timeout()
        signal_timeout = None
    elif timeout == DEFAULT_SHUTDOWN_TIMEOUT:
        rpc_timeout = timeout
        signal_timeout = None
    else:
        signal_timeout = rpc_timeout = timeout

    if is_leader:
        _gather_to_leader(sequence_id, self_name, obj, worker_names)
    else:
        rpc_sync(
            leader_name,
            _gather_to_leader,
            args=(sequence_id, self_name, obj, worker_names),
            timeout=rpc_timeout,
        )

    with _all_gather_dict_lock:
        states = _all_gather_sequence_id_to_states[sequence_id]

    states.proceed_signal.wait(timeout=signal_timeout)

    if is_leader:
        worker_name_to_response_future_dict = {}
        for follower_name in worker_names - {leader_name}:
            fut = rpc_async(
                follower_name,
                _broadcast_to_followers,
                args=(sequence_id, states.gathered_objects),
                timeout=rpc_timeout
            )
            worker_name_to_response_future_dict[follower_name] = fut

        errors = []
        for follower_name, fut in worker_name_to_response_future_dict.items():
            try:
                fut.wait()
            except RuntimeError as ex:
                errors.append((follower_name, ex))

        if errors:
            raise RuntimeError(
                f"Followers {[e[0] for e in errors]} timed out in _all_gather "
                f"after {rpc_timeout:.2f} seconds. The first exception is {errors[0][1]}"
            )

    with _all_gather_dict_lock:
        states = _all_gather_sequence_id_to_states.pop(sequence_id)
    return states.gathered_objects


@_require_initialized
def _barrier(worker_names):
    try:
        _all_gather(None, set(worker_names))
    except RuntimeError as ex:
        logger.error(
            "Failed to complete barrier, got error %s", ex
        )


@_require_initialized
def _wait_all_workers(timeout=DEFAULT_SHUTDOWN_TIMEOUT):
    try:
        _all_gather(None, timeout=timeout)
    except RuntimeError as ex:
        logger.error(
            "Failed to respond to 'Shutdown Proceed' in time, got error %s", ex
        )
        raise ex


@_require_initialized
def shutdown(graceful=True, timeout=DEFAULT_SHUTDOWN_TIMEOUT):
    if graceful:
        try:
            agent = _get_current_rpc_agent()
            if not isinstance(agent, TensorPipeAgent) or agent.is_static_group:
                _wait_all_workers(timeout)
                _delete_all_user_and_unforked_owner_rrefs()
                agent.join(shutdown=True, timeout=timeout)
            else:
                my_worker_info = agent.get_worker_info()
                my_name = my_worker_info.name
                with _group_membership_management(agent.store, my_name, False):
                    all_worker_infos = agent.get_worker_infos()
                    for worker in all_worker_infos:
                        if worker.name != my_name:
                            rpc_sync(worker.name, _update_group_membership, args=(my_worker_info, [], {}, False))
                    agent.join(shutdown=True, timeout=timeout)
        finally:
            _finalize_shutdown()
    else:
        _finalize_shutdown()


def _finalize_shutdown():
    try:
        _destroy_rref_context(_ignore_rref_leak)
    finally:
        _get_current_rpc_agent().shutdown()
        _cleanup_python_rpc_handler()
        _reset_current_rpc_agent()


@_require_initialized
def get_worker_info(worker_name=None):
    if worker_name is not None:
        return _get_current_rpc_agent().get_worker_info(worker_name)
    else:
        return _get_current_rpc_agent().get_worker_info()


def _to_worker_info(to):
    if isinstance(to, WorkerInfo):
        return to
    elif isinstance(to, (str, int)):
        return get_worker_info(to)
    else:
        raise ValueError(f"Cannot get WorkerInfo from name {to}")


def _rref_typeof_on_owner(rref, blocking: bool = True):
    rref_type = type(rref.local_value())
    if blocking:
        return rref_type
    else:
        future = Future[type]()
        future.set_result(rref_type)
        return future


def _rref_typeof_on_user(rref, timeout: float = UNSET_RPC_TIMEOUT, blocking: bool = True):
    fut = rpc_async(
        rref.owner(),
        _rref_typeof_on_owner,
        args=(rref,),
        timeout=timeout
    )
    if blocking:
        return fut.wait()
    else:
        return fut


T = TypeVar("T")
GenericWithOneTypeVar = Generic[T]


if TYPE_CHECKING:
    class RRef(PyRRef[T], Generic[T]):
        pass
else:
    try:
        class RRef(PyRRef, Generic[T]):
            pass
    except TypeError:
        class RRefMeta(PyRRef.__class__, GenericWithOneTypeVar.__class__):  # type: ignore[name-defined, misc, valid-type]
            pass

        class RRef(PyRRef, GenericWithOneTypeVar, metaclass=RRefMeta):  # type: ignore[misc, no-redef, valid-type]
            pass


def method_factory(method_name, docstring):
    def method(self, *args, **kwargs):
        return getattr(super(RRef, self), method_name)(*args, **kwargs)

    if method.__doc__:
        method.__doc__ = docstring
    return method


for method_name, method in inspect.getmembers(PyRRef):
    if method_name.startswith("_") and method_name != "__str__":
        continue

    docstring = getattr(method, "__doc__", None)
    assert docstring is not None, "RRef user-facing methods should all have docstrings."

    docstring = docstring.replace("torch.distributed.rpc.PyRRef", "torch.distributed.rpc.RRef")

    new_method = method_factory(method_name, docstring)
    setattr(RRef, method_name, new_method)


@_require_initialized
def remote(to, func, args=None, kwargs=None, timeout=UNSET_RPC_TIMEOUT):
    torch._C._log_api_usage_once("torch.distributed.rpc_remote")
    qualified_name = torch.jit._builtins._find_builtin(func)
    dst_worker_info = _to_worker_info(to)
    should_profile = _get_should_profile()

    ctx_manager = _enable_rpc_profiler(should_profile, qualified_name, func, RPCExecMode.REMOTE, dst_worker_info)

    with ctx_manager as rf:
        args = args if args else ()
        kwargs = kwargs if kwargs else {}

        is_async_exec = hasattr(func, "_wrapped_async_rpc_function")

        if is_async_exec:
            wrapped = func._wrapped_async_rpc_function
            if isinstance(wrapped, torch.jit.ScriptFunction):
                func = wrapped

        if qualified_name is not None:
            rref = _invoke_remote_builtin(dst_worker_info, qualified_name, timeout, *args, **kwargs)
        elif isinstance(func, torch.jit.ScriptFunction):
            rref = _invoke_remote_torchscript(
                dst_worker_info.name,
                torch._jit_internal._qualified_name(func),
                timeout,
                is_async_exec,
                *args,
                **kwargs,
            )
        else:
            (pickled_python_udf, tensors) = _default_pickler.serialize(
                PythonUDF(func, args, kwargs)
            )
            rref = _invoke_remote_python_udf(
                dst_worker_info,
                pickled_python_udf,
                tensors,
                timeout,
                is_async_exec
            )
        if should_profile:
            assert torch.autograd._profiler_enabled()
            assert rf is not None
            fut = rf._call_end_callbacks_on_future(rref._get_future())
            rref._set_profiling_future(fut)

    return rref


def _invoke_rpc(to, func, rpc_type, args=None, kwargs=None, rpc_timeout: float = UNSET_RPC_TIMEOUT):
    if not callable(func):
        raise TypeError("function should be callable.")

    qualified_name = torch.jit._builtins._find_builtin(func)
    dst_worker_info = _to_worker_info(to)

    should_profile = _get_should_profile()

    ctx_manager = _enable_rpc_profiler(should_profile, qualified_name, func, rpc_type, dst_worker_info)

    with ctx_manager as rf:
        args = args if args else ()
        kwargs = kwargs if kwargs else {}

        is_async_exec = hasattr(func, "_wrapped_async_rpc_function")

        if is_async_exec:
            wrapped = func._wrapped_async_rpc_function
            if isinstance(wrapped, torch.jit.ScriptFunction):
                func = wrapped

        if qualified_name is not None:
            fut = _invoke_rpc_builtin(
                dst_worker_info,
                qualified_name,
                rpc_timeout,
                *args,
                **kwargs
            )
        elif isinstance(func, torch.jit.ScriptFunction):
            fut = _invoke_rpc_torchscript(
                dst_worker_info.name,
                torch._jit_internal._qualified_name(func),
                args,
                kwargs,
                rpc_timeout,
                is_async_exec
            )
        else:
            (pickled_python_udf, tensors) = _default_pickler.serialize(
                PythonUDF(func, args, kwargs)
            )
            fut = _invoke_rpc_python_udf(
                dst_worker_info,
                pickled_python_udf,
                tensors,
                rpc_timeout,
                is_async_exec
            )
        if should_profile:
            assert torch.autograd._profiler_enabled()
            assert rf is not None
            fut = rf._call_end_callbacks_on_future(fut)
    return fut


@_require_initialized
def rpc_sync(to, func, args=None, kwargs=None, timeout: float = UNSET_RPC_TIMEOUT):
    torch._C._log_api_usage_once("torch.distributed.rpc_sync")
    fut = _invoke_rpc(to, func, RPCExecMode.SYNC, args, kwargs, timeout)
    return fut.wait()


@_require_initialized
def rpc_async(to, func, args=None, kwargs=None, timeout=UNSET_RPC_TIMEOUT):
    torch._C._log_api_usage_once("torch.distributed.rpc_async")
    fut = _invoke_rpc(to, func, RPCExecMode.ASYNC, args, kwargs, timeout)
    if hasattr(_thread_local_var, "future_list"):
        _thread_local_var.future_list.append(fut)
    return fut


def _get_should_profile():
    ActiveProfilerType = torch._C._profiler.ActiveProfilerType
    return (
        torch.autograd._profiler_enabled() and
        torch._C._autograd._profiler_type() == ActiveProfilerType.LEGACY  # type: ignore[attr-defined]
    )


def _enable_rpc_profiler(should_profile, qualified_name, func, rpc_type, dst_worker_info):
    ctx_manager = contextlib.nullcontext()

    if should_profile:
        if qualified_name is None:
            func_name = (
                torch._jit_internal._qualified_name(func)
                if isinstance(func, torch.jit.ScriptFunction)
                else func.__qualname__
            )
        else:
            func_name = qualified_name
        rpc_profiling_key = _build_rpc_profiling_key(
            rpc_type,
            func_name,
            get_worker_info().name,
            dst_worker_info.name,
        )
        RemoteProfilerManager.set_current_profiling_key(rpc_profiling_key)
        ctx_manager = torch.autograd.profiler.record_function(rpc_profiling_key)  # type: ignore[assignment]

    return ctx_manager

<END>

<START>
import functools
import itertools
import logging
from typing import Any, Callable, Dict, Iterable, List, Optional, Set, Tuple, Union

import sympy
from sympy import Expr

from torch.fx.experimental.symbolic_shapes import ShapeEnv
from torch.utils._sympy.functions import FloorDiv, ModularIndexing
from torch.utils._sympy.value_ranges import bound_sympy

from .utils import sympy_subs, sympy_symbol, VarRanges
from .virtualized import V

log = logging.getLogger(__name__)


class SizeVarAllocator:
    def __init__(self, shape_env=None):
        super().__init__()
        if shape_env is None:
            shape_env = ShapeEnv()
        self.shape_env = shape_env
        self.var_to_val = self.shape_env.var_to_val
        self.replacements: Dict[sympy.Symbol, Expr] = self.shape_env.replacements
        self.precomputed_replacements: Dict[Expr, sympy.Symbol] = dict()
        self.inv_precomputed_replacements: Dict[sympy.Symbol, Expr] = dict()
        self.stride_vars = self.make_stride_vars_cache()
        self.simplify_with_ranges = self.make_simplify_with_ranges_cache()
        self._simplify_loops = self.make_simplify_loops_cache()

    def simplify(self, expr: Expr):
        return sympy.expand(expr).xreplace(self.replacements)

    def make_simplify_with_ranges_cache(self) -> Callable[[Expr, VarRanges], Expr]:
        cache: Dict[Tuple[Any, ...], Expr] = dict()
        replacement_count = len(self.replacements)

        def simplify_with_ranges(expr: Expr, var_ranges: VarRanges) -> Expr:
            nonlocal replacement_count
            if replacement_count != len(self.replacements):
                cache.clear()
                replacement_count = len(self.replacements)
            key = (expr, *var_ranges.items())
            result = cache.get(key, None)
            if result is None:
                result = self._simplify_with_ranges(expr, var_ranges)
                cache[key] = result
            return result

        return simplify_with_ranges

    def make_simplify_loops_cache(self):
        cache: Dict[Tuple[Any, ...], Any] = dict()
        replacement_count = len(self.replacements)

        def simplify_loops(index_vars, sizes, index_formulas):
            nonlocal replacement_count
            if replacement_count != len(self.replacements):
                cache.clear()
                replacement_count = len(self.replacements)
            key = (*index_vars, *sizes, *index_formulas)
            result = cache.get(key, None)
            if result is None:
                result = self._simplify_loops_impl(index_vars, sizes, index_formulas)
                cache[key] = result
            return result

        return simplify_loops

    def _simplify_with_ranges(self, expr: Expr, var_ranges: VarRanges) -> Expr:

        expr = join_dimensions(self.simplify(expr))
        original_expr = expr

        def remove_zero_terms(base, divisor):
        Try to remove as many axis from loop iterations as possible, by:
            1) removing size==1 dimensions
            2) fuse contiguous dimensions into a single loop
            If channel_last = True, we will prevent the last dim fused with other dims
        Returns a bool indicating if it is sound to optimize as if left and right are equal.
        Returns a bool indicating if it is sound to optimize as if left and right lists are equal.
        Returns a bool indicating if it is sound to optimize as if left is less than or equal to right.
        Returns a bool indicating if it is sound to optimize as if left is less than right.
        Return a bool indicating if it is sound to optimize for the numerator being a multiple of the denominator.
        lv = self.size_hint(left)
        rv = self.size_hint(right)
        if lv <= rv:
            self.guard_leq(left, right)
            return left
        else:
            self.guard_leq(right, left)
            return right

    def evaluate_static_shape(self, left: Expr) -> int:
        right = self.size_hint(left)
        self.guard_equals(left, sympy.Integer(right))
        return int(right)

    def evaluate_static_shapes(self, left: List[Expr]) -> List[int]:
        return [self.evaluate_static_shape(x) for x in left]

    def symbolic_hint(self, expr: Expr) -> Expr:
        if not isinstance(expr, Expr):
            assert isinstance(expr, int)
            return expr
        free_symbols = expr.free_symbols
        if not free_symbols:
            return int(expr)
        while any(s.name.startswith("ps") for s in free_symbols):
            expr = sympy_subs(expr, self.inv_precomputed_replacements)
            free_symbols = expr.free_symbols
        return sympy_subs(expr, self.var_to_val)

    def size_hint(self, expr: Expr, *, fallback: Optional[int] = None) -> int:
        out = self.symbolic_hint(expr)
        if not isinstance(out, (int, sympy.Integer)) and fallback is not None:
            sym_vrs = {
                s: self.shape_env.var_to_range.get(s, None) for s in expr.free_symbols
            }
            if all(vr is not None for vr in sym_vrs.values()):
                expr_vr = bound_sympy(expr, sym_vrs)
                lower = self.size_hint(expr_vr.lower)
                upper = self.size_hint(expr_vr.upper)
                fallback = min(max(fallback, lower), upper)
            return fallback
        try:
            return int(out)
        except Exception:
            log.debug("failed on: %s", out)
            raise

    def size_hints(
        self,
        exprs: Iterable[Expr],
        *,
        fallback: Optional[int] = None,
    ) -> Tuple[int, ...]:
        return tuple(self.size_hint(x, fallback=fallback) for x in exprs)

    def _lru_cache(self, fn, maxsize=None):
        fn_cache = functools.lru_cache(maxsize)(fn)
        prior_len = len(self.replacements)

        @functools.wraps(fn)
        def wrapper(*args, **kwargs):
            nonlocal prior_len
            if prior_len != len(self.replacements):
                prior_len = len(self.replacements)
                fn_cache.cache_clear()
            return fn_cache(*args, **kwargs)

        return wrapper

    def make_stride_vars_cache(self):
        cache = self._lru_cache(self._stride_vars)

        def stride_vars(
            index: Expr,
            vars: List[sympy.Symbol],
            support_vars: Optional[List[sympy.Symbol]] = None,
        ) -> List[Expr]:
            if not support_vars:
                support_vars = vars
            return cache(index, tuple(vars), tuple(support_vars))

        return stride_vars

    def _stride_vars(
        self, index: Expr, vars: List[sympy.Symbol], support_vars: List[sympy.Symbol]
    ) -> List[Expr]:
        strides = []
        index = self.simplify(index)
        index = index - sympy_subs(
            index, {v: sympy.Integer(0) for v in support_vars if v != 0}
        )
        for i in range(len(vars)):
            index_dim = sympy_subs(
                index,
                {
                    support_vars[j]: sympy.Integer(0)
                    for j in range(len(support_vars))
                    if vars[i] != support_vars[j] and support_vars[j] != 0
                },
            )
            v = vars[i]
            if v == 0:
                strides.append(sympy.Integer(0))
            else:
                strides.append(
                    sympy_subs(index_dim, {v: sympy.Integer(1)})
                    - sympy_subs(index_dim, {v: sympy.Integer(0)})
                )
        return strides

    def offset_var(self, index: Expr, vars: List[sympy.Symbol]) -> Expr:
    ModularIndexing(i0, 1, 32) + 32 * ModularIndexing(i0, 32, 4)
    becomes
    ModularIndexing(i0, 1, 128)
    ModularIndexing(i0, 1, 32) + 32 * FloorDiv(i0, 32)
    becomes i0


    This type of pattern can come from view operations
    A wrapper around .virtualize.ops that uses var range information to
    simplify ModularIndexing/FloorDiv.

<END>

<START>
import torch
from torch.fx import GraphModule
from ..utils import (
    get_aten_graph_module,
    remove_tensor_overload_for_qdq_ops,
    _replace_literals_with_new_placeholders,
    _replace_literals_with_existing_placeholders,
)
from torch.ao.quantization.fx._decomposed import quantized_decomposed_lib  # noqa: F401
from torch.fx.subgraph_rewriter import replace_pattern
from torch._higher_order_ops.out_dtype import out_dtype
from typing import Optional, Callable, Tuple, Any
from dataclasses import dataclass

from functools import partial

__all__ = [
    "reference_representation_rewrite",
]


_QUANTIZED_LINEAR_EXAMPLE_INPUTS = (
    torch.randint(-128, 127, (2, 5), dtype=torch.int8),
    torch.randn(1, dtype=torch.float),
    torch.zeros(1, dtype=torch.int),
    torch.tensor([-128], dtype=torch.int),
    torch.tensor([127], dtype=torch.int),
    torch.randint(-128, 127, (5, 5), dtype=torch.int8),
    torch.randn(1, dtype=torch.float),
    torch.zeros(1, dtype=torch.int),
    torch.tensor([-127], dtype=torch.int),
    torch.tensor([127], dtype=torch.int),
    torch.randn(1, dtype=torch.float),
    torch.randn(1, dtype=torch.float),
    torch.zeros(1, dtype=torch.int),
    torch.tensor([-128], dtype=torch.int),
    torch.tensor([127], dtype=torch.int),
)

def _qdq_quantized_linear(
    x_i8, x_scale, x_zero_point, x_quant_min, x_quant_max,
    weight_i8, weight_scale, weight_zero_point, weight_quant_min, weight_quant_max,
    bias_fp32,
    out_scale, out_zero_point, out_quant_min, out_quant_max
):
    x_fp32 = torch.ops.quantized_decomposed.dequantize_per_tensor(
        x_i8, x_scale, x_zero_point, x_quant_min, x_quant_max, torch.int8)
    weight_fp32 = torch.ops.quantized_decomposed.dequantize_per_tensor(
        weight_i8, weight_scale, weight_zero_point, weight_quant_min, weight_quant_max, torch.int8)
    out_fp32 = torch.ops.aten.linear.default(x_fp32, weight_fp32, bias_fp32)
    out_i8 = torch.ops.quantized_decomposed.quantize_per_tensor(
        out_fp32, out_scale, out_zero_point, out_quant_min, out_quant_max, torch.int8)
    return out_i8

def _reference_quantized_linear(
    x_i8, x_scale, x_zero_point, x_quant_min, x_quant_max,
    weight_i8, weight_scale, weight_zero_point, weight_quant_min, weight_quant_max,
    bias_fp32,
    out_scale, out_zero_point, out_quant_min, out_quant_max
):
    x_i8 = torch.ops.aten.clamp(x_i8, x_quant_min, x_quant_max)
    weight_i8 = torch.ops.aten.clamp(weight_i8, weight_quant_min, weight_quant_max)

    x_i16 = x_i8.to(torch.int16)
    weight_i16 = weight_i8.to(torch.int16)
    acc_i32 = out_dtype(
        torch.ops.aten.linear.default,
        torch.int32,
        x_i16 - x_zero_point,
        weight_i16 - weight_zero_point,
        None)
    bias_scale = x_scale * weight_scale
    bias_i32 = out_dtype(torch.ops.aten.div.Tensor, torch.int32, bias_fp32, bias_scale)
    acc_i32 = acc_i32 + bias_i32
    acc_i32 = out_dtype(torch.ops.aten.mul.Tensor, torch.int32, acc_i32, x_scale * weight_scale / out_scale) + out_zero_point
    out_i8 = torch.ops.aten.clamp(acc_i32, out_quant_min, out_quant_max).to(torch.int8)
    return out_i8


_DYNAMIC_QUANTIZED_LINEAR_EXAMPLE_INPUTS = (
    torch.randn((2, 5), dtype=torch.float),
    -128,
    127,
    torch.finfo(torch.float32).eps,
    torch.randint(-128, 127, (5, 5), dtype=torch.int8),
    torch.randn(1, dtype=torch.float),
    torch.zeros(1, dtype=torch.int),
    torch.tensor([-127], dtype=torch.int),
    torch.tensor([127], dtype=torch.int),
    torch.randn(1, dtype=torch.float),
)


def _qdq_dynamic_quantized_linear(
    x_fp32, x_quant_min, x_quant_max, x_eps,
    weight_i8, weight_scale, weight_zero_point, weight_quant_min, weight_quant_max,
    bias_fp32,
):
    x_scale, x_zero_point = torch.ops.quantized_decomposed.choose_qparams(x_fp32, x_quant_min, x_quant_max, x_eps, torch.int8)
    x_i8 = torch.ops.quantized_decomposed.quantize_per_tensor(
        x_fp32, x_scale, x_zero_point, x_quant_min, x_quant_max, torch.int8)
    x_fp32 = torch.ops.quantized_decomposed.dequantize_per_tensor(
        x_i8, x_scale, x_zero_point, x_quant_min, x_quant_max, torch.int8)
    weight_fp32 = torch.ops.quantized_decomposed.dequantize_per_tensor(
        weight_i8, weight_scale, weight_zero_point, weight_quant_min, weight_quant_max, torch.int8)
    out_fp32 = torch.ops.aten.linear.default(x_fp32, weight_fp32, bias_fp32)
    return out_fp32

def _reference_dynamic_quantized_linear(
    x_fp32, x_quant_min, x_quant_max, x_eps,
    weight_i8, weight_scale, weight_zero_point, weight_quant_min, weight_quant_max,
    bias_fp32,
):
    x_scale, x_zero_point = torch.ops.quantized_decomposed.choose_qparams(x_fp32, x_quant_min, x_quant_max, x_eps, torch.int8)
    x_fp32 = x_fp32 / x_scale  # fp32
    x_fp32 = torch.round(x_fp32)  # fp32
    x_i32 = x_fp32.to(dtype=torch.int32)  # int32
    x_i32 = x_i32 + x_zero_point  # int32
    x_i32 = torch.clamp(x_i32, x_quant_min, x_quant_max)  # int32
    x_i8 = x_i32.to(dtype=torch.int8)

    weight_i8 = torch.ops.aten.clamp(weight_i8, weight_quant_min, weight_quant_max)

    x_i16 = x_i8.to(torch.int16)
    weight_i16 = weight_i8.to(torch.int16)
    acc_i32 = out_dtype(
        torch.ops.aten.linear.default,
        torch.int32,
        x_i16 - x_zero_point,
        weight_i16 - weight_zero_point,
        None)
    bias_scale = x_scale * weight_scale
    bias_i32 = out_dtype(torch.ops.aten.div.Tensor, torch.int32, bias_fp32, bias_scale)
    acc_i32 = acc_i32 + bias_i32
    out_fp32 = acc_i32 * (x_scale * weight_scale)
    return out_fp32


_QUANTIZED_CONV2d_EXAMPLE_INPUTS = (
    torch.randint(-128, 127, (1, 3, 3, 3), dtype=torch.int8),
    torch.randn(1, dtype=torch.float),
    torch.zeros(1, dtype=torch.int),
    torch.tensor([-128], dtype=torch.int),
    torch.tensor([127], dtype=torch.int),
    torch.randint(-128, 127, (1, 3, 3, 3), dtype=torch.int8),
    torch.randn(1, dtype=torch.float),
    torch.zeros(1, dtype=torch.int),
    torch.tensor([-127], dtype=torch.int),
    torch.tensor([127], dtype=torch.int),
    torch.randn(1, dtype=torch.float),
    torch.randn(1, dtype=torch.float),
    torch.zeros(1, dtype=torch.int),
    torch.tensor([-128], dtype=torch.int),
    torch.tensor([127], dtype=torch.int),
)

def _qdq_quantized_conv2d(
    x_i8, x_scale, x_zero_point, x_quant_min, x_quant_max,
    weight_i8, weight_scale, weight_zero_point, weight_quant_min, weight_quant_max,
    bias_fp32,
    out_scale, out_zero_point, out_quant_min, out_quant_max
):
    stride = [1, 1]
    padding = [0, 0]
    dilation = [1, 1]
    transposed = False
    output_padding = [0, 0]
    groups = 1
    x_fp32 = torch.ops.quantized_decomposed.dequantize_per_tensor(
        x_i8, x_scale, x_zero_point, x_quant_min, x_quant_max, torch.int8)
    weight_fp32 = torch.ops.quantized_decomposed.dequantize_per_tensor(
        weight_i8, weight_scale, weight_zero_point, weight_quant_min, weight_quant_max, torch.int8)
    out_fp32 = torch.ops.aten.convolution.default(
        x_fp32, weight_fp32, bias_fp32, stride, padding, dilation, transposed, output_padding, groups)
    out_i8 = torch.ops.quantized_decomposed.quantize_per_tensor(
        out_fp32, out_scale, out_zero_point, out_quant_min, out_quant_max, torch.int8)
    return out_i8

def _reference_quantized_conv2d(
    x_i8, x_scale, x_zero_point, x_quant_min, x_quant_max,
    weight_i8, weight_scale, weight_zero_point, weight_quant_min, weight_quant_max,
    bias_fp32,
    out_scale, out_zero_point, out_quant_min, out_quant_max
):
    stride = [1, 1]
    padding = [0, 0]
    dilation = [1, 1]
    transposed = False
    output_padding = [0, 0]
    groups = 1
    x_i8 = torch.ops.aten.clamp(x_i8, x_quant_min, x_quant_max)
    weight_i8 = torch.ops.aten.clamp(weight_i8, weight_quant_min, weight_quant_max)

    x_i16 = x_i8.to(torch.int16)
    weight_i16 = weight_i8.to(torch.int16)
    acc_i32 = out_dtype(
        torch.ops.aten.convolution.default,
        torch.int32,
        x_i16 - x_zero_point,
        weight_i16 - weight_zero_point,
        None, stride, padding, dilation, transposed, output_padding, groups)
    bias_scale = x_scale * weight_scale

    bias_i32 = out_dtype(torch.ops.aten.div.Tensor, torch.int32, bias_fp32, bias_scale)
    bias_i32 = bias_i32.unsqueeze(-1)
    bias_i32 = bias_i32.unsqueeze(-1)
    acc_i32 = acc_i32 + bias_i32
    acc_i32 = out_dtype(
        torch.ops.aten.mul.Tensor, torch.int32, acc_i32, x_scale * weight_scale / out_scale) + out_zero_point
    out_i8 = torch.ops.aten.clamp(acc_i32, out_quant_min, out_quant_max).to(torch.int8)
    return out_i8


_QUANTIZED_ADD_OR_ADD_RELU_EXAMPLE_INPUTS = (
    torch.randint(-128, 127, (1, 3, 3, 3), dtype=torch.int8),
    torch.randn(1, dtype=torch.float),
    torch.zeros(1, dtype=torch.int),
    torch.randint(-128, 127, (1, 3, 3, 3), dtype=torch.int8),
    torch.randn(1, dtype=torch.float),
    torch.zeros(1, dtype=torch.int),
    torch.randn(1, dtype=torch.float),
    torch.zeros(1, dtype=torch.int),
    torch.tensor([-128], dtype=torch.int),
    torch.tensor([127], dtype=torch.int),
)

def _qdq_quantized_add_relu(
    x_i8, x_scale, x_zero_point, y_i8, y_scale, y_zero_point,
    out_scale, out_zero_point, quant_min, quant_max
):
    x_fp32 = torch.ops.quantized_decomposed.dequantize_per_tensor(x_i8, x_scale, x_zero_point, quant_min, quant_max, torch.int8)
    y_fp32 = torch.ops.quantized_decomposed.dequantize_per_tensor(y_i8, y_scale, y_zero_point, quant_min, quant_max, torch.int8)
    out_fp32 = x_fp32 + y_fp32
    out_fp32 = torch.ops.aten.relu(out_fp32)
    out_i8 = torch.ops.quantized_decomposed.quantize_per_tensor(
        out_fp32, out_scale, out_zero_point, quant_min, quant_max, torch.int8
    )
    return out_i8

def _reference_quantized_add_relu(
    x_i8, x_scale, x_zero_point, y_i8, y_scale, y_zero_point,
    out_scale, out_zero_point, quant_min, quant_max
):
    x_i32 = x_i8.to(torch.int32)
    y_i32 = y_i8.to(torch.int32)
    x_i32 = out_dtype(torch.ops.aten.mul.Tensor, torch.int32, (x_i32 - x_zero_point), (x_scale / out_scale))
    y_i32 = out_dtype(torch.ops.aten.mul.Tensor, torch.int32, (y_i32 - y_zero_point), (y_scale / out_scale))
    out_i32 = x_i32 + y_i32 + out_zero_point
    out_i8 = torch.ops.aten.clamp(out_i32, out_zero_point, quant_max).to(torch.int8)
    return out_i8

def _qdq_quantized_add(x_i8, x_scale, x_zero_point, y_i8, y_scale, y_zero_point, out_scale, out_zero_point, quant_min, quant_max):
    x_fp32 = torch.ops.quantized_decomposed.dequantize_per_tensor(x_i8, x_scale, x_zero_point, quant_min, quant_max, torch.int8)
    y_fp32 = torch.ops.quantized_decomposed.dequantize_per_tensor(y_i8, y_scale, y_zero_point, quant_min, quant_max, torch.int8)
    out_fp32 = x_fp32 + y_fp32
    out_i8 = torch.ops.quantized_decomposed.quantize_per_tensor(
        out_fp32, out_scale, out_zero_point, quant_min, quant_max, torch.int8
    )
    return out_i8

def _reference_quantized_add(
    x_i8, x_scale, x_zero_point, y_i8, y_scale, y_zero_point,
    out_scale, out_zero_point, quant_min, quant_max
):
    x_i32 = x_i8.to(torch.int32)
    y_i32 = y_i8.to(torch.int32)
    x_i32 = torch.round((x_scale / out_scale) * (x_i32 - x_zero_point)).to(torch.int32)
    y_i32 = torch.round((y_scale / out_scale) * (y_i32 - y_zero_point)).to(torch.int32)
    out_i32 = x_i32 + y_i32 + out_zero_point
    quant_min = -128
    quant_max = 127
    out_i8 = torch.ops.aten.clamp(out_i32, quant_min, quant_max).to(torch.int8)
    return out_i8

_QUANTIZED_MAX_POOL2D_EXAMPLE_INPUTS = (
    torch.randint(-128, 127, (1, 3, 3, 3), dtype=torch.int8),
    torch.randn(1, dtype=torch.float),
    torch.zeros(1, dtype=torch.int),
    torch.tensor([-128], dtype=torch.int),
    torch.tensor([127], dtype=torch.int),
    torch.randn(1, dtype=torch.float),
    torch.zeros(1, dtype=torch.int),
    torch.tensor([-128], dtype=torch.int),
    torch.tensor([127], dtype=torch.int),
)

def _qdq_quantized_max_pool2d(
        x_i8, x_scale, x_zero_point, x_quant_min, x_quant_max, out_scale, out_zero_point, out_quant_min, out_quant_max):
    kernel_size = 1
    stride = 1
    padding = 0
    dilation = 1
    ceil_mode = False
    x_fp32 = torch.ops.quantized_decomposed.dequantize_per_tensor(x_i8, x_scale, x_zero_point, x_quant_min, x_quant_max, torch.int8)
    out_fp32, _ = torch.ops.aten.max_pool2d_with_indices.default(x_fp32, kernel_size, stride, padding, dilation, ceil_mode)
    out_i8 = torch.ops.quantized_decomposed.quantize_per_tensor(
        out_fp32, out_scale, out_zero_point, out_quant_min, out_quant_max, torch.int8)
    return out_i8

def _reference_quantized_max_pool2d(
        x_i8, x_scale, x_zero_point, x_quant_min, x_quant_max, out_scale, out_zero_point, out_quant_min, out_quant_max):
    kernel_size = 1
    stride = 1
    padding = 0
    dilation = 1
    ceil_mode = False
    x_i8 = torch.clamp(x_i8, x_quant_min, x_quant_max)
    x_i32 = x_i8.to(torch.int32)
    out_i32, _ = torch.ops.aten.max_pool2d_with_indices.default(
        x_i32 - x_zero_point,
        kernel_size,
        stride,
        padding,
        dilation,
        ceil_mode
    )
    out_fp32 = out_i32 * (x_scale / out_scale) + out_zero_point
    out_fp32 = torch.clamp(out_fp32, out_quant_min, out_quant_max)
    out_i8 = out_fp32.to(torch.int8)
    return out_i8

_QUANTIZE_PER_TENSOR_INT8_EXAMPLE_INPUTS = (
    torch.randn(1, 3, 3, 3, dtype=torch.float),
    torch.randn(1, dtype=torch.float),
    torch.zeros(1, dtype=torch.int),
    torch.tensor([-128], dtype=torch.int),
    torch.tensor([127], dtype=torch.int),
)

def _quantize_per_tensor_int8(x_fp32, scale, zero_point, quant_min, quant_max):
    x = torch.ops.quantized_decomposed.quantize_per_tensor(x_fp32, scale, zero_point, quant_min, quant_max, torch.int8)
    return x

def _reference_quantize_per_tensor_int8(x_fp32, scale, zero_point, quant_min, quant_max):
    x = x_fp32 / scale  # fp32
    x = torch.round(x)  # fp32
    x = x.to(dtype=torch.int32)  # int32
    x = x + zero_point  # int32
    x = torch.clamp(x, quant_min, quant_max)  # int32
    x = x.to(dtype=torch.int8)
    return x

_DEQUANTIZE_PER_TENSOR_INT8_EXAMPLE_INPUTS = (
    torch.randint(-128, 127, (1, 3, 3, 3), dtype=torch.int8),
    torch.randn(1, dtype=torch.float),
    torch.zeros(1, dtype=torch.int),
    torch.tensor([-128], dtype=torch.int),
    torch.tensor([127], dtype=torch.int),
)

def _dequantize_per_tensor_int8(x_i8, scale, zero_point, quant_min, quant_max):
    x_fp32 = torch.ops.quantized_decomposed.dequantize_per_tensor(x_i8, scale, zero_point, quant_min, quant_max, torch.int8)
    return x_fp32

def _reference_dequantize_per_tensor_int8(x_i8, scale, zero_point, quant_min, quant_max):
    x_i8 = torch.ops.aten.clamp(x_i8, quant_min, quant_max)
    return ((x_i8.to(torch.float32) - zero_point) * scale).to(dtype=torch.float32)

_QUANTIZE_PER_CHANNEL_INT8_EXAMPLE_INPUTS = (
    torch.randn(1, 3, 3, 3, dtype=torch.float),
    torch.randn(3, dtype=torch.float),
    torch.zeros(3, dtype=torch.int),
    1,
    -128,
    127,
)

def _quantize_per_channel_int8(x_fp32, scales, zero_points, ch_axis, quant_min, quant_max):
    out_i8 = torch.ops.quantized_decomposed.quantize_per_channel(
        x_fp32, scales, zero_points, ch_axis, quant_min, quant_max, torch.int8
    )
    return out_i8

def _reference_quantize_per_channel_int8(x_fp32, scales, zero_points, ch_axis, quant_min, quant_max):
    x_fp32 = torch.transpose(x_fp32, ch_axis, -1)
    out_i32 = torch.ops.aten.clamp(torch.round(x_fp32 / scales).to(torch.int32) + zero_points, quant_min, quant_max)
    out_i32 = torch.transpose(out_i32, ch_axis, -1)
    return out_i32.to(torch.int8)

_DEQUANTIZE_PER_CHANNEL_INT8_EXAMPLE_INPUTS = (
    torch.randint(-128, 127, (1, 3, 3, 3), dtype=torch.int8),
    torch.randn(3, dtype=torch.float),
    torch.zeros(3, dtype=torch.int),
    1,
    -128,
    127,
)

def _dequantize_per_channel_int8(x_i8, scales, zero_points, ch_axis, quant_min, quant_max):
    out_fp32 = torch.ops.quantized_decomposed.dequantize_per_channel(
        x_i8, scales, zero_points, ch_axis, quant_min, quant_max, torch.int8
    )
    return out_fp32

def _reference_dequantize_per_channel_int8(x_i8, scales, zero_points, ch_axis, quant_min, quant_max):
    x_i8 = torch.ops.aten.clamp(x_i8, quant_min, quant_max)
    x_i8 = torch.transpose(x_i8, ch_axis, -1)
    x_i32 = x_i8.to(torch.int32)
    out_fp32 = (x_i32 - zero_points).to(torch.float) * scales
    out_fp32 = torch.transpose(out_fp32, ch_axis, -1)
    return out_fp32

def _replace_ph_qdq_per_channel_replacement(gm: torch.fx.GraphModule):
    return _replace_literals_with_existing_placeholders(
        gm,
        exclude_literals=[-1],
        literal_to_ph_idx={1: 3, -128: 4, 127: 5}
    )


@dataclass
class _RewriteInfo:

    example_inputs: Tuple[Any, ...]
    pattern: Callable
    replacement: Callable
    pattern_post_trans: Optional[Callable[[GraphModule], GraphModule]] = None
    replacement_post_trans: Optional[Callable[[GraphModule], GraphModule]] = None

_REWRITE_INFO_LIST = [
    _RewriteInfo(
        _DYNAMIC_QUANTIZED_LINEAR_EXAMPLE_INPUTS,
        _qdq_dynamic_quantized_linear,
        _reference_dynamic_quantized_linear,
        partial(
            _replace_literals_with_existing_placeholders,
            literal_to_ph_idx={
                -128: 1,
                127: 2,
                torch.finfo(torch.float32).eps: 3
            }
        ),
        partial(
            _replace_literals_with_existing_placeholders,
            literal_to_ph_idx={
                -128: 1,
                127: 2,
                torch.finfo(torch.float32).eps: 3
            }
        ),
    ),
    _RewriteInfo(
        _QUANTIZED_LINEAR_EXAMPLE_INPUTS,
        _qdq_quantized_linear,
        _reference_quantized_linear,
        _replace_literals_with_new_placeholders,
        _replace_literals_with_new_placeholders,
    ),
    _RewriteInfo(
        _QUANTIZED_CONV2d_EXAMPLE_INPUTS,
        _qdq_quantized_conv2d,
        _reference_quantized_conv2d,
        partial(_replace_literals_with_new_placeholders, exclude_literals=[-1]),
        partial(_replace_literals_with_new_placeholders, exclude_literals=[-1]),
    ),
    _RewriteInfo(
        _QUANTIZED_ADD_OR_ADD_RELU_EXAMPLE_INPUTS,
        _qdq_quantized_add_relu,
        _reference_quantized_add_relu
    ),
    _RewriteInfo(
        _QUANTIZED_ADD_OR_ADD_RELU_EXAMPLE_INPUTS,
        _qdq_quantized_add,
        _reference_quantized_add
    ),
    _RewriteInfo(
        _QUANTIZED_MAX_POOL2D_EXAMPLE_INPUTS,
        _qdq_quantized_max_pool2d,
        _reference_quantized_max_pool2d,
        _replace_literals_with_new_placeholders,
        _replace_literals_with_new_placeholders
    ),
    _RewriteInfo(
        _QUANTIZE_PER_TENSOR_INT8_EXAMPLE_INPUTS,
        _quantize_per_tensor_int8,
        _reference_quantize_per_tensor_int8),
    _RewriteInfo(
        _DEQUANTIZE_PER_TENSOR_INT8_EXAMPLE_INPUTS,
        _dequantize_per_tensor_int8,
        _reference_dequantize_per_tensor_int8
    ),
    _RewriteInfo(
        _QUANTIZE_PER_CHANNEL_INT8_EXAMPLE_INPUTS,
        _quantize_per_channel_int8,
        _reference_quantize_per_channel_int8,
        _replace_ph_qdq_per_channel_replacement,
        _replace_ph_qdq_per_channel_replacement
    ),
    _RewriteInfo(
        _DEQUANTIZE_PER_CHANNEL_INT8_EXAMPLE_INPUTS,
        _dequantize_per_channel_int8,
        _reference_dequantize_per_channel_int8,
        _replace_ph_qdq_per_channel_replacement,
        _replace_ph_qdq_per_channel_replacement
    ),
]

def reference_representation_rewrite(model: GraphModule) -> GraphModule:
    remove_tensor_overload_for_qdq_ops(model)
    for rewrite_info in _REWRITE_INFO_LIST:
        example_inputs = rewrite_info.example_inputs
        pattern = rewrite_info.pattern
        replacement = rewrite_info.replacement
        pattern_post_trans = rewrite_info.pattern_post_trans
        replacement_post_trans = rewrite_info.replacement_post_trans
        pattern = get_aten_graph_module(pattern, example_inputs)  # type: ignore[arg-type, assignment]
        remove_tensor_overload_for_qdq_ops(pattern)  # type: ignore[arg-type]
        replacement = get_aten_graph_module(replacement, example_inputs)  # type: ignore[arg-type, assignment]
        remove_tensor_overload_for_qdq_ops(replacement)  # type: ignore[arg-type]
        if pattern_post_trans:
            pattern = pattern_post_trans(pattern)
        if replacement_post_trans:
            replacement = replacement_post_trans(replacement)
        pattern.recompile()  # type: ignore[attr-defined]
        replacement.recompile()  # type: ignore[attr-defined]
        matches = replace_pattern(model, pattern, replacement)
    return model

<END>

<START>
import logging
import multiprocessing as mp
import os
import signal
import time
from queue import Empty
from typing import Any, Dict, List, Set, Tuple

from .api import RequestQueue, TimerClient, TimerRequest, TimerServer

__all__ = ['LocalTimerClient', 'MultiprocessingRequestQueue', 'LocalTimerServer']

log = logging.getLogger(__name__)

class LocalTimerClient(TimerClient):

    def __init__(self, mp_queue):
        super().__init__()
        self._mp_queue = mp_queue

    def acquire(self, scope_id, expiration_time):
        pid = os.getpid()
        acquire_request = TimerRequest(pid, scope_id, expiration_time)
        self._mp_queue.put(acquire_request)

    def release(self, scope_id):
        pid = os.getpid()
        release_request = TimerRequest(pid, scope_id, -1)
        self._mp_queue.put(release_request)


class MultiprocessingRequestQueue(RequestQueue):

    def __init__(self, mp_queue: mp.Queue):
        super().__init__()
        self._mp_queue = mp_queue

    def size(self) -> int:
        return self._mp_queue.qsize()

    def get(self, size, timeout: float) -> List[TimerRequest]:
        requests = []
        wait = timeout
        for _ in range(0, size):
            start = time.time()

            try:
                r = self._mp_queue.get(block=True, timeout=wait)
            except Empty:
                break

            requests.append(r)
            wait = wait - (time.time() - start)
            if wait <= 0:
                break

        return requests


class LocalTimerServer(TimerServer):

    def __init__(
        self, mp_queue: mp.Queue, max_interval: float = 60, daemon: bool = True
    ):
        super().__init__(MultiprocessingRequestQueue(mp_queue), max_interval, daemon)
        self._timers: Dict[Tuple[Any, str], TimerRequest] = {}

    def register_timers(self, timer_requests: List[TimerRequest]) -> None:
        for request in timer_requests:
            pid = request.worker_id
            scope_id = request.scope_id
            expiration_time = request.expiration_time

            if expiration_time < 0:
                self._timers.pop((pid, scope_id), None)
            else:
                self._timers[(pid, scope_id)] = request

    def clear_timers(self, worker_ids: Set[int]) -> None:
        for (pid, scope_id) in list(self._timers.keys()):
            if pid in worker_ids:
                self._timers.pop((pid, scope_id))

    def get_expired_timers(self, deadline: float) -> Dict[Any, List[TimerRequest]]:
        expired_timers: Dict[Any, List[TimerRequest]] = {}
        for request in self._timers.values():
            if request.expiration_time <= deadline:
                expired_scopes = expired_timers.setdefault(request.worker_id, [])
                expired_scopes.append(request)
        return expired_timers

    def _reap_worker(self, worker_id: int) -> bool:
        try:
            os.kill(worker_id, signal.SIGKILL)
            return True
        except ProcessLookupError:
            log.info("Process with pid=%s does not exist. Skipping", worker_id)
            return True
        except Exception:
            log.exception("Error terminating pid=%s", worker_id)
        return False

<END>

<START>

from __future__ import annotations

import dataclasses
from typing import Any, List, Optional

from torch.onnx._internal.diagnostics.infra.sarif import (
    _message,
    _property_bag,
    _thread_flow_location,
)


@dataclasses.dataclass
class ThreadFlow(object):

<END>

<START>
import itertools
import operator
from dataclasses import dataclass
from typing import Callable, Dict, List, NamedTuple, Optional

import torch
import torch.nn.functional as F
from torch._subclasses import FakeTensor
from torch.ao.quantization.fx.utils import get_new_attr_name_with_prefix
from torch.ao.quantization.pt2e.graph_utils import find_sequential_partitions
from torch.ao.quantization.pt2e.utils import (
    _conv1d_bn_example_inputs,
    _conv2d_bn_example_inputs,
    get_aten_graph_module,
)
from torch.ao.quantization.quantizer import (
    QuantizationAnnotation,
    QuantizationSpec,
    QuantizationSpecBase,
    SharedQuantizationSpec,
)

from torch.ao.quantization.quantizer.utils import (
    _annotate_input_qspec_map,
    _annotate_output_qspec,
)
from torch.fx import Node
from torch.fx.passes.utils.matcher_with_name_node_map_utils import (
    SubgraphMatcherWithNameNodeMap,
)
from torch.fx.passes.utils.source_matcher_utils import get_source_partitions


__all__ = [
    "OperatorConfig",
    "OperatorPatternType",
    "QuantizationConfig",
    "get_input_act_qspec",
    "get_output_act_qspec",
    "get_weight_qspec",
    "get_bias_qspec",
    "OP_TO_ANNOTATOR",
    "propagate_annotation",
]


@dataclass(eq=True, frozen=True)
class QuantizationConfig:
    input_activation: Optional[QuantizationSpec]
    output_activation: Optional[QuantizationSpec]
    weight: Optional[QuantizationSpec]
    bias: Optional[QuantizationSpec]
    is_qat: bool = False


OperatorPatternType = List[Callable]
OperatorPatternType.__module__ = (
    "torch.ao.quantization.quantizer.xnnpack_quantizer_utils"
)

AnnotatorType = Callable[
    [
        torch.fx.GraphModule,
        Optional[QuantizationConfig],
        Optional[Callable[[Node], bool]],
    ],
    Optional[List[List[Node]]],
]
OP_TO_ANNOTATOR: Dict[str, AnnotatorType] = {}


def register_annotator(op: str):
    def decorator(annotator: AnnotatorType):
        OP_TO_ANNOTATOR[op] = annotator

    return decorator


class OperatorConfig(NamedTuple):
    config: QuantizationConfig
    operators: List[OperatorPatternType]


def _is_annotated(nodes: List[Node]):
    annotated = False
    for node in nodes:
        annotated = annotated or (
            "quantization_annotation" in node.meta
            and node.meta["quantization_annotation"]._annotated
        )
    return annotated


def _mark_nodes_as_annotated(nodes: List[Node]):
    for node in nodes:
        if node is not None:
            if "quantization_annotation" not in node.meta:
                node.meta["quantization_annotation"] = QuantizationAnnotation()
            node.meta["quantization_annotation"]._annotated = True


def get_input_act_qspec(quantization_config: Optional[QuantizationConfig]):
    if quantization_config is None:
        return None
    if quantization_config.input_activation is None:
        return None
    quantization_spec: QuantizationSpec = quantization_config.input_activation
    assert quantization_spec.qscheme in [
        torch.per_tensor_affine,
        torch.per_tensor_symmetric,
    ]
    return quantization_spec


def get_output_act_qspec(quantization_config: Optional[QuantizationConfig]):
    if quantization_config is None:
        return None
    if quantization_config.output_activation is None:
        return None
    quantization_spec: QuantizationSpec = quantization_config.output_activation
    assert quantization_spec.qscheme in [
        torch.per_tensor_affine,
        torch.per_tensor_symmetric,
    ]
    return quantization_spec


def get_weight_qspec(quantization_config: Optional[QuantizationConfig]):
    if quantization_config is None:
        return None
    assert quantization_config is not None
    if quantization_config.weight is None:
        return None
    quantization_spec: QuantizationSpec = quantization_config.weight
    if quantization_spec.qscheme not in [
        torch.per_tensor_symmetric,
        torch.per_channel_symmetric,
    ]:
        raise ValueError(
            f"Unsupported quantization_spec {quantization_spec} for weight"
        )
    return quantization_spec


def get_bias_qspec(quantization_config: Optional[QuantizationConfig]):
    if quantization_config is None:
        return None
    assert quantization_config is not None
    if quantization_config.bias is None:
        return None
    quantization_spec: QuantizationSpec = quantization_config.bias
    assert (
        quantization_spec.dtype == torch.float
    ), "Only float dtype for bias is supported for bias right now"
    return quantization_spec


@register_annotator("linear")
def _annotate_linear(
    gm: torch.fx.GraphModule,
    quantization_config: Optional[QuantizationConfig],
    filter_fn: Optional[Callable[[Node], bool]] = None,
) -> Optional[List[List[Node]]]:
    annotated_partitions = []
    input_act_qspec = get_input_act_qspec(quantization_config)
    output_act_qspec = get_output_act_qspec(quantization_config)
    weight_qspec = get_weight_qspec(quantization_config)
    bias_qspec = get_bias_qspec(quantization_config)
    for node in gm.graph.nodes:
        if node.op != "call_function" or node.target != torch.ops.aten.linear.default:
            continue
        if filter_fn and not filter_fn(node):
            continue
        act_node = node.args[0]
        weight_node = node.args[1]
        bias_node = None
        if len(node.args) > 2:
            bias_node = node.args[2]

        if _is_annotated([node]) is False:  # type: ignore[list-item]
            _annotate_input_qspec_map(
                node,
                act_node,
                input_act_qspec,
            )
            _annotate_input_qspec_map(
                node,
                weight_node,
                weight_qspec,
            )
            nodes_to_mark_annotated = [node, weight_node]
            if bias_node:
                _annotate_input_qspec_map(
                    node,
                    bias_node,
                    bias_qspec,
                )
                nodes_to_mark_annotated.append(bias_node)
            _annotate_output_qspec(node, output_act_qspec)
            _mark_nodes_as_annotated(nodes_to_mark_annotated)
            annotated_partitions.append(nodes_to_mark_annotated)

    return annotated_partitions


@register_annotator("conv")
def _annotate_conv(
    gm: torch.fx.GraphModule,
    quantization_config: Optional[QuantizationConfig],
    filter_fn: Optional[Callable[[Node], bool]] = None,
) -> Optional[List[List[Node]]]:
    annotated_partitions = []
    for n in gm.graph.nodes:
        if n.op != "call_function" or n.target not in [
            torch.ops.aten.conv1d.default,
            torch.ops.aten.conv2d.default,
        ]:
            continue
        conv_node = n

        input_qspec_map = {}
        input_act = conv_node.args[0]
        assert isinstance(input_act, Node)
        input_qspec_map[input_act] = get_input_act_qspec(quantization_config)

        weight = conv_node.args[1]
        assert isinstance(weight, Node)
        input_qspec_map[weight] = get_weight_qspec(quantization_config)

        partition = [conv_node, conv_node.args[1]]

        bias = conv_node.args[2] if len(conv_node.args) > 2 else None
        if isinstance(bias, Node):
            input_qspec_map[bias] = get_bias_qspec(quantization_config)
            partition.append(bias)

        if _is_annotated(partition):
            continue

        if filter_fn and any(not filter_fn(n) for n in partition):
            continue

        conv_node.meta["quantization_annotation"] = QuantizationAnnotation(
            input_qspec_map=input_qspec_map,
            output_qspec=get_output_act_qspec(quantization_config),
            _annotated=True,
        )
        _mark_nodes_as_annotated(partition)
        annotated_partitions.append(partition)
    return annotated_partitions


@register_annotator("conv_relu")
def _annotate_conv_relu(
    gm: torch.fx.GraphModule,
    quantization_config: Optional[QuantizationConfig],
    filter_fn: Optional[Callable[[Node], bool]] = None,
) -> Optional[List[List[Node]]]:
    annotated_partitions = []
    for n in gm.graph.nodes:
        if n.op != "call_function" or n.target not in [
            torch.ops.aten.relu.default,
            torch.ops.aten.relu_.default,
        ]:
            continue
        relu_node = n
        maybe_conv_node = n.args[0]
        if (
            not isinstance(maybe_conv_node, Node)
            or maybe_conv_node.op != "call_function"
            or maybe_conv_node.target
            not in [
                torch.ops.aten.conv1d.default,
                torch.ops.aten.conv2d.default,
            ]
        ):
            continue
        conv_node = maybe_conv_node

        input_qspec_map = {}
        input_act = conv_node.args[0]
        assert isinstance(input_act, Node)
        input_qspec_map[input_act] = get_input_act_qspec(quantization_config)

        weight = conv_node.args[1]
        assert isinstance(weight, Node)
        input_qspec_map[weight] = get_weight_qspec(quantization_config)

        partition = [relu_node, conv_node, conv_node.args[1]]
        bias = conv_node.args[2] if len(conv_node.args) > 2 else None
        if isinstance(bias, Node):
            input_qspec_map[bias] = get_bias_qspec(quantization_config)
            partition.append(bias)

        if _is_annotated(partition):
            continue

        if filter_fn and any(not filter_fn(n) for n in partition):
            continue

        conv_node.meta["quantization_annotation"] = QuantizationAnnotation(
            input_qspec_map=input_qspec_map, _annotated=True
        )
        relu_node.meta["quantization_annotation"] = QuantizationAnnotation(
            output_qspec=get_output_act_qspec(quantization_config),  # type: ignore[arg-type]
            _annotated=True,
        )
        _mark_nodes_as_annotated(partition)
        annotated_partitions.append(partition)
    return annotated_partitions


@register_annotator("conv_bn")
def _annotate_conv_bn(
    gm: torch.fx.GraphModule,
    quantization_config: Optional[QuantizationConfig],
    filter_fn: Optional[Callable[[Node], bool]] = None,
) -> Optional[List[List[Node]]]:
    return _do_annotate_conv_bn(gm, quantization_config, filter_fn, has_relu=False)


@register_annotator("conv_bn_relu")
def _annotate_conv_bn_relu(
    gm: torch.fx.GraphModule,
    quantization_config: Optional[QuantizationConfig],
    filter_fn: Optional[Callable[[Node], bool]] = None,
) -> Optional[List[List[Node]]]:
    return _do_annotate_conv_bn(gm, quantization_config, filter_fn, has_relu=True)


def _do_annotate_conv_bn(
    gm: torch.fx.GraphModule,
    quantization_config: Optional[QuantizationConfig],
    filter_fn: Optional[Callable[[Node], bool]],
    has_relu: bool,
) -> List[List[Node]]:

    def get_pattern(conv_fn: Callable, relu_is_inplace: bool):
        def _conv_bn(x, conv_weight, conv_bias, bn_weight, bn_bias, bn_rm, bn_rv):
            conv = conv_fn(x, conv_weight, conv_bias)
            bn = F.batch_norm(conv, bn_rm, bn_rv, bn_weight, bn_bias, training=True)
            if has_relu:
                output = F.relu_(bn) if relu_is_inplace else F.relu(bn)
            else:
                output = bn
            return output, {
                "input": x,
                "conv": conv,
                "weight": conv_weight,
                "bias": conv_bias,
                "output": output,
            }

        return _conv_bn

    gm.graph.eliminate_dead_code()
    gm.recompile()

    matches = []
    combinations = [
        (F.conv1d, _conv1d_bn_example_inputs),
        (F.conv2d, _conv2d_bn_example_inputs),
    ]

    combinations = itertools.product(
        combinations,
        [True, False] if torch.cuda.is_available() else [False],  # is_cuda
        [True, False] if has_relu else [False],  # relu_is_inplace
    )

    for (conv_fn, example_inputs), is_cuda, relu_is_inplace in combinations:
        pattern = get_pattern(conv_fn, relu_is_inplace)
        pattern = get_aten_graph_module(pattern, example_inputs, is_cuda)
        pattern.graph.eliminate_dead_code()
        pattern.recompile()
        matcher = SubgraphMatcherWithNameNodeMap(pattern, ignore_literals=True)
        matches.extend(matcher.match(gm.graph))

    annotated_partitions = []
    for match in matches:
        name_node_map = match.name_node_map
        input_node = name_node_map["input"]
        conv_node = name_node_map["conv"]
        weight_node = name_node_map["weight"]
        bias_node = name_node_map["bias"]
        output_node = name_node_map["output"]


        if conv_node.args[0] is not input_node:
            raise ValueError("Conv arg did not contain input node ", input_node)
        if conv_node.args[1] is not weight_node:
            raise ValueError("Conv arg did not contain weight node ", weight_node)
        if len(conv_node.args) > 2 and conv_node.args[2] is not bias_node:
            raise ValueError("Conv arg did not contain bias node ", bias_node)

        partition = [conv_node, weight_node]
        if bias_node is not None:
            partition.append(bias_node)
        if _is_annotated(partition):
            continue
        if filter_fn and any(not filter_fn(n) for n in partition):
            continue

        input_qspec_map = {}
        input_qspec_map[input_node] = get_input_act_qspec(quantization_config)
        input_qspec_map[weight_node] = get_weight_qspec(quantization_config)
        if bias_node is not None:
            input_qspec_map[bias_node] = get_bias_qspec(quantization_config)
        conv_node.meta["quantization_annotation"] = QuantizationAnnotation(
            input_qspec_map=input_qspec_map,
            _annotated=True,
        )
        output_node.meta["quantization_annotation"] = QuantizationAnnotation(
            output_qspec=get_output_act_qspec(quantization_config),  # type: ignore[arg-type]
            _annotated=True,
        )
        _mark_nodes_as_annotated(partition)
        annotated_partitions.append(partition)
    return annotated_partitions


@register_annotator("gru_io_only")
def _annotate_gru_io_only(
    gm: torch.fx.GraphModule,
    quantization_config: Optional[QuantizationConfig],
    filter_fn: Optional[Callable[[Node], bool]] = None,
) -> Optional[List[List[Node]]]:
    gru_partitions = get_source_partitions(gm.graph, [torch.nn.GRU], filter_fn)
    gru_partitions = list(itertools.chain.from_iterable(gru_partitions.values()))
    annotated_partitions = []
    for gru_partition in gru_partitions:
        annotated_partitions.append(gru_partition.nodes)
        output_nodes = gru_partition.output_nodes
        input_nodes = gru_partition.input_nodes
        if _is_annotated(input_nodes + output_nodes):
            continue
        input_qspec_map: Dict[Node, QuantizationSpecBase] = {}
        input_act = input_nodes[0]
        input_act_user = next(iter(input_act.users.keys()))
        assert isinstance(input_act, Node)
        assert isinstance(input_act_user, Node)
        input_act_user.meta["quantization_annotation"] = QuantizationAnnotation(
            input_qspec_map={
                input_act: get_input_act_qspec(quantization_config),
            },
            _annotated=True,
        )

        hidden_state = input_nodes[1]
        hidden_state_user = next(iter(hidden_state.users.keys()))
        assert isinstance(hidden_state, Node)
        assert isinstance(hidden_state_user, Node)
        hidden_state_user.meta["quantization_annotation"] = QuantizationAnnotation(
            input_qspec_map={
                hidden_state: get_input_act_qspec(quantization_config),
            },
            _annotated=True,
        )

        assert len(output_nodes) == 2, "expecting GRU to have two outputs"
        for output in output_nodes:
            output.meta["quantization_annotation"] = QuantizationAnnotation(
                output_qspec=get_output_act_qspec(quantization_config),
                _annotated=True,
            )
        nodes_to_mark_annotated = list(gru_partition.nodes)
        _mark_nodes_as_annotated(nodes_to_mark_annotated)
    return annotated_partitions


@register_annotator("max_pool2d")
def _annotate_max_pool2d(
    gm: torch.fx.GraphModule,
    quantization_config: Optional[QuantizationConfig],
    filter_fn: Optional[Callable[[Node], bool]] = None,
) -> Optional[List[List[Node]]]:
    module_partitions = get_source_partitions(
        gm.graph, [torch.nn.MaxPool2d, torch.nn.functional.max_pool2d], filter_fn
    )
    maxpool_partitions = list(itertools.chain.from_iterable(module_partitions.values()))
    annotated_partitions = []
    for maxpool_partition in maxpool_partitions:
        annotated_partitions.append(maxpool_partition.nodes)
        output_node = maxpool_partition.output_nodes[0]
        maxpool_node = None
        for n in maxpool_partition.nodes:
            if n.target == torch.ops.aten.max_pool2d.default:
                maxpool_node = n
        assert (
            maxpool_node is not None
        ), "XNNPACKQuantizer only works with torch.ops.aten.max_pool2d.default, "
        "please make sure you are exporting the model correctly"
        if _is_annotated([output_node, maxpool_node]):  # type: ignore[list-item]
            continue

        input_act = maxpool_node.args[0]  # type: ignore[union-attr]
        assert isinstance(input_act, Node)

        if (
            "quantization_annotation" not in input_act.meta
            or not input_act.meta["quantization_annotation"]._annotated
            or input_act.meta["quantization_annotation"].output_qspec is None
        ):
            continue
        act_qspec = SharedQuantizationSpec(input_act)
        maxpool_node.meta["quantization_annotation"] = QuantizationAnnotation(  # type: ignore[union-attr]
            input_qspec_map={
                input_act: act_qspec,
            },
            _annotated=True,
        )
        output_node.meta["quantization_annotation"] = QuantizationAnnotation(
            output_qspec=act_qspec,
            _annotated=True,
        )
    return annotated_partitions


@register_annotator("adaptive_avg_pool2d")
def _annotate_adaptive_avg_pool2d(
    gm: torch.fx.GraphModule,
    quantization_config: Optional[QuantizationConfig],
    filter_fn: Optional[Callable[[Node], bool]] = None,
) -> Optional[List[List[Node]]]:
    since histc op (in HistogramObserver) only works for values up to certain upper bound
    since observers only works with float Tensors

<END>

<START>
import collections
import importlib.machinery
import io
import linecache
import pickletools
import platform
import types
from collections import defaultdict, OrderedDict
from dataclasses import dataclass
from enum import Enum
from importlib.machinery import SourceFileLoader
from pathlib import Path
from typing import (
    Any,
    BinaryIO,
    Callable,
    cast,
    DefaultDict,
    Dict,
    List,
    Optional,
    Sequence,
    Set,
    Union,
)

import torch
from torch.serialization import location_tag, normalize_storage_type
from torch.types import Storage
from torch.utils.hooks import RemovableHandle

from ._digraph import DiGraph
from ._importlib import _normalize_path
from ._mangling import demangle, is_mangled
from ._package_pickler import create_pickler
from ._stdlib import is_stdlib_module
from .find_file_dependencies import find_files_source_depends_on
from .glob_group import GlobGroup, GlobPattern
from .importer import Importer, OrderedImporter, sys_importer

__all__ = [
    "PackagingErrorReason",
    "EmptyMatchError",
    "PackagingError",
    "PackageExporter",
]

_gate_torchscript_serialization = True

ActionHook = Callable[["PackageExporter", str], None]


class _ModuleProviderAction(Enum):

    INTERN = 1
    EXTERN = 2
    MOCK = 3
    DENY = 4
    REPACKAGED_MOCK_MODULE = 5
    SKIP = 6


class PackagingErrorReason(Enum):

    def __repr__(self):
        return f"<{self.__class__.__name__}.{self.name}>"

    IS_EXTENSION_MODULE = (
        "Module is a C extension module. torch.package supports Python modules only."
    )
    NO_DUNDER_FILE = "Module had no __file__ defined."
    SOURCE_FILE_NOT_FOUND = (
        "Module had a __file__, but we could not find it in your filesystem."
    )
    DEPENDENCY_RESOLUTION_FAILED = "Dependency resolution failed."
    NO_ACTION = (
        "Module did not match against any action pattern. Extern, mock, or intern it."
    )
    DENIED = "Module was denied by a pattern."
    MOCKED_BUT_STILL_USED = (
        "Module was mocked out, but is still being used in the package. "
        "Please intern or extern the mocked modules if objects are supposed to be in "
        "the package."
    )


@dataclass
class _PatternInfo:
    ``allow_empty=False``, and is not matched with any module during packaging.
    ``PackageExporter`` will attempt to gather up all the errors and present
    them to you at once.
    arbitrary binary and text resources into a self-contained package.

    Imports can load this code in a hermetic way, such that code is loaded
    from the package rather than the normal Python import system. This allows
    for the packaging of PyTorch model code and data so that it can be run
    on a server or used in the future for transfer learning.

    The code contained in packages is copied file-by-file from the original
    source when it is created, and the file format is a specially organized
    zip file. Future users of the package can unzip the package, and edit the code
    in order to perform custom modifications to it.

    The importer for packages ensures that code in the module can only be loaded from
    within the package, except for modules explicitly listed as external using :meth:`extern`.
    The file ``extern_modules`` in the zip archive lists all the modules that a package externally depends on.
    This prevents "implicit" dependencies where the package runs locally because it is importing
    a locally-installed package, but then fails when the package is copied to another machine.

    When source code is added to the package, the exporter can optionally scan it
    for further code dependencies (``dependencies=True``). It looks for import statements,
    resolves relative references to qualified module names, and performs an action specified by the user
    (See: :meth:`extern`, :meth:`mock`, and :meth:`intern`).
    pickled objects. The default module environment just uses sys_importer, which searches the Python environment.
        Create an exporter.

        Args:
            f: The location to export to. Can be a  ``string``/``Path`` object containing a filename
                or a binary I/O object.
            importer: If a single Importer is passed, use that to search for modules.
                If a sequence of importers are passed, an ``OrderedImporter`` will be constructed out of them.
            debug: If set to True, add path of broken modules to PackagingErrors.
        for ``module_name``.

        Args:
            module_name (str): e.g. ``"my_package.my_subpackage"``, code will be saved to provide code for this package.
            file_or_directory (str): the path to a file or directory of code. When a directory, all python files in the directory
                are recursively copied using :meth:`save_source_file`. If a file is named ``"/__init__.py"`` the code is treated
                as a package.
            dependencies (bool, optional): If ``True``, we scan the source for dependencies.
        ret = str(self._unique_id)
        self._unique_id += 1
        return ret

    def _get_dependencies(
        self, src: str, module_name: str, is_package: bool
    ) -> List[str]:
        package_name = (
            module_name if is_package else module_name.rsplit(".", maxsplit=1)[0]
        )
        try:
            dep_pairs = find_files_source_depends_on(src, package_name)
        except Exception as e:
            self.dependency_graph.add_node(
                module_name,
                error=PackagingErrorReason.DEPENDENCY_RESOLUTION_FAILED,
                error_context=str(e),
            )
            return []

        dependencies = {}
        for dep_module_name, dep_module_obj in dep_pairs:
            if dep_module_obj is not None:
                possible_submodule = f"{dep_module_name}.{dep_module_obj}"
                if self._module_exists(possible_submodule):
                    dependencies[possible_submodule] = True
                    continue
            if self._module_exists(dep_module_name):
                dependencies[dep_module_name] = True

        return list(dependencies.keys())

    def save_source_string(
        self,
        module_name: str,
        src: str,
        is_package: bool = False,
        dependencies: bool = True,
    ):
        self.dependency_graph.add_node(
            module_name,
            source=src,
            is_package=is_package,
            provided=True,
            action=_ModuleProviderAction.INTERN,
        )

        if dependencies:
            deps = self._get_dependencies(src, module_name, is_package)

            for dep in deps:
                self.dependency_graph.add_edge(module_name, dep)
                self.add_dependency(dep)

    def _write_source_string(
        self,
        module_name: str,
        src: str,
        is_package: bool = False,
    ):
        extension = "/__init__.py" if is_package else ".py"
        filename = module_name.replace(".", "/") + extension

        self._write(filename, src)

    def _import_module(self, module_name: str):
        try:
            return self.importer.import_module(module_name)
        except ModuleNotFoundError as e:
            if not is_mangled(module_name):
                raise
            msg = (
                f"Module not found: '{module_name}'. Make sure the PackageImporter that "
                "created this module is present in `self.importer`"
            )
            raise ModuleNotFoundError(msg) from None

    def _module_exists(self, module_name: str) -> bool:
        try:
            self._import_module(module_name)
            return True
        except Exception:
            return False

    def _get_source_of_module(self, module: types.ModuleType) -> Optional[str]:
        filename = None
        spec = getattr(module, "__spec__", None)
        if spec is not None:
            loader = getattr(spec, "loader", None)
            if loader is not None and isinstance(loader, SourceFileLoader):
                try:
                    filename = loader.get_filename(module.__name__)
                except ImportError:
                    pass
        if filename is None:
            filename = getattr(module, "__file__", None)
        if isinstance(filename, str) and filename.endswith(".py"):
            return "".join(linecache.getlines(filename, module.__dict__))
        return None

    def add_dependency(self, module_name: str, dependencies=True):
        if (
            module_name in self.dependency_graph
            and self.dependency_graph.nodes[module_name].get("provided") is True
        ):
            return

        if module_name == "torch_package_importer":
            self.dependency_graph.add_node(
                module_name,
                action=_ModuleProviderAction.SKIP,
                provided=True,
            )
            return

        if module_name == "_mock":
            self.dependency_graph.add_node(
                module_name,
                action=_ModuleProviderAction.REPACKAGED_MOCK_MODULE,
                provided=True,
            )
            return

        if self._can_implicitly_extern(module_name):
            self.dependency_graph.add_node(
                module_name, action=_ModuleProviderAction.EXTERN, provided=True
            )
            return

        for pattern, pattern_info in self.patterns.items():
            if pattern.matches(module_name):
                pattern_info.was_matched = True
                self.dependency_graph.add_node(
                    module_name, action=pattern_info.action, provided=True
                )

                if pattern_info.action == _ModuleProviderAction.DENY:
                    self.dependency_graph.add_node(
                        module_name, error=PackagingErrorReason.DENIED
                    )

                if pattern_info.action == _ModuleProviderAction.INTERN:
                    self._intern_module(module_name, dependencies)
                return

        self.dependency_graph.add_node(
            module_name, error=PackagingErrorReason.NO_ACTION
        )

    def save_module(self, module_name: str, dependencies=True):
        if not isinstance(module_name, str):
            raise TypeError(
                "save_module() expects a string input, did you perhaps mean to pass `__name__`?"
            )

        self._intern_module(module_name, dependencies)

    def _intern_module(
        self,
        module_name: str,
        dependencies: bool,
    ):
        module_obj = self._import_module(module_name)
        module_name = demangle(module_name)

        is_package = hasattr(module_obj, "__path__")
        source = self._get_source_of_module(module_obj)
        if source is None:
            filename = getattr(module_obj, "__file__", None)
            error_context = None
            if filename is None:
                packaging_error = PackagingErrorReason.NO_DUNDER_FILE
            elif filename.endswith(tuple(importlib.machinery.EXTENSION_SUFFIXES)):
                packaging_error = PackagingErrorReason.IS_EXTENSION_MODULE
            else:
                packaging_error = PackagingErrorReason.SOURCE_FILE_NOT_FOUND
                error_context = f"filename: {filename}"
            self.dependency_graph.add_node(
                module_name,
                action=_ModuleProviderAction.INTERN,
                is_package=is_package,
                error=packaging_error,
                error_context=error_context,
                provided=True,
            )
            return

        self.dependency_graph.add_node(
            module_name,
            action=_ModuleProviderAction.INTERN,
            is_package=is_package,
            source=source,
            provided=True,
        )

        if dependencies:
            deps = self._get_dependencies(source, module_name, is_package)
            for dep in deps:
                self.dependency_graph.add_edge(module_name, dep)
                self.add_dependency(dep)

    def save_pickle(
        self,
        package: str,
        resource: str,
        obj: Any,
        dependencies: bool = True,
        pickle_protocol: int = 3,
    ):

        assert (pickle_protocol == 4) or (
            pickle_protocol == 3
        ), "torch.package only supports pickle protocols 3 and 4"

        filename = self._filename(package, resource)
        data_buf = io.BytesIO()
        pickler = create_pickler(data_buf, self.importer, protocol=pickle_protocol)
        pickler.persistent_id = self._persistent_id
        pickler.dump(obj)
        data_value = data_buf.getvalue()
        mocked_modules = defaultdict(list)
        name_in_dependency_graph = f"<{package}.{resource}>"
        self.dependency_graph.add_node(
            name_in_dependency_graph,
            action=_ModuleProviderAction.INTERN,
            provided=True,
            is_pickle=True,
        )

        def _check_mocked_error(module: Optional[str], field: Optional[str]):

            assert isinstance(module, str)
            assert isinstance(field, str)
            if self._can_implicitly_extern(module):
                return
            for pattern, pattern_info in self.patterns.items():
                if pattern.matches(module):
                    if pattern_info.action == _ModuleProviderAction.MOCK:
                        mocked_modules[module].append(field)
                    return

        if dependencies:
            all_dependencies = []
            module = None
            field = None
            memo: DefaultDict[int, str] = defaultdict(None)
            memo_count = 0
            for opcode, arg, pos in pickletools.genops(data_value):
                if pickle_protocol == 4:
                    if (
                        opcode.name == "SHORT_BINUNICODE"
                        or opcode.name == "BINUNICODE"
                        or opcode.name == "BINUNICODE8"
                    ):
                        assert isinstance(arg, str)
                        module = field
                        field = arg
                        memo[memo_count] = arg
                    elif (
                        opcode.name == "LONG_BINGET"
                        or opcode.name == "BINGET"
                        or opcode.name == "GET"
                    ):
                        assert isinstance(arg, int)
                        module = field
                        field = memo.get(arg, None)
                    elif opcode.name == "MEMOIZE":
                        memo_count += 1
                    elif opcode.name == "STACK_GLOBAL":
                        if module is None:
                            continue
                        assert isinstance(module, str)
                        if module not in all_dependencies:
                            all_dependencies.append(module)
                        _check_mocked_error(module, field)
                elif (
                    pickle_protocol == 3 and opcode.name == "GLOBAL"
                ):  # a global reference
                    assert isinstance(arg, str)
                    module, field = arg.split(" ")
                    if module not in all_dependencies:
                        all_dependencies.append(module)
                    _check_mocked_error(module, field)
            for module_name in all_dependencies:
                self.dependency_graph.add_edge(name_in_dependency_graph, module_name)

                if module in mocked_modules:
                    assert isinstance(module, str)
                    fields = mocked_modules[module]
                    self.dependency_graph.add_node(
                        module_name,
                        action=_ModuleProviderAction.MOCK,
                        error=PackagingErrorReason.MOCKED_BUT_STILL_USED,
                        error_context=f"Object(s) '{fields}' from module `{module_name}` was mocked out during packaging "
                        f"but is being used in resource - `{resource}` in package `{package}`. ",
                        provided=True,
                    )
                else:
                    self.add_dependency(module_name)

        self._write(filename, data_value)

    def save_text(self, package: str, resource: str, text: str):
        return self.save_binary(package, resource, text.encode("utf-8"))

    def save_binary(self, package, resource, binary: bytes):
        filename = self._filename(package, resource)
        self._write(filename, binary)

    def register_extern_hook(self, hook: ActionHook) -> RemovableHandle:
        handle = RemovableHandle(self._extern_hooks)
        self._extern_hooks[handle.id] = hook
        return handle

    def register_mock_hook(self, hook: ActionHook) -> RemovableHandle:
        handle = RemovableHandle(self._mock_hooks)
        self._mock_hooks[handle.id] = hook
        return handle

    def register_intern_hook(self, hook: ActionHook) -> RemovableHandle:
        handle = RemovableHandle(self._intern_hooks)
        self._intern_hooks[handle.id] = hook
        return handle

    def intern(
        self,
        include: "GlobPattern",
        *,
        exclude: "GlobPattern" = (),
        allow_empty: bool = True,
    ):
        self.patterns[GlobGroup(include, exclude=exclude)] = _PatternInfo(
            _ModuleProviderAction.INTERN, allow_empty
        )

    def mock(
        self,
        include: "GlobPattern",
        *,
        exclude: "GlobPattern" = (),
        allow_empty: bool = True,
    ):
        self.patterns[GlobGroup(include, exclude=exclude)] = _PatternInfo(
            _ModuleProviderAction.MOCK, allow_empty
        )

    def extern(
        self,
        include: "GlobPattern",
        *,
        exclude: "GlobPattern" = (),
        allow_empty: bool = True,
    ):
        self.patterns[GlobGroup(include, exclude=exclude)] = _PatternInfo(
            _ModuleProviderAction.EXTERN, allow_empty
        )

    def deny(self, include: "GlobPattern", *, exclude: "GlobPattern" = ()):
        self.patterns[GlobGroup(include, exclude=exclude)] = _PatternInfo(
            _ModuleProviderAction.DENY, allow_empty=True
        )

    def _persistent_id(self, obj):
        if torch.is_storage(obj) or isinstance(obj, torch.storage.TypedStorage):
            storage: Storage
            if isinstance(obj, torch.storage.TypedStorage):
                untyped_storage = obj._untyped_storage
                storage_type_str = obj.pickle_storage_type()
                storage_type = getattr(torch, storage_type_str)
                storage = cast(Storage, untyped_storage)
                storage_numel = obj.size()

            elif isinstance(obj, torch.UntypedStorage):
                untyped_storage = obj
                storage = cast(Storage, untyped_storage)
                storage_type = normalize_storage_type(type(storage))
                storage_numel = storage.nbytes()
            else:
                raise RuntimeError(f"storage type not recognized: {type(obj)}")

            location = location_tag(storage)

            storage_present = self.storage_context.has_storage(storage)
            storage_id = self.storage_context.get_or_add_storage(storage)
            if not storage_present:
                if storage.device.type != "cpu":
                    storage = storage.cpu()
                num_bytes = storage.nbytes()
                self.zip_file.write_record(
                    f".data/{storage_id}.storage", storage.data_ptr(), num_bytes
                )
            return ("storage", storage_type, storage_id, location, storage_numel)

        if hasattr(obj, "__reduce_package__"):
            if _gate_torchscript_serialization and isinstance(
                obj, torch.jit.RecursiveScriptModule
            ):
                raise Exception(
                    "Serializing ScriptModules directly into a package is a beta feature. "
                    "To use, set global "
                    "`torch.package.package_exporter._gate_torchscript_serialization` to `False`."
                )
            if self.serialized_reduces.get(id(obj)) is None:
                self.serialized_reduces[id(obj)] = (
                    "reduce_package",
                    id(obj),
                    *obj.__reduce_package__(self),
                )

            return self.serialized_reduces[id(obj)]

        return None

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_value, traceback):
        if exc_type is not None:
            self._finalize_zip()
            return

        self.close()

    def _write(self, filename, str_or_bytes):
        if filename in self._written_files:
            raise AssertionError(
                f"Tried to write file '{filename}', but it already exists in this archive. "
                "Please file a bug."
            )
        self._written_files.add(filename)

        if is_mangled(filename):
            raise AssertionError(
                f"Tried to save a torch.package'd module as '{filename}'. "
                "Directly saving torch.package'd modules is not allowed."
            )
        if isinstance(str_or_bytes, str):
            str_or_bytes = str_or_bytes.encode("utf-8")
        self.zip_file.write_record(filename, str_or_bytes, len(str_or_bytes))

    def _validate_dependency_graph(self):
        for attrs in self.dependency_graph.nodes.values():
            if "error" in attrs:
                raise PackagingError(self.dependency_graph, debug=self.debug)

        for pattern, pattern_info in self.patterns.items():
            if not pattern_info.allow_empty and not pattern_info.was_matched:
                raise EmptyMatchError(
                    f"Exporter did not match any modules to {pattern}, which was marked as allow_empty=False"
                )

    def _write_mock_file(self):
        if "_mock.py" not in self._written_files:
            mock_file = str(Path(__file__).parent / "_mock.py")
            self._write_source_string("_mock", _read_file(mock_file), is_package=False)

    def _execute_dependency_graph(self):
        self._validate_dependency_graph()

        extern_modules = []
        for module_name, attrs in self.dependency_graph.nodes.items():
            action = attrs["action"]

            if action == _ModuleProviderAction.EXTERN:
                for hook in self._extern_hooks.values():
                    hook(self, module_name)

                extern_modules.append(module_name)

            elif action == _ModuleProviderAction.MOCK:
                for hook in self._mock_hooks.values():
                    hook(self, module_name)

                self._write_mock_file()

                is_package = hasattr(self._import_module(module_name), "__path__")
                self._write_source_string(module_name, _MOCK_IMPL, is_package)

            elif action == _ModuleProviderAction.INTERN:
                for hook in self._intern_hooks.values():
                    hook(self, module_name)

                if "provided" not in attrs:
                    raise AssertionError(
                        f"Module was marked `intern` but not provided: {module_name}"
                    )

                if attrs.get("is_pickle") is True:
                    continue

                is_package = attrs["is_package"]
                source = attrs["source"]
                self._write_source_string(module_name, source, is_package)

            elif action == _ModuleProviderAction.REPACKAGED_MOCK_MODULE:
                self._write_mock_file()
            elif action == _ModuleProviderAction.SKIP:
                continue
            else:
                raise AssertionError(
                    f"Invalid action: {module_name}, {action}. Please report a bug to PyTorch."
                )

        extern_file_contents = "\n".join(extern_modules) + "\n"
        self._write(".data/extern_modules", extern_file_contents)

    def _write_python_version(self):
        It is preferable to use resource guard syntax instead::

            with PackageExporter("file.zip") as e:
                ...
        del self.zip_file
        if self.buffer:
            self.buffer.flush()

    def _filename(self, package, resource):
        package_path = package.replace(".", "/")
        resource = _normalize_path(resource)
        return f"{package_path}/{resource}"

    def _can_implicitly_extern(self, module_name: str):
        top_level_package_name = module_name.partition(".")[0]
        return top_level_package_name == "torch" or (
            top_level_package_name not in _DISALLOWED_MODULES
            and is_stdlib_module(top_level_package_name)
        )

    def dependency_graph_string(self) -> str:
        return self.dependency_graph.to_dot()

    def _nodes_with_action_type(
        self, action: Optional[_ModuleProviderAction]
    ) -> List[str]:
        result = []
        for name, node_dict in self.dependency_graph.nodes.items():
            node_action = node_dict.get("action", None)
            if node_action == action and "is_pickle" not in node_dict:
                result.append(name)
        result.sort()
        return result

    def externed_modules(self) -> List[str]:
        return self._nodes_with_action_type(_ModuleProviderAction.EXTERN)

    def interned_modules(self) -> List[str]:
        return self._nodes_with_action_type(_ModuleProviderAction.INTERN)

    def mocked_modules(self) -> List[str]:
        return self._nodes_with_action_type(_ModuleProviderAction.MOCK)

    def denied_modules(self) -> List[str]:
        return self._nodes_with_action_type(_ModuleProviderAction.DENY)

    def get_rdeps(self, module_name: str) -> List[str]:
        if module_name in self.dependency_graph._pred.keys():
            return list(self.dependency_graph._pred[module_name].keys())
        else:
            return []

    def all_paths(self, src: str, dst: str) -> str:
        return self.dependency_graph.all_paths(src, dst)


_DISALLOWED_MODULES = ["sys", "io"]



def _read_file(filename: str) -> str:
    with open(filename, "rb") as f:
        b = f.read()
        return b.decode("utf-8")

<END>

<START>
import inspect
from typing import Callable, Dict, List, Optional, Tuple

import torch
import torch._decomp
from torch import Tensor
from torch._prims_common.wrappers import _maybe_remove_out_wrapper

decomposition_table = torch._decomp.decomposition_table
decomposition_table_for_jvp: Dict[torch._ops.OperatorBase, Callable] = {}
register_decomposition = torch._decomp.register_decomposition
aten = torch.ops.aten



def maybe_register_decomposition(op):
    def decorator(f):
        try:
            return register_decomposition(op)(f)
        except Exception:
            return f

    return decorator


decomposition_table_for_jvp = {}


def register_decomposition_for_jvp(fn):
    return register_decomposition(fn, registry=decomposition_table_for_jvp)


def _register_jit_decomposition_for_jvp(decomp, use_python=False):
    if decomp in decomposition_table_for_jvp:
        decomposition_table_used = decomposition_table_for_jvp
    elif decomp in decomposition_table:
        decomposition_table_used = decomposition_table
    else:
        raise RuntimeError(f"could not find decomposition for {decomp}")
    decomp_fn = decomposition_table_used[decomp]

    decomp_fn = _maybe_remove_out_wrapper(decomp_fn)

    if use_python:
        decomp_fn = torch.jit.ignore(decomp_fn)
        sig = inspect.signature(decomp_fn)

        def get_function_def(sig):
            param_def = [f"{param_str}" for param_str in sig.parameters.values()]
            param_use = [f"{param_str}" for param_str in sig.parameters.keys()]

            return f"def wrapped_decomp({', '.join(param_def)}):\n  return decomp_fn({', '.join(param_use)})\n"

        f_str = get_function_def(sig)
        graph = torch.jit.CompilationUnit(f_str).wrapped_decomp.graph
    else:
        graph = torch.jit.script(decomp_fn).graph
    torch.jit._register_decomposition(decomp, graph)




@maybe_register_decomposition(aten.trace.default)
def trace(self: Tensor) -> Tensor:
    return torch.sum(torch.diag(self))


@maybe_register_decomposition(aten.log_sigmoid_forward.default)
def log_sigmoid_forward(self: Tensor) -> Tuple[Tensor, Tensor]:
    min = torch.minimum(self.new_zeros(()), self)
    z = torch.exp(-torch.abs(self))
    if self.is_cuda:
        buffer = self.new_zeros((0,))
    else:
        buffer = z
    return min - torch.log1p(z), buffer


def recompute_mean_var(
    input: Tensor, rstd: Tensor, inner_dim_indices: List[int], keepdim: bool
):

    mean = torch.mean(input, dim=inner_dim_indices, keepdim=keepdim)
    var = torch.var(input, dim=inner_dim_indices, unbiased=False, keepdim=keepdim)
    eps = torch.pow(1 / rstd, 2) - var  # this makes me so sad inside
    eps = eps.detach()
    rstd = 1 / torch.sqrt(var + eps)
    return mean, rstd


@register_decomposition_for_jvp(aten.native_layer_norm_backward)
def native_layer_norm_backward(
    grad_out: Tensor,
    input: Tensor,
    normalized_shape: List[int],
    mean: Tensor,
    rstd: Tensor,
    weight: Optional[Tensor],
    bias: Optional[Tensor],
    output_mask: List[bool],
) -> Tuple[Optional[Tensor], Optional[Tensor], Optional[Tensor]]:
    input_shape = input.shape
    input_ndim = input.dim()

    axis = input_ndim - len(normalized_shape)
    inner_dims = input_shape[axis:]
    outer_dims = input_shape[:axis]
    inner_dim_indices = list(range(axis, input_ndim))
    outer_dim_indices = list(range(0, axis))

    N = 1
    for i in inner_dims:
        N *= i
    M = 1
    for i in outer_dims:
        M *= i
    if M <= 0 or N <= 0:
        return (
            input.new_zeros(input_shape),
            input.new_zeros(input_shape[axis:]),
            input.new_zeros(input_shape[axis:]),
        )

    mean_, rstd_ = recompute_mean_var(input, rstd, inner_dim_indices, keepdim=True)

    x_hat = (input - mean_) * rstd_
    if weight is not None:
        grad_x_hat = grad_out * weight
    else:
        grad_x_hat = grad_out
    a = grad_x_hat * N
    b = torch.sum(grad_x_hat, inner_dim_indices, True)
    c1 = torch.mul(grad_x_hat, x_hat)
    c2 = torch.sum(c1, inner_dim_indices, True)
    c3 = torch.mul(x_hat, c2)
    inner = a - b - c3

    if output_mask[0]:
        d_input: Optional[Tensor] = (rstd_ / N) * inner
    else:
        d_input = torch.zeros_like(input)  # should be None but doesn't work with vjp

    if output_mask[1] and weight is not None:
        if len(outer_dim_indices) > 0:
            d_weight: Optional[Tensor] = torch.sum(
                grad_out * x_hat, outer_dim_indices, False
            )
        else:
            d_weight = grad_out * x_hat
    elif weight is not None:
        d_weight = torch.zeros_like(weight)  # should be None but doesn't work with vjp
    else:
        d_weight = torch.zeros(())  # should be None but doesn't work with vjp

    if output_mask[2] and bias is not None:
        if len(outer_dim_indices) > 0:
            d_bias: Optional[Tensor] = torch.sum(grad_out, outer_dim_indices, False)
        else:
            d_bias = grad_out.clone()
    elif bias is not None:
        d_bias = torch.zeros_like(bias)  # should be None but doesn't work with vjp
    else:
        d_bias = torch.zeros(())  # should be None but doesn't work with vjp

    return (d_input, d_weight, d_bias)


def prod(x: List[int]):
    r = 1
    for i in x:
        r *= i
    return r


@register_decomposition_for_jvp(aten.native_batch_norm_backward)
def native_batch_norm_backward(
    grad_out: Tensor,
    input: Tensor,
    weight: Optional[Tensor],
    running_mean: Optional[Tensor],
    running_var: Optional[Tensor],
    save_mean: Optional[Tensor],
    save_invstd: Optional[Tensor],
    train: bool,
    eps: float,
    output_mask: List[bool],
) -> Tuple[Tensor, Optional[Tensor], Optional[Tensor]]:
    input_shape = input.shape
    input_rank = input.dim()
    assert input_rank >= 2, "rank of the input must be at least 2"

    axis = 1
    num_features = prod(input_shape) / input_shape[axis]  # type: ignore[arg-type]
    mean = save_mean
    invstd = save_invstd
    if train:
        assert (
            save_mean is not None and save_invstd is not None
        ), "when train=True, save_mean and save_invstd are required"

        reduciton_dims = [0] + list(range(2, input.dim()))
        assert invstd is not None  # for typing
        mean, invstd = recompute_mean_var(input, invstd, reduciton_dims, keepdim=False)
    else:
        assert running_mean is not None and running_var is not None
        mean = running_mean
        invstd = torch.rsqrt(running_var + eps)

    assert invstd is not None and mean is not None

    broadcast_mask = [1] * input_rank
    broadcast_mask[axis] = input_shape[axis]

    reduction_axes: List[int] = []
    for i in range(input_rank):
        if i != axis:
            reduction_axes.append(i)

    mean = torch.reshape(mean, broadcast_mask)
    norm = 1.0 / num_features
    grad_output_sum = torch.sum(grad_out, reduction_axes)
    dot_p = torch.sum(grad_out * (input - mean), reduction_axes)

    grad_mean = torch.reshape(grad_output_sum * norm, broadcast_mask)
    proj_scale = torch.reshape(torch.mul(dot_p * norm, invstd * invstd), broadcast_mask)

    if weight is None:
        grad_scale = torch.reshape(invstd, broadcast_mask) * 1.0
    else:
        grad_scale = torch.reshape(invstd * weight, broadcast_mask)

    if train:
        proj = (input - mean) * proj_scale
        grad_input = ((grad_out - proj) - grad_mean) * grad_scale
    else:
        grad_input = grad_out * grad_scale

    if output_mask[1]:
        grad_weight = dot_p * invstd
    elif weight is not None:
        grad_weight = torch.zeros_like(
            weight
        )  # should be None but doesn't work with vjp
    else:
        grad_weight = torch.zeros(())  # should be None but doesn't work with vjp

    if output_mask[2]:
        grad_bias = grad_output_sum
    else:
        grad_bias = torch.zeros_like(
            grad_output_sum
        )  # should be None but doesn't work with vjp

    return (grad_input, grad_weight, grad_bias)


_register_jit_decomposition_for_jvp(torch.ops.aten.trace.default, use_python=True)
_register_jit_decomposition_for_jvp(torch.ops.aten.nll_loss_backward.default)
_register_jit_decomposition_for_jvp(torch.ops.aten.nll_loss2d_backward.default)
_register_jit_decomposition_for_jvp(torch.ops.aten._log_softmax_backward_data.default)
_register_jit_decomposition_for_jvp(torch.ops.aten._softmax_backward_data.default)
_register_jit_decomposition_for_jvp(torch.ops.aten.log_sigmoid_forward.default)
_register_jit_decomposition_for_jvp(torch.ops.aten.native_layer_norm_backward.default)
_register_jit_decomposition_for_jvp(torch.ops.aten.native_batch_norm_backward.default)
_register_jit_decomposition_for_jvp(torch.ops.aten.cudnn_batch_norm_backward.default)

<END>

<START>
from typing import Any, Dict, List, Optional
import torch
from collections import defaultdict
from torch import nn
import copy
from ...sparsifier.utils import fqn_to_module, module_to_fqn
import warnings

__all__ = ['ActivationSparsifier']


class ActivationSparsifier:
    def __init__(self, model: nn.Module, aggregate_fn=None, reduce_fn=None, mask_fn=None,
                 features=None, feature_dim=None, **sparse_config):
        self.model = model
        self.defaults: Dict[str, Any] = defaultdict()
        self.defaults['sparse_config'] = sparse_config

        self.defaults['aggregate_fn'] = aggregate_fn
        self.defaults['reduce_fn'] = reduce_fn
        self.defaults['mask_fn'] = mask_fn

        self.defaults['features'] = features
        self.defaults['feature_dim'] = feature_dim

        self.data_groups: Dict[str, Dict] = defaultdict(dict)  # contains all relevant info w.r.t each registered layer

        self.state: Dict[str, Any] = defaultdict(dict)  # layer name -> mask

    @staticmethod
    def _safe_rail_checks(args):

        features, feature_dim = args['features'], args['feature_dim']
        if features is not None:
            assert feature_dim is not None, "need feature dim to select features"

        fn_keys = ['aggregate_fn', 'reduce_fn', 'mask_fn']
        for key in fn_keys:
            fn = args[key]
            assert callable(fn), 'function should be callable'

    def _aggregate_hook(self, name):

        feature_dim = self.data_groups[name]['feature_dim']
        features = self.data_groups[name]['features']
        agg_fn = self.data_groups[name]['aggregate_fn']

        def hook(module, input) -> None:
            input_data = input[0]

            data = self.data_groups[name].get('data')  # aggregated data
            if features is None:
                if data is None:
                    data = torch.zeros_like(input_data)
                    self.state[name]['mask'] = torch.ones_like(input_data)
                out_data = agg_fn(data, input_data)
            else:
                if data is None:
                    out_data = [0 for _ in range(0, len(features))]  # create one incase of 1st forward
                    self.state[name]['mask'] = [0 for _ in range(0, len(features))]
                else:
                    out_data = data  # a list

                for feature_idx in range(len(features)):
                    feature_tensor = torch.Tensor([features[feature_idx]]).long().to(input_data.device)
                    data_feature = torch.index_select(input_data, feature_dim, feature_tensor)
                    if data is None:
                        curr_data = torch.zeros_like(data_feature)
                        self.state[name]['mask'][feature_idx] = torch.ones_like(data_feature)
                    else:
                        curr_data = data[feature_idx]
                    out_data[feature_idx] = agg_fn(curr_data, data_feature)
            self.data_groups[name]['data'] = out_data
        return hook

    def register_layer(self, layer: nn.Module, aggregate_fn=None, reduce_fn=None,
                       mask_fn=None, features=None, feature_dim=None, **sparse_config):
        name = module_to_fqn(self.model, layer)
        assert name is not None, "layer not found in the model"  # satisfy mypy

        if name in self.data_groups:  # unregister layer if already present
            warnings.warn("layer already attached to the sparsifier, deregistering the layer and registering with new config")
            self.unregister_layer(name=name)

        local_args = copy.deepcopy(self.defaults)
        update_dict = {
            'aggregate_fn': aggregate_fn,
            'reduce_fn': reduce_fn,
            'mask_fn': mask_fn,
            'features': features,
            'feature_dim': feature_dim,
            'layer': layer
        }
        local_args.update((arg, val) for arg, val in update_dict.items() if val is not None)
        local_args['sparse_config'].update(sparse_config)

        self._safe_rail_checks(local_args)

        self.data_groups[name] = local_args
        agg_hook = layer.register_forward_pre_hook(self._aggregate_hook(name=name))

        self.state[name]['mask'] = None  # mask will be created when model forward is called.

        self.data_groups[name]['hook'] = agg_hook

        self.data_groups[name]['hook_state'] = "aggregate"  # aggregate hook is attached

    def get_mask(self, name: Optional[str] = None, layer: Optional[nn.Module] = None):
        assert name is not None or layer is not None, "Need at least name or layer obj to retrieve mask"

        if name is None:
            assert layer is not None
            name = module_to_fqn(self.model, layer)
            assert name is not None, "layer not found in the specified model"

        if name not in self.state:
            raise ValueError("Error: layer with the given name not found")

        mask = self.state[name].get('mask', None)

        if mask is None:
            raise ValueError("Error: shape unknown, call layer() routine at least once to infer mask")
        return mask

    def unregister_layer(self, name):

        self.data_groups[name]['hook'].remove()

        self.state.pop(name)

        self.data_groups.pop(name)

    def step(self):
        with torch.no_grad():
            for name, configs in self.data_groups.items():
                data = configs['data']
                self.update_mask(name, data, configs)

                self.data_groups[name].pop('data')  # reset the accumulated data

    def update_mask(self, name, data, configs):
        mask = self.get_mask(name)
        sparse_config = configs['sparse_config']
        features = configs['features']
        reduce_fn = configs['reduce_fn']
        mask_fn = configs['mask_fn']
        if features is None:
            data = reduce_fn(data)
            mask.data = mask_fn(data, **sparse_config)
        else:
            for feature_idx in range(len(features)):
                data_feature = reduce_fn(data[feature_idx])
                mask[feature_idx].data = mask_fn(data_feature, **sparse_config)

    def _sparsify_hook(self, name):
        mask = self.get_mask(name)
        features = self.data_groups[name]['features']
        feature_dim = self.data_groups[name]['feature_dim']

        def hook(module, input):
            input_data = input[0]
            if features is None:
                return input_data * mask
            else:
                for feature_idx in range(0, len(features)):
                    feature = torch.Tensor([features[feature_idx]]).long().to(input_data.device)
                    sparsified = torch.index_select(input_data, feature_dim, feature) * mask[feature_idx]
                    input_data.index_copy_(feature_dim, feature, sparsified)
                return input_data
        return hook

    def squash_mask(self, attach_sparsify_hook=True, **kwargs):
        for name, configs in self.data_groups.items():
            configs['hook'].remove()
            configs.pop('hook')
            self.data_groups[name]['hook_state'] = "None"
            if attach_sparsify_hook:
                configs['hook'] = configs['layer'].register_forward_pre_hook(self._sparsify_hook(name))
            configs['hook_state'] = "sparsify"  # signals that sparsify hook is now attached

    def _get_serializable_data_groups(self):
        data_groups: Dict[str, Any] = defaultdict()
        for name, config in self.data_groups.items():
            new_config = {key: value for key, value in config.items() if key not in ['hook', 'layer']}
            data_groups[name] = new_config
        return data_groups

    def _convert_mask(self, states_dict, sparse_coo=True):
        states = copy.deepcopy(states_dict)
        for state in states.values():
            if state['mask'] is not None:
                if isinstance(state['mask'], List):
                    for idx in range(len(state['mask'])):
                        if sparse_coo:
                            state['mask'][idx] = state['mask'][idx].to_sparse_coo()
                        else:
                            state['mask'][idx] = state['mask'][idx].to_dense()
                else:
                    if sparse_coo:
                        state['mask'] = state['mask'].to_sparse_coo()
                    else:
                        state['mask'] = state['mask'].to_dense()
        return states

    def state_dict(self) -> Dict[str, Any]:
        data_groups = self._get_serializable_data_groups()
        state = self._convert_mask(self.state)
        return {
            'state': state,
            'data_groups': data_groups,
            'defaults': self.defaults
        }

    def load_state_dict(self, state_dict: Dict[str, Any]) -> None:
        state = state_dict['state']
        data_groups, defaults = state_dict['data_groups'], state_dict['defaults']

        self.__set_state__({'state': state, 'data_groups': data_groups, 'defaults': defaults})

    def __get_state__(self) -> Dict[str, Any]:

        data_groups = self._get_serializable_data_groups()
        state = self._convert_mask(self.state)
        return {
            'defaults': self.defaults,
            'state': state,
            'data_groups': data_groups,
        }

    def __set_state__(self, state: Dict[str, Any]) -> None:
        state['state'] = self._convert_mask(state['state'], sparse_coo=False)  # convert mask to dense tensor
        self.__dict__.update(state)

        for name, config in self.data_groups.items():
            layer = fqn_to_module(self.model, name)
            assert layer is not None  # satisfy mypy

            if "hook_state" in config and config['hook_state'] == "aggregate":
                hook = layer.register_forward_pre_hook(self._aggregate_hook(name))

            elif "hook_state" in config and config["hook_state"] == "sparsify":
                hook = layer.register_forward_pre_hook(self._sparsify_hook(name))

            config['layer'] = layer
            config['hook'] = hook

    def __repr__(self):
        format_string = self.__class__.__name__ + ' ('
        for name, config in self.data_groups.items():
            format_string += '\n'
            format_string += '\tData Group\n'
            format_string += f'\t    name: {name}\n'
            for key in sorted(config.keys()):
                if key in ['data', 'hook', 'reduce_fn', 'mask_fn', 'aggregate_fn']:
                    continue
                format_string += f'\t    {key}: {config[key]}\n'
        format_string += ')'
        return format_string

<END>

<START>
from functools import partial
from typing import Any, Optional, Tuple

import torch
from torch.distributed._tensor import DeviceMesh, DTensor, Replicate, Shard

__all__ = [
    "input_reshard",
]


def input_reshard(
    module: torch.nn.Module,
    tp_device_mesh: DeviceMesh,
    input_reshard_dim: Optional[int] = None,
) -> torch.nn.Module:
    cx: Optional[torch.autograd.graph.saved_tensors_hooks] = None

    def input_reshard_forward_pre_hook(_: torch.nn.Module, _i: Tuple[Any, ...]) -> None:
        saved_tensor_hooks = torch.autograd.graph.saved_tensors_hooks(
            partial(_pack_hook_tp, tp_device_mesh, input_reshard_dim),
            partial(_unpack_hook_tp, tp_device_mesh, input_reshard_dim),
        )
        saved_tensor_hooks.__enter__()
        nonlocal cx
        cx = saved_tensor_hooks  # type: ignore[name-defined]

    def input_reshard_backward_hook(_: torch.nn.Module, _i: Tuple[Any, ...], _o: Any) -> Any:
        nonlocal cx
        cx.__exit__()  # type: ignore[name-defined, union-attr]

    if input_reshard_dim is None:
        return module
    module.register_forward_pre_hook(input_reshard_forward_pre_hook)
    module.register_forward_hook(input_reshard_backward_hook)
    return module


def _pack_hook_tp(mesh: DeviceMesh, input_reshard_dim: int, x: torch.Tensor) -> Any:  # noqa: D401
    if (
        isinstance(x, DTensor)
        and len(x._spec.placements) == 1
        and x._spec.placements[0].is_shard()
    ):
        return x.redistribute(device_mesh=mesh, placements=[Replicate()])
    elif (
        not isinstance(x, DTensor)
        and isinstance(x, torch.Tensor)
        and x.numel() >= mesh.size()
    ):
        return (
            DTensor.from_local(
                x, device_mesh=mesh, placements=[Shard(input_reshard_dim)]
            )
            .redistribute(device_mesh=mesh, placements=[Replicate()])
            .to_local()
        )
    else:
        return x

<END>

<START>
    memory_format (:class:`torch.memory_format`, optional): the desired memory format of
        returned Tensor. Default: ``torch.preserve_format``.
    size (int...): a list, tuple, or :class:`torch.Size` of integers defining the
        shape of the output tensor.
    dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.
        Default: if None, same :class:`torch.dtype` as this tensor.
    device (:class:`torch.device`, optional): the desired device of returned tensor.
        Default: if None, same :class:`torch.device` as this tensor.
    requires_grad (bool, optional): If autograd should record operations on the
        returned tensor. Default: ``False``.
    pin_memory (bool, optional): If set, returned tensor would be allocated in
        the pinned memory. Works only for CPU tensors. Default: ``False``.
    layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.
        Default: ``torch.strided``.
new_tensor(data, *, dtype=None, device=None, requires_grad=False, layout=torch.strided, \
pin_memory=False) -> Tensor

Returns a new Tensor with :attr:`data` as the tensor data.
By default, the returned Tensor has the same :class:`torch.dtype` and
:class:`torch.device` as this tensor.

.. warning::

    :func:`new_tensor` always copies :attr:`data`. If you have a Tensor
    ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`
    or :func:`torch.Tensor.detach`.
    If you have a numpy array and want to avoid a copy, use
    :func:`torch.from_numpy`.

.. warning::

    When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,
    and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``
    and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.
    The equivalents using ``clone()`` and ``detach()`` are recommended.

Args:
    data (array_like): The returned Tensor copies :attr:`data`.

Keyword args:
    {dtype}
    {device}
    {requires_grad}
    {layout}
    {pin_memory}

Example::

    >>> tensor = torch.ones((2,), dtype=torch.int8)
    >>> data = [[0, 1], [2, 3]]
    >>> tensor.new_tensor(data)
    tensor([[ 0,  1],
            [ 2,  3]], dtype=torch.int8)

new_full(size, fill_value, *, dtype=None, device=None, requires_grad=False, layout=torch.strided, \
pin_memory=False) -> Tensor

Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.
By default, the returned Tensor has the same :class:`torch.dtype` and
:class:`torch.device` as this tensor.

Args:
    fill_value (scalar): the number to fill the output tensor with.

Keyword args:
    {dtype}
    {device}
    {requires_grad}
    {layout}
    {pin_memory}

Example::

    >>> tensor = torch.ones((2,), dtype=torch.float64)
    >>> tensor.new_full((3, 4), 3.141592)
    tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],
            [ 3.1416,  3.1416,  3.1416,  3.1416],
            [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)

new_empty(size, *, dtype=None, device=None, requires_grad=False, layout=torch.strided, \
pin_memory=False) -> Tensor

Returns a Tensor of size :attr:`size` filled with uninitialized data.
By default, the returned Tensor has the same :class:`torch.dtype` and
:class:`torch.device` as this tensor.

Args:
    size (int...): a list, tuple, or :class:`torch.Size` of integers defining the
        shape of the output tensor.

Keyword args:
    {dtype}
    {device}
    {requires_grad}
    {layout}
    {pin_memory}

Example::

    >>> tensor = torch.ones(())
    >>> tensor.new_empty((2, 3))
    tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],
            [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])

new_empty_strided(size, stride, dtype=None, device=None, requires_grad=False, layout=torch.strided, \
pin_memory=False) -> Tensor

Returns a Tensor of size :attr:`size` and strides :attr:`stride` filled with
uninitialized data. By default, the returned Tensor has the same
:class:`torch.dtype` and :class:`torch.device` as this tensor.

Args:
    size (int...): a list, tuple, or :class:`torch.Size` of integers defining the
        shape of the output tensor.

Keyword args:
    {dtype}
    {device}
    {requires_grad}
    {layout}
    {pin_memory}

Example::

    >>> tensor = torch.ones(())
    >>> tensor.new_empty_strided((2, 3), (3, 1))
    tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],
            [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])

new_ones(size, *, dtype=None, device=None, requires_grad=False, layout=torch.strided, \
pin_memory=False) -> Tensor

Returns a Tensor of size :attr:`size` filled with ``1``.
By default, the returned Tensor has the same :class:`torch.dtype` and
:class:`torch.device` as this tensor.

Args:
    size (int...): a list, tuple, or :class:`torch.Size` of integers defining the
        shape of the output tensor.

Keyword args:
    {dtype}
    {device}
    {requires_grad}
    {layout}
    {pin_memory}

Example::

    >>> tensor = torch.tensor((), dtype=torch.int32)
    >>> tensor.new_ones((2, 3))
    tensor([[ 1,  1,  1],
            [ 1,  1,  1]], dtype=torch.int32)

new_zeros(size, *, dtype=None, device=None, requires_grad=False, layout=torch.strided, \
pin_memory=False) -> Tensor

Returns a Tensor of size :attr:`size` filled with ``0``.
By default, the returned Tensor has the same :class:`torch.dtype` and
:class:`torch.device` as this tensor.

Args:
    size (int...): a list, tuple, or :class:`torch.Size` of integers defining the
        shape of the output tensor.

Keyword args:
    {dtype}
    {device}
    {requires_grad}
    {layout}
    {pin_memory}

Example::

    >>> tensor = torch.tensor((), dtype=torch.float64)
    >>> tensor.new_zeros((2, 3))
    tensor([[ 0.,  0.,  0.],
            [ 0.,  0.,  0.]], dtype=torch.float64)

abs() -> Tensor

See :func:`torch.abs`
abs_() -> Tensor

In-place version of :meth:`~Tensor.abs`
absolute() -> Tensor

Alias for :func:`abs`
absolute_() -> Tensor

In-place version of :meth:`~Tensor.absolute`
Alias for :func:`abs_`
acos() -> Tensor

See :func:`torch.acos`
acos_() -> Tensor

In-place version of :meth:`~Tensor.acos`
arccos() -> Tensor

See :func:`torch.arccos`
arccos_() -> Tensor

In-place version of :meth:`~Tensor.arccos`
acosh() -> Tensor

See :func:`torch.acosh`
acosh_() -> Tensor

In-place version of :meth:`~Tensor.acosh`
acosh() -> Tensor

See :func:`torch.arccosh`
acosh_() -> Tensor

In-place version of :meth:`~Tensor.arccosh`
add(other, *, alpha=1) -> Tensor

Add a scalar or tensor to :attr:`self` tensor. If both :attr:`alpha`
and :attr:`other` are specified, each element of :attr:`other` is scaled by
:attr:`alpha` before being used.

When :attr:`other` is a tensor, the shape of :attr:`other` must be
:ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying
tensor

See :func:`torch.add`
add_(other, *, alpha=1) -> Tensor

In-place version of :meth:`~Tensor.add`
addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor

See :func:`torch.addbmm`
addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor

In-place version of :meth:`~Tensor.addbmm`
addcdiv(tensor1, tensor2, *, value=1) -> Tensor

See :func:`torch.addcdiv`
addcdiv_(tensor1, tensor2, *, value=1) -> Tensor

In-place version of :meth:`~Tensor.addcdiv`
addcmul(tensor1, tensor2, *, value=1) -> Tensor

See :func:`torch.addcmul`
addcmul_(tensor1, tensor2, *, value=1) -> Tensor

In-place version of :meth:`~Tensor.addcmul`
addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor

See :func:`torch.addmm`
addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor

In-place version of :meth:`~Tensor.addmm`
addmv(mat, vec, *, beta=1, alpha=1) -> Tensor

See :func:`torch.addmv`
addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor

In-place version of :meth:`~Tensor.addmv`
sspaddmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor

See :func:`torch.sspaddmm`
smm(mat) -> Tensor

See :func:`torch.smm`
addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor

See :func:`torch.addr`
addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor

In-place version of :meth:`~Tensor.addr`
align_as(other) -> Tensor

Permutes the dimensions of the :attr:`self` tensor to match the dimension order
in the :attr:`other` tensor, adding size-one dims for any new names.

This operation is useful for explicit broadcasting by names (see examples).

All of the dims of :attr:`self` must be named in order to use this method.
The resulting tensor is a view on the original tensor.

All dimension names of :attr:`self` must be present in ``other.names``.
:attr:`other` may contain named dimensions that are not in ``self.names``;
the output tensor has a size-one dimension for each of those new names.

To align a tensor to a specific order, use :meth:`~Tensor.align_to`.

Examples::

    >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H')
    >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C'))
    >>> imgs.masked_fill_(mask.align_as(imgs), 0)


    >>> def scale_channels(input, scale):
    >>>    scale = scale.refine_names('C')
    >>>    return input * scale.align_as(input)

    >>> num_channels = 3
    >>> scale = torch.randn(num_channels, names=('C',))
    >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C'))
    >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W'))
    >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D'))

    >>> scale_channels(imgs, scale)
    >>> scale_channels(more_imgs, scale)
    >>> scale_channels(videos, scale)

.. warning::
    The named tensor API is experimental and subject to change.

all(dim=None, keepdim=False) -> Tensor

See :func:`torch.all`
allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor

See :func:`torch.allclose`
angle() -> Tensor

See :func:`torch.angle`
any(dim=None, keepdim=False) -> Tensor

See :func:`torch.any`
apply_(callable) -> Tensor

Applies the function :attr:`callable` to each element in the tensor, replacing
each element with the value returned by :attr:`callable`.

.. note::

    This function only works with CPU tensors and should not be used in code
    sections that require high performance.
asin() -> Tensor

See :func:`torch.asin`
asin_() -> Tensor

In-place version of :meth:`~Tensor.asin`
arcsin() -> Tensor

See :func:`torch.arcsin`
arcsin_() -> Tensor

In-place version of :meth:`~Tensor.arcsin`
asinh() -> Tensor

See :func:`torch.asinh`
asinh_() -> Tensor

In-place version of :meth:`~Tensor.asinh`
arcsinh() -> Tensor

See :func:`torch.arcsinh`
arcsinh_() -> Tensor

In-place version of :meth:`~Tensor.arcsinh`
as_strided(size, stride, storage_offset=None) -> Tensor

See :func:`torch.as_strided`
as_strided_(size, stride, storage_offset=None) -> Tensor

In-place version of :meth:`~Tensor.as_strided`
atan() -> Tensor

See :func:`torch.atan`
atan_() -> Tensor

In-place version of :meth:`~Tensor.atan`
arctan() -> Tensor

See :func:`torch.arctan`
arctan_() -> Tensor

In-place version of :meth:`~Tensor.arctan`
atan2(other) -> Tensor

See :func:`torch.atan2`
atan2_(other) -> Tensor

In-place version of :meth:`~Tensor.atan2`
arctan2(other) -> Tensor

See :func:`torch.arctan2`
atan2_(other) -> Tensor

In-place version of :meth:`~Tensor.arctan2`
atanh() -> Tensor

See :func:`torch.atanh`
atanh_(other) -> Tensor

In-place version of :meth:`~Tensor.atanh`
arctanh() -> Tensor

See :func:`torch.arctanh`
arctanh_(other) -> Tensor

In-place version of :meth:`~Tensor.arctanh`
baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor

See :func:`torch.baddbmm`
baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor

In-place version of :meth:`~Tensor.baddbmm`
bernoulli(*, generator=None) -> Tensor

Returns a result tensor where each :math:`\texttt{result[i]}` is independently
sampled from :math:`\text{Bernoulli}(\texttt{self[i]})`. :attr:`self` must have
floating point ``dtype``, and the result will have the same ``dtype``.

See :func:`torch.bernoulli`
bernoulli_(p=0.5, *, generator=None) -> Tensor

Fills each location of :attr:`self` with an independent sample from
:math:`\text{Bernoulli}(\texttt{p})`. :attr:`self` can have integral
``dtype``.

:attr:`p` should either be a scalar or tensor containing probabilities to be
used for drawing the binary random number.

If it is a tensor, the :math:`\text{i}^{th}` element of :attr:`self` tensor
will be set to a value sampled from
:math:`\text{Bernoulli}(\texttt{p\_tensor[i]})`. In this case `p` must have
floating point ``dtype``.

See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`
bincount(weights=None, minlength=0) -> Tensor

See :func:`torch.bincount`
bitwise_not() -> Tensor

See :func:`torch.bitwise_not`
bitwise_not_() -> Tensor

In-place version of :meth:`~Tensor.bitwise_not`
bitwise_and() -> Tensor

See :func:`torch.bitwise_and`
bitwise_and_() -> Tensor

In-place version of :meth:`~Tensor.bitwise_and`
bitwise_or() -> Tensor

See :func:`torch.bitwise_or`
bitwise_or_() -> Tensor

In-place version of :meth:`~Tensor.bitwise_or`
bitwise_xor() -> Tensor

See :func:`torch.bitwise_xor`
bitwise_xor_() -> Tensor

In-place version of :meth:`~Tensor.bitwise_xor`
bitwise_left_shift(other) -> Tensor

See :func:`torch.bitwise_left_shift`
bitwise_left_shift_(other) -> Tensor

In-place version of :meth:`~Tensor.bitwise_left_shift`
bitwise_right_shift(other) -> Tensor

See :func:`torch.bitwise_right_shift`
bitwise_right_shift_(other) -> Tensor

In-place version of :meth:`~Tensor.bitwise_right_shift`
broadcast_to(shape) -> Tensor

See :func:`torch.broadcast_to`.
logical_and() -> Tensor

See :func:`torch.logical_and`
logical_and_() -> Tensor

In-place version of :meth:`~Tensor.logical_and`
logical_not() -> Tensor

See :func:`torch.logical_not`
logical_not_() -> Tensor

In-place version of :meth:`~Tensor.logical_not`
logical_or() -> Tensor

See :func:`torch.logical_or`
logical_or_() -> Tensor

In-place version of :meth:`~Tensor.logical_or`
logical_xor() -> Tensor

See :func:`torch.logical_xor`
logical_xor_() -> Tensor

In-place version of :meth:`~Tensor.logical_xor`
bmm(batch2) -> Tensor

See :func:`torch.bmm`
cauchy_(median=0, sigma=1, *, generator=None) -> Tensor

Fills the tensor with numbers drawn from the Cauchy distribution:

.. math::

    f(x) = \dfrac{1}{\pi} \dfrac{\sigma}{(x - \text{median})^2 + \sigma^2}

.. note::
  Sigma (:math:`\sigma`) is used to denote the scale parameter in Cauchy distribution.
ceil() -> Tensor

See :func:`torch.ceil`
ceil_() -> Tensor

In-place version of :meth:`~Tensor.ceil`
cholesky(upper=False) -> Tensor

See :func:`torch.cholesky`
cholesky_solve(input2, upper=False) -> Tensor

See :func:`torch.cholesky_solve`
cholesky_inverse(upper=False) -> Tensor

See :func:`torch.cholesky_inverse`
clamp(min=None, max=None) -> Tensor

See :func:`torch.clamp`
clamp_(min=None, max=None) -> Tensor

In-place version of :meth:`~Tensor.clamp`
clip(min=None, max=None) -> Tensor

Alias for :meth:`~Tensor.clamp`.
clip_(min=None, max=None) -> Tensor

Alias for :meth:`~Tensor.clamp_`.
clone(*, memory_format=torch.preserve_format) -> Tensor

See :func:`torch.clone`
coalesce() -> Tensor

Returns a coalesced copy of :attr:`self` if :attr:`self` is an
:ref:`uncoalesced tensor <sparse-uncoalesced-coo-docs>`.

Returns :attr:`self` if :attr:`self` is a coalesced tensor.

.. warning::
  Throws an error if :attr:`self` is not a sparse COO tensor.
contiguous(memory_format=torch.contiguous_format) -> Tensor

Returns a contiguous in memory tensor containing the same data as :attr:`self` tensor. If
:attr:`self` tensor is already in the specified memory format, this function returns the
:attr:`self` tensor.

Args:
    memory_format (:class:`torch.memory_format`, optional): the desired memory format of
        returned Tensor. Default: ``torch.contiguous_format``.
copy_(src, non_blocking=False) -> Tensor

Copies the elements from :attr:`src` into :attr:`self` tensor and returns
:attr:`self`.

The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`
with the :attr:`self` tensor. It may be of a different data type or reside on a
different device.

Args:
    src (Tensor): the source tensor to copy from
    non_blocking (bool): if ``True`` and this copy is between CPU and GPU,
        the copy may occur asynchronously with respect to the host. For other
        cases, this argument has no effect.
conj() -> Tensor

See :func:`torch.conj`
conj_physical() -> Tensor

See :func:`torch.conj_physical`
conj_physical_() -> Tensor

In-place version of :meth:`~Tensor.conj_physical`
resolve_conj() -> Tensor

See :func:`torch.resolve_conj`
resolve_neg() -> Tensor

See :func:`torch.resolve_neg`
copysign(other) -> Tensor

See :func:`torch.copysign`
copysign_(other) -> Tensor

In-place version of :meth:`~Tensor.copysign`
cos() -> Tensor

See :func:`torch.cos`
cos_() -> Tensor

In-place version of :meth:`~Tensor.cos`
cosh() -> Tensor

See :func:`torch.cosh`
cosh_() -> Tensor

In-place version of :meth:`~Tensor.cosh`
cpu(memory_format=torch.preserve_format) -> Tensor

Returns a copy of this object in CPU memory.

If this object is already in CPU memory and on the correct device,
then no copy is performed and the original object is returned.

Args:
    {memory_format}

count_nonzero(dim=None) -> Tensor

See :func:`torch.count_nonzero`
cov(*, correction=1, fweights=None, aweights=None) -> Tensor

See :func:`torch.cov`
corrcoef() -> Tensor

See :func:`torch.corrcoef`
cross(other, dim=None) -> Tensor

See :func:`torch.cross`
cuda(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor

Returns a copy of this object in CUDA memory.

If this object is already in CUDA memory and on the correct device,
then no copy is performed and the original object is returned.

Args:
    device (:class:`torch.device`): The destination GPU device.
        Defaults to the current CUDA device.
    non_blocking (bool): If ``True`` and the source is in pinned memory,
        the copy will be asynchronous with respect to the host.
        Otherwise, the argument has no effect. Default: ``False``.
    {memory_format}
ipu(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor

Returns a copy of this object in IPU memory.

If this object is already in IPU memory and on the correct device,
then no copy is performed and the original object is returned.

Args:
    device (:class:`torch.device`): The destination IPU device.
        Defaults to the current IPU device.
    non_blocking (bool): If ``True`` and the source is in pinned memory,
        the copy will be asynchronous with respect to the host.
        Otherwise, the argument has no effect. Default: ``False``.
    {memory_format}
xpu(device=None, non_blocking=False, memory_format=torch.preserve_format) -> Tensor

Returns a copy of this object in XPU memory.

If this object is already in XPU memory and on the correct device,
then no copy is performed and the original object is returned.

Args:
    device (:class:`torch.device`): The destination XPU device.
        Defaults to the current XPU device.
    non_blocking (bool): If ``True`` and the source is in pinned memory,
        the copy will be asynchronous with respect to the host.
        Otherwise, the argument has no effect. Default: ``False``.
    {memory_format}
logcumsumexp(dim) -> Tensor

See :func:`torch.logcumsumexp`
cummax(dim) -> (Tensor, Tensor)

See :func:`torch.cummax`
cummin(dim) -> (Tensor, Tensor)

See :func:`torch.cummin`
cumprod(dim, dtype=None) -> Tensor

See :func:`torch.cumprod`
cumprod_(dim, dtype=None) -> Tensor

In-place version of :meth:`~Tensor.cumprod`
cumsum(dim, dtype=None) -> Tensor

See :func:`torch.cumsum`
cumsum_(dim, dtype=None) -> Tensor

In-place version of :meth:`~Tensor.cumsum`
data_ptr() -> int

Returns the address of the first element of :attr:`self` tensor.
dequantize() -> Tensor

Given a quantized Tensor, dequantize it and return the dequantized float Tensor.
dense_dim() -> int

Return the number of dense dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.

.. note::
  Returns ``len(self.shape)`` if :attr:`self` is not a sparse tensor.

See also :meth:`Tensor.sparse_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.
diag(diagonal=0) -> Tensor

See :func:`torch.diag`
diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor

See :func:`torch.diag_embed`
diagflat(offset=0) -> Tensor

See :func:`torch.diagflat`
diagonal(offset=0, dim1=0, dim2=1) -> Tensor

See :func:`torch.diagonal`
diagonal_scatter(src, offset=0, dim1=0, dim2=1) -> Tensor

See :func:`torch.diagonal_scatter`
as_strided_scatter(src, size, stride, storage_offset=None) -> Tensor

See :func:`torch.as_strided_scatter`
fill_diagonal_(fill_value, wrap=False) -> Tensor

Fill the main diagonal of a tensor that has at least 2-dimensions.
When dims>2, all dimensions of input must be of equal length.
This function modifies the input tensor in-place, and returns the input tensor.

Arguments:
    fill_value (Scalar): the fill value
    wrap (bool): the diagonal 'wrapped' after N columns for tall matrices.

Example::

    >>> a = torch.zeros(3, 3)
    >>> a.fill_diagonal_(5)
    tensor([[5., 0., 0.],
            [0., 5., 0.],
            [0., 0., 5.]])
    >>> b = torch.zeros(7, 3)
    >>> b.fill_diagonal_(5)
    tensor([[5., 0., 0.],
            [0., 5., 0.],
            [0., 0., 5.],
            [0., 0., 0.],
            [0., 0., 0.],
            [0., 0., 0.],
            [0., 0., 0.]])
    >>> c = torch.zeros(7, 3)
    >>> c.fill_diagonal_(5, wrap=True)
    tensor([[5., 0., 0.],
            [0., 5., 0.],
            [0., 0., 5.],
            [0., 0., 0.],
            [5., 0., 0.],
            [0., 5., 0.],
            [0., 0., 5.]])

floor_divide(value) -> Tensor

See :func:`torch.floor_divide`
floor_divide_(value) -> Tensor

In-place version of :meth:`~Tensor.floor_divide`
diff(n=1, dim=-1, prepend=None, append=None) -> Tensor

See :func:`torch.diff`
digamma() -> Tensor

See :func:`torch.digamma`
digamma_() -> Tensor

In-place version of :meth:`~Tensor.digamma`
dim() -> int

Returns the number of dimensions of :attr:`self` tensor.
dist(other, p=2) -> Tensor

See :func:`torch.dist`
div(value, *, rounding_mode=None) -> Tensor

See :func:`torch.div`
div_(value, *, rounding_mode=None) -> Tensor

In-place version of :meth:`~Tensor.div`
divide(value, *, rounding_mode=None) -> Tensor

See :func:`torch.divide`
divide_(value, *, rounding_mode=None) -> Tensor

In-place version of :meth:`~Tensor.divide`
dot(other) -> Tensor

See :func:`torch.dot`
element_size() -> int

Returns the size in bytes of an individual element.

Example::

    >>> torch.tensor([]).element_size()
    4
    >>> torch.tensor([], dtype=torch.uint8).element_size()
    1

eq(other) -> Tensor

See :func:`torch.eq`
eq_(other) -> Tensor

In-place version of :meth:`~Tensor.eq`
equal(other) -> bool

See :func:`torch.equal`
erf() -> Tensor

See :func:`torch.erf`
erf_() -> Tensor

In-place version of :meth:`~Tensor.erf`
erfc() -> Tensor

See :func:`torch.erfc`
erfc_() -> Tensor

In-place version of :meth:`~Tensor.erfc`
erfinv() -> Tensor

See :func:`torch.erfinv`
erfinv_() -> Tensor

In-place version of :meth:`~Tensor.erfinv`
exp() -> Tensor

See :func:`torch.exp`
exp_() -> Tensor

In-place version of :meth:`~Tensor.exp`
exp2() -> Tensor

See :func:`torch.exp2`
exp2_() -> Tensor

In-place version of :meth:`~Tensor.exp2`
expm1() -> Tensor

See :func:`torch.expm1`
expm1_() -> Tensor

In-place version of :meth:`~Tensor.expm1`
exponential_(lambd=1, *, generator=None) -> Tensor

Fills :attr:`self` tensor with elements drawn from the PDF (probability density function):

.. math::

    f(x) = \lambda e^{-\lambda x}, x > 0

.. note::
  In probability theory, exponential distribution is supported on interval [0, :math:`\inf`) (i.e., :math:`x >= 0`)
  implying that zero can be sampled from the exponential distribution.
  However, :func:`torch.Tensor.exponential_` does not sample zero,
  which means that its actual support is the interval (0, :math:`\inf`).

  Note that :func:`torch.distributions.exponential.Exponential` is supported on the interval [0, :math:`\inf`) and can sample zero.
fill_(value) -> Tensor

Fills :attr:`self` tensor with the specified value.
floor() -> Tensor

See :func:`torch.floor`
flip(dims) -> Tensor

See :func:`torch.flip`
fliplr() -> Tensor

See :func:`torch.fliplr`
flipud() -> Tensor

See :func:`torch.flipud`
roll(shifts, dims) -> Tensor

See :func:`torch.roll`
floor_() -> Tensor

In-place version of :meth:`~Tensor.floor`
fmod(divisor) -> Tensor

See :func:`torch.fmod`
fmod_(divisor) -> Tensor

In-place version of :meth:`~Tensor.fmod`
frac() -> Tensor

See :func:`torch.frac`
frac_() -> Tensor

In-place version of :meth:`~Tensor.frac`
frexp(input) -> (Tensor mantissa, Tensor exponent)

See :func:`torch.frexp`
flatten(start_dim=0, end_dim=-1) -> Tensor

See :func:`torch.flatten`
gather(dim, index) -> Tensor

See :func:`torch.gather`
gcd(other) -> Tensor

See :func:`torch.gcd`
gcd_(other) -> Tensor

In-place version of :meth:`~Tensor.gcd`
ge(other) -> Tensor

See :func:`torch.ge`.
ge_(other) -> Tensor

In-place version of :meth:`~Tensor.ge`.
greater_equal(other) -> Tensor

See :func:`torch.greater_equal`.
greater_equal_(other) -> Tensor

In-place version of :meth:`~Tensor.greater_equal`.
geometric_(p, *, generator=None) -> Tensor

Fills :attr:`self` tensor with elements drawn from the geometric distribution:

.. math::

    P(X=k) = (1 - p)^{k - 1} p, k = 1, 2, ...

.. note::
  :func:`torch.Tensor.geometric_` `k`-th trial is the first success hence draws samples in :math:`\{1, 2, \ldots\}`, whereas
  :func:`torch.distributions.geometric.Geometric` :math:`(k+1)`-th trial is the first success
  hence draws samples in :math:`\{0, 1, \ldots\}`.
geqrf() -> (Tensor, Tensor)

See :func:`torch.geqrf`
ger(vec2) -> Tensor

See :func:`torch.ger`
inner(other) -> Tensor

See :func:`torch.inner`.
outer(vec2) -> Tensor

See :func:`torch.outer`.
hypot(other) -> Tensor

See :func:`torch.hypot`
hypot_(other) -> Tensor

In-place version of :meth:`~Tensor.hypot`
i0() -> Tensor

See :func:`torch.i0`
i0_() -> Tensor

In-place version of :meth:`~Tensor.i0`
igamma(other) -> Tensor

See :func:`torch.igamma`
igamma_(other) -> Tensor

In-place version of :meth:`~Tensor.igamma`
igammac(other) -> Tensor
See :func:`torch.igammac`
igammac_(other) -> Tensor
In-place version of :meth:`~Tensor.igammac`
indices() -> Tensor

Return the indices tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.

.. warning::
  Throws an error if :attr:`self` is not a sparse COO tensor.

See also :meth:`Tensor.values`.

.. note::
  This method can only be called on a coalesced sparse tensor. See
  :meth:`Tensor.coalesce` for details.
get_device() -> Device ordinal (Integer)

For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.
For CPU tensors, this function returns `-1`.

Example::

    >>> x = torch.randn(3, 4, 5, device='cuda:0')
    >>> x.get_device()
    0
    >>> x.cpu().get_device()
    -1
values() -> Tensor

Return the values tensor of a :ref:`sparse COO tensor <sparse-coo-docs>`.

.. warning::
  Throws an error if :attr:`self` is not a sparse COO tensor.

See also :meth:`Tensor.indices`.

.. note::
  This method can only be called on a coalesced sparse tensor. See
  :meth:`Tensor.coalesce` for details.
gt(other) -> Tensor

See :func:`torch.gt`.
gt_(other) -> Tensor

In-place version of :meth:`~Tensor.gt`.
greater(other) -> Tensor

See :func:`torch.greater`.
greater_(other) -> Tensor

In-place version of :meth:`~Tensor.greater`.
Is ``True`` if any of this tensor's dimensions are named. Otherwise, is ``False``.
hardshrink(lambd=0.5) -> Tensor

See :func:`torch.nn.functional.hardshrink`
heaviside(values) -> Tensor

See :func:`torch.heaviside`
heaviside_(values) -> Tensor

In-place version of :meth:`~Tensor.heaviside`
histc(bins=100, min=0, max=0) -> Tensor

See :func:`torch.histc`
histogram(input, bins, *, range=None, weight=None, density=False) -> (Tensor, Tensor)

See :func:`torch.histogram`
index_add_(dim, index, source, *, alpha=1) -> Tensor

Accumulate the elements of :attr:`alpha` times ``source`` into the :attr:`self`
tensor by adding to the indices in the order given in :attr:`index`. For example,
if ``dim == 0``, ``index[i] == j``, and ``alpha=-1``, then the ``i``\ th row of
``source`` is subtracted from the ``j``\ th row of :attr:`self`.

The :attr:`dim`\ th dimension of ``source`` must have the same size as the
length of :attr:`index` (which must be a vector), and all other dimensions must
match :attr:`self`, or an error will be raised.

For a 3-D tensor the output is given as::

    self[index[i], :, :] += alpha * src[i, :, :]  # if dim == 0
    self[:, index[i], :] += alpha * src[:, i, :]  # if dim == 1
    self[:, :, index[i]] += alpha * src[:, :, i]  # if dim == 2

Note:
    {forward_reproducibility_note}

Args:
    dim (int): dimension along which to index
    index (Tensor): indices of ``source`` to select from,
            should have dtype either `torch.int64` or `torch.int32`
    source (Tensor): the tensor containing values to add

Keyword args:
    alpha (Number): the scalar multiplier for ``source``

Example::

    >>> x = torch.ones(5, 3)
    >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)
    >>> index = torch.tensor([0, 4, 2])
    >>> x.index_add_(0, index, t)
    tensor([[  2.,   3.,   4.],
            [  1.,   1.,   1.],
            [  8.,   9.,  10.],
            [  1.,   1.,   1.],
            [  5.,   6.,   7.]])
    >>> x.index_add_(0, index, t, alpha=-1)
    tensor([[  1.,   1.,   1.],
            [  1.,   1.,   1.],
            [  1.,   1.,   1.],
            [  1.,   1.,   1.],
            [  1.,   1.,   1.]])
index_copy_(dim, index, tensor) -> Tensor

Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting
the indices in the order given in :attr:`index`. For example, if ``dim == 0``
and ``index[i] == j``, then the ``i``\ th row of :attr:`tensor` is copied to the
``j``\ th row of :attr:`self`.

The :attr:`dim`\ th dimension of :attr:`tensor` must have the same size as the
length of :attr:`index` (which must be a vector), and all other dimensions must
match :attr:`self`, or an error will be raised.

.. note::
    If :attr:`index` contains duplicate entries, multiple elements from
    :attr:`tensor` will be copied to the same index of :attr:`self`. The result
    is nondeterministic since it depends on which copy occurs last.

Args:
    dim (int): dimension along which to index
    index (LongTensor): indices of :attr:`tensor` to select from
    tensor (Tensor): the tensor containing values to copy

Example::

    >>> x = torch.zeros(5, 3)
    >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)
    >>> index = torch.tensor([0, 4, 2])
    >>> x.index_copy_(0, index, t)
    tensor([[ 1.,  2.,  3.],
            [ 0.,  0.,  0.],
            [ 7.,  8.,  9.],
            [ 0.,  0.,  0.],
            [ 4.,  5.,  6.]])
index_fill_(dim, index, value) -> Tensor

Fills the elements of the :attr:`self` tensor with value :attr:`value` by
selecting the indices in the order given in :attr:`index`.

Args:
    dim (int): dimension along which to index
    index (LongTensor): indices of :attr:`self` tensor to fill in
    value (float): the value to fill with

Example::
    >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)
    >>> index = torch.tensor([0, 2])
    >>> x.index_fill_(1, index, -1)
    tensor([[-1.,  2., -1.],
            [-1.,  5., -1.],
            [-1.,  8., -1.]])
index_put_(indices, values, accumulate=False) -> Tensor

Puts values from the tensor :attr:`values` into the tensor :attr:`self` using
the indices specified in :attr:`indices` (which is a tuple of Tensors). The
expression ``tensor.index_put_(indices, values)`` is equivalent to
``tensor[indices] = values``. Returns :attr:`self`.

If :attr:`accumulate` is ``True``, the elements in :attr:`values` are added to
:attr:`self`. If accumulate is ``False``, the behavior is undefined if indices
contain duplicate elements.

Args:
    indices (tuple of LongTensor): tensors used to index into `self`.
    values (Tensor): tensor of same dtype as `self`.
    accumulate (bool): whether to accumulate into self
index_put(indices, values, accumulate=False) -> Tensor

Out-place version of :meth:`~Tensor.index_put_`.
index_reduce_(dim, index, source, reduce, *, include_self=True) -> Tensor

Accumulate the elements of ``source`` into the :attr:`self`
tensor by accumulating to the indices in the order given in :attr:`index`
using the reduction given by the ``reduce`` argument. For example, if ``dim == 0``,
``index[i] == j``, ``reduce == prod`` and ``include_self == True`` then the ``i``\ th
row of ``source`` is multiplied by the ``j``\ th row of :attr:`self`. If
:obj:`include_self="True"`, the values in the :attr:`self` tensor are included
in the reduction, otherwise, rows in the :attr:`self` tensor that are accumulated
to are treated as if they were filled with the reduction identites.

The :attr:`dim`\ th dimension of ``source`` must have the same size as the
length of :attr:`index` (which must be a vector), and all other dimensions must
match :attr:`self`, or an error will be raised.

For a 3-D tensor with :obj:`reduce="prod"` and :obj:`include_self=True` the
output is given as::

    self[index[i], :, :] *= src[i, :, :]  # if dim == 0
    self[:, index[i], :] *= src[:, i, :]  # if dim == 1
    self[:, :, index[i]] *= src[:, :, i]  # if dim == 2

Note:
    {forward_reproducibility_note}

.. note::

    This function only supports floating point tensors.

.. warning::

    This function is in beta and may change in the near future.

Args:
    dim (int): dimension along which to index
    index (Tensor): indices of ``source`` to select from,
        should have dtype either `torch.int64` or `torch.int32`
    source (FloatTensor): the tensor containing values to accumulate
    reduce (str): the reduction operation to apply
        (:obj:`"prod"`, :obj:`"mean"`, :obj:`"amax"`, :obj:`"amin"`)

Keyword args:
    include_self (bool): whether the elements from the ``self`` tensor are
        included in the reduction

Example::

    >>> x = torch.empty(5, 3).fill_(2)
    >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]], dtype=torch.float)
    >>> index = torch.tensor([0, 4, 2, 0])
    >>> x.index_reduce_(0, index, t, 'prod')
    tensor([[20., 44., 72.],
            [ 2.,  2.,  2.],
            [14., 16., 18.],
            [ 2.,  2.,  2.],
            [ 8., 10., 12.]])
    >>> x = torch.empty(5, 3).fill_(2)
    >>> x.index_reduce_(0, index, t, 'prod', include_self=False)
    tensor([[10., 22., 36.],
            [ 2.,  2.,  2.],
            [ 7.,  8.,  9.],
            [ 2.,  2.,  2.],
            [ 4.,  5.,  6.]])
index_select(dim, index) -> Tensor

See :func:`torch.index_select`
sparse_mask(mask) -> Tensor

Returns a new :ref:`sparse tensor <sparse-docs>` with values from a
strided tensor :attr:`self` filtered by the indices of the sparse
tensor :attr:`mask`. The values of :attr:`mask` sparse tensor are
ignored. :attr:`self` and :attr:`mask` tensors must have the same
shape.

.. note::

  The returned sparse tensor might contain duplicate values if :attr:`mask`
  is not coalesced. It is therefore advisable to pass ``mask.coalesce()``
  if such behavior is not desired.

.. note::

  The returned sparse tensor has the same indices as the sparse tensor
  :attr:`mask`, even when the corresponding values in :attr:`self` are
  zeros.

Args:
    mask (Tensor): a sparse tensor whose indices are used as a filter

Example::

    >>> nse = 5
    >>> dims = (5, 5, 2, 2)
    >>> I = torch.cat([torch.randint(0, dims[0], size=(nse,)),
    ...                torch.randint(0, dims[1], size=(nse,))], 0).reshape(2, nse)
    >>> V = torch.randn(nse, dims[2], dims[3])
    >>> S = torch.sparse_coo_tensor(I, V, dims).coalesce()
    >>> D = torch.randn(dims)
    >>> D.sparse_mask(S)
    tensor(indices=tensor([[0, 0, 0, 2],
                           [0, 1, 4, 3]]),
           values=tensor([[[ 1.6550,  0.2397],
                           [-0.1611, -0.0779]],

                          [[ 0.2326, -1.0558],
                           [ 1.4711,  1.9678]],

                          [[-0.5138, -0.0411],
                           [ 1.9417,  0.5158]],

                          [[ 0.0793,  0.0036],
                           [-0.2569, -0.1055]]]),
           size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)
inverse() -> Tensor

See :func:`torch.inverse`
isnan() -> Tensor

See :func:`torch.isnan`
isinf() -> Tensor

See :func:`torch.isinf`
isposinf() -> Tensor

See :func:`torch.isposinf`
isneginf() -> Tensor

See :func:`torch.isneginf`
isfinite() -> Tensor

See :func:`torch.isfinite`
isclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor

See :func:`torch.isclose`
isreal() -> Tensor

See :func:`torch.isreal`
is_coalesced() -> bool

Returns ``True`` if :attr:`self` is a :ref:`sparse COO tensor
<sparse-coo-docs>` that is coalesced, ``False`` otherwise.

.. warning::
  Throws an error if :attr:`self` is not a sparse COO tensor.

See :meth:`coalesce` and :ref:`uncoalesced tensors <sparse-uncoalesced-coo-docs>`.
is_contiguous(memory_format=torch.contiguous_format) -> bool

Returns True if :attr:`self` tensor is contiguous in memory in the order specified
by memory format.

Args:
    memory_format (:class:`torch.memory_format`, optional): Specifies memory allocation
        order. Default: ``torch.contiguous_format``.
Returns true if this tensor resides in pinned memory.
is_floating_point() -> bool

Returns True if the data type of :attr:`self` is a floating point data type.
is_complex() -> bool

Returns True if the data type of :attr:`self` is a complex data type.
is_inference() -> bool

See :func:`torch.is_inference`
is_conj() -> bool

Returns True if the conjugate bit of :attr:`self` is set to true.
is_neg() -> bool

Returns True if the negative bit of :attr:`self` is set to true.
is_signed() -> bool

Returns True if the data type of :attr:`self` is a signed data type.
is_set_to(tensor) -> bool

Returns True if both tensors are pointing to the exact same memory (same
storage, offset, size and stride).
item() -> number

Returns the value of this tensor as a standard Python number. This only works
for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.

This operation is not differentiable.

Example::

    >>> x = torch.tensor([1.0])
    >>> x.item()
    1.0

kron(other) -> Tensor

See :func:`torch.kron`
kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)

See :func:`torch.kthvalue`
ldexp(other) -> Tensor

See :func:`torch.ldexp`
ldexp_(other) -> Tensor

In-place version of :meth:`~Tensor.ldexp`
lcm(other) -> Tensor

See :func:`torch.lcm`
lcm_(other) -> Tensor

In-place version of :meth:`~Tensor.lcm`
le(other) -> Tensor

See :func:`torch.le`.
le_(other) -> Tensor

In-place version of :meth:`~Tensor.le`.
less_equal(other) -> Tensor

See :func:`torch.less_equal`.
less_equal_(other) -> Tensor

In-place version of :meth:`~Tensor.less_equal`.
lerp(end, weight) -> Tensor

See :func:`torch.lerp`
lerp_(end, weight) -> Tensor

In-place version of :meth:`~Tensor.lerp`
lgamma() -> Tensor

See :func:`torch.lgamma`
lgamma_() -> Tensor

In-place version of :meth:`~Tensor.lgamma`
log() -> Tensor

See :func:`torch.log`
log_() -> Tensor

In-place version of :meth:`~Tensor.log`
log10() -> Tensor

See :func:`torch.log10`
log10_() -> Tensor

In-place version of :meth:`~Tensor.log10`
log1p() -> Tensor

See :func:`torch.log1p`
log1p_() -> Tensor

In-place version of :meth:`~Tensor.log1p`
log2() -> Tensor

See :func:`torch.log2`
log2_() -> Tensor

In-place version of :meth:`~Tensor.log2`
logaddexp(other) -> Tensor

See :func:`torch.logaddexp`
logaddexp2(other) -> Tensor

See :func:`torch.logaddexp2`
log_normal_(mean=1, std=2, *, generator=None)

Fills :attr:`self` tensor with numbers samples from the log-normal distribution
parameterized by the given mean :math:`\mu` and standard deviation
:math:`\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and
standard deviation of the underlying normal distribution, and not of the
returned distribution:

.. math::

    f(x) = \dfrac{1}{x \sigma \sqrt{2\pi}}\ e^{-\frac{(\ln x - \mu)^2}{2\sigma^2}}
logsumexp(dim, keepdim=False) -> Tensor

See :func:`torch.logsumexp`
lt(other) -> Tensor

See :func:`torch.lt`.
lt_(other) -> Tensor

In-place version of :meth:`~Tensor.lt`.
lt(other) -> Tensor

See :func:`torch.less`.
less_(other) -> Tensor

In-place version of :meth:`~Tensor.less`.
lu_solve(LU_data, LU_pivots) -> Tensor

See :func:`torch.lu_solve`
map_(tensor, callable)

Applies :attr:`callable` for each element in :attr:`self` tensor and the given
:attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and
the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.

The :attr:`callable` should have the signature::

    def callable(a, b) -> number
masked_scatter_(mask, source)

Copies elements from :attr:`source` into :attr:`self` tensor at positions where
the :attr:`mask` is True. Elements from :attr:`source` are copied into :attr:`self`
starting at position 0 of :attr:`source` and continuing in order one-by-one for each
occurrence of :attr:`mask` being True.
The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`
with the shape of the underlying tensor. The :attr:`source` should have at least
as many elements as the number of ones in :attr:`mask`.

Args:
    mask (BoolTensor): the boolean mask
    source (Tensor): the tensor to copy from

.. note::

    The :attr:`mask` operates on the :attr:`self` tensor, not on the given
    :attr:`source` tensor.

Example:

    >>> self = torch.tensor([[0, 0, 0, 0, 0], [0, 0, 0, 0, 0]])
    >>> mask = torch.tensor([[0, 0, 0, 1, 1], [1, 1, 0, 1, 1]])
    >>> source = torch.tensor([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]])
    >>> self.masked_scatter_(mask, source)
    tensor([[0, 0, 0, 0, 1],
            [2, 3, 0, 4, 5]])

masked_fill_(mask, value)

Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is
True. The shape of :attr:`mask` must be
:ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying
tensor.

Args:
    mask (BoolTensor): the boolean mask
    value (float): the value to fill in with
masked_select(mask) -> Tensor

See :func:`torch.masked_select`
matrix_power(n) -> Tensor

.. note:: :meth:`~Tensor.matrix_power` is deprecated, use :func:`torch.linalg.matrix_power` instead.

Alias for :func:`torch.linalg.matrix_power`
matrix_exp() -> Tensor

See :func:`torch.matrix_exp`
max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)

See :func:`torch.max`
amax(dim=None, keepdim=False) -> Tensor

See :func:`torch.amax`
maximum(other) -> Tensor

See :func:`torch.maximum`
fmax(other) -> Tensor

See :func:`torch.fmax`
argmax(dim=None, keepdim=False) -> LongTensor

See :func:`torch.argmax`
argwhere() -> Tensor

See :func:`torch.argwhere`
mean(dim=None, keepdim=False, *, dtype=None) -> Tensor

See :func:`torch.mean`
nanmean(dim=None, keepdim=False, *, dtype=None) -> Tensor

See :func:`torch.nanmean`
median(dim=None, keepdim=False) -> (Tensor, LongTensor)

See :func:`torch.median`
nanmedian(dim=None, keepdim=False) -> (Tensor, LongTensor)

See :func:`torch.nanmedian`
min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)

See :func:`torch.min`
amin(dim=None, keepdim=False) -> Tensor

See :func:`torch.amin`
minimum(other) -> Tensor

See :func:`torch.minimum`
aminmax(*, dim=None, keepdim=False) -> (Tensor min, Tensor max)

See :func:`torch.aminmax`
fmin(other) -> Tensor

See :func:`torch.fmin`
argmin(dim=None, keepdim=False) -> LongTensor

See :func:`torch.argmin`
mm(mat2) -> Tensor

See :func:`torch.mm`
mode(dim=None, keepdim=False) -> (Tensor, LongTensor)

See :func:`torch.mode`
movedim(source, destination) -> Tensor

See :func:`torch.movedim`
moveaxis(source, destination) -> Tensor

See :func:`torch.moveaxis`
mul(value) -> Tensor

See :func:`torch.mul`.
mul_(value) -> Tensor

In-place version of :meth:`~Tensor.mul`.
multiply(value) -> Tensor

See :func:`torch.multiply`.
multiply_(value) -> Tensor

In-place version of :meth:`~Tensor.multiply`.
multinomial(num_samples, replacement=False, *, generator=None) -> Tensor

See :func:`torch.multinomial`
mv(vec) -> Tensor

See :func:`torch.mv`
mvlgamma(p) -> Tensor

See :func:`torch.mvlgamma`
mvlgamma_(p) -> Tensor

In-place version of :meth:`~Tensor.mvlgamma`
narrow(dimension, start, length) -> Tensor

See :func:`torch.narrow`.
narrow_copy(dimension, start, length) -> Tensor

See :func:`torch.narrow_copy`.
ndimension() -> int

Alias for :meth:`~Tensor.dim()`
nan_to_num(nan=0.0, posinf=None, neginf=None) -> Tensor

See :func:`torch.nan_to_num`.
nan_to_num_(nan=0.0, posinf=None, neginf=None) -> Tensor

In-place version of :meth:`~Tensor.nan_to_num`.
ne(other) -> Tensor

See :func:`torch.ne`.
ne_(other) -> Tensor

In-place version of :meth:`~Tensor.ne`.
not_equal(other) -> Tensor

See :func:`torch.not_equal`.
not_equal_(other) -> Tensor

In-place version of :meth:`~Tensor.not_equal`.
neg() -> Tensor

See :func:`torch.neg`
negative() -> Tensor

See :func:`torch.negative`
neg_() -> Tensor

In-place version of :meth:`~Tensor.neg`
negative_() -> Tensor

In-place version of :meth:`~Tensor.negative`
nelement() -> int

Alias for :meth:`~Tensor.numel`
nextafter(other) -> Tensor
See :func:`torch.nextafter`
nextafter_(other) -> Tensor
In-place version of :meth:`~Tensor.nextafter`
nonzero() -> LongTensor

See :func:`torch.nonzero`
nonzero_static(input, *, size, fill_value=-1) -> Tensor

Returns a 2-D tensor where each row is the index for a non-zero value.
The returned Tensor has the same `torch.dtype` as `torch.nonzero()`.

Args:
    input (Tensor): the input tensor to count non-zero elements.

Keyword args:
    size (int): the size of non-zero elements expected to be included in the out
        tensor. Pad the out tensor with `fill_value` if the `size` is larger
        than total number of non-zero elements, truncate out tensor if `size`
        is smaller. The size must be a non-negative integer.
    fill_value (int): the value to fill the output tensor with when `size` is larger
        than the total number of non-zero elements. Default is `-1` to represent
        invalid index.

Example:

    >>> input_tensor = torch.tensor([[1, 0], [3, 2]])
    >>> static_size = 4
    >>> t = torch.nonzero_static(input_tensor, size = static_size)
    tensor([[  0,   0],
            [  1,   0],
            [  1,   1],
            [  -1, -1]], dtype=torch.int64)

    >>> input_tensor = torch.tensor([[1, 0], [3, 2]])
    >>> static_size = 2
    >>> t = torch.nonzero_static(input_tensor, size = static_size)
    tensor([[  0,   0],
            [  1,   0]], dtype=torch.int64)

    >>> input_tensor = torch.tensor([10])
    >>> static_size = 0
    >>> t = torch.nonzero_static(input_tensor, size = static_size)
    tensor([], size=(0, 1), dtype=torch.int64)

    >>> input_tensor = torch.tensor(10)
    >>> static_size = 2
    >>> t = torch.nonzero_static(input_tensor, size = static_size)
    tensor([], size=(2, 0), dtype=torch.int64)
norm(p=2, dim=None, keepdim=False) -> Tensor

See :func:`torch.norm`
normal_(mean=0, std=1, *, generator=None) -> Tensor

Fills :attr:`self` tensor with elements samples from the normal distribution
parameterized by :attr:`mean` and :attr:`std`.
numel() -> int

See :func:`torch.numel`
numpy(*, force=False) -> numpy.ndarray

Returns the tensor as a NumPy :class:`ndarray`.

If :attr:`force` is ``False`` (the default), the conversion
is performed only if the tensor is on the CPU, does not require grad,
does not have its conjugate bit set, and is a dtype and layout that
NumPy supports. The returned ndarray and the tensor will share their
storage, so changes to the tensor will be reflected in the ndarray
and vice versa.

If :attr:`force` is ``True`` this is equivalent to
calling ``t.detach().cpu().resolve_conj().resolve_neg().numpy()``.
If the tensor isn't on the CPU or the conjugate or negative bit is set,
the tensor won't share its storage with the returned ndarray.
Setting :attr:`force` to ``True`` can be a useful shorthand.

Args:
    force (bool): if ``True``, the ndarray may be a copy of the tensor
               instead of always sharing memory, defaults to ``False``.
orgqr(input2) -> Tensor

See :func:`torch.orgqr`
ormqr(input2, input3, left=True, transpose=False) -> Tensor

See :func:`torch.ormqr`
permute(*dims) -> Tensor

See :func:`torch.permute`
polygamma(n) -> Tensor

See :func:`torch.polygamma`
polygamma_(n) -> Tensor

In-place version of :meth:`~Tensor.polygamma`
positive() -> Tensor

See :func:`torch.positive`
pow(exponent) -> Tensor

See :func:`torch.pow`
pow_(exponent) -> Tensor

In-place version of :meth:`~Tensor.pow`
float_power(exponent) -> Tensor

See :func:`torch.float_power`
float_power_(exponent) -> Tensor

In-place version of :meth:`~Tensor.float_power`
prod(dim=None, keepdim=False, dtype=None) -> Tensor

See :func:`torch.prod`
put_(index, source, accumulate=False) -> Tensor

Copies the elements from :attr:`source` into the positions specified by
:attr:`index`. For the purpose of indexing, the :attr:`self` tensor is treated as if
it were a 1-D tensor.

:attr:`index` and :attr:`source` need to have the same number of elements, but not necessarily
the same shape.

If :attr:`accumulate` is ``True``, the elements in :attr:`source` are added to
:attr:`self`. If accumulate is ``False``, the behavior is undefined if :attr:`index`
contain duplicate elements.

Args:
    index (LongTensor): the indices into self
    source (Tensor): the tensor containing values to copy from
    accumulate (bool): whether to accumulate into self

Example::

    >>> src = torch.tensor([[4, 3, 5],
    ...                     [6, 7, 8]])
    >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))
    tensor([[  4,   9,   5],
            [ 10,   7,   8]])
put(input, index, source, accumulate=False) -> Tensor

Out-of-place version of :meth:`torch.Tensor.put_`.
`input` corresponds to `self` in :meth:`torch.Tensor.put_`.
qr(some=True) -> (Tensor, Tensor)

See :func:`torch.qr`
qscheme() -> torch.qscheme

Returns the quantization scheme of a given QTensor.
quantile(q, dim=None, keepdim=False, *, interpolation='linear') -> Tensor

See :func:`torch.quantile`
nanquantile(q, dim=None, keepdim=False, *, interpolation='linear') -> Tensor

See :func:`torch.nanquantile`
q_scale() -> float

Given a Tensor quantized by linear(affine) quantization,
returns the scale of the underlying quantizer().
q_zero_point() -> int

Given a Tensor quantized by linear(affine) quantization,
returns the zero_point of the underlying quantizer().
q_per_channel_scales() -> Tensor

Given a Tensor quantized by linear (affine) per-channel quantization,
returns a Tensor of scales of the underlying quantizer. It has the number of
elements that matches the corresponding dimensions (from q_per_channel_axis) of
the tensor.
q_per_channel_zero_points() -> Tensor

Given a Tensor quantized by linear (affine) per-channel quantization,
returns a tensor of zero_points of the underlying quantizer. It has the number of
elements that matches the corresponding dimensions (from q_per_channel_axis) of
the tensor.
q_per_channel_axis() -> int

Given a Tensor quantized by linear (affine) per-channel quantization,
returns the index of dimension on which per-channel quantization is applied.
random_(from=0, to=None, *, generator=None) -> Tensor

Fills :attr:`self` tensor with numbers sampled from the discrete uniform
distribution over ``[from, to - 1]``. If not specified, the values are usually
only bounded by :attr:`self` tensor's data type. However, for floating point
types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every
value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`
will be uniform in ``[0, 2^53]``.
rad2deg() -> Tensor

See :func:`torch.rad2deg`
rad2deg_() -> Tensor

In-place version of :meth:`~Tensor.rad2deg`
deg2rad() -> Tensor

See :func:`torch.deg2rad`
deg2rad_() -> Tensor

In-place version of :meth:`~Tensor.deg2rad`
ravel() -> Tensor

see :func:`torch.ravel`
reciprocal() -> Tensor

See :func:`torch.reciprocal`
reciprocal_() -> Tensor

In-place version of :meth:`~Tensor.reciprocal`
record_stream(stream)

Marks the tensor as having been used by this stream.  When the tensor
is deallocated, ensure the tensor memory is not reused for another tensor
until all work queued on :attr:`stream` at the time of deallocation is
complete.

.. note::

    The caching allocator is aware of only the stream where a tensor was
    allocated. Due to the awareness, it already correctly manages the life
    cycle of tensors on only one stream. But if a tensor is used on a stream
    different from the stream of origin, the allocator might reuse the memory
    unexpectedly. Calling this method lets the allocator know which streams
    have used the tensor.

.. warning::

    This method is most suitable for use cases where you are providing a
    function that created a tensor on a side stream, and want users to be able
    to make use of the tensor without having to think carefully about stream
    safety when making use of them.  These safety guarantees come at some
    performance and predictability cost (analogous to the tradeoff between GC
    and manual memory management), so if you are in a situation where
    you manage the full lifetime of your tensors, you may consider instead
    manually managing CUDA events so that calling this method is not necessary.
    In particular, when you call this method, on later allocations the
    allocator will poll the recorded stream to see if all operations have
    completed yet; you can potentially race with side stream computation and
    non-deterministically reuse or fail to reuse memory for an allocation.

    You can safely use tensors allocated on side streams without
    :meth:`~Tensor.record_stream`; you must manually ensure that
    any non-creation stream uses of a tensor are synced back to the creation
    stream before you deallocate the tensor.  As the CUDA caching allocator
    guarantees that the memory will only be reused with the same creation stream,
    this is sufficient to ensure that writes to future reallocations of the
    memory will be delayed until non-creation stream uses are done.
    (Counterintuitively, you may observe that on the CPU side we have already
    reallocated the tensor, even though CUDA kernels on the old tensor are
    still in progress.  This is fine, because CUDA operations on the new
    tensor will appropriately wait for the old operations to complete, as they
    are all on the same stream.)

    Concretely, this looks like this::

        with torch.cuda.stream(s0):
            x = torch.zeros(N)

        s1.wait_stream(s0)
        with torch.cuda.stream(s1):
            y = some_comm_op(x)

        ... some compute on s0 ...

        s0.wait_stream(s1)
        del x

    Note that some discretion is required when deciding when to perform
    ``s0.wait_stream(s1)``.  In particular, if we were to wait immediately
    after ``some_comm_op``, there wouldn't be any point in having the side
    stream; it would be equivalent to have run ``some_comm_op`` on ``s0``.
    Instead, the synchronization must be placed at some appropriate, later
    point in time where you expect the side stream ``s1`` to have finished
    work.  This location is typically identified via profiling, e.g., using
    Chrome traces produced
    :meth:`torch.autograd.profiler.profile.export_chrome_trace`.  If you
    place the wait too early, work on s0 will block until ``s1`` has finished,
    preventing further overlapping of communication and computation.  If you
    place the wait too late, you will use more memory than is strictly
    necessary (as you are keeping ``x`` live for longer.)  For a concrete
    example of how this guidance can be applied in practice, see this post:
    `FSDP and CUDACachingAllocator
    <https://dev-discuss.pytorch.org/t/fsdp-cudacachingallocator-an-outsider-newb-perspective/1486>`_.
remainder(divisor) -> Tensor

See :func:`torch.remainder`
remainder_(divisor) -> Tensor

In-place version of :meth:`~Tensor.remainder`
renorm(p, dim, maxnorm) -> Tensor

See :func:`torch.renorm`
renorm_(p, dim, maxnorm) -> Tensor

In-place version of :meth:`~Tensor.renorm`
repeat(*sizes) -> Tensor

Repeats this tensor along the specified dimensions.

Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.

.. warning::

    :meth:`~Tensor.repeat` behaves differently from
    `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,
    but is more similar to
    `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.
    For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.

Args:
    sizes (torch.Size or int...): The number of times to repeat this tensor along each
        dimension

Example::

    >>> x = torch.tensor([1, 2, 3])
    >>> x.repeat(4, 2)
    tensor([[ 1,  2,  3,  1,  2,  3],
            [ 1,  2,  3,  1,  2,  3],
            [ 1,  2,  3,  1,  2,  3],
            [ 1,  2,  3,  1,  2,  3]])
    >>> x.repeat(4, 2, 1).size()
    torch.Size([4, 2, 3])
repeat_interleave(repeats, dim=None, *, output_size=None) -> Tensor

See :func:`torch.repeat_interleave`.
requires_grad_(requires_grad=True) -> Tensor

Change if autograd should record operations on this tensor: sets this tensor's
:attr:`requires_grad` attribute in-place. Returns this tensor.

:func:`requires_grad_`'s main use case is to tell autograd to begin recording
operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``
(because it was obtained through a DataLoader, or required preprocessing or
initialization), ``tensor.requires_grad_()`` makes it so that autograd will
begin to record operations on ``tensor``.

Args:
    requires_grad (bool): If autograd should record operations on this tensor.
        Default: ``True``.

Example::

    >>> # Let's say we want to preprocess some saved weights and use
    >>> # the result as new weights.
    >>> saved_weights = [0.1, 0.2, 0.3, 0.25]
    >>> loaded_weights = torch.tensor(saved_weights)
    >>> weights = preprocess(loaded_weights)  # some function
    >>> weights
    tensor([-0.5503,  0.4926, -2.1158, -0.8303])

    >>> # Now, start to record operations done to weights
    >>> weights.requires_grad_()
    >>> out = weights.pow(2).sum()
    >>> out.backward()
    >>> weights.grad
    tensor([-1.1007,  0.9853, -4.2316, -1.6606])

reshape(*shape) -> Tensor

Returns a tensor with the same data and number of elements as :attr:`self`
but with the specified shape. This method returns a view if :attr:`shape` is
compatible with the current shape. See :meth:`torch.Tensor.view` on when it is
possible to return a view.

See :func:`torch.reshape`

Args:
    shape (tuple of ints or int...): the desired shape

reshape_as(other) -> Tensor

Returns this tensor as the same shape as :attr:`other`.
``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.
This method returns a view if ``other.sizes()`` is compatible with the current
shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.

Please see :meth:`reshape` for more information about ``reshape``.

Args:
    other (:class:`torch.Tensor`): The result tensor has the same shape
        as :attr:`other`.
resize_(*sizes, memory_format=torch.contiguous_format) -> Tensor

Resizes :attr:`self` tensor to the specified size. If the number of elements is
larger than the current storage size, then the underlying storage is resized
to fit the new number of elements. If the number of elements is smaller, the
underlying storage is not changed. Existing elements are preserved but any new
memory is uninitialized.

.. warning::

    This is a low-level method. The storage is reinterpreted as C-contiguous,
    ignoring the current strides (unless the target size equals the current
    size, in which case the tensor is left unchanged). For most purposes, you
    will instead want to use :meth:`~Tensor.view()`, which checks for
    contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To
    change the size in-place with custom strides, see :meth:`~Tensor.set_()`.

.. note::

    If :func:`torch.use_deterministic_algorithms()` and
    :attr:`torch.utils.deterministic.fill_uninitialized_memory` are both set to
    ``True``, new elements are initialized to prevent nondeterministic behavior
    from using the result as an input to an operation. Floating point and
    complex values are set to NaN, and integer values are set to the maximum
    value.

Args:
    sizes (torch.Size or int...): the desired size
    memory_format (:class:`torch.memory_format`, optional): the desired memory format of
        Tensor. Default: ``torch.contiguous_format``. Note that memory format of
        :attr:`self` is going to be unaffected if ``self.size()`` matches ``sizes``.

Example::

    >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])
    >>> x.resize_(2, 2)
    tensor([[ 1,  2],
            [ 3,  4]])
resize_as_(tensor, memory_format=torch.contiguous_format) -> Tensor

Resizes the :attr:`self` tensor to be the same size as the specified
:attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.

Args:
    memory_format (:class:`torch.memory_format`, optional): the desired memory format of
        Tensor. Default: ``torch.contiguous_format``. Note that memory format of
        :attr:`self` is going to be unaffected if ``self.size()`` matches ``tensor.size()``.

rot90(k, dims) -> Tensor

See :func:`torch.rot90`
round(decimals=0) -> Tensor

See :func:`torch.round`
round_(decimals=0) -> Tensor

In-place version of :meth:`~Tensor.round`
rsqrt() -> Tensor

See :func:`torch.rsqrt`
rsqrt_() -> Tensor

In-place version of :meth:`~Tensor.rsqrt`
scatter_(dim, index, src, reduce=None) -> Tensor

Writes all values from the tensor :attr:`src` into :attr:`self` at the indices
specified in the :attr:`index` tensor. For each value in :attr:`src`, its output
index is specified by its index in :attr:`src` for ``dimension != dim`` and by
the corresponding value in :attr:`index` for ``dimension = dim``.

For a 3-D tensor, :attr:`self` is updated as::

    self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0
    self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1
    self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2

This is the reverse operation of the manner described in :meth:`~Tensor.gather`.

:attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should all have
the same number of dimensions. It is also required that
``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that
``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.
Note that ``index`` and ``src`` do not broadcast.

Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be
between ``0`` and ``self.size(dim) - 1`` inclusive.

.. warning::

    When indices are not unique, the behavior is non-deterministic (one of the
    values from ``src`` will be picked arbitrarily) and the gradient will be
    incorrect (it will be propagated to all locations in the source that
    correspond to the same index)!

.. note::

    The backward pass is implemented only for ``src.shape == index.shape``.

Additionally accepts an optional :attr:`reduce` argument that allows
specification of an optional reduction operation, which is applied to all
values in the tensor :attr:`src` into :attr:`self` at the indices
specified in the :attr:`index`. For each value in :attr:`src`, the reduction
operation is applied to an index in :attr:`self` which is specified by
its index in :attr:`src` for ``dimension != dim`` and by the corresponding
value in :attr:`index` for ``dimension = dim``.

Given a 3-D tensor and reduction using the multiplication operation, :attr:`self`
is updated as::

    self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0
    self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1
    self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2

Reducing with the addition operation is the same as using
:meth:`~torch.Tensor.scatter_add_`.

.. warning::
    The reduce argument with Tensor ``src`` is deprecated and will be removed in
    a future PyTorch release. Please use :meth:`~torch.Tensor.scatter_reduce_`
    instead for more reduction options.

Args:
    dim (int): the axis along which to index
    index (LongTensor): the indices of elements to scatter, can be either empty
        or of the same dimensionality as ``src``. When empty, the operation
        returns ``self`` unchanged.
    src (Tensor or float): the source element(s) to scatter.
    reduce (str, optional): reduction operation to apply, can be either
        ``'add'`` or ``'multiply'``.

Example::

    >>> src = torch.arange(1, 11).reshape((2, 5))
    >>> src
    tensor([[ 1,  2,  3,  4,  5],
            [ 6,  7,  8,  9, 10]])
    >>> index = torch.tensor([[0, 1, 2, 0]])
    >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)
    tensor([[1, 0, 0, 4, 0],
            [0, 2, 0, 0, 0],
            [0, 0, 3, 0, 0]])
    >>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])
    >>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)
    tensor([[1, 2, 3, 0, 0],
            [6, 7, 0, 0, 8],
            [0, 0, 0, 0, 0]])

    >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),
    ...            1.23, reduce='multiply')
    tensor([[2.0000, 2.0000, 2.4600, 2.0000],
            [2.0000, 2.0000, 2.0000, 2.4600]])
    >>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),
    ...            1.23, reduce='add')
    tensor([[2.0000, 2.0000, 3.2300, 2.0000],
            [2.0000, 2.0000, 2.0000, 3.2300]])

scatter_add_(dim, index, src) -> Tensor

Adds all values from the tensor :attr:`src` into :attr:`self` at the indices
specified in the :attr:`index` tensor in a similar fashion as
:meth:`~torch.Tensor.scatter_`. For each value in :attr:`src`, it is added to
an index in :attr:`self` which is specified by its index in :attr:`src`
for ``dimension != dim`` and by the corresponding value in :attr:`index` for
``dimension = dim``.

For a 3-D tensor, :attr:`self` is updated as::

    self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0
    self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1
    self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2

:attr:`self`, :attr:`index` and :attr:`src` should have same number of
dimensions. It is also required that ``index.size(d) <= src.size(d)`` for all
dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions
``d != dim``. Note that ``index`` and ``src`` do not broadcast.

Note:
    {forward_reproducibility_note}

.. note::

    The backward pass is implemented only for ``src.shape == index.shape``.

Args:
    dim (int): the axis along which to index
    index (LongTensor): the indices of elements to scatter and add, can be
        either empty or of the same dimensionality as ``src``. When empty, the
        operation returns ``self`` unchanged.
    src (Tensor): the source elements to scatter and add

Example::

    >>> src = torch.ones((2, 5))
    >>> index = torch.tensor([[0, 1, 2, 0, 0]])
    >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)
    tensor([[1., 0., 0., 1., 1.],
            [0., 1., 0., 0., 0.],
            [0., 0., 1., 0., 0.]])
    >>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])
    >>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)
    tensor([[2., 0., 0., 1., 1.],
            [0., 2., 0., 0., 0.],
            [0., 0., 2., 1., 1.]])

scatter_reduce_(dim, index, src, reduce, *, include_self=True) -> Tensor

Reduces all values from the :attr:`src` tensor to the indices specified in
the :attr:`index` tensor in the :attr:`self` tensor using the applied reduction
defined via the :attr:`reduce` argument (:obj:`"sum"`, :obj:`"prod"`, :obj:`"mean"`,
:obj:`"amax"`, :obj:`"amin"`). For each value in :attr:`src`, it is reduced to an
index in :attr:`self` which is specified by its index in :attr:`src` for
``dimension != dim`` and by the corresponding value in :attr:`index` for
``dimension = dim``. If :obj:`include_self="True"`, the values in the :attr:`self`
tensor are included in the reduction.

:attr:`self`, :attr:`index` and :attr:`src` should all have
the same number of dimensions. It is also required that
``index.size(d) <= src.size(d)`` for all dimensions ``d``, and that
``index.size(d) <= self.size(d)`` for all dimensions ``d != dim``.
Note that ``index`` and ``src`` do not broadcast.

For a 3-D tensor with :obj:`reduce="sum"` and :obj:`include_self=True` the
output is given as::

    self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0
    self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1
    self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2

Note:
    {forward_reproducibility_note}

.. note::

    The backward pass is implemented only for ``src.shape == index.shape``.

.. warning::

    This function is in beta and may change in the near future.

Args:
    dim (int): the axis along which to index
    index (LongTensor): the indices of elements to scatter and reduce.
    src (Tensor): the source elements to scatter and reduce
    reduce (str): the reduction operation to apply for non-unique indices
        (:obj:`"sum"`, :obj:`"prod"`, :obj:`"mean"`, :obj:`"amax"`, :obj:`"amin"`)
    include_self (bool): whether elements from the :attr:`self` tensor are
        included in the reduction

Example::

    >>> src = torch.tensor([1., 2., 3., 4., 5., 6.])
    >>> index = torch.tensor([0, 1, 0, 1, 2, 1])
    >>> input = torch.tensor([1., 2., 3., 4.])
    >>> input.scatter_reduce(0, index, src, reduce="sum")
    tensor([5., 14., 8., 4.])
    >>> input.scatter_reduce(0, index, src, reduce="sum", include_self=False)
    tensor([4., 12., 5., 4.])
    >>> input2 = torch.tensor([5., 4., 3., 2.])
    >>> input2.scatter_reduce(0, index, src, reduce="amax")
    tensor([5., 6., 5., 2.])
    >>> input2.scatter_reduce(0, index, src, reduce="amax", include_self=False)
    tensor([3., 6., 5., 2.])


select(dim, index) -> Tensor

See :func:`torch.select`
select_scatter(src, dim, index) -> Tensor

See :func:`torch.select_scatter`
slice_scatter(src, dim=0, start=None, end=None, step=1) -> Tensor

See :func:`torch.slice_scatter`
set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor

Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,
:attr:`self` tensor will share the same storage and have the same size and
strides as :attr:`source`. Changes to elements in one tensor will be reflected
in the other.

If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying
storage, offset, size, and stride.

Args:
    source (Tensor or Storage): the tensor or storage to use
    storage_offset (int, optional): the offset in the storage
    size (torch.Size, optional): the desired size. Defaults to the size of the source.
    stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.
sigmoid() -> Tensor

See :func:`torch.sigmoid`
sigmoid_() -> Tensor

In-place version of :meth:`~Tensor.sigmoid`
logit() -> Tensor

See :func:`torch.logit`
logit_() -> Tensor

In-place version of :meth:`~Tensor.logit`
sign() -> Tensor

See :func:`torch.sign`
sign_() -> Tensor

In-place version of :meth:`~Tensor.sign`
signbit() -> Tensor

See :func:`torch.signbit`
sgn() -> Tensor

See :func:`torch.sgn`
sgn_() -> Tensor

In-place version of :meth:`~Tensor.sgn`
sin() -> Tensor

See :func:`torch.sin`
sin_() -> Tensor

In-place version of :meth:`~Tensor.sin`
sinc() -> Tensor

See :func:`torch.sinc`
sinc_() -> Tensor

In-place version of :meth:`~Tensor.sinc`
sinh() -> Tensor

See :func:`torch.sinh`
sinh_() -> Tensor

In-place version of :meth:`~Tensor.sinh`
size(dim=None) -> torch.Size or int

Returns the size of the :attr:`self` tensor. If ``dim`` is not specified,
the returned value is a :class:`torch.Size`, a subclass of :class:`tuple`.
If ``dim`` is specified, returns an int holding the size of that dimension.

Args:
  dim (int, optional): The dimension for which to retrieve the size.

Example::

    >>> t = torch.empty(3, 4, 5)
    >>> t.size()
    torch.Size([3, 4, 5])
    >>> t.size(dim=1)
    4

shape() -> torch.Size

Returns the size of the :attr:`self` tensor. Alias for :attr:`size`.

See also :meth:`Tensor.size`.

Example::

    >>> t = torch.empty(3, 4, 5)
    >>> t.size()
    torch.Size([3, 4, 5])
    >>> t.shape
    torch.Size([3, 4, 5])

sort(dim=-1, descending=False) -> (Tensor, LongTensor)

See :func:`torch.sort`
msort() -> Tensor

See :func:`torch.msort`
argsort(dim=-1, descending=False) -> LongTensor

See :func:`torch.argsort`
sparse_dim() -> int

Return the number of sparse dimensions in a :ref:`sparse tensor <sparse-docs>` :attr:`self`.

.. note::
  Returns ``0`` if :attr:`self` is not a sparse tensor.

See also :meth:`Tensor.dense_dim` and :ref:`hybrid tensors <sparse-hybrid-coo-docs>`.
sparse_resize_(size, sparse_dim, dense_dim) -> Tensor

Resizes :attr:`self` :ref:`sparse tensor <sparse-docs>` to the desired
size and the number of sparse and dense dimensions.

.. note::
  If the number of specified elements in :attr:`self` is zero, then
  :attr:`size`, :attr:`sparse_dim`, and :attr:`dense_dim` can be any
  size and positive integers such that ``len(size) == sparse_dim +
  dense_dim``.

  If :attr:`self` specifies one or more elements, however, then each
  dimension in :attr:`size` must not be smaller than the corresponding
  dimension of :attr:`self`, :attr:`sparse_dim` must equal the number
  of sparse dimensions in :attr:`self`, and :attr:`dense_dim` must
  equal the number of dense dimensions in :attr:`self`.

.. warning::
  Throws an error if :attr:`self` is not a sparse tensor.

Args:
    size (torch.Size): the desired size. If :attr:`self` is non-empty
      sparse tensor, the desired size cannot be smaller than the
      original size.
    sparse_dim (int): the number of sparse dimensions
    dense_dim (int): the number of dense dimensions
sparse_resize_and_clear_(size, sparse_dim, dense_dim) -> Tensor

Removes all specified elements from a :ref:`sparse tensor
<sparse-docs>` :attr:`self` and resizes :attr:`self` to the desired
size and the number of sparse and dense dimensions.

.. warning:
  Throws an error if :attr:`self` is not a sparse tensor.

Args:
    size (torch.Size): the desired size.
    sparse_dim (int): the number of sparse dimensions
    dense_dim (int): the number of dense dimensions
sqrt() -> Tensor

See :func:`torch.sqrt`
sqrt_() -> Tensor

In-place version of :meth:`~Tensor.sqrt`
square() -> Tensor

See :func:`torch.square`
square_() -> Tensor

In-place version of :meth:`~Tensor.square`
squeeze(dim=None) -> Tensor

See :func:`torch.squeeze`
squeeze_(dim=None) -> Tensor

In-place version of :meth:`~Tensor.squeeze`
std(dim=None, *, correction=1, keepdim=False) -> Tensor

See :func:`torch.std`
storage_offset() -> int

Returns :attr:`self` tensor's offset in the underlying storage in terms of
number of storage elements (not bytes).

Example::

    >>> x = torch.tensor([1, 2, 3, 4, 5])
    >>> x.storage_offset()
    0
    >>> x[3:].storage_offset()
    3

untyped_storage() -> torch.UntypedStorage

Returns the underlying :class:`UntypedStorage`.
stride(dim) -> tuple or int

Returns the stride of :attr:`self` tensor.

Stride is the jump necessary to go from one element to the next one in the
specified dimension :attr:`dim`. A tuple of all strides is returned when no
argument is passed in. Otherwise, an integer value is returned as the stride in
the particular dimension :attr:`dim`.

Args:
    dim (int, optional): the desired dimension in which stride is required

Example::

    >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])
    >>> x.stride()
    (5, 1)
    >>> x.stride(0)
    5
    >>> x.stride(-1)
    1

sub(other, *, alpha=1) -> Tensor

See :func:`torch.sub`.
sub_(other, *, alpha=1) -> Tensor

In-place version of :meth:`~Tensor.sub`
subtract(other, *, alpha=1) -> Tensor

See :func:`torch.subtract`.
subtract_(other, *, alpha=1) -> Tensor

In-place version of :meth:`~Tensor.subtract`.
sum(dim=None, keepdim=False, dtype=None) -> Tensor

See :func:`torch.sum`
nansum(dim=None, keepdim=False, dtype=None) -> Tensor

See :func:`torch.nansum`
svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)

See :func:`torch.svd`
swapdims(dim0, dim1) -> Tensor

See :func:`torch.swapdims`
swapdims_(dim0, dim1) -> Tensor

In-place version of :meth:`~Tensor.swapdims`
swapaxes(axis0, axis1) -> Tensor

See :func:`torch.swapaxes`
swapaxes_(axis0, axis1) -> Tensor

In-place version of :meth:`~Tensor.swapaxes`
t() -> Tensor

See :func:`torch.t`
t_() -> Tensor

In-place version of :meth:`~Tensor.t`
tile(dims) -> Tensor

See :func:`torch.tile`
to(*args, **kwargs) -> Tensor

Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are
inferred from the arguments of ``self.to(*args, **kwargs)``.

.. note::

    If the ``self`` Tensor already
    has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.
    Otherwise, the returned tensor is a copy of ``self`` with the desired
    :class:`torch.dtype` and :class:`torch.device`.

Here are the ways to call ``to``:

.. method:: to(dtype, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor
   :noindex:

    Returns a Tensor with the specified :attr:`dtype`

    Args:
        {memory_format}

.. method:: to(device=None, dtype=None, non_blocking=False, copy=False, memory_format=torch.preserve_format) -> Tensor
   :noindex:

    Returns a Tensor with the specified :attr:`device` and (optional)
    :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.
    When :attr:`non_blocking`, tries to convert asynchronously with respect to
    the host if possible, e.g., converting a CPU Tensor with pinned memory to a
    CUDA Tensor.
    When :attr:`copy` is set, a new Tensor is created even when the Tensor
    already matches the desired conversion.

    Args:
        {memory_format}

.. method:: to(other, non_blocking=False, copy=False) -> Tensor
   :noindex:

    Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as
    the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert
    asynchronously with respect to the host if possible, e.g., converting a CPU
    Tensor with pinned memory to a CUDA Tensor.
    When :attr:`copy` is set, a new Tensor is created even when the Tensor
    already matches the desired conversion.

Example::

    >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu
    >>> tensor.to(torch.float64)
    tensor([[-0.5044,  0.0005],
            [ 0.3310, -0.0584]], dtype=torch.float64)

    >>> cuda0 = torch.device('cuda:0')
    >>> tensor.to(cuda0)
    tensor([[-0.5044,  0.0005],
            [ 0.3310, -0.0584]], device='cuda:0')

    >>> tensor.to(cuda0, dtype=torch.float64)
    tensor([[-0.5044,  0.0005],
            [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')

    >>> other = torch.randn((), dtype=torch.float64, device=cuda0)
    >>> tensor.to(other, non_blocking=True)
    tensor([[-0.5044,  0.0005],
            [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')
byte(memory_format=torch.preserve_format) -> Tensor

``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.

Args:
    {memory_format}
bool(memory_format=torch.preserve_format) -> Tensor

``self.bool()`` is equivalent to ``self.to(torch.bool)``. See :func:`to`.

Args:
    {memory_format}
char(memory_format=torch.preserve_format) -> Tensor

``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.

Args:
    {memory_format}
bfloat16(memory_format=torch.preserve_format) -> Tensor
``self.bfloat16()`` is equivalent to ``self.to(torch.bfloat16)``. See :func:`to`.

Args:
    {memory_format}
double(memory_format=torch.preserve_format) -> Tensor

``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.

Args:
    {memory_format}
float(memory_format=torch.preserve_format) -> Tensor

``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.

Args:
    {memory_format}
cdouble(memory_format=torch.preserve_format) -> Tensor

``self.cdouble()`` is equivalent to ``self.to(torch.complex128)``. See :func:`to`.

Args:
    {memory_format}
cfloat(memory_format=torch.preserve_format) -> Tensor

``self.cfloat()`` is equivalent to ``self.to(torch.complex64)``. See :func:`to`.

Args:
    {memory_format}
chalf(memory_format=torch.preserve_format) -> Tensor

``self.chalf()`` is equivalent to ``self.to(torch.complex32)``. See :func:`to`.

Args:
     {memory_format}
half(memory_format=torch.preserve_format) -> Tensor

``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.

Args:
    {memory_format}
int(memory_format=torch.preserve_format) -> Tensor

``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.

Args:
    {memory_format}
int_repr() -> Tensor

Given a quantized Tensor,
``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the
underlying uint8_t values of the given Tensor.
long(memory_format=torch.preserve_format) -> Tensor

``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.

Args:
    {memory_format}
short(memory_format=torch.preserve_format) -> Tensor

``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.

Args:
    {memory_format}
take(indices) -> Tensor

See :func:`torch.take`
take_along_dim(indices, dim) -> Tensor

See :func:`torch.take_along_dim`
tan() -> Tensor

See :func:`torch.tan`
tan_() -> Tensor

In-place version of :meth:`~Tensor.tan`
tanh() -> Tensor

See :func:`torch.tanh`
softmax(dim) -> Tensor

Alias for :func:`torch.nn.functional.softmax`.
tanh_() -> Tensor

In-place version of :meth:`~Tensor.tanh`
tolist() -> list or number

Returns the tensor as a (nested) list. For scalars, a standard
Python number is returned, just like with :meth:`~Tensor.item`.
Tensors are automatically moved to the CPU first if necessary.

This operation is not differentiable.

Examples::

    >>> a = torch.randn(2, 2)
    >>> a.tolist()
    [[0.012766935862600803, 0.5415473580360413],
     [-0.08909505605697632, 0.7729271650314331]]
    >>> a[0,0].tolist()
    0.012766935862600803
topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)

See :func:`torch.topk`
to_dense(dtype=None, *, masked_grad=True) -> Tensor

Creates a strided copy of :attr:`self` if :attr:`self` is not a strided tensor, otherwise returns :attr:`self`.

Keyword args:
    {dtype}
    masked_grad (bool, optional): If set to ``True`` (default) and
      :attr:`self` has a sparse layout then the backward of
      :meth:`to_dense` returns ``grad.sparse_mask(self)``.

Example::

    >>> s = torch.sparse_coo_tensor(
    ...        torch.tensor([[1, 1],
    ...                      [0, 2]]),
    ...        torch.tensor([9, 10]),
    ...        size=(3, 3))
    >>> s.to_dense()
    tensor([[ 0,  0,  0],
            [ 9,  0, 10],
            [ 0,  0,  0]])
to_sparse(sparseDims) -> Tensor

Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in
:ref:`coordinate format <sparse-coo-docs>`.

Args:
    sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor

Example::

    >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])
    >>> d
    tensor([[ 0,  0,  0],
            [ 9,  0, 10],
            [ 0,  0,  0]])
    >>> d.to_sparse()
    tensor(indices=tensor([[1, 1],
                           [0, 2]]),
           values=tensor([ 9, 10]),
           size=(3, 3), nnz=2, layout=torch.sparse_coo)
    >>> d.to_sparse(1)
    tensor(indices=tensor([[1]]),
           values=tensor([[ 9,  0, 10]]),
           size=(3, 3), nnz=1, layout=torch.sparse_coo)

.. method:: to_sparse(*, layout=None, blocksize=None, dense_dim=None) -> Tensor
   :noindex:

Returns a sparse tensor with the specified layout and blocksize.  If
the :attr:`self` is strided, the number of dense dimensions could be
specified, and a hybrid sparse tensor will be created, with
`dense_dim` dense dimensions and `self.dim() - 2 - dense_dim` batch
dimension.

.. note:: If the :attr:`self` layout and blocksize parameters match
          with the specified layout and blocksize, return
          :attr:`self`. Otherwise, return a sparse tensor copy of
          :attr:`self`.

Args:

    layout (:class:`torch.layout`, optional): The desired sparse
      layout. One of ``torch.sparse_coo``, ``torch.sparse_csr``,
      ``torch.sparse_csc``, ``torch.sparse_bsr``, or
      ``torch.sparse_bsc``. Default: if ``None``,
      ``torch.sparse_coo``.

    blocksize (list, tuple, :class:`torch.Size`, optional): Block size
      of the resulting BSR or BSC tensor. For other layouts,
      specifying the block size that is not ``None`` will result in a
      RuntimeError exception.  A block size must be a tuple of length
      two such that its items evenly divide the two sparse dimensions.

    dense_dim (int, optional): Number of dense dimensions of the
      resulting CSR, CSC, BSR or BSC tensor.  This argument should be
      used only if :attr:`self` is a strided tensor, and must be a
      value between 0 and dimension of :attr:`self` tensor minus two.

Example::

    >>> x = torch.tensor([[1, 0], [0, 0], [2, 3]])
    >>> x.to_sparse(layout=torch.sparse_coo)
    tensor(indices=tensor([[0, 2, 2],
                           [0, 0, 1]]),
           values=tensor([1, 2, 3]),
           size=(3, 2), nnz=3, layout=torch.sparse_coo)
    >>> x.to_sparse(layout=torch.sparse_bsr, blocksize=(1, 2))
    tensor(crow_indices=tensor([0, 1, 1, 2]),
           col_indices=tensor([0, 0]),
           values=tensor([[[1, 0]],
                          [[2, 3]]]), size=(3, 2), nnz=2, layout=torch.sparse_bsr)
    >>> x.to_sparse(layout=torch.sparse_bsr, blocksize=(2, 1))
    RuntimeError: Tensor size(-2) 3 needs to be divisible by blocksize[0] 2
    >>> x.to_sparse(layout=torch.sparse_csr, blocksize=(3, 1))
    RuntimeError: to_sparse for Strided to SparseCsr conversion does not use specified blocksize

    >>> x = torch.tensor([[[1], [0]], [[0], [0]], [[2], [3]]])
    >>> x.to_sparse(layout=torch.sparse_csr, dense_dim=1)
    tensor(crow_indices=tensor([0, 1, 1, 3]),
           col_indices=tensor([0, 0, 1]),
           values=tensor([[1],
                          [2],
                          [3]]), size=(3, 2, 1), nnz=3, layout=torch.sparse_csr)

to_sparse_csr(dense_dim=None) -> Tensor

Convert a tensor to compressed row storage format (CSR).  Except for
strided tensors, only works with 2D tensors.  If the :attr:`self` is
strided, then the number of dense dimensions could be specified, and a
hybrid CSR tensor will be created, with `dense_dim` dense dimensions
and `self.dim() - 2 - dense_dim` batch dimension.

Args:

    dense_dim (int, optional): Number of dense dimensions of the
      resulting CSR tensor.  This argument should be used only if
      :attr:`self` is a strided tensor, and must be a value between 0
      and dimension of :attr:`self` tensor minus two.

Example::

    >>> dense = torch.randn(5, 5)
    >>> sparse = dense.to_sparse_csr()
    >>> sparse._nnz()
    25

    >>> dense = torch.zeros(3, 3, 1, 1)
    >>> dense[0, 0] = dense[1, 2] = dense[2, 1] = 1
    >>> dense.to_sparse_csr(dense_dim=2)
    tensor(crow_indices=tensor([0, 1, 2, 3]),
           col_indices=tensor([0, 2, 1]),
           values=tensor([[[1.]],

                          [[1.]],

                          [[1.]]]), size=(3, 3, 1, 1), nnz=3,
           layout=torch.sparse_csr)

to_sparse_csc() -> Tensor

Convert a tensor to compressed column storage (CSC) format.  Except
for strided tensors, only works with 2D tensors.  If the :attr:`self`
is strided, then the number of dense dimensions could be specified,
and a hybrid CSC tensor will be created, with `dense_dim` dense
dimensions and `self.dim() - 2 - dense_dim` batch dimension.

Args:

    dense_dim (int, optional): Number of dense dimensions of the
      resulting CSC tensor.  This argument should be used only if
      :attr:`self` is a strided tensor, and must be a value between 0
      and dimension of :attr:`self` tensor minus two.

Example::

    >>> dense = torch.randn(5, 5)
    >>> sparse = dense.to_sparse_csc()
    >>> sparse._nnz()
    25

    >>> dense = torch.zeros(3, 3, 1, 1)
    >>> dense[0, 0] = dense[1, 2] = dense[2, 1] = 1
    >>> dense.to_sparse_csc(dense_dim=2)
    tensor(ccol_indices=tensor([0, 1, 2, 3]),
           row_indices=tensor([0, 2, 1]),
           values=tensor([[[1.]],

                          [[1.]],

                          [[1.]]]), size=(3, 3, 1, 1), nnz=3,
           layout=torch.sparse_csc)

to_sparse_bsr(blocksize, dense_dim) -> Tensor

Convert a tensor to a block sparse row (BSR) storage format of given
blocksize.  If the :attr:`self` is strided, then the number of dense
dimensions could be specified, and a hybrid BSR tensor will be
created, with `dense_dim` dense dimensions and `self.dim() - 2 -
dense_dim` batch dimension.

Args:

    blocksize (list, tuple, :class:`torch.Size`, optional): Block size
      of the resulting BSR tensor. A block size must be a tuple of
      length two such that its items evenly divide the two sparse
      dimensions.

    dense_dim (int, optional): Number of dense dimensions of the
      resulting BSR tensor.  This argument should be used only if
      :attr:`self` is a strided tensor, and must be a value between 0
      and dimension of :attr:`self` tensor minus two.

Example::

    >>> dense = torch.randn(10, 10)
    >>> sparse = dense.to_sparse_csr()
    >>> sparse_bsr = sparse.to_sparse_bsr((5, 5))
    >>> sparse_bsr.col_indices()
    tensor([0, 1, 0, 1])

    >>> dense = torch.zeros(4, 3, 1)
    >>> dense[0:2, 0] = dense[0:2, 2] = dense[2:4, 1] = 1
    >>> dense.to_sparse_bsr((2, 1), 1)
    tensor(crow_indices=tensor([0, 2, 3]),
           col_indices=tensor([0, 2, 1]),
           values=tensor([[[[1.]],

                           [[1.]]],


                          [[[1.]],

                           [[1.]]],


                          [[[1.]],

                           [[1.]]]]), size=(4, 3, 1), nnz=3,
           layout=torch.sparse_bsr)

to_sparse_bsc(blocksize, dense_dim) -> Tensor

Convert a tensor to a block sparse column (BSC) storage format of
given blocksize.  If the :attr:`self` is strided, then the number of
dense dimensions could be specified, and a hybrid BSC tensor will be
created, with `dense_dim` dense dimensions and `self.dim() - 2 -
dense_dim` batch dimension.

Args:

    blocksize (list, tuple, :class:`torch.Size`, optional): Block size
      of the resulting BSC tensor. A block size must be a tuple of
      length two such that its items evenly divide the two sparse
      dimensions.

    dense_dim (int, optional): Number of dense dimensions of the
      resulting BSC tensor.  This argument should be used only if
      :attr:`self` is a strided tensor, and must be a value between 0
      and dimension of :attr:`self` tensor minus two.

Example::

    >>> dense = torch.randn(10, 10)
    >>> sparse = dense.to_sparse_csr()
    >>> sparse_bsc = sparse.to_sparse_bsc((5, 5))
    >>> sparse_bsc.row_indices()
    tensor([0, 1, 0, 1])

    >>> dense = torch.zeros(4, 3, 1)
    >>> dense[0:2, 0] = dense[0:2, 2] = dense[2:4, 1] = 1
    >>> dense.to_sparse_bsc((2, 1), 1)
    tensor(ccol_indices=tensor([0, 1, 2, 3]),
           row_indices=tensor([0, 1, 0]),
           values=tensor([[[[1.]],

                           [[1.]]],


                          [[[1.]],

                           [[1.]]],


                          [[[1.]],

                           [[1.]]]]), size=(4, 3, 1), nnz=3,
           layout=torch.sparse_bsc)

to_mkldnn() -> Tensor
Returns a copy of the tensor in ``torch.mkldnn`` layout.

trace() -> Tensor

See :func:`torch.trace`
transpose(dim0, dim1) -> Tensor

See :func:`torch.transpose`
transpose_(dim0, dim1) -> Tensor

In-place version of :meth:`~Tensor.transpose`
triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)

See :func:`torch.triangular_solve`
tril(diagonal=0) -> Tensor

See :func:`torch.tril`
tril_(diagonal=0) -> Tensor

In-place version of :meth:`~Tensor.tril`
triu(diagonal=0) -> Tensor

See :func:`torch.triu`
triu_(diagonal=0) -> Tensor

In-place version of :meth:`~Tensor.triu`
true_divide(value) -> Tensor

See :func:`torch.true_divide`
true_divide_(value) -> Tensor

In-place version of :meth:`~Tensor.true_divide_`
trunc() -> Tensor

See :func:`torch.trunc`
fix() -> Tensor

See :func:`torch.fix`.
trunc_() -> Tensor

In-place version of :meth:`~Tensor.trunc`
fix_() -> Tensor

In-place version of :meth:`~Tensor.fix`
type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor
Returns the type if `dtype` is not provided, else casts this object to
the specified type.

If this is already of the correct type, no copy is performed and the
original object is returned.

Args:
    dtype (dtype or string): The desired type
    non_blocking (bool): If ``True``, and the source is in pinned memory
        and destination is on the GPU or vice versa, the copy is performed
        asynchronously with respect to the host. Otherwise, the argument
        has no effect.
    **kwargs: For compatibility, may contain the key ``async`` in place of
        the ``non_blocking`` argument. The ``async`` arg is deprecated.
type_as(tensor) -> Tensor

Returns this tensor cast to the type of the given tensor.

This is a no-op if the tensor is already of the correct type. This is
equivalent to ``self.type(tensor.type())``

Args:
    tensor (Tensor): the tensor which has the desired type
unfold(dimension, size, step) -> Tensor

Returns a view of the original tensor which contains all slices of size :attr:`size` from
:attr:`self` tensor in the dimension :attr:`dimension`.

Step between two slices is given by :attr:`step`.

If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of
dimension :attr:`dimension` in the returned tensor will be
`(sizedim - size) / step + 1`.

An additional dimension of size :attr:`size` is appended in the returned tensor.

Args:
    dimension (int): dimension in which unfolding happens
    size (int): the size of each slice that is unfolded
    step (int): the step between each slice

Example::

    >>> x = torch.arange(1., 8)
    >>> x
    tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])
    >>> x.unfold(0, 2, 1)
    tensor([[ 1.,  2.],
            [ 2.,  3.],
            [ 3.,  4.],
            [ 4.,  5.],
            [ 5.,  6.],
            [ 6.,  7.]])
    >>> x.unfold(0, 2, 2)
    tensor([[ 1.,  2.],
            [ 3.,  4.],
            [ 5.,  6.]])
uniform_(from=0, to=1, *, generator=None) -> Tensor

Fills :attr:`self` tensor with numbers sampled from the continuous uniform
distribution:

.. math::
    f(x) = \dfrac{1}{\text{to} - \text{from}}
unsqueeze(dim) -> Tensor

See :func:`torch.unsqueeze`
unsqueeze_(dim) -> Tensor

In-place version of :meth:`~Tensor.unsqueeze`
var(dim=None, *, correction=1, keepdim=False) -> Tensor

See :func:`torch.var`
vdot(other) -> Tensor

See :func:`torch.vdot`
view(*shape) -> Tensor

Returns a new tensor with the same data as the :attr:`self` tensor but of a
different :attr:`shape`.

The returned tensor shares the same data and must have the same number
of elements, but may have a different size. For a tensor to be viewed, the new
view size must be compatible with its original size and stride, i.e., each new
view dimension must either be a subspace of an original dimension, or only span
across original dimensions :math:`d, d+1, \dots, d+k` that satisfy the following
contiguity-like condition that :math:`\forall i = d, \dots, d+k-1`,

.. math::

  \text{stride}[i] = \text{stride}[i+1] \times \text{size}[i+1]

Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`
without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a
:meth:`view` can be performed, it is advisable to use :meth:`reshape`, which
returns a view if the shapes are compatible, and copies (equivalent to calling
:meth:`contiguous`) otherwise.

Args:
    shape (torch.Size or int...): the desired size

Example::

    >>> x = torch.randn(4, 4)
    >>> x.size()
    torch.Size([4, 4])
    >>> y = x.view(16)
    >>> y.size()
    torch.Size([16])
    >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions
    >>> z.size()
    torch.Size([2, 8])

    >>> a = torch.randn(1, 2, 3, 4)
    >>> a.size()
    torch.Size([1, 2, 3, 4])
    >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension
    >>> b.size()
    torch.Size([1, 3, 2, 4])
    >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory
    >>> c.size()
    torch.Size([1, 3, 2, 4])
    >>> torch.equal(b, c)
    False


.. method:: view(dtype) -> Tensor
   :noindex:

Returns a new tensor with the same data as the :attr:`self` tensor but of a
different :attr:`dtype`.

If the element size of :attr:`dtype` is different than that of ``self.dtype``,
then the size of the last dimension of the output will be scaled
proportionally.  For instance, if :attr:`dtype` element size is twice that of
``self.dtype``, then each pair of elements in the last dimension of
:attr:`self` will be combined, and the size of the last dimension of the output
will be half that of :attr:`self`. If :attr:`dtype` element size is half that
of ``self.dtype``, then each element in the last dimension of :attr:`self` will
be split in two, and the size of the last dimension of the output will be
double that of :attr:`self`. For this to be possible, the following conditions
must be true:

    * ``self.dim()`` must be greater than 0.
    * ``self.stride(-1)`` must be 1.

Additionally, if the element size of :attr:`dtype` is greater than that of
``self.dtype``, the following conditions must be true as well:

    * ``self.size(-1)`` must be divisible by the ratio between the element
      sizes of the dtypes.
    * ``self.storage_offset()`` must be divisible by the ratio between the
      element sizes of the dtypes.
    * The strides of all dimensions, except the last dimension, must be
      divisible by the ratio between the element sizes of the dtypes.

If any of the above conditions are not met, an error is thrown.

.. warning::

    This overload is not supported by TorchScript, and using it in a Torchscript
    program will cause undefined behavior.


Args:
    dtype (:class:`torch.dtype`): the desired dtype

Example::

    >>> x = torch.randn(4, 4)
    >>> x
    tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],
            [-0.1520,  0.7472,  0.5617, -0.8649],
            [-2.4724, -0.0334, -0.2976, -0.8499],
            [-0.2109,  1.9913, -0.9607, -0.6123]])
    >>> x.dtype
    torch.float32

    >>> y = x.view(torch.int32)
    >>> y
    tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],
            [-1105482831,  1061112040,  1057999968, -1084397505],
            [-1071760287, -1123489973, -1097310419, -1084649136],
            [-1101533110,  1073668768, -1082790149, -1088634448]],
        dtype=torch.int32)
    >>> y[0, 0] = 1000000000
    >>> x
    tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],
            [-0.1520,  0.7472,  0.5617, -0.8649],
            [-2.4724, -0.0334, -0.2976, -0.8499],
            [-0.2109,  1.9913, -0.9607, -0.6123]])

    >>> x.view(torch.cfloat)
    tensor([[ 0.0047-0.0310j,  1.4999-0.5316j],
            [-0.1520+0.7472j,  0.5617-0.8649j],
            [-2.4724-0.0334j, -0.2976-0.8499j],
            [-0.2109+1.9913j, -0.9607-0.6123j]])
    >>> x.view(torch.cfloat).size()
    torch.Size([4, 2])

    >>> x.view(torch.uint8)
    tensor([[  0, 202, 154,  59, 182, 243, 253, 188, 185, 252, 191,  63, 240,  22,
               8, 191],
            [227, 165,  27, 190, 128,  72,  63,  63, 146, 203,  15,  63,  22, 106,
              93, 191],
            [205,  59,  30, 192, 112, 206,   8, 189,   7,  95, 152, 190,  12, 147,
              89, 191],
            [ 43, 246,  87, 190, 235, 226, 254,  63, 111, 240, 117, 191, 177, 191,
              28, 191]], dtype=torch.uint8)
    >>> x.view(torch.uint8).size()
    torch.Size([4, 16])
view_as(other) -> Tensor

View this tensor as the same size as :attr:`other`.
``self.view_as(other)`` is equivalent to ``self.view(other.size())``.

Please see :meth:`~Tensor.view` for more information about ``view``.

Args:
    other (:class:`torch.Tensor`): The result tensor has the same size
        as :attr:`other`.
expand(*sizes) -> Tensor

Returns a new view of the :attr:`self` tensor with singleton dimensions expanded
to a larger size.

Passing -1 as the size for a dimension means not changing the size of
that dimension.

Tensor can be also expanded to a larger number of dimensions, and the
new ones will be appended at the front. For the new dimensions, the
size cannot be set to -1.

Expanding a tensor does not allocate new memory, but only creates a
new view on the existing tensor where a dimension of size one is
expanded to a larger size by setting the ``stride`` to 0. Any dimension
of size 1 can be expanded to an arbitrary value without allocating new
memory.

Args:
    *sizes (torch.Size or int...): the desired expanded size

.. warning::

    More than one element of an expanded tensor may refer to a single
    memory location. As a result, in-place operations (especially ones that
    are vectorized) may result in incorrect behavior. If you need to write
    to the tensors, please clone them first.

Example::

    >>> x = torch.tensor([[1], [2], [3]])
    >>> x.size()
    torch.Size([3, 1])
    >>> x.expand(3, 4)
    tensor([[ 1,  1,  1,  1],
            [ 2,  2,  2,  2],
            [ 3,  3,  3,  3]])
    >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension
    tensor([[ 1,  1,  1,  1],
            [ 2,  2,  2,  2],
            [ 3,  3,  3,  3]])
expand_as(other) -> Tensor

Expand this tensor to the same size as :attr:`other`.
``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.

Please see :meth:`~Tensor.expand` for more information about ``expand``.

Args:
    other (:class:`torch.Tensor`): The result tensor has the same size
        as :attr:`other`.
sum_to_size(*size) -> Tensor

Sum ``this`` tensor to :attr:`size`.
:attr:`size` must be broadcastable to ``this`` tensor size.

Args:
    size (int...): a sequence of integers defining the shape of the output tensor.
zero_() -> Tensor

Fills :attr:`self` tensor with zeros.
matmul(tensor2) -> Tensor

See :func:`torch.matmul`
chunk(chunks, dim=0) -> List of Tensors

See :func:`torch.chunk`
unsafe_chunk(chunks, dim=0) -> List of Tensors

See :func:`torch.unsafe_chunk`
unsafe_split(split_size, dim=0) -> List of Tensors

See :func:`torch.unsafe_split`
tensor_split(indices_or_sections, dim=0) -> List of Tensors

See :func:`torch.tensor_split`
hsplit(split_size_or_sections) -> List of Tensors

See :func:`torch.hsplit`
vsplit(split_size_or_sections) -> List of Tensors

See :func:`torch.vsplit`
dsplit(split_size_or_sections) -> List of Tensors

See :func:`torch.dsplit`
stft(frame_length, hop, fft_size=None, return_onesided=True, window=None, pad_end=0) -> Tensor

See :func:`torch.stft`
istft(n_fft, hop_length=None, win_length=None, window=None,
 center=True, normalized=False, onesided=True, length=None) -> Tensor

See :func:`torch.istft`
det() -> Tensor

See :func:`torch.det`
where(condition, y) -> Tensor

``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.
See :func:`torch.where`
logdet() -> Tensor

See :func:`torch.logdet`
slogdet() -> (Tensor, Tensor)

See :func:`torch.slogdet`
unbind(dim=0) -> seq

See :func:`torch.unbind`
pin_memory() -> Tensor

Copies the tensor to pinned memory, if it's not already pinned.
pinverse() -> Tensor

See :func:`torch.pinverse`
index_add(dim, index, source, *, alpha=1) -> Tensor

Out-of-place version of :meth:`torch.Tensor.index_add_`.
index_copy(dim, index, tensor2) -> Tensor

Out-of-place version of :meth:`torch.Tensor.index_copy_`.
index_fill(dim, index, value) -> Tensor

Out-of-place version of :meth:`torch.Tensor.index_fill_`.
scatter(dim, index, src) -> Tensor

Out-of-place version of :meth:`torch.Tensor.scatter_`
scatter_add(dim, index, src) -> Tensor

Out-of-place version of :meth:`torch.Tensor.scatter_add_`
scatter_reduce(dim, index, src, reduce, *, include_self=True) -> Tensor

Out-of-place version of :meth:`torch.Tensor.scatter_reduce_`
masked_scatter(mask, tensor) -> Tensor

Out-of-place version of :meth:`torch.Tensor.masked_scatter_`

.. note::

    The inputs :attr:`self` and :attr:`mask`
    :ref:`broadcast <broadcasting-semantics>`.

Example:

    >>> self = torch.tensor([0, 0, 0, 0, 0])
    >>> mask = torch.tensor([[0, 0, 0, 1, 1], [1, 1, 0, 1, 1]])
    >>> source = torch.tensor([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]])
    >>> self.masked_scatter(mask, source)
    tensor([[0, 0, 0, 0, 1],
            [2, 3, 0, 4, 5]])

xlogy(other) -> Tensor

See :func:`torch.xlogy`
xlogy_(other) -> Tensor

In-place version of :meth:`~Tensor.xlogy`
masked_fill(mask, value) -> Tensor

Out-of-place version of :meth:`torch.Tensor.masked_fill_`
This attribute is ``None`` by default and becomes a Tensor the first time a call to
:func:`backward` computes gradients for ``self``.
The attribute will then contain the gradients computed and future calls to
:func:`backward` will accumulate (add) gradients into it.
retain_grad() -> None

Enables this Tensor to have their :attr:`grad` populated during
:func:`backward`. This is a no-op for leaf tensors.
Is ``True`` if this Tensor is non-leaf and its :attr:`grad` is enabled to be
populated during :func:`backward`, ``False`` otherwise.
Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.

.. note::

    The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`
    attribute will be populated, see :attr:`is_leaf` for more details.

All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.

For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were
created by the user. This means that they are not the result of an operation and so
:attr:`grad_fn` is None.

Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.
To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.

Example::

    >>> a = torch.rand(10, requires_grad=True)
    >>> a.is_leaf
    True
    >>> b = torch.rand(10, requires_grad=True).cuda()
    >>> b.is_leaf
    False
    >>> c = torch.rand(10, requires_grad=True) + 2
    >>> c.is_leaf
    False
    >>> d = torch.rand(10).cuda()
    >>> d.is_leaf
    True
    >>> e = torch.rand(10).cuda().requires_grad_()
    >>> e.is_leaf
    True
    >>> f = torch.rand(10, requires_grad=True, device="cuda")
    >>> f.is_leaf
    True


Stores names for each of this tensor's dimensions.

``names[idx]`` corresponds to the name of tensor dimension ``idx``.
Names are either a string if the dimension is named or ``None`` if the
dimension is unnamed.

Dimension names may contain characters or underscore. Furthermore, a dimension
name must be a valid Python variable name (i.e., does not start with underscore).

Tensors may not have two named dimensions with the same name.

.. warning::
    The named tensor API is experimental and subject to change.

Is ``True`` if the Tensor is stored on the GPU, ``False`` otherwise.
Is ``True`` if the Tensor is stored on the CPU, ``False`` otherwise.
Is ``True`` if the Tensor is stored on an XLA device, ``False`` otherwise.
Is ``True`` if the Tensor is stored on the IPU, ``False`` otherwise.
Is ``True`` if the Tensor is stored on the XPU, ``False`` otherwise.
Is ``True`` if the Tensor is quantized, ``False`` otherwise.
Is ``True`` if the Tensor is a meta tensor, ``False`` otherwise.  Meta tensors
are like normal tensors, but they carry no data.
Is ``True`` if the Tensor is stored on the MPS device, ``False`` otherwise.
Is ``True`` if the Tensor uses sparse COO storage layout, ``False`` otherwise.
Is ``True`` if the Tensor uses sparse CSR storage layout, ``False`` otherwise.
Is the :class:`torch.device` where this Tensor is.
Alias for :meth:`~Tensor.dim()`
Alias for :meth:`~Tensor.element_size()`
Returns the number of bytes consumed by the "view" of elements of the Tensor
if the Tensor does not use sparse storage layout.
Defined to be :meth:`~Tensor.numel()` * :meth:`~Tensor.element_size()`
Returns a view of this tensor with its dimensions reversed.

If ``n`` is the number of dimensions in ``x``,
``x.T`` is equivalent to ``x.permute(n-1, n-2, ..., 0)``.

.. warning::
    The use of :func:`Tensor.T` on tensors of dimension other than 2 to reverse their shape
    is deprecated and it will throw an error in a future release. Consider :attr:`~.Tensor.mT`
    to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse
    the dimensions of a tensor.
Returns a view of a matrix (2-D tensor) conjugated and transposed.

``x.H`` is equivalent to ``x.transpose(0, 1).conj()`` for complex matrices and
``x.transpose(0, 1)`` for real matrices.

.. seealso::

        :attr:`~.Tensor.mH`: An attribute that also works on batches of matrices.
Returns a view of this tensor with the last two dimensions transposed.

``x.mT`` is equivalent to ``x.transpose(-2, -1)``.
Accessing this property is equivalent to calling :func:`adjoint`.
adjoint() -> Tensor

Alias for :func:`adjoint`
Returns a new tensor containing real values of the :attr:`self` tensor for a complex-valued input tensor.
The returned tensor and :attr:`self` share the same underlying storage.

Returns :attr:`self` if :attr:`self` is a real-valued tensor tensor.

Example::
    >>> x=torch.randn(4, dtype=torch.cfloat)
    >>> x
    tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])
    >>> x.real
    tensor([ 0.3100, -0.5445, -1.6492, -0.0638])

Returns a new tensor containing imaginary values of the :attr:`self` tensor.
The returned tensor and :attr:`self` share the same underlying storage.

.. warning::
    :func:`imag` is only supported for tensors with complex dtypes.

Example::
    >>> x=torch.randn(4, dtype=torch.cfloat)
    >>> x
    tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])
    >>> x.imag
    tensor([ 0.3553, -0.7896, -0.0633, -0.8119])

as_subclass(cls) -> Tensor

Makes a ``cls`` instance with the same data pointer as ``self``. Changes
in the output mirror changes in ``self``, and the output stays attached
to the autograd graph. ``cls`` must be a subclass of ``Tensor``.
crow_indices() -> IntTensor

Returns the tensor containing the compressed row indices of the :attr:`self`
tensor when :attr:`self` is a sparse CSR tensor of layout ``sparse_csr``.
The ``crow_indices`` tensor is strictly of shape (:attr:`self`.size(0) + 1)
and of type ``int32`` or ``int64``. When using MKL routines such as sparse
matrix multiplication, it is necessary to use ``int32`` indexing in order
to avoid downcasting and potentially losing information.

Example::
    >>> csr = torch.eye(5,5).to_sparse_csr()
    >>> csr.crow_indices()
    tensor([0, 1, 2, 3, 4, 5], dtype=torch.int32)

col_indices() -> IntTensor

Returns the tensor containing the column indices of the :attr:`self`
tensor when :attr:`self` is a sparse CSR tensor of layout ``sparse_csr``.
The ``col_indices`` tensor is strictly of shape (:attr:`self`.nnz())
and of type ``int32`` or ``int64``.  When using MKL routines such as sparse
matrix multiplication, it is necessary to use ``int32`` indexing in order
to avoid downcasting and potentially losing information.

Example::
    >>> csr = torch.eye(5,5).to_sparse_csr()
    >>> csr.col_indices()
    tensor([0, 1, 2, 3, 4], dtype=torch.int32)

to_padded_tensor(padding, output_size=None) -> Tensor
See :func:`to_padded_tensor`

<END>

<START>
from tensorboard.compat.proto.graph_pb2 import GraphDef
from tensorboard.compat.proto.node_def_pb2 import NodeDef
from tensorboard.compat.proto.versions_pb2 import VersionDef
from tensorboard.compat.proto.attr_value_pb2 import AttrValue
from tensorboard.compat.proto.tensor_shape_pb2 import TensorShapeProto


def load_onnx_graph(fname):
    import onnx

    m = onnx.load(fname)  # type: ignore[attr-defined]
    g = m.graph
    return parse(g)


def parse(graph):
    nodes = []
    import itertools

    nodes_proto = list(itertools.chain(graph.input, graph.output))

    for node in nodes_proto:
        print(node.name)
        shapeproto = TensorShapeProto(
            dim=[
                TensorShapeProto.Dim(size=d.dim_value)
                for d in node.type.tensor_type.shape.dim
            ]
        )
        nodes.append(
            NodeDef(
                name=node.name.encode(encoding="utf_8"),
                op="Variable",
                input=[],
                attr={
                    "dtype": AttrValue(type=node.type.tensor_type.elem_type),
                    "shape": AttrValue(shape=shapeproto),
                },
            )
        )

    for node in graph.node:
        _attr = []
        for s in node.attribute:
            _attr.append(" = ".join([str(f[1]) for f in s.ListFields()]))
        attr = ", ".join(_attr).encode(encoding="utf_8")
        print(node.output[0])
        nodes.append(
            NodeDef(
                name=node.output[0].encode(encoding="utf_8"),
                op=node.op_type,
                input=node.input,
                attr={"parameters": AttrValue(s=attr)},
            )
        )

    mapping = {}
    for node in nodes:
        mapping[node.name] = node.op + "_" + node.name

    return GraphDef(node=nodes, versions=VersionDef(producer=22))

<END>

<START>
import functools
import importlib
import logging
import os
import tempfile

import torch
from .common import device_from_inputs, fake_tensor_unsupported

from .registry import register_backend

log = logging.getLogger(__name__)


@register_backend
@fake_tensor_unsupported
def tvm(gm, example_inputs, *, scheduler=None, trials=20000):
    import tvm  # type: ignore[import]
    from tvm import relay  # type: ignore[import]
    from tvm.contrib import graph_executor  # type: ignore[import]

    jit_mod = torch.jit.trace(gm, example_inputs)
    device = device_from_inputs(example_inputs)
    shape_list = [(f"inp_{idx}", i.shape) for idx, i in enumerate(example_inputs)]
    example_outputs = gm(*example_inputs)
    if len(example_outputs) == 0:
        log.warning("Explicitly fall back to eager due to zero output")
        return gm.forward
    mod, params = relay.frontend.from_pytorch(jit_mod, shape_list)
    if device.type == "cuda":
        dev = tvm.cuda(device.index)
        target = tvm.target.cuda()
    else:
        dev = tvm.cpu(0)
        target = tvm.target.Target(llvm_target())

    if scheduler is None:
        scheduler = os.environ.get("TVM_SCHEDULER", None)

    if scheduler == "auto_scheduler":
        from tvm import auto_scheduler

        log_file = tempfile.NamedTemporaryFile()

        if not os.path.exists(log_file):
            tasks, task_weights = auto_scheduler.extract_tasks(
                mod["main"], params, target
            )
            for task in tasks:
                print(task.compute_dag)
            else:
                print("No tasks")
            if len(tasks) != 0:
                tuner = auto_scheduler.TaskScheduler(tasks, task_weights)
                if not os.path.exists(log_file):
                    assert trials > 0
                    tune_option = auto_scheduler.TuningOptions(
                        num_measure_trials=trials,
                        measure_callbacks=[auto_scheduler.RecordToFile(log_file)],
                        early_stopping=2000,
                    )
                    try:
                        tuner.tune(tune_option)
                    except Exception:
                        if os.path.exists(log_file):
                            os.unlink(log_file)
                        raise

        with auto_scheduler.ApplyHistoryBest(log_file):
            with tvm.transform.PassContext(
                opt_level=3, config={"relay.backend.use_auto_scheduler": True}
            ):
                lib = relay.build(mod, target=target, params=params)
    elif scheduler == "meta_schedule":
        from tvm import meta_schedule as ms

        with tempfile.TemporaryDirectory() as work_dir:
            if device.type != "cuda":
                target = tvm.target.Target(
                    f"{llvm_target()} --num-cores {ms.utils.cpu_count(logical=False)}"
                )
            database = ms.relay_integration.tune_relay(
                mod=mod,
                target=target,
                work_dir=work_dir,
                max_trials_global=20000,
                num_trials_per_iter=64,
                params=params,
                strategy="evolutionary",
            )
            lib = ms.relay_integration.compile_relay(
                database=database,
                mod=mod,
                target=target,
                params=params,
            )
    elif scheduler == "default" or not scheduler:
        with tvm.transform.PassContext(opt_level=10):
            lib = relay.build(mod, target=target, params=params)
    else:
        raise NotImplementedError(
            "This tuning option is invalid/not implemented for torchdynamo's TVM-related backend. "
            "There are three available options: default, auto_scheduler and meta_schedule."
        )
    m = graph_executor.GraphModule(lib["default"](dev))

    def to_torch_tensor(nd_tensor):
        if torch_tensor.dtype == torch.bool:
            return tvm.nd.array(torch_tensor.cpu().numpy())
        return tvm.nd.from_dlpack(torch_tensor)

    def exec_tvm(*i_args):
        args = [a.contiguous() for a in i_args]
        shape_info, _ = m.get_input_info()
        active_inputs = {name for name, _ in shape_info.items()}
        for idx, arg in enumerate(args, 0):
            if arg.dim() != 0:
                if arg.requires_grad:
                    arg = arg.detach()
                inp_name = f"inp_{idx}"
                if inp_name not in active_inputs:
                    log.warning(
                        "input %s skipped as not found in tvm's runtime library",
                        inp_name,
                    )
                    continue
                m.set_input(
                    inp_name,
                    to_tvm_tensor(arg),
                )
        m.run()
        return [to_torch_tensor(m.get_output(i)) for i in range(m.get_num_outputs())]

    return exec_tvm


tvm_meta_schedule = functools.partial(tvm, scheduler="meta_schedule")
tvm_auto_scheduler = functools.partial(tvm, scheduler="auto_scheduler")


def has_tvm():
    try:
        importlib.import_module("tvm")
        return True
    except ImportError:
        return False


@functools.lru_cache(None)
def llvm_target():
    if "avx512" in open("/proc/cpuinfo").read():
        return "llvm -mcpu=skylake-avx512"
    return "llvm -mcpu=core-avx2"

<END>

<START>
from .module import Module

from typing import Tuple, Union
from torch import Tensor
from torch.types import _size

__all__ = ['Flatten', 'Unflatten']

class Flatten(Module):

    __constants__ = ['start_dim', 'end_dim']
    start_dim: int
    end_dim: int

    def __init__(self, start_dim: int = 1, end_dim: int = -1) -> None:
        super().__init__()
        self.start_dim = start_dim
        self.end_dim = end_dim

    def forward(self, input: Tensor) -> Tensor:
        return input.flatten(self.start_dim, self.end_dim)

    def extra_repr(self) -> str:
        return f'start_dim={self.start_dim}, end_dim={self.end_dim}'


class Unflatten(Module):

    NamedShape = Tuple[Tuple[str, int]]

    __constants__ = ['dim', 'unflattened_size']
    dim: Union[int, str]
    unflattened_size: Union[_size, NamedShape]

    def __init__(self, dim: Union[int, str], unflattened_size: Union[_size, NamedShape]) -> None:
        super().__init__()

        if isinstance(dim, int):
            self._require_tuple_int(unflattened_size)
        elif isinstance(dim, str):
            self._require_tuple_tuple(unflattened_size)
        else:
            raise TypeError("invalid argument type for dim parameter")

        self.dim = dim
        self.unflattened_size = unflattened_size

    def _require_tuple_tuple(self, input):
        if (isinstance(input, tuple)):
            for idx, elem in enumerate(input):
                if not isinstance(elem, tuple):
                    raise TypeError("unflattened_size must be tuple of tuples, " +
                                    f"but found element of type {type(elem).__name__} at pos {idx}")
            return
        raise TypeError("unflattened_size must be a tuple of tuples, " +
                        f"but found type {type(input).__name__}")

    def _require_tuple_int(self, input):
        if (isinstance(input, (tuple, list))):
            for idx, elem in enumerate(input):
                if not isinstance(elem, int):
                    raise TypeError("unflattened_size must be tuple of ints, " +
                                    f"but found element of type {type(elem).__name__} at pos {idx}")
            return
        raise TypeError(f"unflattened_size must be a tuple of ints, but found type {type(input).__name__}")

    def forward(self, input: Tensor) -> Tensor:
        return input.unflatten(self.dim, self.unflattened_size)

    def extra_repr(self) -> str:
        return f'dim={self.dim}, unflattened_size={self.unflattened_size}'

<END>

<START>
from typing import Final

SARIF_VERSION: Final = "2.1.0"
SARIF_SCHEMA_LINK: Final = "https://docs.oasis-open.org/sarif/sarif/v2.1.0/cs01/schemas/sarif-schema-2.1.0.json"

<END>

<START>
import torch
import torch.distributed as dist

from torch.autograd.function import Function

class SyncBatchNorm(Function):

    @staticmethod
    def forward(self, input, weight, bias, running_mean, running_var, eps, momentum, process_group, world_size):
        if not (
            input.is_contiguous(memory_format=torch.channels_last) or
            input.is_contiguous(memory_format=torch.channels_last_3d)
        ):
            input = input.contiguous()
        if weight is not None:
            weight = weight.contiguous()

        size = int(input.numel() // input.size(1))
        if size == 1 and world_size < 2:
            raise ValueError(f'Expected more than 1 value per channel when training, got input size {size}')

        num_channels = input.shape[1]
        if input.numel() > 0:
            mean, invstd = torch.batch_norm_stats(input, eps)

            count = torch.full(
                (1,),
                input.numel() // input.size(1),
                dtype=mean.dtype,
                device=mean.device
            )

            combined = torch.cat([mean, invstd, count], dim=0)
        else:
            combined = torch.zeros(
                2 * num_channels + 1,
                dtype=input.dtype,
                device=input.device
            )

        if process_group._get_backend_name() != "gloo":
            combined_size = combined.numel()
            combined_flat = torch.empty(1,
                                        combined_size * world_size,
                                        dtype=combined.dtype,
                                        device=combined.device)
            dist.all_gather_into_tensor(combined_flat, combined, process_group, async_op=False)
            combined = torch.reshape(combined_flat, (world_size, combined_size))
            mean_all, invstd_all, count_all = torch.split(combined, num_channels, dim=1)
        else:
            combined_list = [
                torch.empty_like(combined) for _ in range(world_size)
            ]
            dist.all_gather(combined_list, combined, process_group, async_op=False)
            combined = torch.stack(combined_list, dim=0)
            mean_all, invstd_all, count_all = torch.split(combined, num_channels, dim=1)

        if not (torch.cuda.is_available() and torch.cuda.is_current_stream_capturing()):

            mask = count_all.squeeze(-1) >= 1
            count_all = count_all[mask]
            mean_all = mean_all[mask]
            invstd_all = invstd_all[mask]

        counts = count_all.view(-1)
        if running_mean is not None and counts.dtype != running_mean.dtype:
            counts = counts.to(running_mean.dtype)
        mean, invstd = torch.batch_norm_gather_stats_with_counts(
            input,
            mean_all,
            invstd_all,
            running_mean,
            running_var,
            momentum,
            eps,
            counts,
        )

        self.save_for_backward(input, weight, mean, invstd, count_all.to(torch.int32))
        self.process_group = process_group

        if input.numel() > 0:
            return torch.batch_norm_elemt(input, weight, bias, mean, invstd, eps)
        else:
            return torch.empty_like(input)

    @staticmethod
    def backward(self, grad_output):
        if not (
            grad_output.is_contiguous(memory_format=torch.channels_last) or
            grad_output.is_contiguous(memory_format=torch.channels_last_3d)
        ):
            grad_output = grad_output.contiguous()
        saved_input, weight, mean, invstd, count_tensor = self.saved_tensors
        grad_input = grad_weight = grad_bias = None
        process_group = self.process_group

        if saved_input.numel() > 0:
            sum_dy, sum_dy_xmu, grad_weight, grad_bias = torch.batch_norm_backward_reduce(
                grad_output,
                saved_input,
                mean,
                invstd,
                weight,
                self.needs_input_grad[0],
                self.needs_input_grad[1],
                self.needs_input_grad[2]
            )

            if self.needs_input_grad[0]:
                num_channels = sum_dy.shape[0]
                combined = torch.cat([sum_dy, sum_dy_xmu], dim=0)
                torch.distributed.all_reduce(
                    combined, torch.distributed.ReduceOp.SUM, process_group, async_op=False)
                sum_dy, sum_dy_xmu = torch.split(combined, num_channels)

                if weight is not None and weight.dtype != mean.dtype:
                    weight = weight.to(mean.dtype)
                grad_input = torch.batch_norm_backward_elemt(
                    grad_output,
                    saved_input,
                    mean,
                    invstd,
                    weight,
                    sum_dy,
                    sum_dy_xmu,
                    count_tensor
                )
            if weight is None or not self.needs_input_grad[1]:
                grad_weight = None

            if weight is None or not self.needs_input_grad[2]:
                grad_bias = None
        else:
            num_channels = saved_input.shape[1]
            if self.needs_input_grad[0]:
                combined = torch.zeros(
                    2 * num_channels,
                    dtype=saved_input.dtype,
                    device=saved_input.device
                )
                torch.distributed.all_reduce(
                    combined, torch.distributed.ReduceOp.SUM, process_group, async_op=False)


        return grad_input, grad_weight, grad_bias, None, None, None, None, None, None

class CrossMapLRN2d(Function):

    @staticmethod
    def forward(ctx, input, size, alpha=1e-4, beta=0.75, k=1):
        ctx.size = size
        ctx.alpha = alpha
        ctx.beta = beta
        ctx.k = k
        ctx.scale = None

        if input.dim() != 4:
            raise ValueError(f"CrossMapLRN2d: Expected input to be 4D, got {input.dim()}D instead.")

        ctx.scale = ctx.scale or input.new()
        output = input.new()

        batch_size = input.size(0)
        channels = input.size(1)
        input_height = input.size(2)
        input_width = input.size(3)

        output.resize_as_(input)
        ctx.scale.resize_as_(input)

        input_square = output
        torch.pow(input, 2, out=input_square)

        pre_pad = int((ctx.size - 1) / 2 + 1)
        pre_pad_crop = min(pre_pad, channels)

        scale_first = ctx.scale.select(1, 0)
        scale_first.zero_()
        for c in range(pre_pad_crop):
            scale_first.add_(input_square.select(1, c))

        for c in range(1, channels):
            scale_previous = ctx.scale.select(1, c - 1)
            scale_current = ctx.scale.select(1, c)
            scale_current.copy_(scale_previous)
            if c < channels - pre_pad + 1:
                square_next = input_square.select(1, c + pre_pad - 1)
                scale_current.add_(square_next, alpha=1)

            if c > pre_pad:
                square_previous = input_square.select(1, c - pre_pad)
                scale_current.add_(square_previous, alpha=-1)

        ctx.scale.mul_(ctx.alpha / ctx.size).add_(ctx.k)

        torch.pow(ctx.scale, -ctx.beta, out=output)
        output.mul_(input)

        ctx.save_for_backward(input, output)
        return output

    @staticmethod
    def backward(ctx, grad_output):
        input, output = ctx.saved_tensors
        grad_input = grad_output.new()

        batch_size = input.size(0)
        channels = input.size(1)
        input_height = input.size(2)
        input_width = input.size(3)

        paddded_ratio = input.new(channels + ctx.size - 1, input_height,
                                  input_width)
        accum_ratio = input.new(input_height, input_width)

        cache_ratio_value = 2 * ctx.alpha * ctx.beta / ctx.size
        inversePrePad = int(ctx.size - (ctx.size - 1) / 2)

        grad_input.resize_as_(input)
        torch.pow(ctx.scale, -ctx.beta, out=grad_input).mul_(grad_output)

        paddded_ratio.zero_()
        padded_ratio_center = paddded_ratio.narrow(0, inversePrePad,
                                                   channels)
        for n in range(batch_size):
            torch.mul(grad_output[n], output[n], out=padded_ratio_center)
            padded_ratio_center.div_(ctx.scale[n])
            torch.sum(
                paddded_ratio.narrow(0, 0, ctx.size - 1), 0, keepdim=False, out=accum_ratio)
            for c in range(channels):
                accum_ratio.add_(paddded_ratio[c + ctx.size - 1])
                grad_input[n][c].addcmul_(input[n][c], accum_ratio, value=-cache_ratio_value)
                accum_ratio.add_(paddded_ratio[c], alpha=-1)

        return grad_input, None, None, None, None

class BackwardHookFunction(torch.autograd.Function):
    @staticmethod
    def forward(ctx, *args):
        ctx.mark_non_differentiable(*[arg for arg in args if not arg.requires_grad])
        return args

    @staticmethod
    def backward(ctx, *args):
        return args

<END>

<START>


class _BaseDatasetFetcher:
    def __init__(self, dataset, auto_collation, collate_fn, drop_last):
        self.dataset = dataset
        self.auto_collation = auto_collation
        self.collate_fn = collate_fn
        self.drop_last = drop_last

    def fetch(self, possibly_batched_index):
        raise NotImplementedError()


class _IterableDatasetFetcher(_BaseDatasetFetcher):
    def __init__(self, dataset, auto_collation, collate_fn, drop_last):
        super().__init__(dataset, auto_collation, collate_fn, drop_last)
        self.dataset_iter = iter(dataset)
        self.ended = False

    def fetch(self, possibly_batched_index):
        if self.ended:
            raise StopIteration

        if self.auto_collation:
            data = []
            for _ in possibly_batched_index:
                try:
                    data.append(next(self.dataset_iter))
                except StopIteration:
                    self.ended = True
                    break
            if len(data) == 0 or (
                self.drop_last and len(data) < len(possibly_batched_index)
            ):
                raise StopIteration
        else:
            data = next(self.dataset_iter)
        return self.collate_fn(data)


class _MapDatasetFetcher(_BaseDatasetFetcher):
    def fetch(self, possibly_batched_index):
        if self.auto_collation:
            if hasattr(self.dataset, "__getitems__") and self.dataset.__getitems__:
                data = self.dataset.__getitems__(possibly_batched_index)
            else:
                data = [self.dataset[idx] for idx in possibly_batched_index]
        else:
            data = self.dataset[possibly_batched_index]
        return self.collate_fn(data)

<END>

<START>
import torch
from ._common_operator_config_utils import (
    _get_binary_op_configs,
    _get_bn_configs,
    _get_cat_config,
    _get_conv_configs,
    _get_default_op_configs,
    _get_embedding_op_configs,
    _get_fixed_qparams_op_configs,
    _get_linear_configs,
    _get_ln_configs,
    _get_rnn_op_configs,
    _get_share_qparams_op_configs,
    _get_tensor_info_op_configs,
)
from .backend_config import BackendConfig, DTypeConfig

__all__ = [
    "get_test_only_legacy_native_backend_config",
    "default_op_quint8_dtype_config",
    "default_op_fp16_dtype_config",
    "default_dynamic_int8_dtype_config",
    "default_dynamic_float16_dtype_config",
    "input_output_only_quint8_dtype_config",
    "weight_only_quint8_dtype_config",
    "weight_only_quint4x2_dtype_config",
    "get_native_backend_config",
    "get_native_backend_config_dict",
    "get_test_only_legacy_native_backend_config_dict",
]


weighted_op_quint8_dtype_config = DTypeConfig(
    input_dtype=torch.quint8,
    output_dtype=torch.quint8,
    weight_dtype=torch.qint8,
    bias_dtype=torch.float,
)

default_op_quint8_dtype_config = DTypeConfig(
    input_dtype=torch.quint8,
    output_dtype=torch.quint8,
)

default_op_fp16_dtype_config = DTypeConfig(
    input_dtype=torch.float16,
    output_dtype=torch.float16,
    weight_dtype=torch.float16,
    bias_dtype=torch.float16,
)

default_dynamic_int8_dtype_config = DTypeConfig(
    input_dtype=torch.quint8,
    output_dtype=torch.float,
    weight_dtype=torch.qint8,
    bias_dtype=torch.float,
    is_dynamic=True,
)

default_dynamic_float16_dtype_config = DTypeConfig(
    input_dtype=torch.float16,
    output_dtype=torch.float,
    weight_dtype=torch.float16,
    bias_dtype=torch.float,
    is_dynamic=True,
)

input_output_only_quint8_dtype_config = DTypeConfig(
    input_dtype=torch.quint8,
    output_dtype=torch.quint8,
    weight_dtype=torch.float,
    bias_dtype=torch.float,
)

weight_only_quint8_dtype_config = DTypeConfig(
    input_dtype=torch.float,
    output_dtype=torch.float,
    weight_dtype=torch.quint8,
)

weight_only_quint4x2_dtype_config = DTypeConfig(
    input_dtype=torch.float,
    output_dtype=torch.float,
    weight_dtype=torch.quint4x2,
)



def get_test_only_legacy_native_backend_config() -> BackendConfig:
    conv_dtype_configs = [weighted_op_quint8_dtype_config]
    linear_dtype_configs = [
        weighted_op_quint8_dtype_config,
        default_dynamic_int8_dtype_config,
        default_dynamic_float16_dtype_config,
        default_op_fp16_dtype_config,
    ]
    binary_op_dtype_configs = [
        default_op_quint8_dtype_config,
        default_op_fp16_dtype_config,
    ]
    default_op_dtype_configs = [default_op_quint8_dtype_config]
    fixed_qparams_op_dtype_configs = [
        default_op_quint8_dtype_config,
        default_op_fp16_dtype_config,
    ]
    share_qparams_op_dtype_configs = [
        default_op_quint8_dtype_config,
        default_op_fp16_dtype_config
    ]
    tensor_info_op_dtype_configs = [
        default_op_quint8_dtype_config,
    ]
    rnn_op_dtype_configs = [
        default_dynamic_int8_dtype_config,
        default_dynamic_float16_dtype_config,
    ]
    embedding_op_dtype_configs = [
        weight_only_quint8_dtype_config,
        weight_only_quint4x2_dtype_config,
    ]
    layer_norm_op_dtype_configs = [input_output_only_quint8_dtype_config]
    return BackendConfig("_native_and_fp16") \
        .set_backend_pattern_configs(_get_conv_configs(conv_dtype_configs)) \
        .set_backend_pattern_configs(_get_linear_configs(linear_dtype_configs)) \
        .set_backend_pattern_configs(_get_binary_op_configs(binary_op_dtype_configs)) \
        .set_backend_pattern_config(_get_cat_config(default_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_default_op_configs(default_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_fixed_qparams_op_configs(fixed_qparams_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_share_qparams_op_configs(share_qparams_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_tensor_info_op_configs(tensor_info_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_bn_configs(default_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_ln_configs(layer_norm_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_rnn_op_configs(rnn_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_embedding_op_configs(embedding_op_dtype_configs))

def get_native_backend_config() -> BackendConfig:
    conv_dtype_configs = [weighted_op_quint8_dtype_config]
    linear_dtype_configs = [
        weighted_op_quint8_dtype_config,
        default_dynamic_int8_dtype_config,
        default_dynamic_float16_dtype_config,
    ]
    binary_op_dtype_configs = [default_op_quint8_dtype_config]
    default_op_dtype_configs = [default_op_quint8_dtype_config]
    fixed_qparams_op_dtype_configs = [default_op_quint8_dtype_config]
    share_qparams_op_dtype_configs = [default_op_quint8_dtype_config]
    tensor_info_op_dtype_configs = [default_op_quint8_dtype_config]
    rnn_op_dtype_configs = [
        default_dynamic_int8_dtype_config,
        default_dynamic_float16_dtype_config,
    ]
    embedding_op_dtype_configs = [
        weight_only_quint8_dtype_config,
        weight_only_quint4x2_dtype_config,
    ]
    layer_norm_op_dtype_configs = [input_output_only_quint8_dtype_config]
    return BackendConfig("native") \
        .set_backend_pattern_configs(_get_conv_configs(conv_dtype_configs)) \
        .set_backend_pattern_configs(_get_linear_configs(linear_dtype_configs)) \
        .set_backend_pattern_configs(_get_binary_op_configs(binary_op_dtype_configs)) \
        .set_backend_pattern_config(_get_cat_config(default_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_default_op_configs(default_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_fixed_qparams_op_configs(fixed_qparams_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_share_qparams_op_configs(share_qparams_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_tensor_info_op_configs(tensor_info_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_bn_configs(default_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_ln_configs(layer_norm_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_rnn_op_configs(rnn_op_dtype_configs)) \
        .set_backend_pattern_configs(_get_embedding_op_configs(embedding_op_dtype_configs))

def get_native_backend_config_dict():
    return get_native_backend_config().to_dict()

def get_test_only_legacy_native_backend_config_dict():
    return get_test_only_legacy_native_backend_config().to_dict()

<END>

<START>
import _compat_pickle
import pickle

from .importer import Importer


class PackageUnpickler(pickle._Unpickler):  # type: ignore[name-defined]

    def __init__(self, importer: Importer, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._importer = importer

    def find_class(self, module, name):
        if self.proto < 3 and self.fix_imports:  # type: ignore[attr-defined]
            if (module, name) in _compat_pickle.NAME_MAPPING:
                module, name = _compat_pickle.NAME_MAPPING[(module, name)]
            elif module in _compat_pickle.IMPORT_MAPPING:
                module = _compat_pickle.IMPORT_MAPPING[module]
        mod = self._importer.import_module(module)
        return getattr(mod, name)

<END>

<START>
import contextlib

INTERMEDIATE_HOOKS = []


@contextlib.contextmanager
def intermediate_hook(fn):
    INTERMEDIATE_HOOKS.append(fn)
    try:
        yield
    finally:
        INTERMEDIATE_HOOKS.pop()


def run_intermediate_hooks(name, val):
    global INTERMEDIATE_HOOKS
    hooks = INTERMEDIATE_HOOKS
    INTERMEDIATE_HOOKS = []
    try:
        for hook in hooks:
            hook(name, val)
    finally:
        INTERMEDIATE_HOOKS = hooks

<END>

<START>
import warnings

from typing import List, Optional, Tuple

import torch
from torch import _VF, Tensor  # noqa: F401
from torch.nn.utils.rnn import PackedSequence


class QuantizedLinear(torch.jit.ScriptModule):
    __constants__ = ["scale", "zero_point"]

    def __init__(self, other):
        super().__init__()
        warnings.warn(
            "torch.jit.QuantizedLinear is deprecated and will be removed in an upcoming "
            "PyTorch release. Please use the torch.ao.nn.quantized.dynamic.Linear instead."
        )

        self.in_features = other.in_features
        self.out_features = other.out_features
        (
            self.weight,
            self.col_offsets,
            self.scale,
            self.zero_point,
        ) = torch.fbgemm_linear_quantize_weight(
            other.weight.clone(memory_format=torch.contiguous_format).float()
        )
        self.weight = torch.nn.Parameter(self.weight, requires_grad=False)
        self.col_offsets = torch.nn.Parameter(self.col_offsets, requires_grad=False)
        assert other.bias is not None, "QuantizedLinear requires a bias"
        self.bias = torch.nn.Parameter(
            other.bias.clone(memory_format=torch.contiguous_format).float(),
            requires_grad=False,
        )

        self.register_buffer(
            "packed_tensor_ptr",
            torch.fbgemm_pack_quantized_matrix(
                self.weight.clone(memory_format=torch.contiguous_format)
            ),
        )

    @torch.jit.script_method
    def _unpack(self):
        self.packed_tensor_ptr.set_(torch.fbgemm_pack_quantized_matrix(self.weight))

    @torch.jit.script_method
    def _pack(self):
        self.packed_tensor_ptr.set_(
            torch.zeros(torch.jit.annotate(List[int], []), dtype=torch.uint8).detach()
        )

    @torch.jit.script_method
    def forward(self, input):
        out = torch.fbgemm_linear_int8_weight_fp32_activation(
            input.float(),
            self.weight,
            self.packed_tensor_ptr,
            self.col_offsets,
            self.scale,
            self.zero_point,
            self.bias,
        )
        return out.to(input.dtype)

    def extra_repr(self):
        repr = (
            "in_features={in_features}, out_features={out_features}, "
            "scale={scale}, zero_point={zero_point}".format(**self.__dict__)
        )
        return repr


class QuantizedLinearFP16(torch.jit.ScriptModule):
    def __init__(self, other):
        super().__init__()
        warnings.warn(
            "torch.jit.QuantizedLinearFP16 is deprecated and will be removed in an upcoming "
            "PyTorch release. Please use the torch.ao.nn.quantized.dynamic.Linear instead."
        )
        self.in_features = other.in_features
        self.out_features = other.out_features
        self.original_weight = other.weight
        self.weight = torch.fbgemm_pack_gemm_matrix_fp16(
            other.weight.clone(memory_format=torch.contiguous_format).float()
        )
        assert other.bias is not None, "QuantizedLinearFP16 requires a bias"
        self.bias = torch.nn.Parameter(
            other.bias.clone(memory_format=torch.contiguous_format).float(),
            requires_grad=False,
        )
        self.register_buffer("packed_weight", self.weight)

    @torch.jit.script_method
    def _unpack(self):
        self.packed_weight.set_(
            torch.fbgemm_pack_gemm_matrix_fp16(self.original_weight)
        )

    @torch.jit.script_method
    def _pack(self):
        self.packed_weight.set_(
            torch.zeros(torch.jit.annotate(List[int], []), dtype=torch.uint8).detach()
        )

    @torch.jit.script_method
    def forward(self, input):
        out = torch.fbgemm_linear_fp16_weight_fp32_activation(
            input.float(), self.packed_weight, self.bias
        )
        return out

    def extra_repr(self):
        repr = "in_features={in_features}, out_features={out_features}, ".format(
            **self.__dict__
        )
        return repr


class QuantizedRNNCellBase(torch.jit.ScriptModule):
    __constants__ = [
        "input_size",
        "hidden_size",
        "bias",
        "scale_hh",
        "scale_ih",
        "zero_point_ih",
        "zero_point_hh",
    ]

    def __init__(self, other):
        super().__init__()
        warnings.warn(
            "torch.jit.QuantizedRNNCellBase is deprecated and will be removed in an upcoming "
            "PyTorch release. Please use the torch.ao.nn.quantized.dynamic.RNNCell instead."
        )

        self.input_size = other.input_size
        self.hidden_size = other.hidden_size
        self.bias = other.bias
        if not self.bias:
            raise ValueError("Quantized RNN cells require bias terms")

        (
            weight_ih,
            col_offsets_ih,
            self.scale_ih,
            self.zero_point_ih,
        ) = torch.fbgemm_linear_quantize_weight(
            other.weight_ih.clone(memory_format=torch.contiguous_format).float()
        )
        self.register_buffer("weight_ih", weight_ih)
        self.register_buffer("col_offsets_ih", col_offsets_ih)
        (
            weight_hh,
            col_offsets_hh,
            self.scale_hh,
            self.zero_point_hh,
        ) = torch.fbgemm_linear_quantize_weight(
            other.weight_hh.clone(memory_format=torch.contiguous_format).float()
        )
        self.register_buffer("weight_hh", weight_hh)
        self.register_buffer("col_offsets_hh", col_offsets_hh)

        packed_ih = torch.fbgemm_pack_quantized_matrix(self.weight_ih)
        self.register_buffer("packed_ih", packed_ih)
        packed_hh = torch.fbgemm_pack_quantized_matrix(self.weight_hh)
        self.register_buffer("packed_hh", packed_hh)

        self.bias_ih = torch.nn.Parameter(
            other.bias_ih.clone(memory_format=torch.contiguous_format).float(),
            requires_grad=False,
        )
        self.bias_hh = torch.nn.Parameter(
            other.bias_hh.clone(memory_format=torch.contiguous_format).float(),
            requires_grad=False,
        )

    def extra_repr(self):
        s = "{input_size}, {hidden_size}"
        if "bias" in self.__dict__ and self.bias is not True:
            s += ", bias={bias}"
        if "nonlinearity" in self.__dict__ and self.nonlinearity != "tanh":
            s += ", nonlinearity={nonlinearity}"
        return s.format(**self.__dict__)

    @torch.jit.script_method
    def check_forward_input(self, input):
        if input.size(1) != self.input_size:
            raise RuntimeError(
                f"input has inconsistent input_size: got {input.size(1)}, expected {self.input_size}"
            )

    @torch.jit.script_method
    def check_forward_hidden(
        self, input: Tensor, hx: Tensor, hidden_label: str = ""
    ) -> None:
        if input.size(0) != hx.size(0):
            raise RuntimeError(
                f"Input batch size {input.size(0)} doesn't match hidden{hidden_label} batch size {hx.size(0)}"
            )

        if hx.size(1) != self.hidden_size:
            raise RuntimeError(
                f"hidden{hidden_label} has inconsistent hidden_size: got {hx.size(1)}, expected {self.hidden_size}"
            )

    @torch.jit.script_method
    def _unpack(self):
        self.packed_ih.set_(torch.fbgemm_pack_quantized_matrix(self.weight_ih))
        self.packed_hh.set_(torch.fbgemm_pack_quantized_matrix(self.weight_hh))

    @torch.jit.script_method
    def _pack(self):
        self.packed_ih.set_(
            torch.zeros(torch.jit.annotate(List[int], []), dtype=torch.uint8).detach()
        )
        self.packed_hh.set_(
            torch.zeros(torch.jit.annotate(List[int], []), dtype=torch.uint8).detach()
        )


class QuantizedRNNCell(QuantizedRNNCellBase):
    __constants__ = [
        "input_size",
        "hidden_size",
        "bias",
        "scale_hh",
        "scale_ih",
        "zero_point_ih",
        "zero_point_hh",
        "nonlinearity",
    ]

    def __init__(self, other):
        super().__init__(other)
        warnings.warn(
            "torch.jit.QuantizedRNNCell is deprecated and will be removed in an upcoming "
            "PyTorch release. Please use the torch.ao.nn.quantized.dynamic.RNNCell instead."
        )
        self.nonlinearity = other.nonlinearity

    @torch.jit.script_method
    def forward(self, input: Tensor, hx: Optional[Tensor] = None) -> Tensor:
        self.check_forward_input(input)
        if hx is None:
            hx = torch.zeros(
                input.size(0), self.hidden_size, dtype=input.dtype, device=input.device
            )
        self.check_forward_hidden(input, hx, "")
        if self.nonlinearity == "tanh":
            ret = _VF.quantized_rnn_tanh_cell(
                input,
                hx,
                self.weight_ih,
                self.weight_hh,
                self.bias_ih,
                self.bias_hh,
                self.packed_ih,
                self.packed_hh,
                self.col_offsets_ih,
                self.col_offsets_hh,
                self.scale_ih,
                self.scale_hh,
                self.zero_point_ih,
                self.zero_point_hh,
            )
        elif self.nonlinearity == "relu":
            ret = _VF.quantized_rnn_relu_cell(
                input,
                hx,
                self.weight_ih,
                self.weight_hh,
                self.bias_ih,
                self.bias_hh,
                self.packed_ih,
                self.packed_hh,
                self.col_offsets_ih,
                self.col_offsets_hh,
                self.scale_ih,
                self.scale_hh,
                self.zero_point_ih,
                self.zero_point_hh,
            )
        else:
            ret = input  # TODO: remove when jit supports exception flow
            raise RuntimeError(f"Unknown nonlinearity: {self.nonlinearity}")
        return ret


class QuantizedLSTMCell(QuantizedRNNCellBase):
    def __init__(self, other):
        super().__init__(other)
        warnings.warn(
            "torch.jit.QuantizedLSTMCell is deprecated and will be removed in an upcoming "
            "PyTorch release. Please use the torch.ao.nn.quantized.dynamic.LSTMCell instead."
        )

    @torch.jit.script_method
    def forward(
        self, input: Tensor, hx: Optional[Tuple[Tensor, Tensor]] = None
    ) -> Tuple[Tensor, Tensor]:
        self.check_forward_input(input)
        if hx is None:
            zeros = torch.zeros(
                input.size(0), self.hidden_size, dtype=input.dtype, device=input.device
            )
            hx = (zeros, zeros)
        self.check_forward_hidden(input, hx[0], "[0]")
        self.check_forward_hidden(input, hx[1], "[1]")
        return _VF.quantized_lstm_cell(
            input,
            hx,
            self.weight_ih,
            self.weight_hh,
            self.bias_ih,
            self.bias_hh,
            self.packed_ih,
            self.packed_hh,
            self.col_offsets_ih,
            self.col_offsets_hh,
            self.scale_ih,
            self.scale_hh,
            self.zero_point_ih,
            self.zero_point_hh,
        )


class QuantizedGRUCell(QuantizedRNNCellBase):
    def __init__(self, other):
        super().__init__(other)
        warnings.warn(
            "torch.jit.QuantizedGRUCell is deprecated and will be removed in an upcoming "
            "PyTorch release. Please use the torch.ao.nn.quantized.dynamic.GRUCell instead."
        )

    @torch.jit.script_method
    def forward(self, input: Tensor, hx: Optional[Tensor] = None) -> Tensor:
        self.check_forward_input(input)
        if hx is None:
            hx = torch.zeros(
                input.size(0), self.hidden_size, dtype=input.dtype, device=input.device
            )
        self.check_forward_hidden(input, hx, "")
        return _VF.quantized_gru_cell(
            input,
            hx,
            self.weight_ih,
            self.weight_hh,
            self.bias_ih,
            self.bias_hh,
            self.packed_ih,
            self.packed_hh,
            self.col_offsets_ih,
            self.col_offsets_hh,
            self.scale_ih,
            self.scale_hh,
            self.zero_point_ih,
            self.zero_point_hh,
        )


def apply_permutation(tensor: Tensor, permutation: Tensor, dim: int = 1) -> Tensor:
    return tensor.index_select(dim, permutation)


class QuantizedRNNBase(torch.jit.ScriptModule):
    __constants__ = [
        "mode",
        "input_size",
        "hidden_size",
        "num_layers",
        "bias",
        "batch_first",
        "dropout",
        "bidirectional",
        "dtype",
    ]

    def __init__(self, other, dtype=torch.int8):
        super().__init__()
        warnings.warn(
            "torch.jit.QuantizedRNNBase is deprecated and will be removed in an upcoming "
            "PyTorch release. Please use the torch.ao.nn.quantized.dynamic instead."
        )
        self.mode = other.mode
        self.input_size = other.input_size
        self.hidden_size = other.hidden_size
        self.num_layers = other.num_layers
        self.bias = other.bias
        self.batch_first = other.batch_first
        if self.mode != "GRU":
            assert not self.batch_first
        self.dropout = other.dropout
        self.bidirectional = other.bidirectional
        num_directions = 2 if self.bidirectional else 1
        self.dtype = dtype

        assert self.bias

        if self.mode != "LSTM" and self.mode != "GRU":
            raise RuntimeError("Only LSTM or GRU is supported for QuantizedRNN")

        if dtype != torch.int8 and dtype != torch.float16:
            raise RuntimeError(f"Unsupported dtype: {dtype}")

        self.all_weights = []
        for layer in range(self.num_layers):
            for direction in range(num_directions):
                layer_input_size = (
                    self.input_size if layer == 0 else self.hidden_size * num_directions
                )

                suffix = "_reverse" if direction == 1 else ""

                def get_weight_bias(ihhh):
                    weight_name = f"weight_{ihhh}_l{layer}{suffix}"
                    bias_name = f"bias_{ihhh}_l{layer}{suffix}"

                    weight = getattr(other, weight_name)
                    bias = getattr(other, bias_name)
                    return weight, bias

                weight_ih, bias_ih = get_weight_bias("ih")
                weight_hh, bias_hh = get_weight_bias("hh")

                if dtype == torch.int8:
                    cell_params = torch.ops.quantized.make_quantized_cell_params(
                        weight_ih, weight_hh, bias_ih, bias_hh
                    )
                else:
                    packed_ih = torch.ops.quantized.linear_prepack_fp16(
                        weight_ih.float(), bias_ih
                    )
                    packed_hh = torch.ops.quantized.linear_prepack_fp16(
                        weight_hh.float(), bias_hh
                    )

                    cell_params = torch.ops.quantized.make_quantized_cell_params_fp16(
                        packed_ih, packed_hh
                    )

                setattr(self, f"cell_params_{layer}_{suffix}", cell_params)
                self.all_weights.append(cell_params)

    @torch.jit.script_method
    def check_input(self, input: Tensor, batch_sizes: Optional[Tensor]) -> None:
        expected_input_dim = 2 if batch_sizes is not None else 3
        if input.dim() != expected_input_dim:
            raise RuntimeError(
                f"input must have {expected_input_dim} dimensions, got {input.dim()}"
            )
        if self.input_size != input.size(-1):
            raise RuntimeError(
                f"input.size(-1) must be equal to input_size. Expected {self.input_size}, got {input.size(-1)}"
            )

    @torch.jit.script_method
    def get_expected_hidden_size(
        self, input: Tensor, batch_sizes: Optional[Tensor]
    ) -> Tuple[int, int, int]:
        if batch_sizes is not None:
            mini_batch = int(batch_sizes[0])
        else:
            mini_batch = input.size(0) if self.batch_first else input.size(1)
        num_directions = 2 if self.bidirectional else 1
        expected_hidden_size = (
            self.num_layers * num_directions,
            mini_batch,
            self.hidden_size,
        )
        return expected_hidden_size

    @torch.jit.script_method
    def check_hidden_size(
        self,
        hx: Tensor,
        expected_hidden_size: Tuple[int, int, int],
        msg: str = "Expected hidden size {}, got {}",
    ) -> None:
        if hx.size() != expected_hidden_size:
            raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))

    @torch.jit.script_method
    def check_forward_args(
        self, input: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]
    ) -> None:
        self.check_input(input, batch_sizes)
        expected_hidden_size = self.get_expected_hidden_size(input, batch_sizes)
        self.check_hidden_size(
            hidden, expected_hidden_size, msg="Expected hidden size {}, got {}"
        )

    @torch.jit.script_method
    def permute_hidden(self, hx: Tensor, permutation: Optional[Tensor]) -> Tensor:
        if permutation is None:
            return hx
        return apply_permutation(hx, permutation)


class QuantizedLSTM(QuantizedRNNBase):
    __overloads__ = {"forward": ["forward_packed", "forward_tensor"]}

    def __init__(self, other, dtype):
        super().__init__(other, dtype)
        warnings.warn(
            "torch.jit.QuantizedLSTM is deprecated and will be removed in an upcoming "
            "PyTorch release. Please use the torch.ao.nn.quantized.dynamic.LSTM instead."
        )

    @torch.jit.script_method
    def forward_impl(
        self,
        input: Tensor,
        hx: Optional[Tuple[Tensor, Tensor]],
        batch_sizes: Optional[Tensor],
        max_batch_size: int,
        sorted_indices: Optional[Tensor],
    ) -> Tuple[Tensor, Tuple[Tensor, Tensor]]:
        if hx is None:
            num_directions = 2 if self.bidirectional else 1
            zeros = torch.zeros(
                self.num_layers * num_directions,
                max_batch_size,
                self.hidden_size,
                dtype=input.dtype,
                device=input.device,
            )
            hx = (zeros, zeros)
        else:
            hx = self.permute_hidden(hx, sorted_indices)

        self.check_forward_args(input, hx, batch_sizes)
        assert batch_sizes is None
        result = torch.quantized_lstm(
            input,
            hx,
            self.all_weights,
            self.bias,
            self.num_layers,
            float(self.dropout),
            self.training,
            self.bidirectional,
            self.batch_first,
            dtype=self.dtype,
            use_dynamic=False,
        )
        output = result[0]
        hidden = result[1:]

        return output, hidden

    @torch.jit.script_method
    def forward_tensor(
        self, input: Tensor, hx: Optional[Tuple[Tensor, Tensor]] = None
    ) -> Tuple[Tensor, Tuple[Tensor, Tensor]]:
        batch_sizes = None
        max_batch_size = input.size(0) if self.batch_first else input.size(1)
        sorted_indices = None
        unsorted_indices = None

        output, hidden = self.forward_impl(
            input, hx, batch_sizes, max_batch_size, sorted_indices
        )

        return output, self.permute_hidden(hidden, unsorted_indices)

    @torch.jit.script_method
    def forward_packed(
        self, input: PackedSequence, hx: Optional[Tuple[Tensor, Tensor]] = None
    ) -> Tuple[PackedSequence, Tuple[Tensor, Tensor]]:
        input_, batch_sizes, sorted_indices, unsorted_indices = input
        max_batch_size = int(batch_sizes[0])

        output, hidden = self.forward_impl(
            input_, hx, batch_sizes, max_batch_size, sorted_indices
        )

        output = PackedSequence(output, batch_sizes, sorted_indices, unsorted_indices)
        return output, self.permute_hidden(hidden, unsorted_indices)

    @torch.jit.script_method
    def permute_hidden(
        self, hx: Tuple[Tensor, Tensor], permutation: Optional[Tensor]
    ) -> Tuple[Tensor, Tensor]:
        if permutation is None:
            return hx
        return apply_permutation(hx[0], permutation), apply_permutation(
            hx[1], permutation
        )

    @torch.jit.script_method
    def check_forward_args(
        self,
        input: Tensor,
        hidden: Tuple[Tensor, Tensor],
        batch_sizes: Optional[Tensor],
    ) -> None:
        self.check_input(input, batch_sizes)
        expected_hidden_size = self.get_expected_hidden_size(input, batch_sizes)

        self.check_hidden_size(
            hidden[0], expected_hidden_size, "Expected hidden[0] size {}, got {}"
        )
        self.check_hidden_size(
            hidden[1], expected_hidden_size, "Expected hidden[1] size {}, got {}"
        )

    def forward(self, input, hx=None):
        if isinstance(input, PackedSequence):
            return self.forward_packed(input, hx)
        else:
            return self.forward_tensor(input, hx)


class QuantizedGRU(QuantizedRNNBase):
    __overloads__ = {"forward": ["forward_packed", "forward_tensor"]}

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        warnings.warn(
            "torch.jit.QuantizedGRU is deprecated and will be removed in an upcoming "
            "PyTorch release. Please use the torch.ao.nn.quantized.dynamic.GRU instead."
        )

    @torch.jit.script_method
    def forward_impl(
        self,
        input: Tensor,
        hx: Optional[Tensor],
        batch_sizes: Optional[Tensor],
        max_batch_size: int,
        sorted_indices: Optional[Tensor],
    ) -> Tuple[Tensor, Tensor]:
        if hx is None:
            num_directions = 2 if self.bidirectional else 1
            hx = torch.zeros(
                self.num_layers * num_directions,
                max_batch_size,
                self.hidden_size,
                dtype=input.dtype,
                device=input.device,
            )
        else:
            hx = self.permute_hidden(hx, sorted_indices)

        self.check_forward_args(input, hx, batch_sizes)
        if batch_sizes is None:
            result = torch.quantized_gru(
                input,
                hx,
                self.all_weights,
                self.bias,
                self.num_layers,
                float(self.dropout),
                self.training,
                self.bidirectional,
                self.batch_first,
            )
        else:
            result = torch.quantized_gru(
                input,
                batch_sizes,
                hx,
                self.all_weights,
                self.bias,
                self.num_layers,
                float(self.dropout),
                self.training,
                self.bidirectional,
            )

        output = result[0]
        hidden = result[1]

        return output, hidden

    @torch.jit.script_method
    def forward_tensor(
        self, input: Tensor, hx: Optional[Tensor] = None
    ) -> Tuple[Tensor, Tensor]:
        batch_sizes = None
        max_batch_size = input.size(0) if self.batch_first else input.size(1)
        sorted_indices = None
        unsorted_indices = None

        output, hidden = self.forward_impl(
            input, hx, batch_sizes, max_batch_size, sorted_indices
        )
        return output, self.permute_hidden(hidden, unsorted_indices)

    @torch.jit.script_method
    def forward_packed(
        self, input: PackedSequence, hx: Optional[Tensor] = None
    ) -> Tuple[PackedSequence, Tensor]:
        input_, batch_sizes, sorted_indices, unsorted_indices = input
        max_batch_size = int(batch_sizes[0])

        output, hidden = self.forward_impl(
            input_, hx, batch_sizes, max_batch_size, sorted_indices
        )

        output = PackedSequence(output, batch_sizes, sorted_indices, unsorted_indices)
        return output, self.permute_hidden(hidden, unsorted_indices)

    def forward(self, input, hx=None):
        if isinstance(input, PackedSequence):
            return self.forward_packed(input, hx)
        else:
            return self.forward_tensor(input, hx)


def quantize_rnn_cell_modules(module):
    warnings.warn(
        "quantize_rnn_cell_modules function has been deprecated. "
        "Please use torch.ao.quantization.quantize_dynamic API instead."
    )
    reassign = {}
    for name, mod in module.named_modules():
        if mod is module:
            continue
        new_mod = quantize_rnn_cell_modules(mod)
        if new_mod is not mod:
            reassign[name] = new_mod
    for name, mod in reassign.items():
        setattr(module, name, mod)
    if isinstance(module, torch.nn.LSTMCell):
        return QuantizedLSTMCell(module)
    if isinstance(module, torch.nn.GRUCell):
        return QuantizedGRUCell(module)
    if isinstance(module, torch.nn.RNNCell):
        return QuantizedRNNCell(module)
    return module


def quantize_linear_modules(module, dtype=torch.int8):
    warnings.warn(
        "quantize_linear_modules function has been deprecated. "
        "Please use torch.ao.quantization.quantize_dynamic API instead."
    )

    reassign = {}
    for name, mod in module.named_modules():
        if mod is module:
            continue
        new_mod = quantize_linear_modules(mod, dtype)
        if new_mod is not mod:
            reassign[name] = new_mod

    for name, mod in reassign.items():
        setattr(module, name, mod)
    if isinstance(module, torch.nn.Linear):
        if dtype == torch.int8:
            return QuantizedLinear(module)
        elif dtype == torch.float16:
            return QuantizedLinearFP16(module)
        else:
            raise RuntimeError(f"Unsupported dtype: {dtype}")
    return module


def quantize_rnn_modules(module, dtype=torch.int8):
    warnings.warn(
        "quantize_rnn_modules function has been deprecated. "
        "Please use torch.ao.quantization.quantize_dynamic API instead."
    )
    reassign = {}
    for name, mod in module.named_modules():
        if mod is module:
            continue
        new_mod = quantize_rnn_modules(mod, dtype)
        if new_mod is not mod:
            reassign[name] = new_mod

    for name, mod in reassign.items():
        setattr(module, name, mod)
    if isinstance(module, torch.nn.LSTM):
        if dtype != torch.int8 and dtype != torch.float16:
            raise RuntimeError(f"Unsupported dtype: {dtype}")
        return QuantizedLSTM(module, dtype)
    if isinstance(module, torch.nn.GRU):
        return QuantizedGRU(module)
    return module

<END>

<START>
import math
from numbers import Number, Real

import torch
from torch.distributions import constraints
from torch.distributions.exp_family import ExponentialFamily
from torch.distributions.utils import _standard_normal, broadcast_all

__all__ = ["Normal"]


class Normal(ExponentialFamily):
    arg_constraints = {"loc": constraints.real, "scale": constraints.positive}
    support = constraints.real
    has_rsample = True
    _mean_carrier_measure = 0

    @property
    def mean(self):
        return self.loc

    @property
    def mode(self):
        return self.loc

    @property
    def stddev(self):
        return self.scale

    @property
    def variance(self):
        return self.stddev.pow(2)

    def __init__(self, loc, scale, validate_args=None):
        self.loc, self.scale = broadcast_all(loc, scale)
        if isinstance(loc, Number) and isinstance(scale, Number):
            batch_shape = torch.Size()
        else:
            batch_shape = self.loc.size()
        super().__init__(batch_shape, validate_args=validate_args)

    def expand(self, batch_shape, _instance=None):
        new = self._get_checked_instance(Normal, _instance)
        batch_shape = torch.Size(batch_shape)
        new.loc = self.loc.expand(batch_shape)
        new.scale = self.scale.expand(batch_shape)
        super(Normal, new).__init__(batch_shape, validate_args=False)
        new._validate_args = self._validate_args
        return new

    def sample(self, sample_shape=torch.Size()):
        shape = self._extended_shape(sample_shape)
        with torch.no_grad():
            return torch.normal(self.loc.expand(shape), self.scale.expand(shape))

    def rsample(self, sample_shape=torch.Size()):
        shape = self._extended_shape(sample_shape)
        eps = _standard_normal(shape, dtype=self.loc.dtype, device=self.loc.device)
        return self.loc + eps * self.scale

    def log_prob(self, value):
        if self._validate_args:
            self._validate_sample(value)
        var = self.scale**2
        log_scale = (
            math.log(self.scale) if isinstance(self.scale, Real) else self.scale.log()
        )
        return (
            -((value - self.loc) ** 2) / (2 * var)
            - log_scale
            - math.log(math.sqrt(2 * math.pi))
        )

    def cdf(self, value):
        if self._validate_args:
            self._validate_sample(value)
        return 0.5 * (
            1 + torch.erf((value - self.loc) * self.scale.reciprocal() / math.sqrt(2))
        )

    def icdf(self, value):
        return self.loc + self.scale * torch.erfinv(2 * value - 1) * math.sqrt(2)

    def entropy(self):
        return 0.5 + 0.5 * math.log(2 * math.pi) + torch.log(self.scale)

    @property
    def _natural_params(self):
        return (self.loc / self.scale.pow(2), -0.5 * self.scale.pow(2).reciprocal())

    def _log_normalizer(self, x, y):
        return -0.25 * x.pow(2) / y + 0.5 * torch.log(-math.pi / y)

<END>

<START>
from torch.distributed.device_mesh import (  # noqa: F401
    _get_device_handle,
    _mesh_resources,
    DeviceMesh,
    init_device_mesh,
)

<END>

<START>

import math

import torch
from torch.distributions import Beta, constraints
from torch.distributions.distribution import Distribution
from torch.distributions.utils import broadcast_all

__all__ = ["LKJCholesky"]


class LKJCholesky(Distribution):
    arg_constraints = {"concentration": constraints.positive}
    support = constraints.corr_cholesky

    def __init__(self, dim, concentration=1.0, validate_args=None):
        if dim < 2:
            raise ValueError(
                f"Expected dim to be an integer greater than or equal to 2. Found dim={dim}."
            )
        self.dim = dim
        (self.concentration,) = broadcast_all(concentration)
        batch_shape = self.concentration.size()
        event_shape = torch.Size((dim, dim))
        marginal_conc = self.concentration + 0.5 * (self.dim - 2)
        offset = torch.arange(
            self.dim - 1,
            dtype=self.concentration.dtype,
            device=self.concentration.device,
        )
        offset = torch.cat([offset.new_zeros((1,)), offset])
        beta_conc1 = offset + 0.5
        beta_conc0 = marginal_conc.unsqueeze(-1) - 0.5 * offset
        self._beta = Beta(beta_conc1, beta_conc0)
        super().__init__(batch_shape, event_shape, validate_args)

    def expand(self, batch_shape, _instance=None):
        new = self._get_checked_instance(LKJCholesky, _instance)
        batch_shape = torch.Size(batch_shape)
        new.dim = self.dim
        new.concentration = self.concentration.expand(batch_shape)
        new._beta = self._beta.expand(batch_shape + (self.dim,))
        super(LKJCholesky, new).__init__(
            batch_shape, self.event_shape, validate_args=False
        )
        new._validate_args = self._validate_args
        return new

    def sample(self, sample_shape=torch.Size()):
        y = self._beta.sample(sample_shape).unsqueeze(-1)
        u_normal = torch.randn(
            self._extended_shape(sample_shape), dtype=y.dtype, device=y.device
        ).tril(-1)
        u_hypersphere = u_normal / u_normal.norm(dim=-1, keepdim=True)
        u_hypersphere[..., 0, :].fill_(0.0)
        w = torch.sqrt(y) * u_hypersphere
        eps = torch.finfo(w.dtype).tiny
        diag_elems = torch.clamp(1 - torch.sum(w**2, dim=-1), min=eps).sqrt()
        w += torch.diag_embed(diag_elems)
        return w

    def log_prob(self, value):
        if self._validate_args:
            self._validate_sample(value)
        diag_elems = value.diagonal(dim1=-1, dim2=-2)[..., 1:]
        order = torch.arange(2, self.dim + 1, device=self.concentration.device)
        order = 2 * (self.concentration - 1).unsqueeze(-1) + self.dim - order
        unnormalized_log_pdf = torch.sum(order * diag_elems.log(), dim=-1)
        dm1 = self.dim - 1
        alpha = self.concentration + 0.5 * dm1
        denominator = torch.lgamma(alpha) * dm1
        numerator = torch.mvlgamma(alpha - 0.5, dm1)
        pi_constant = 0.5 * dm1 * math.log(math.pi)
        normalize_term = pi_constant + numerator - denominator
        return unnormalized_log_pdf - normalize_term

<END>

<START>
import dataclasses
from enum import auto, Enum
from typing import Collection, Dict, List, Mapping, Optional, Set, Tuple, Union


__all__ = [
    "ConstantArgument",
    "ExportBackwardSignature",
    "ExportGraphSignature",
    "InputKind",
    "InputSpec",
    "OutputKind",
    "OutputSpec",
    "SymIntArgument",
    "TensorArgument",
]


@dataclasses.dataclass
class TensorArgument:
    name: str


@dataclasses.dataclass
class SymIntArgument:
    name: str


@dataclasses.dataclass
class ConstantArgument:
    value: Union[int, float, bool, None]


ArgumentSpec = Union[TensorArgument, SymIntArgument, ConstantArgument]


class InputKind(Enum):
    USER_INPUT = auto()
    PARAMETER = auto()
    BUFFER = auto()
    CONSTANT_TENSOR = auto()


@dataclasses.dataclass
class InputSpec:
    kind: InputKind
    arg: ArgumentSpec
    target: Optional[str]

    def __post_init__(self):
        assert isinstance(self.arg, (TensorArgument, SymIntArgument, ConstantArgument))


class OutputKind(Enum):
    USER_OUTPUT = auto()
    LOSS_OUTPUT = auto()
    BUFFER_MUTATION = auto()
    GRADIENT_TO_PARAMETER = auto()
    GRADIENT_TO_USER_INPUT = auto()
    USER_INPUT_MUTATION = auto()


@dataclasses.dataclass
class OutputSpec:
    kind: OutputKind
    arg: ArgumentSpec
    target: Optional[str]

    def __post_init__(self):
        assert isinstance(self.arg, (TensorArgument, SymIntArgument, ConstantArgument))


def _sig_to_specs(
    *,
    user_inputs: Set[str],
    inputs_to_parameters: Mapping[str, str],
    inputs_to_buffers: Mapping[str, str],
    user_outputs: Set[str],
    buffer_mutations: Mapping[str, str],
    user_input_mutations: Mapping[str, str],
    grad_params: Mapping[str, str],
    grad_user_inputs: Mapping[str, str],
    loss_output: Optional[str],
    inputs: List[ArgumentSpec],
    outputs: List[ArgumentSpec],
) -> Tuple[List[InputSpec], List[OutputSpec]]:
    def to_input_spec(i: ArgumentSpec) -> InputSpec:
        if not isinstance(i, TensorArgument):
            return InputSpec(kind=InputKind.USER_INPUT, arg=i, target=None)
        name = i.name
        if name in user_inputs:
            return InputSpec(kind=InputKind.USER_INPUT, arg=i, target=None)
        elif name in inputs_to_parameters:
            return InputSpec(
                kind=InputKind.PARAMETER,
                arg=i,
                target=inputs_to_parameters[name],
            )
        elif name in inputs_to_buffers:
            return InputSpec(
                kind=InputKind.BUFFER, arg=i, target=inputs_to_buffers[name]
            )
        else:
            raise AssertionError(f"Unknown tensor input kind: {name}")

    def to_output_spec(idx: int, o: ArgumentSpec) -> OutputSpec:
        if not isinstance(o, TensorArgument):
            return OutputSpec(kind=OutputKind.USER_OUTPUT, arg=o, target=None)
        name = o.name
        if idx < len(buffer_mutations) + len(user_input_mutations):
            if name in buffer_mutations:
                return OutputSpec(
                    kind=OutputKind.BUFFER_MUTATION,
                    arg=o,
                    target=buffer_mutations[name],
                )
            elif name in user_input_mutations:
                return OutputSpec(
                    kind=OutputKind.USER_INPUT_MUTATION,
                    arg=o,
                    target=user_input_mutations[name],
                )
            else:
                raise AssertionError(f"Unknown tensor mutation kind: {name}")
        else:
            if name in user_outputs:
                return OutputSpec(kind=OutputKind.USER_OUTPUT, arg=o, target=None)

            elif name in grad_params:
                return OutputSpec(
                    kind=OutputKind.GRADIENT_TO_PARAMETER,
                    arg=o,
                    target=grad_params[name],
                )
            elif name in grad_user_inputs:
                return OutputSpec(
                    kind=OutputKind.GRADIENT_TO_USER_INPUT,
                    arg=o,
                    target=grad_user_inputs[name],
                )
            elif name == loss_output:
                return OutputSpec(kind=OutputKind.LOSS_OUTPUT, arg=o, target=None)

            else:
                raise AssertionError(f"Unknown tensor output kind: {name}")

    input_specs = [to_input_spec(i) for i in inputs]
    output_specs = [to_output_spec(idx, o) for idx, o in enumerate(outputs)]
    return input_specs, output_specs


@dataclasses.dataclass
class ExportBackwardSignature:
    gradients_to_parameters: Dict[str, str]
    gradients_to_user_inputs: Dict[str, str]
    loss_output: str


@dataclasses.dataclass
class ExportGraphSignature:

    input_specs: List[InputSpec]
    output_specs: List[OutputSpec]

    @property
    def parameters(self) -> Collection[str]:
        return [
            s.target
            for s in self.input_specs
            if s.kind == InputKind.PARAMETER
            if isinstance(s.target, str)
        ]

    @property
    def buffers(self) -> Collection[str]:
        return [
            s.target
            for s in self.input_specs
            if s.kind == InputKind.BUFFER
            if isinstance(s.target, str)
        ]

    @property
    def lifted_tensor_constants(self) -> Collection[str]:
        return [
            s.target
            for s in self.input_specs
            if s.kind == InputKind.CONSTANT_TENSOR
            if isinstance(s.target, str)
        ]

    @property
    def user_inputs(self) -> Collection[str]:
        return tuple(
            s.arg.name
            for s in self.input_specs
            if s.kind == InputKind.USER_INPUT and isinstance(s.arg, TensorArgument)
        )

    @property
    def user_outputs(self) -> Collection[str]:
        return tuple(
            s.arg.name
            for s in self.output_specs
            if s.kind == OutputKind.USER_OUTPUT and isinstance(s.arg, TensorArgument)
        )

    @property
    def inputs_to_parameters(self) -> Mapping[str, str]:
        return {
            s.arg.name: s.target
            for s in self.input_specs
            if s.kind == InputKind.PARAMETER
            and isinstance(s.arg, TensorArgument)
            and isinstance(s.target, str)
        }

    @property
    def inputs_to_buffers(self) -> Mapping[str, str]:
        return {
            s.arg.name: s.target
            for s in self.input_specs
            if s.kind == InputKind.BUFFER
            and isinstance(s.arg, TensorArgument)
            and isinstance(s.target, str)
        }

    @property
    def buffers_to_mutate(self) -> Mapping[str, str]:
        return {
            s.arg.name: s.target
            for s in self.output_specs
            if s.kind == OutputKind.BUFFER_MUTATION
            and isinstance(s.arg, TensorArgument)
            and isinstance(s.target, str)
        }

    @property
    def user_inputs_to_mutate(self) -> Mapping[str, str]:
        return {
            s.arg.name: s.target
            for s in self.output_specs
            if s.kind == OutputKind.USER_INPUT_MUTATION
            and isinstance(s.arg, TensorArgument)
            and isinstance(s.target, str)
        }

    @property
    def inputs_to_lifted_tensor_constants(self) -> Mapping[str, str]:
        return {
            s.arg.name: s.target
            for s in self.input_specs
            if s.kind == InputKind.CONSTANT_TENSOR
            and isinstance(s.arg, TensorArgument)
            and isinstance(s.target, str)
        }

    @property
    def backward_signature(self) -> Optional[ExportBackwardSignature]:
        loss_output = None
        gradients_to_parameters: Dict[str, str] = {}
        gradients_to_user_inputs: Dict[str, str] = {}
        for spec in self.output_specs:
            if spec.kind == OutputKind.LOSS_OUTPUT:
                assert loss_output is None
                assert isinstance(spec.arg, TensorArgument)
                loss_output = spec.arg.name
            elif spec.kind == OutputKind.GRADIENT_TO_PARAMETER:
                assert isinstance(spec.target, str)
                assert isinstance(spec.arg, TensorArgument)
                gradients_to_parameters[spec.arg.name] = spec.target
            elif spec.kind == OutputKind.GRADIENT_TO_USER_INPUT:
                assert isinstance(spec.target, str)
                assert isinstance(spec.arg, TensorArgument)
                gradients_to_user_inputs[spec.arg.name] = spec.target

        if loss_output is None:
            return None

        return ExportBackwardSignature(
            loss_output=loss_output,
            gradients_to_parameters=gradients_to_parameters,
            gradients_to_user_inputs=gradients_to_user_inputs,
        )

    @property
    def assertion_dep_token(self) -> Optional[Mapping[int, str]]:
        return None

    def __post_init__(self) -> None:
        assertion_dep_token = self.assertion_dep_token
        if assertion_dep_token is None:
            return
        assert len(assertion_dep_token) == 1
        assertion_dep_token_index = next(iter(assertion_dep_token.keys()))
        assert (
            len(self.user_outputs) + len(self.buffers_to_mutate)
            == assertion_dep_token_index
        )

    def replace_all_uses(self, old: str, new: str):
        assert isinstance(old, str)
        assert isinstance(new, str)
        for o in self.output_specs:
            if isinstance(o.arg, TensorArgument):
                if o.arg.name == old:
                    o.arg.name = new

<END>

<START>
import cmath
import math
import warnings

from collections import OrderedDict
from typing import Dict, Optional

import torch
import torch.backends.cudnn as cudnn

from ..nn.modules.utils import _list_with_default, _pair, _quadruple, _single, _triple

_builtin_table: Optional[Dict[int, str]] = None

_modules_containing_builtins = (torch, torch._C._nn, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._sparse, torch._C._special)  # type: ignore[attr-defined] # noqa: B950

_builtin_ops = [
    (_pair, "aten::_pair"),
    (_quadruple, "aten::_quadruple"),
    (_single, "aten::_single"),
    (_triple, "aten::_triple"),
    (_list_with_default, "aten::list_with_default"),
    (OrderedDict, "aten::dict"),
    (dict, "aten::dict"),
    (cudnn.is_acceptable, "aten::cudnn_is_acceptable"),
    (math.ceil, "aten::ceil"),
    (math.copysign, "aten::copysign"),
    (math.erf, "aten::erf"),
    (math.erfc, "aten::erfc"),
    (math.exp, "aten::exp"),
    (math.expm1, "aten::expm1"),
    (math.fabs, "aten::fabs"),
    (math.floor, "aten::floor"),
    (math.gamma, "aten::gamma"),
    (math.lgamma, "aten::lgamma"),
    (math.log, "aten::log"),
    (math.log10, "aten::log10"),
    (math.log1p, "aten::log1p"),
    (math.pow, "aten::pow"),
    (math.sqrt, "aten::sqrt"),
    (math.isnan, "aten::isnan"),
    (math.asinh, "aten::asinh"),
    (math.atanh, "aten::atanh"),
    (math.cosh, "aten::cosh"),
    (math.sinh, "aten::sinh"),
    (math.tanh, "aten::tanh"),
    (math.acos, "aten::acos"),
    (math.asin, "aten::asin"),
    (math.atan, "aten::atan"),
    (math.atan2, "aten::atan2"),
    (math.cos, "aten::cos"),
    (math.sin, "aten::sin"),
    (math.tan, "aten::tan"),
    (math.asinh, "aten::asinh"),
    (math.atanh, "aten::atanh"),
    (math.acosh, "aten::acosh"),
    (math.fmod, "aten::fmod"),
    (math.modf, "aten::modf"),
    (math.factorial, "aten::factorial"),
    (math.frexp, "aten::frexp"),
    (math.isinf, "aten::isinf"),
    (math.degrees, "aten::degrees"),
    (math.radians, "aten::radians"),
    (cmath.isnan, "aten::isnan"),
    (cmath.isfinite, "aten::isfinite"),
    (cmath.isinf, "aten::isinf"),
    (cmath.phase, "aten::angle"),
    (cmath.rect, "aten::polar"),
    (cmath.log, "aten::log"),
    (cmath.log10, "aten::log10"),
    (cmath.sqrt, "aten::sqrt"),
    (cmath.exp, "aten::exp"),
    (cmath.sin, "aten::sin"),
    (cmath.tan, "aten::tan"),
    (cmath.cos, "aten::cos"),
    (cmath.asin, "aten::asin"),
    (cmath.acos, "aten::acos"),
    (cmath.atan, "aten::atan"),
    (cmath.sinh, "aten::sinh"),
    (cmath.cosh, "aten::cosh"),
    (cmath.tanh, "aten::tanh"),
    (cmath.asinh, "aten::asinh"),
    (cmath.acosh, "aten::acosh"),
    (cmath.atanh, "aten::atanh"),
    (math.ldexp, "aten::ldexp"),
    (torch._assert, "aten::_assert"),
    (torch.autograd.grad, "aten::grad"),
    (torch.autograd.backward, "aten::backward"),
    (torch._C._infer_size, "aten::_infer_size"),
    (torch.nn.functional._no_grad_embedding_renorm_, "aten::_no_grad_embedding_renorm_"),  # type: ignore[attr-defined]
    (torch.nn.functional.assert_int_or_pair, "aten::_assert_int_or_pair"),
    (torch.nn.init._no_grad_fill_, "aten::_no_grad_fill_"),
    (torch.nn.init._no_grad_normal_, "aten::_no_grad_normal_"),
    (torch.nn.init._no_grad_uniform_, "aten::_no_grad_uniform_"),
    (torch.nn.init._no_grad_zero_, "aten::_no_grad_zero_"),
    (torch._C._get_tracing_state, "aten::_get_tracing_state"),
    (torch._C._get_cpu_capability, "aten::_get_cpu_capability"),
    (warnings.warn, "aten::warn"),
    (torch._VF.stft, "aten::stft"),  # type: ignore[attr-defined]
    (torch._VF.istft, "aten::istft"),  # type: ignore[attr-defined]
    (torch._VF.cdist, "aten::cdist"),  # type: ignore[attr-defined]
    (torch._VF.norm, "aten::norm"),  # type: ignore[attr-defined]
    (torch._VF.unique_dim, "aten::unique_dim"),
    (torch._VF.unique_consecutive, "aten::unique_consecutive"),  # type: ignore[attr-defined]
    (torch._VF.nuclear_norm, "aten::nuclear_norm"),
    (torch._VF.frobenius_norm, "aten::frobenius_norm"),
    (torch._VF.tensordot, "aten::tensordot"),  # type: ignore[attr-defined]
]



def _gen_torch_functional_registered_ops():
    ops = [
        "stft",
        "istft",
        "lu",
        "cdist",
        "norm",
        "unique",
        "unique_consecutive",
        "tensordot",
    ]
    return {getattr(torch.functional, name) for name in ops}


_functional_registered_ops = _gen_torch_functional_registered_ops()


def _is_special_functional_bound_op(fn):
    return fn in _functional_registered_ops


def _get_builtin_table():
    global _builtin_table
    if _builtin_table is not None:
        return _builtin_table
    _builtin_table = {}

    def register_all(mod):
        for name in dir(mod):
            v = getattr(mod, name)
            if (
                callable(v)
                and not _is_special_functional_bound_op(v)
                and v is not torch.no_grad
                and v is not torch.autocast
            ):
                if name == "_segment_reduce":
                    name = name[1:]
                _builtin_ops.append((v, "aten::" + name))

    for mod in _modules_containing_builtins:
        register_all(mod)

    _builtin_ops.append((math.gcd, "aten::gcd"))
    _builtin_ops.append((math.isfinite, "aten::isfinite"))
    _builtin_ops.append((math.remainder, "aten::mathremainder"))  # type: ignore[attr-defined]

    import torch.distributed.autograd as dist_autograd

    if dist_autograd.is_available():
        _builtin_ops.append((dist_autograd.get_gradients, "aten::get_gradients"))
        _builtin_ops.append((dist_autograd.backward, "aten::dist_backward"))

    for builtin, aten_op in _builtin_ops:
        _builtin_table[id(builtin)] = aten_op

    return _builtin_table


def _register_builtin(fn, op):
    _get_builtin_table()[id(fn)] = op


def _find_builtin(fn):
    return _get_builtin_table().get(id(fn))

<END>

<START>
from torch.onnx._internal.onnxruntime import (
    is_onnxrt_backend_supported,
    torch_compile_backend,
)
from .registry import register_backend


def has_onnxruntime():
    return is_onnxrt_backend_supported()


if is_onnxrt_backend_supported():
    register_backend(name="onnxrt", compiler_fn=torch_compile_backend)
else:

    def information_displaying_backend(*args, **kwargs):
        raise ImportError(
            "onnxrt is not registered as a backend. "
            "Please make sure all dependencies such as "
            "numpy, onnx, onnxscript, and onnxruntime-training are installed. "
            "Suggested procedure to fix dependency problem:\n"
            "  (1) pip or conda install numpy onnx onnxscript onnxruntime-training.\n"
            "  (2) Open a new python terminal.\n"
            "  (3) Call the API `torch.onnx.is_onnxrt_backend_supported()`:\n"
            "  (4)   If it returns `True`, then you can use `onnxrt` backend.\n"
            "  (5)   If it returns `False`, please execute the package importing section in "
            "torch/onnx/_internal/onnxruntime.py under pdb line-by-line to see which import fails."
        )

    register_backend(name="onnxrt", compiler_fn=information_displaying_backend)

<END>

<START>
import functools
import logging
from typing import Optional

import torch

from ... import config

log = logging.getLogger(__name__)


def get_cuda_arch() -> Optional[str]:
    try:
        cuda_arch = config.cuda.arch
        if cuda_arch is None:
            major, minor = torch.cuda.get_device_capability(0)
            cuda_arch = major * 10 + minor
        return str(cuda_arch)
    except Exception as e:
        log.error("Error getting cuda arch: %s", e)
        return None


def get_cuda_version() -> Optional[str]:
    try:
        cuda_version = config.cuda.version
        if cuda_version is None:
            cuda_version = torch.version.cuda
        return cuda_version
    except Exception as e:
        log.error("Error getting cuda version: %s", e)
        return None


@functools.lru_cache(None)
def nvcc_exist(nvcc_path: str = "nvcc") -> bool:
    if nvcc_path is None:
        return False
    import subprocess

    res = subprocess.call(
        ["which", nvcc_path], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
    )
    return res == 0

<END>

<START>


def _verify_module(module: nn.Sequential) -> None:
    if not isinstance(module, nn.Sequential):
        raise TypeError("module must be nn.Sequential to be partitioned")

    named_children = list(module.named_children())
    if len(named_children) != len(module):
        raise ValueError("module with duplicate children is not supported")


def _verify_splitting(
    module: nn.Sequential, partitions: List[nn.Sequential], devices: List[torch.device]
) -> None:
    num_parameters = len(list(module.parameters()))
    num_child_parameters = sum(len(list(child.parameters())) for child in module.children())
    if num_parameters == num_child_parameters:
        return

    for i in range(len(partitions)):
        for j in range(i + 1, len(partitions)):
            parti = partitions[i]
            partj = partitions[j]
            if devices[i] == devices[j]:
                continue
            for p in parti.parameters():
                for q in partj.parameters():
                    if p is q:
                        raise ValueError("module with duplicate parameters on distinct devices is not supported")


class BalanceError(ValueError):
    pass


def _retrieve_device(module: nn.Module) -> torch.device:

    device = None
    for parameter in module.parameters():
        if device is None:
            device = parameter.device
        elif device != parameter.device:
            raise ValueError(
                f'nn.Module: {module}, should have all parameters on a single device,'
                ' please use .to() to place the module on a single device')

    return device if device is not None else torch.device("cpu")


class PipeSequential(nn.Sequential):

    def forward(self, *inputs):
        for module in self:
            if isinstance(inputs, Tuple):  # type: ignore[arg-type]
                inputs = module(*inputs)
            else:
                inputs = module(inputs)
        return inputs


class WithDevice(nn.Module):
    def __init__(self, module: nn.Module, device: torch.device):
        super().__init__()
        self._module = module
        self._device = torch.device(device)

    def forward(self, *args, **kwargs):
        return self._module(*args, **kwargs)

    @property
    def module(self):
        return self._module

    @property
    def device(self):
        return self._device


def _assemble_partition(modules: List[nn.Module]):
    modules_list: List[nn.Module] = []
    for module in modules:
        if isinstance(module, nn.Sequential):
            modules_list.extend(module.children())
        else:
            modules_list.append(module)
    return PipeSequential(*modules_list)


def _split_module(modules: nn.Sequential) -> Tuple[List[nn.Sequential], List[torch.device]]:
    partitions = []
    devices = []

    current_partition = []
    current_device = None
    for name, module in modules.named_children():
        if isinstance(module, WithDevice):
            device = module.device
            module = module.module
            module.to(device)
        else:
            device = _retrieve_device(module)
        if current_device is not None and (current_device != device or device.type == 'cpu'):
            partitions.append(_assemble_partition(current_partition))
            devices.append(current_device)
            current_partition = []
        current_device = device
        current_partition.append(module)

    if current_device is not None:
        partitions.append(_assemble_partition(current_partition))
        devices.append(current_device)

    partitions = cast(List[nn.Sequential], nn.ModuleList(partitions))

    return partitions, devices


MOVING_DENIED = TypeError("denied to move parameters and buffers, because Pipe should manage device placement")


class Pipe(Module):

    def __init__(
        self,
        module: nn.Sequential,
        chunks: int = 1,
        checkpoint: str = "except_last",
        deferred_batch_norm: bool = False,
    ) -> None:
        super().__init__()

        if not torch.distributed.rpc._is_current_rpc_agent_set():
            raise RuntimeError(
                'Please initialize RPC framework for Pipe using '
                'torch.distributed.rpc.init_rpc')

        chunks = int(chunks)
        checkpoint = str(checkpoint)

        if chunks <= 0:
            raise ValueError("number of chunks must be positive integer")
        if checkpoint not in ["always", "except_last", "never"]:
            raise ValueError("checkpoint is not one of 'always', 'except_last', or 'never'")

        _verify_module(module)

        verify_skippables(module)

        self.chunks = chunks
        self.checkpoint = checkpoint

        if deferred_batch_norm:
            module = DeferredBatchNorm.convert_deferred_batch_norm(module, chunks)

        self.partitions, self.devices = _split_module(module)
        _verify_splitting(module, self.partitions, self.devices)

        self._copy_streams: List[List[AbstractStream]] = []
        self._skip_layout = inspect_skip_layout(self.partitions)

        copy_streams = self._ensure_copy_streams()

        checkpoint_stop = {"always": self.chunks, "except_last": self.chunks - 1, "never": 0}[self.checkpoint]

        self.pipeline = Pipeline(self.partitions, self.devices, copy_streams, self._skip_layout, checkpoint_stop)

    def __len__(self) -> int:
        partitions = self.partitions
        if index < 0:
            partitions = partitions[::-1]

        for partition in partitions:
            try:
                return partition[index]
            except IndexError:
                pass

            shift = len(partition)

            if index < 0:
                index += shift
            else:
                index -= shift

        raise IndexError

    def __iter__(self) -> Iterator[nn.Module]:

        It's worth to cache CUDA streams although PyTorch already manages a
        pool of pre-allocated CUDA streams, because it may reduce GPU memory
        fragmentation when the number of micro-batches is small.

        Processes a single input mini-batch through the pipe and returns an
        :class:`~torch.distributed.rpc.RRef` pointing to the output.
        :class:`Pipe` is a fairly transparent module wrapper. It doesn't
        modify the input and output signature of the underlying module. But
        there's type restriction. Input and output have to contain at least one
        tensor. This restriction is applied at partition boundaries too.

        The sequence of inputs are fed into the first stage of the pipeline as
        ``*inputs``. As a result the positional args for this function should
        match the positional args for the first stage of the pipeline. The same
        condition applies for output of one stage of the pipeline which is the
        input for the next stage.

        The input tensor is split into multiple micro-batches based on the
        ``chunks`` parameter used to initialize :class:`Pipe`. The batch size
        is assumed to be the first dimension of the tensor and if the batch
        size is less than ``chunks``, the number of micro-batches is equal to
        the batch size.

        Only tensors are split into multiple micro-batches, non-Tensor inputs
        are just replicated as-is in each micro-batch. For non-Tensor outputs
        in the last stage of the pipeline, they are aggregated as a ``List``
        and returned the user. For example, if you have 2 micro-batches
        returning the integer 5, the user would receive the consolidated
        output of `[5, 5]`

        All the input tensors need to be on the same device as the first
        partition of the pipeline.

        If a tensor is wrapped with the :class:`NoChunk` wrapper, the tensor
        is not split across micro-batches and is replicated as-is similar to
        non-tensors.

        Args:
            inputs: input mini-batch

        Returns:
            :class:`~torch.distributed.rpc.RRef` to the output of the mini-batch

        Raises:
            TypeError: input doesn't contain at least one tensor


<END>

<START>
import torch

from torch._export.db.case import export_case, SupportLevel


@export_case(
    example_inputs=(torch.randn(3, 2), "attr"),
    tags={"python.builtin"},
    support_level=SupportLevel.SUPPORTED,
)
def tensor_setattr(x, attr):
    setattr(x, attr, torch.randn(3, 2))
    return x + 4

<END>

<START>
from typing import TYPE_CHECKING

import torch
from torch.utils._python_dispatch import is_traceable_wrapper_subclass
from . import trace_rules, variables
from .eval_frame import DisableContext, innermost_fn, RunOnlyContext
from .exc import IncorrectUsage

if TYPE_CHECKING:
    from torch._C._dynamo.eval_frame import (  # noqa: F401
        reset_code,
        set_eval_frame,
        set_guard_error_hook,
        skip_code,
        unsupported,
    )
else:
    for name in dir(torch._C._dynamo.eval_frame):
        if name.startswith("__"):
            continue
        globals()[name] = getattr(torch._C._dynamo.eval_frame, name)


def run(fn=None):
    Decorator and context manager to disable TorchDynamo

    If recursive=True, Dynamo is completely skipped on the decorated function
    frame as well as the recursively invoked functions.

    If recursive=False, Dynamo skips frames associated with the function code,
    but still process recursively invoked frames.
    Skip frames associated with the function code, but still process recursively
    invoked frames
    Customize which functions TorchDynamo will include in the generated
    graph. Similar to `torch.fx.wrap()`.
    ::

        torch._dynamo.allow_in_graph(my_custom_function)

        @torch._dynamo.optimize(...)
        def fn(a):
            x = torch.add(x, 1)
            x = my_custom_function(x)
            x = torch.add(x, 1)
            return x

        fn(...)

    Will capture a single graph containing `my_custom_function()`.
    Customize which functions TorchDynamo will exclude in the generated
    graph and force a graph break on.
    ::

        torch._dynamo.disallow_in_graph(torch.sub)

        @torch._dynamo.optimize(...)
        def fn(a):
            x = torch.add(x, 1)
            x = torch.sub(x, 1)
            x = torch.add(x, 1)
            return x

        fn(...)

    Will break the graph on `torch.sub`, and give two graphs each with a
    single `torch.add()` op.
    pass


def forbid_in_graph(fn):
    if isinstance(fn, (list, tuple)):
        return [forbid_in_graph(x) for x in fn]
    assert callable(fn), "forbid_in_graph applies only to callables"
    fn._dynamo_forbidden = True
    return fn


def _apply_func_to_inner_tensors_of_same_dim(func, t, *args):
    assert is_traceable_wrapper_subclass(t)

    attrs, ctx = t.__tensor_flatten__()
    for attr in attrs:
        inner = getattr(t, attr)
        if inner.dim() == t.dim():
            func(inner, *args)


@forbid_in_graph
def mark_dynamic(t, index):
    if is_traceable_wrapper_subclass(t):
        _apply_func_to_inner_tensors_of_same_dim(mark_dynamic, t, index)

    if isinstance(index, int):
        if not hasattr(t, "_dynamo_dynamic_indices"):
            t._dynamo_dynamic_indices = set()
        t._dynamo_dynamic_indices.add(index)
        return

    assert isinstance(index, (list, tuple))
    for i in index:
        mark_dynamic(t, i)


@forbid_in_graph
def maybe_mark_dynamic(t, index):
    if is_traceable_wrapper_subclass(t):
        _apply_func_to_inner_tensors_of_same_dim(maybe_mark_dynamic, t, index)

    if isinstance(index, int):
        if not hasattr(t, "_dynamo_weak_dynamic_indices"):
            t._dynamo_weak_dynamic_indices = set()
        t._dynamo_weak_dynamic_indices.add(index)
        return

    assert isinstance(index, (list, tuple))
    for i in index:
        maybe_mark_dynamic(t, i)


@forbid_in_graph
def mark_static(t, index=None):
    if is_traceable_wrapper_subclass(t):
        _apply_func_to_inner_tensors_of_same_dim(mark_static, t, index)

    if isinstance(index, int):
        if not hasattr(t, "_dynamo_static_indices"):
            t._dynamo_static_indices = set()
        t._dynamo_static_indices.add(index)
    elif index is None:
        for i in range(t.dim()):
            mark_static(t, i)
    else:
        assert isinstance(index, (list, tuple))
        for i in index:
            mark_static(t, i)


@forbid_in_graph
def mark_static_address(t, guard=True):
    if not isinstance(t, torch.Tensor):
        raise TypeError(f"mark_static_address expects a tensor but recieved {type(t)}")

    if guard:
        t._dynamo_static_input_type = "guarded"  # type: ignore[attr-defined]
    else:
        t._dynamo_static_input_type = "unguarded"  # type: ignore[attr-defined]


def _allow_in_graph_einops():
    import einops

    try:
        from einops._torch_specific import (  # type: ignore[attr-defined]  # noqa: F401
            _ops_were_registered_in_torchdynamo,
        )

        pass
    except ImportError:
        allow_in_graph(einops.rearrange)
        allow_in_graph(einops.reduce)
        if hasattr(einops, "repeat"):
            allow_in_graph(einops.repeat)  # available since einops 0.2.0
        if hasattr(einops, "einsum"):
            allow_in_graph(einops.einsum)  # available since einops 0.5.0
        if hasattr(einops, "pack"):
            allow_in_graph(einops.pack)  # available since einops 0.6.0
        if hasattr(einops, "unpack"):
            allow_in_graph(einops.unpack)  # available since einops 0.6.0


trace_rules.add_module_init_func("einops", _allow_in_graph_einops)

<END>

<START>
import torch

from torch._export.db.case import export_case


@export_case(
    example_inputs=(torch.ones(3, 2), torch.ones(2)),
    tags={"python.closure"},
)
def nested_function(a, b):
    x = a + b
    z = a - b

    def closure(y):
        nonlocal x
        x += 1
        return x * y + z

    return closure(x)

<END>

<START>

import collections
from functools import wraps
from typing import Callable, DefaultDict, Dict, List

import torch
import torch.utils._pytree as pytree
from torch import Tensor
from torch._logging import getArtifactLogger
from torch._subclasses.functional_tensor import FunctionalTensor, FunctionalTensorMode
from torch._subclasses.meta_utils import safe_is_leaf
from torch.fx.experimental.symbolic_shapes import is_concrete_int
from torch.multiprocessing.reductions import StorageWeakRef
from torch.utils._python_dispatch import (
    is_traceable_wrapper_subclass,
    transform_subclass,
)
from .functional_utils import (
    _get_mutation_type,
    are_all_mutations_hidden_from_autograd,
    are_all_mutations_under_no_grad_or_inference_mode,
    from_fun,
    has_data_mutation,
    has_metadata_mutation,
    has_same_metadata,
    to_fun,
)
from .schemas import (
    InputAliasInfo,
    MutationType,
    OutputAliasInfo,
    OutputType,
    ViewAndMutationMeta,
)
from .subclass_utils import create_subclass_meta

from .utils import _get_autocast_states, KNOWN_TYPES, strict_zip

zip = strict_zip

aot_graphs_log = getArtifactLogger(__name__, "aot_graphs")


def run_functionalized_fw_and_collect_metadata(
    f,
    *,
    keep_input_mutations: bool,
    is_train: bool = False,
    requires_subclass_dispatch: bool = False,
    pre_dispatch: bool = False,
) -> Callable[..., ViewAndMutationMeta]:
    memo: Dict[Tensor, Tensor] = {}

    def _to_fun(t):
        if isinstance(t, Tensor):
            if t in memo:
                return memo[t]
            r = to_fun(t)
            memo[t] = r
            return r
        else:
            return t

    @wraps(f)
    def inner(*flat_args):
        assert all(isinstance(a, KNOWN_TYPES) for a in flat_args)

        input_info: List[InputAliasInfo] = []
        output_info: List[OutputAliasInfo] = []

        prior_grad_enabled = torch.is_grad_enabled()
        prior_autocast_states = _get_autocast_states()

        disable_above = torch._C._ExcludeDispatchKeyGuard(
            torch._C.DispatchKeySet(torch._C.DispatchKey.Functionalize)
        )

        with disable_above, FunctionalTensorMode():
            flat_f_args = pytree.tree_map(_to_fun, flat_args)
            flat_f_outs = f(*flat_f_args)

        if prior_autocast_states != _get_autocast_states():
            raise RuntimeError(
                "AOTAutograd does not support tracing graphs that mutate the autocast state. "
                "Dynamo will only insert autocast context managers (e.g. with torch.autocast(..)) into the graph, "
                "which will unwind all of their mutations to autocast state before the graph exits. "
                "If you encounter this error while using torch.compile, please file a bug."
            )

        for i, (arg, f_arg) in enumerate(zip(flat_args, flat_f_args)):
            if not isinstance(arg, Tensor):
                new_arg = arg
            else:
                new_arg = from_fun(f_arg)
            mutates_metadata = has_metadata_mutation(
                f_arg, arg, check_only_storage_mutation=False
            )
            if mutates_metadata and is_traceable_wrapper_subclass(arg):
                raise RuntimeError(
                    "Metadata mutations are currently not allowed on tensor subclasses"
                )
            mutates_storage_metadata = has_metadata_mutation(
                f_arg, arg, check_only_storage_mutation=True
            )
            mutates_data = has_data_mutation(f_arg)
            mutations_hidden_from_autograd = are_all_mutations_hidden_from_autograd(
                f_arg
            )
            mutations_under_no_grad_or_inference_mode = (
                mutates_data
                and are_all_mutations_under_no_grad_or_inference_mode(f_arg)
            )

            if mutates_storage_metadata:
                mutates_data = False

            requires_grad = isinstance(f_arg, torch.Tensor) and f_arg.requires_grad

            input_info.append(
                InputAliasInfo(
                    is_leaf=isinstance(arg, Tensor) and safe_is_leaf(arg),
                    mutates_data=mutates_data,
                    mutates_metadata=mutates_metadata,
                    mutations_hidden_from_autograd=mutations_hidden_from_autograd,
                    mutates_storage_metadata=mutates_storage_metadata,
                    mutations_under_no_grad_or_inference_mode=mutations_under_no_grad_or_inference_mode,
                    requires_grad=requires_grad,
                    mutation_type=_get_mutation_type(
                        keep_input_mutations,
                        mutates_data,
                        mutates_metadata,
                        mutations_hidden_from_autograd,
                        mutations_under_no_grad_or_inference_mode,
                        requires_grad,
                    ),
                )
            )


        inp_storage_refs = {
            StorageWeakRef(inpt.untyped_storage()): idx
            for idx, inpt in enumerate(flat_f_args)
            if isinstance(inpt, Tensor)
        }

        inp_tensor_ids = {id(inpt) for inpt in flat_f_args if isinstance(inpt, Tensor)}
        out_tensor_ids = {id(o): i for i, o in enumerate(flat_f_outs)}

        out_tensor_alias_counts: DefaultDict = collections.defaultdict(int)
        num_aliased_tensors_that_are_multi_output_views: DefaultDict = (
            collections.defaultdict(int)
        )
        out_storage_to_tensors: DefaultDict = collections.defaultdict(set)
        curr_storage = None
        for o in flat_f_outs:
            if isinstance(o, torch.Tensor):
                curr_storage = StorageWeakRef(o.untyped_storage())
                out_tensor_alias_counts[curr_storage] += 1
                is_cur_tensor_multi_out_view = isinstance(
                    o, FunctionalTensor
                ) and torch._functionalize_is_multi_output_view(  # type: ignore[attr-defined]
                    o.elem
                )
                if is_cur_tensor_multi_out_view:
                    num_aliased_tensors_that_are_multi_output_views[curr_storage] += 1
                out_storage_to_tensors[curr_storage].add(o)

        intermediate_base_tensor_id_to_output_idx: Dict[int, int] = {}
        intermediate_bases: List[torch.Tensor] = []
        for o in flat_f_outs:
            functional_tensor_storage_changed = isinstance(
                o, FunctionalTensor
            ) and torch._functionalize_was_storage_changed(  # type: ignore[attr-defined]
                o.elem
            )
            curr_storage = (
                None
                if not isinstance(o, torch.Tensor)
                else StorageWeakRef(o.untyped_storage())
            )
            outs_with_identical_metadata_that_require_grad = (
                []
                if not isinstance(o, Tensor)
                else [
                    curr
                    for curr in out_storage_to_tensors[curr_storage]
                    if has_same_metadata(o, curr)
                    and curr.requires_grad
                    and o is not curr
                ]
            )
            is_result_of_custom_autograd_fn = False
            if isinstance(o, Tensor):
                if type(o.grad_fn).__name__ == "CppFunction":
                    is_result_of_custom_autograd_fn = True
                if isinstance(o.grad_fn, torch.autograd.function.BackwardCFunction):
                    is_result_of_custom_autograd_fn = True

            if not isinstance(o, Tensor):
                output_type = OutputType.non_alias
                base_idx = None
            elif (
                curr_storage in inp_storage_refs
                and o.grad_fn is not None
                and is_result_of_custom_autograd_fn
            ):
                output_type = OutputType.custom_function_view
                base_idx = None
            elif (
                curr_storage in inp_storage_refs
                and not functional_tensor_storage_changed
            ):
                base_idx = inp_storage_refs[curr_storage]
                is_input_tensor = id(o) in inp_tensor_ids
                num_aliased_outs = out_tensor_alias_counts[curr_storage]
                num_multi_output_view_outs = (
                    num_aliased_tensors_that_are_multi_output_views[curr_storage]
                )
                num_aliased_outs_that_are_not_multi_output_views = (
                    num_aliased_outs - num_multi_output_view_outs
                )
                if (
                    o.grad_fn is not None
                    and num_aliased_outs_that_are_not_multi_output_views == 0
                ):
                    aot_graphs_log.info(
                        "Encountered AOTAutograd case: differentiable outputs that \
alias each other from a multi-output view call"
                    )
                    output_type = OutputType.non_alias
                elif is_input_tensor:
                    output_type = OutputType.is_input
                else:
                    output_type = OutputType.alias_of_input

            elif o._base is not None and o.requires_grad and o._base.requires_grad:
                num_aliased_outs = out_tensor_alias_counts[curr_storage]
                num_multi_output_view_outs = (
                    num_aliased_tensors_that_are_multi_output_views[curr_storage]
                )
                num_aliased_outs_that_are_not_multi_output_views = (
                    num_aliased_outs - num_multi_output_view_outs
                )
                if (
                    out_tensor_alias_counts[curr_storage] == 1
                    or num_aliased_outs_that_are_not_multi_output_views <= 1
                ):
                    if (
                        out_tensor_alias_counts[curr_storage] != 1
                        and num_aliased_outs_that_are_not_multi_output_views <= 1
                    ):
                        aot_graphs_log.info(
                            "Encountered AOTAutograd case: differentiable outputs that alias each other \
from a multi-output view call"
                        )
                    output_type = OutputType.unsafe_view_alias
                    base_idx = None
                else:
                    maybe_existing_out_idx = out_tensor_ids.get(id(o._base), None)
                    if maybe_existing_out_idx is not None:
                        output_type = (
                            OutputType.alias_of_intermediate_base_is_user_output
                        )
                        base_idx = maybe_existing_out_idx
                    else:
                        maybe_existing_base_output_idx = (
                            intermediate_base_tensor_id_to_output_idx.get(
                                id(o._base), None
                            )
                        )
                        if maybe_existing_base_output_idx is not None:
                            output_type = OutputType.alias_of_intermediate
                            base_idx = maybe_existing_base_output_idx
                        else:
                            new_out_idx = len(intermediate_bases)
                            base_idx = new_out_idx
                            output_type = (
                                OutputType.alias_of_intermediate_save_as_output
                            )
                            intermediate_base_tensor_id_to_output_idx[
                                id(o._base)
                            ] = new_out_idx
                            intermediate_bases.append(o._base)
            elif (
                out_tensor_alias_counts[curr_storage] > 1
                and len(outs_with_identical_metadata_that_require_grad) > 0
                and not o.requires_grad
            ):
                assert len(outs_with_identical_metadata_that_require_grad) > 0
                out_alias = outs_with_identical_metadata_that_require_grad[0]
                existing_out_idx = out_tensor_ids[id(out_alias)]
                output_type = OutputType.alias_of_intermediate_base_is_user_output
                base_idx = existing_out_idx
            else:
                output_type = OutputType.non_alias
                base_idx = None

            if isinstance(o, torch.Tensor):
                dynamic_dims = {
                    i for i, s in enumerate(o.shape) if not is_concrete_int(s)
                }
            else:
                dynamic_dims = None
            out_info = OutputAliasInfo(
                output_type=output_type,
                raw_type=type(o),
                base_idx=base_idx,
                dynamic_dims=dynamic_dims,
                requires_grad=isinstance(o, torch.Tensor) and o.requires_grad,
            )
            output_info.append(out_info)

        def view_avoid_dupes_with_primals(t):
            if isinstance(t, Tensor) and is_traceable_wrapper_subclass(t):
                return transform_subclass(
                    t, lambda _, inner_t: view_avoid_dupes_with_primals(inner_t)
                )
            if isinstance(t, Tensor):
                return t.view(t.shape)
            return t

        f_input_tangents = [
            inp
            for inp, info in zip(flat_f_args, input_info)
            if _get_mutation_type(
                keep_input_mutations,
                mutates_data=info.mutates_data,
                mutates_metadata=info.mutates_metadata,
                mutations_hidden_from_autograd=info.mutations_hidden_from_autograd,
                mutations_under_no_grad_or_inference_mode=info.mutations_under_no_grad_or_inference_mode,
                requires_grad=info.requires_grad
            )
            == MutationType.MUTATED_OUT_GRAPH
            and info.mutates_data
            and info.requires_grad
        ]
        f_output_tangents = [
            o
            for o, info in zip(flat_f_outs, output_info)
            if info.output_type
            in [
                OutputType.non_alias,
                OutputType.unsafe_view_alias,
                OutputType.custom_function_view,
            ]
            and issubclass(info.raw_type, torch.Tensor)
            and info.requires_grad
        ]
        f_tangents = f_input_tangents + f_output_tangents + intermediate_bases
        traced_tangents = pytree.tree_map(from_fun, f_tangents)
        traced_tangents = pytree.tree_map(
            view_avoid_dupes_with_primals, traced_tangents
        )
        user_outs = pytree.tree_map(from_fun, f_output_tangents)

        f_mutated_inputs = [
            inp
            for inp, info in zip(flat_f_args, input_info)
            if info.mutates_data or info.mutates_metadata
        ]
        f_metadata_mutated_inputs = [
            inp for inp, info in zip(flat_f_args, input_info) if info.mutates_metadata
        ]
        f_fw_graph_outs = list(flat_f_outs)
        if is_train or not keep_input_mutations:
            f_fw_graph_outs = f_mutated_inputs + f_fw_graph_outs
        else:
            f_fw_graph_outs = f_metadata_mutated_inputs + f_fw_graph_outs
        if is_train:
            f_fw_graph_outs = f_fw_graph_outs + intermediate_bases
        fw_graph_outs = pytree.tree_map(from_fun, f_fw_graph_outs)

        grad_enabled_mutation = None
        if torch.is_grad_enabled() != prior_grad_enabled:
            grad_enabled_mutation = torch.is_grad_enabled()
            torch.set_grad_enabled(
                prior_grad_enabled
            )  # Restore the prior state after tracing it
            aot_graphs_log.info(
                (
                    "grad_mode mutation encountered in graph. "
                    "Will emit mutation epilogue, to set grad_mode=%s"
                ),
                grad_enabled_mutation,
            )

        metadata = ViewAndMutationMeta(
            input_info=input_info,
            output_info=output_info,
            num_intermediate_bases=len(intermediate_bases),
            keep_input_mutations=keep_input_mutations,
            traced_tangents=traced_tangents,
            subclass_inp_meta=create_subclass_meta(flat_args),
            subclass_fw_graph_out_meta=create_subclass_meta(fw_graph_outs),
            subclass_tangent_meta=create_subclass_meta(traced_tangents),
            is_train=is_train,
            grad_enabled_mutation=grad_enabled_mutation,
            requires_subclass_dispatch=requires_subclass_dispatch,
        )
        return metadata

    return inner

<END>

<START>
import sys
from typing import Any, Callable, Iterable, List, Tuple

__all__ = ["trace_dependencies"]


def trace_dependencies(
    callable: Callable[[Any], Any], inputs: Iterable[Tuple[Any, ...]]
) -> List[str]:
    modules_used = set()

    def record_used_modules(frame, event, arg):
        if event != "call":
            return

        name = frame.f_code.co_name
        module = None

        if name in frame.f_globals:
            module = frame.f_globals[name].__module__
        elif name in frame.f_locals:
            module = frame.f_locals[name].__module__
        elif "self" in frame.f_locals:
            method = getattr(frame.f_locals["self"], name, None)
            module = method.__module__ if method else None

        if module:
            modules_used.add(module)

    try:
        sys.setprofile(record_used_modules)

        for inp in inputs:
            callable(*inp)

    finally:
        sys.setprofile(None)

    return list(modules_used)

<END>

<START>
from abc import ABC, abstractmethod
import contextlib
from typing import Any
import torch
import torch.utils._pytree as pytree
from torch._C._functorch import (
    TransformType,
    RandomnessType,
    CInterpreter,
    CGradInterpreterPtr,
    CFunctionalizeInterpreterPtr,
    CVmapInterpreterPtr,
    CJvpInterpreterPtr,
    pop_dynamic_layer_stack,
    push_dynamic_layer_stack,
)
from torch.autograd.forward_ad import _set_fwd_grad_enabled



class FuncTorchInterpreter(ABC):
    def __init__(self, cptr: Any):
        self._cptr = cptr

    @abstractmethod
    def process(self, op, args, kwargs):
        pass

    def lower(self):
        return temporarily_pop_interpreter_stack()

    def level(self):
        return self._cptr.level()

    def key(self):
        return self._cptr.key()


@contextlib.contextmanager
def temporarily_pop_interpreter_stack():
    try:
        saved = pop_dynamic_layer_stack()
        yield
    finally:
        push_dynamic_layer_stack(saved)


class VmapInterpreter(FuncTorchInterpreter):
    def __init__(self, cdata: CInterpreter):
        assert cdata.key() == TransformType.Vmap
        self._cdata = cdata
        self._cptr = CVmapInterpreterPtr(cdata)

    def process(self, op, args, kwargs):
        kernel = op.functorch_table[TransformType.Vmap]
        return kernel(self, *args, **kwargs)

    def batch_size(self):
        return self._cptr.batchSize()

    def randomness(self):
        typ = self._cptr.randomness()
        if typ == RandomnessType.Error:
            return "error"
        elif typ == RandomnessType.Same:
            return "same"
        elif typ == RandomnessType.Different:
            return "different"
        raise RuntimeError(f"Unknown RandomnessType: {typ}")


@contextlib.contextmanager
def nested(*contexts):
    with contextlib.ExitStack() as stack:
        for ctx in contexts:
            stack.enter_context(ctx)
        yield contexts


class GradInterpreter(FuncTorchInterpreter):
    def __init__(self, cdata: CInterpreter):
        assert cdata.key() == TransformType.Grad
        self._cdata = cdata
        self._cptr = CGradInterpreterPtr(cdata)

    def lift(self, args, kwargs):
        args, kwargs = pytree.tree_map_only(torch.Tensor, self._cptr.lift, [args, kwargs])
        return args, kwargs

    def process(self, op, args, kwargs):
        kernel = op.functorch_table[TransformType.Grad]
        args, kwargs = self.lift(args, kwargs)
        return kernel(self, *args, **kwargs)

    def lower(self):
        prev_grad_mode = self.prev_grad_mode()
        if not prev_grad_mode:
            return nested(torch.no_grad(), super().lower())
        return super().lower()

    def prev_grad_mode(self):
        return self._cptr.prevGradMode()


class JvpInterpreter(FuncTorchInterpreter):
    def __init__(self, cdata: CInterpreter):
        assert cdata.key() == TransformType.Jvp
        self._cdata = cdata
        self._cptr = CJvpInterpreterPtr(cdata)

    def lift(self, args, kwargs):
        args, kwargs = pytree.tree_map_only(torch.Tensor, self._cptr.lift, [args, kwargs])
        return args, kwargs

    def process(self, op, args, kwargs):
        kernel = op.functorch_table[TransformType.Jvp]
        args, kwargs = self.lift(args, kwargs)
        return kernel(self, *args, **kwargs)

    def lower(self):
        prev_fwd_grad_mode = self.prev_fwd_grad_mode()
        if not prev_fwd_grad_mode:
            return nested(_set_fwd_grad_enabled(False), super().lower())
        return super().lower()

    def prev_fwd_grad_mode(self):
        return self._cptr.prevFwdGradMode()


class FunctionalizeInterpreter(FuncTorchInterpreter):
    def __init__(self, cdata: CInterpreter):
        assert cdata.key() == TransformType.Functionalize
        self._cdata = cdata
        self._cptr = CFunctionalizeInterpreterPtr(cdata)

    def process(self, op, args, kwargs):
        kernel = op.functorch_table[TransformType.Functionalize]
        return kernel(self, *args, **kwargs)

    def functionalize_add_back_views(self):
        return self._cptr.functionalizeAddBackViews()


def coerce_cinterpreter(cinterpreter: CInterpreter) -> FuncTorchInterpreter:
    key = cinterpreter.key()
    if key == TransformType.Grad:
        return GradInterpreter(cinterpreter)
    if key == TransformType.Vmap:
        return VmapInterpreter(cinterpreter)
    if key == TransformType.Jvp:
        return JvpInterpreter(cinterpreter)
    if key == TransformType.Functionalize:
        return FunctionalizeInterpreter(cinterpreter)
    raise RuntimeError(f"NYI: PyDispatcher has not implemented support for {key}")


def retrieve_current_functorch_interpreter():
    interpreter = torch._C._functorch.peek_interpreter_stack()
    assert interpreter is not None
    return coerce_cinterpreter(interpreter)


def dispatch_functorch(op, args, kwargs):
    interpreter = retrieve_current_functorch_interpreter()
    args, kwargs = pytree.tree_map_only(
        torch.Tensor, torch._C._functorch.unwrap_if_dead, (args, kwargs))
    return interpreter.process(op, args, kwargs)

<END>

<START>
from .module import Module
from .. import functional as F

from torch import Tensor

__all__ = ['PairwiseDistance', 'CosineSimilarity']

class PairwiseDistance(Module):

    __constants__ = ['norm', 'eps', 'keepdim']
    norm: float
    eps: float
    keepdim: bool

    def __init__(self, p: float = 2., eps: float = 1e-6, keepdim: bool = False) -> None:
        super().__init__()
        self.norm = p
        self.eps = eps
        self.keepdim = keepdim

    def forward(self, x1: Tensor, x2: Tensor) -> Tensor:
        return F.pairwise_distance(x1, x2, self.norm, self.eps, self.keepdim)


class CosineSimilarity(Module):

    __constants__ = ['dim', 'eps']
    dim: int
    eps: float

    def __init__(self, dim: int = 1, eps: float = 1e-8) -> None:
        super().__init__()
        self.dim = dim
        self.eps = eps

    def forward(self, x1: Tensor, x2: Tensor) -> Tensor:
        return F.cosine_similarity(x1, x2, self.dim, self.eps)

<END>

<START>

import torch
import torch._inductor

aten = torch.ops.aten
prims = torch.ops.prims

from torch._inductor.pattern_matcher import (
   Arg,
   CallFunction,
   CallFunctionVarArgs,
   CallMethod,
   CallMethodVarArgs,
   CallModule,
   CallModuleVarArgs,
   ExclusiveKeywordArg,
   Ignored,
   KeywordArg,
   ListOf,
   MultiOutputPattern,
   PatternExpr,
   RepeatedExpr,
   _TargetArgsExpr,
   _TargetExpr,
   _TargetExprVarArgs,
)
expand_default = CallFunction(aten.expand.default, KeywordArg('query'), Ignored())
view_default = CallFunction(aten.view.default, expand_default, Ignored(), _users=2)
permute_default = CallFunction(aten.permute.default, KeywordArg('key'), Ignored())
expand_default_1 = CallFunction(aten.expand.default, permute_default, Ignored())
view_default_1 = CallFunction(aten.view.default, expand_default_1, Ignored(), _users=2)
bmm_default = CallFunction(aten.bmm.default, view_default, view_default_1)
view_default_2 = CallFunction(aten.view.default, bmm_default, Ignored())
mul_Tensor = CallFunction(aten.mul.Tensor, view_default_2, KeywordArg('scale_factor'), _users=2)
amax_default = CallFunction(aten.amax.default, mul_Tensor, Ignored(), True)
sub_Tensor = CallFunction(aten.sub.Tensor, mul_Tensor, amax_default)
exp_default = CallFunction(aten.exp.default, sub_Tensor, _users=2)
sum_dim_IntList = CallFunction(aten.sum.dim_IntList, exp_default, Ignored(), True)
div_Tensor = CallFunction(aten.div.Tensor, exp_default, sum_dim_IntList, _users=2)
expand_default_2 = CallFunction(aten.expand.default, div_Tensor, Ignored())
view_default_3 = CallFunction(aten.view.default, expand_default_2, Ignored(), _users=2)
expand_default_3 = CallFunction(aten.expand.default, KeywordArg('value'), Ignored())
view_default_4 = CallFunction(aten.view.default, expand_default_3, Ignored(), _users=2)
bmm_default_1 = CallFunction(aten.bmm.default, view_default_3, view_default_4)
view_default_5 = CallFunction(aten.view.default, bmm_default_1, Ignored())
view_default_6 = CallFunction(aten.view.default, KeywordArg('tangents_1'), Ignored(), _users=2)
permute_default_1 = CallFunction(aten.permute.default, view_default_4, Ignored())
bmm_default_2 = CallFunction(aten.bmm.default, view_default_6, permute_default_1)
view_default_7 = CallFunction(aten.view.default, bmm_default_2, Ignored())
alias_default = CallFunction(aten.alias.default, div_Tensor)
alias_default_1 = CallFunction(aten.alias.default, alias_default)
alias_default_2 = CallFunction(aten.alias.default, alias_default_1)
alias_default_3 = CallFunction(aten.alias.default, alias_default_2, _users=2)
mul_Tensor_1 = CallFunction(aten.mul.Tensor, view_default_7, alias_default_3, _users=2)
sum_dim_IntList_1 = CallFunction(aten.sum.dim_IntList, mul_Tensor_1, Ignored(), True)
mul_Tensor_2 = CallFunction(aten.mul.Tensor, alias_default_3, sum_dim_IntList_1)
sub_Tensor_1 = CallFunction(aten.sub.Tensor, mul_Tensor_1, mul_Tensor_2)
mul_Tensor_3 = CallFunction(aten.mul.Tensor, sub_Tensor_1, KeywordArg('scale_factor'))
view_default_8 = CallFunction(aten.view.default, mul_Tensor_3, Ignored(), _users=2)
permute_default_2 = CallFunction(aten.permute.default, view_default_1, Ignored())
bmm_default_3 = CallFunction(aten.bmm.default, view_default_8, permute_default_2)
view_default_9 = CallFunction(aten.view.default, bmm_default_3, Ignored())
permute_default_3 = CallFunction(aten.permute.default, view_default, Ignored())
bmm_default_4 = CallFunction(aten.bmm.default, permute_default_3, view_default_8)
view_default_10 = CallFunction(aten.view.default, bmm_default_4, Ignored())
permute_default_4 = CallFunction(aten.permute.default, view_default_10, Ignored())
permute_default_5 = CallFunction(aten.permute.default, view_default_3, Ignored())
bmm_default_5 = CallFunction(aten.bmm.default, permute_default_5, view_default_6)
view_default_11 = CallFunction(aten.view.default, bmm_default_5, Ignored())
_sfdp_pattern_2_training = MultiOutputPattern([view_default_5,
  view_default_9,
  permute_default_4,
  view_default_11,
  None
])


expand_default = CallFunction(aten.expand.default, KeywordArg('query'), Ignored())
view_default = CallFunction(aten.view.default, expand_default, Ignored())
permute_default = CallFunction(aten.permute.default, KeywordArg('key'), Ignored())
expand_default_1 = CallFunction(aten.expand.default, permute_default, Ignored())
view_default_1 = CallFunction(aten.view.default, expand_default_1, Ignored())
bmm_default = CallFunction(aten.bmm.default, view_default, view_default_1)
view_default_2 = CallFunction(aten.view.default, bmm_default, Ignored())
mul_Tensor = CallFunction(aten.mul.Tensor, view_default_2, KeywordArg('scale_factor'), _users=2)
amax_default = CallFunction(aten.amax.default, mul_Tensor, Ignored(), True)
sub_Tensor = CallFunction(aten.sub.Tensor, mul_Tensor, amax_default)
exp_default = CallFunction(aten.exp.default, sub_Tensor, _users=2)
sum_dim_IntList = CallFunction(aten.sum.dim_IntList, exp_default, Ignored(), True)
div_Tensor = CallFunction(aten.div.Tensor, exp_default, sum_dim_IntList)
expand_default_2 = CallFunction(aten.expand.default, div_Tensor, Ignored())
view_default_3 = CallFunction(aten.view.default, expand_default_2, Ignored())
expand_default_3 = CallFunction(aten.expand.default, KeywordArg('value'), Ignored())
view_default_4 = CallFunction(aten.view.default, expand_default_3, Ignored())
bmm_default_1 = CallFunction(aten.bmm.default, view_default_3, view_default_4)
_sfdp_pattern_2_inference = CallFunction(aten.view.default, bmm_default_1, Ignored())


expand_default = CallFunction(aten.expand.default, KeywordArg('query'), Ignored())
view_default = CallFunction(aten.view.default, expand_default, Ignored(), _users=2)
permute_default = CallFunction(aten.permute.default, KeywordArg('key'), Ignored())
expand_default_1 = CallFunction(aten.expand.default, permute_default, Ignored())
view_default_1 = CallFunction(aten.view.default, expand_default_1, Ignored(), _users=2)
bmm_default = CallFunction(aten.bmm.default, view_default, view_default_1)
view_default_2 = CallFunction(aten.view.default, bmm_default, Ignored())
mul_Tensor = CallFunction(aten.mul.Tensor, view_default_2, KeywordArg('scale_factor'))
convert_element_type_default = CallFunction(prims.convert_element_type.default, mul_Tensor, Ignored(), _users=2)
amax_default = CallFunction(aten.amax.default, convert_element_type_default, Ignored(), True)
sub_Tensor = CallFunction(aten.sub.Tensor, convert_element_type_default, amax_default)
exp_default = CallFunction(aten.exp.default, sub_Tensor, _users=2)
sum_dim_IntList = CallFunction(aten.sum.dim_IntList, exp_default, Ignored(), True)
div_Tensor = CallFunction(aten.div.Tensor, exp_default, sum_dim_IntList)
convert_element_type_default_1 = CallFunction(prims.convert_element_type.default, div_Tensor, Ignored(), _users=2)
expand_default_2 = CallFunction(aten.expand.default, convert_element_type_default_1, Ignored())
view_default_3 = CallFunction(aten.view.default, expand_default_2, Ignored(), _users=2)
expand_default_3 = CallFunction(aten.expand.default, KeywordArg('value'), Ignored())
view_default_4 = CallFunction(aten.view.default, expand_default_3, Ignored(), _users=2)
bmm_default_1 = CallFunction(aten.bmm.default, view_default_3, view_default_4)
view_default_5 = CallFunction(aten.view.default, bmm_default_1, Ignored())
view_default_6 = CallFunction(aten.view.default, KeywordArg('tangents_1'), Ignored(), _users=2)
permute_default_1 = CallFunction(aten.permute.default, view_default_4, Ignored())
bmm_default_2 = CallFunction(aten.bmm.default, view_default_6, permute_default_1)
view_default_7 = CallFunction(aten.view.default, bmm_default_2, Ignored())
convert_element_type_default_2 = CallFunction(prims.convert_element_type.default, view_default_7, Ignored())
alias_default = CallFunction(aten.alias.default, convert_element_type_default_1)
alias_default_1 = CallFunction(aten.alias.default, alias_default)
alias_default_2 = CallFunction(aten.alias.default, alias_default_1)
alias_default_3 = CallFunction(aten.alias.default, alias_default_2)
convert_element_type_default_3 = CallFunction(prims.convert_element_type.default, alias_default_3, Ignored(), _users=2)
mul_Tensor_1 = CallFunction(aten.mul.Tensor, convert_element_type_default_2, convert_element_type_default_3, _users=2)
sum_dim_IntList_1 = CallFunction(aten.sum.dim_IntList, mul_Tensor_1, Ignored(), True)
mul_Tensor_2 = CallFunction(aten.mul.Tensor, convert_element_type_default_3, sum_dim_IntList_1)
sub_Tensor_1 = CallFunction(aten.sub.Tensor, mul_Tensor_1, mul_Tensor_2)
convert_element_type_default_4 = CallFunction(prims.convert_element_type.default, sub_Tensor_1, Ignored())
mul_Tensor_3 = CallFunction(aten.mul.Tensor, convert_element_type_default_4, KeywordArg('scale_factor'))
view_default_8 = CallFunction(aten.view.default, mul_Tensor_3, Ignored(), _users=2)
permute_default_2 = CallFunction(aten.permute.default, view_default_1, Ignored())
bmm_default_3 = CallFunction(aten.bmm.default, view_default_8, permute_default_2)
view_default_9 = CallFunction(aten.view.default, bmm_default_3, Ignored())
permute_default_3 = CallFunction(aten.permute.default, view_default, Ignored())
bmm_default_4 = CallFunction(aten.bmm.default, permute_default_3, view_default_8)
view_default_10 = CallFunction(aten.view.default, bmm_default_4, Ignored())
permute_default_4 = CallFunction(aten.permute.default, view_default_10, Ignored())
permute_default_5 = CallFunction(aten.permute.default, view_default_3, Ignored())
bmm_default_5 = CallFunction(aten.bmm.default, permute_default_5, view_default_6)
view_default_11 = CallFunction(aten.view.default, bmm_default_5, Ignored())
_sfdp_pattern_2_training_half = MultiOutputPattern([view_default_5,
  view_default_9,
  permute_default_4,
  view_default_11,
  None
])


expand_default = CallFunction(aten.expand.default, KeywordArg('query'), Ignored())
view_default = CallFunction(aten.view.default, expand_default, Ignored())
permute_default = CallFunction(aten.permute.default, KeywordArg('key'), Ignored())
expand_default_1 = CallFunction(aten.expand.default, permute_default, Ignored())
view_default_1 = CallFunction(aten.view.default, expand_default_1, Ignored())
bmm_default = CallFunction(aten.bmm.default, view_default, view_default_1)
view_default_2 = CallFunction(aten.view.default, bmm_default, Ignored())
mul_Tensor = CallFunction(aten.mul.Tensor, view_default_2, KeywordArg('scale_factor'))
convert_element_type_default = CallFunction(prims.convert_element_type.default, mul_Tensor, Ignored(), _users=2)
amax_default = CallFunction(aten.amax.default, convert_element_type_default, Ignored(), True)
sub_Tensor = CallFunction(aten.sub.Tensor, convert_element_type_default, amax_default)
exp_default = CallFunction(aten.exp.default, sub_Tensor, _users=2)
sum_dim_IntList = CallFunction(aten.sum.dim_IntList, exp_default, Ignored(), True)
div_Tensor = CallFunction(aten.div.Tensor, exp_default, sum_dim_IntList)
convert_element_type_default_1 = CallFunction(prims.convert_element_type.default, div_Tensor, Ignored())
expand_default_2 = CallFunction(aten.expand.default, convert_element_type_default_1, Ignored())
view_default_3 = CallFunction(aten.view.default, expand_default_2, Ignored())
expand_default_3 = CallFunction(aten.expand.default, KeywordArg('value'), Ignored())
view_default_4 = CallFunction(aten.view.default, expand_default_3, Ignored())
bmm_default_1 = CallFunction(aten.bmm.default, view_default_3, view_default_4)
_sfdp_pattern_2_inference_half = CallFunction(aten.view.default, bmm_default_1, Ignored())

<END>

<START>
import dataclasses
import itertools
import operator
from typing import Any, Callable, Dict, List, Tuple, TYPE_CHECKING

import torch
from torch.fx import Graph, GraphModule, Node
from torch.fx.subgraph_rewriter import (
    replace_pattern_with_filters,
    ReplacedPatterns,
)
import torch.nn.functional as F
from torch.ao.quantization.fx._decomposed import quantized_decomposed_lib  # noqa: F401
from torch.ao.quantization.quantizer import (
    DerivedQuantizationSpec,
    EdgeOrNode,
    SharedQuantizationSpec,
    QuantizationSpecBase,
)
from .utils import (
    _conv1d_bn_example_inputs,
    _conv2d_bn_example_inputs,
    _is_conv,
    _is_bn_node,
    fold_bn_weights_into_conv_node,
    get_aten_graph_module,
)

if TYPE_CHECKING:
    from torch.fx.passes.utils.matcher_with_name_node_map_utils import InternalMatch

__all__ = []  # type: ignore[var-annotated]


_quantized_conv1d_bn_example_inputs = (
    torch.randn(1, 1, 3),  # x
    torch.randn(1, 1, 1),  # conv_weight
    torch.randn(1),        # bn_weight
    torch.randn(1),        # bn_bias
    torch.randn(1),        # bn_running_mean
    torch.randn(1),        # bn_running_var
)

_quantized_conv2d_bn_example_inputs = (
    torch.randn(1, 1, 3, 3),  # x
    torch.randn(1, 1, 1, 1),  # conv_weight
    torch.randn(1),           # bn_weight
    torch.randn(1),           # bn_bias
    torch.randn(1),           # bn_running_mean
    torch.randn(1),           # bn_running_var
)


def _get_quantized_conv_bn_example_inputs_kwargs(
    is_per_channel: bool,
    has_bias: bool,
    is_cuda: bool,
) -> Dict[str, Any]:
    kwargs = {}
    if is_per_channel:
        kwargs["scale"] = torch.tensor([1], dtype=torch.float)
        kwargs["zero_point"] = torch.tensor([0], dtype=torch.int)
    if has_bias:
        kwargs["conv_bias"] = torch.randn(1)
    if is_cuda:
        for k, v in kwargs.items():
            if isinstance(v, torch.Tensor):
                kwargs[k] = v.cuda()
    return kwargs

def _get_conv_bn_pattern(conv_fn: Callable) -> Callable:
    def _conv_bn_pattern(
        x: torch.Tensor,
        conv_weight: torch.Tensor,
        conv_bias: torch.Tensor,
        bn_weight: torch.Tensor,
        bn_bias: torch.Tensor,
        bn_running_mean: torch.Tensor,
        bn_running_var: torch.Tensor,
    ) -> torch.Tensor:
        x = conv_fn(x, conv_weight, conv_bias)
        x = F.batch_norm(x, bn_running_mean, bn_running_var, bn_weight, bn_bias, training=True)
        return x
    return _conv_bn_pattern

def _get_qat_conv_bn_pattern(conv_fn: Callable) -> Callable:
    def _qat_conv_bn_pattern(
        x: torch.Tensor,
        conv_weight: torch.Tensor,
        conv_bias: torch.Tensor,
        bn_weight: torch.Tensor,
        bn_bias: torch.Tensor,
        bn_running_mean: torch.Tensor,
        bn_running_var: torch.Tensor,
    ) -> torch.Tensor:
        bn_eps = 1e-5
        running_std = torch.sqrt(bn_running_var + bn_eps)
        scale_factor = bn_weight / running_std
        weight_shape = [1] * len(conv_weight.shape)
        weight_shape[0] = -1
        bias_shape = [1] * len(conv_weight.shape)
        bias_shape[1] = -1
        scaled_weight = conv_weight * scale_factor.reshape(weight_shape)
        zero_bias = torch.zeros_like(conv_bias, dtype=x.dtype)
        x = conv_fn(x, scaled_weight, zero_bias)
        x = x / scale_factor.reshape(bias_shape)
        x = x + conv_bias.reshape(bias_shape)
        x = F.batch_norm(x, bn_running_mean, bn_running_var, bn_weight, bn_bias, training=True, eps=bn_eps)
        return x
    return _qat_conv_bn_pattern

def _get_qat_conv_bn_pattern_no_conv_bias(conv_fn: Callable) -> Callable:
    def _qat_conv_bn_pattern_no_conv_bias(
        x: torch.Tensor,
        conv_weight: torch.Tensor,
        conv_bias: torch.Tensor,
        bn_weight: torch.Tensor,
        bn_bias: torch.Tensor,
        bn_running_mean: torch.Tensor,
        bn_running_var: torch.Tensor,
    ) -> torch.Tensor:
        bn_eps = 1e-5
        running_std = torch.sqrt(bn_running_var + bn_eps)
        scale_factor = bn_weight / running_std
        weight_shape = [1] * len(conv_weight.shape)
        weight_shape[0] = -1
        bias_shape = [1] * len(conv_weight.shape)
        bias_shape[1] = -1
        scaled_weight = conv_weight * scale_factor.reshape(weight_shape)
        x = conv_fn(x, scaled_weight, None)
        x = x / scale_factor.reshape(bias_shape)
        x = F.batch_norm(x, bn_running_mean, bn_running_var, bn_weight, bn_bias, training=True, eps=bn_eps)
        return x
    return _qat_conv_bn_pattern_no_conv_bias

def _append_qdq(x, is_per_channel, kwargs):
    per_channel_axis = 0
    scale = kwargs["scale"] if is_per_channel else 1.0
    zp = kwargs["zero_point"] if is_per_channel else 0
    qmin = -127
    qmax = 127
    dtype = torch.int8

    qd = torch.ops.quantized_decomposed
    if is_per_channel:
        x = qd.quantize_per_channel(x, scale, zp, per_channel_axis, qmin, qmax, dtype)
        x = qd.dequantize_per_channel(x, scale, zp, per_channel_axis, qmin, qmax, dtype)
    else:
        x = qd.quantize_per_tensor(x, scale, zp, qmin, qmax, dtype)
        x = qd.dequantize_per_tensor(x, scale, zp, qmin, qmax, dtype)
    return x

def _get_quantized_qat_conv_bn_pattern(
    is_per_channel: bool,
    has_bias: bool,
    bias_is_quantized: bool,
    conv_fn: Callable,
    bn_is_training: bool,
) -> Callable:
    bn_eps = 1e-5

    def _quantized_qat_conv_bn_pattern(
        x: torch.Tensor,
        conv_weight: torch.Tensor,
        bn_weight: torch.Tensor,
        bn_bias: torch.Tensor,
        bn_running_mean: torch.Tensor,
        bn_running_var: torch.Tensor,
        **kwargs,
    ) -> torch.Tensor:
        running_std = torch.sqrt(bn_running_var + bn_eps)
        scale_factor = bn_weight / running_std
        weight_shape = [1] * len(conv_weight.shape)
        weight_shape[0] = -1
        bias_shape = [1] * len(conv_weight.shape)
        bias_shape[1] = -1
        scaled_weight = conv_weight * scale_factor.reshape(weight_shape)
        scaled_weight = _append_qdq(scaled_weight, is_per_channel, kwargs)
        if has_bias:
            zero_bias = torch.zeros_like(kwargs["conv_bias"], dtype=x.dtype)
            if bias_is_quantized:
                zero_bias = _append_qdq(zero_bias, is_per_channel, kwargs)
            x = conv_fn(x, scaled_weight, zero_bias)
        else:
            x = conv_fn(x, scaled_weight, None)
        x = x / scale_factor.reshape(bias_shape)
        if has_bias:
            x = x + kwargs["conv_bias"].reshape(bias_shape)
        x = F.batch_norm(x, bn_running_mean, bn_running_var, bn_weight, bn_bias, training=bn_is_training, eps=bn_eps)
        return x
    return _quantized_qat_conv_bn_pattern

def _get_folded_quantized_qat_conv_bn_pattern(
    is_per_channel: bool,
    has_bias: bool,
    bias_is_quantized: bool,
    conv_fn: Callable,
    bn_is_training: bool,
) -> Callable:
    bn_eps = 1e-5

    def _folded_quantized_qat_conv_bn_pattern(
        x: torch.Tensor,
        conv_weight: torch.Tensor,
        bn_weight: torch.Tensor,
        bn_bias: torch.Tensor,
        bn_running_mean: torch.Tensor,
        bn_running_var: torch.Tensor,
        **kwargs,
    ) -> torch.Tensor:
        conv_weight = _append_qdq(conv_weight, is_per_channel, kwargs)
        if has_bias:
            bias = kwargs["conv_bias"]
            if bias_is_quantized:
                bias = _append_qdq(bias, is_per_channel, kwargs)
        else:
            bias = None
        x = conv_fn(x, conv_weight, bias)
        x = F.batch_norm(x, bn_running_mean, bn_running_var, bn_weight, bn_bias, training=bn_is_training, eps=bn_eps)
        return x
    return _folded_quantized_qat_conv_bn_pattern

def _has_conv_bias_filter(
    match: "InternalMatch",
    original_graph: Graph,
    pattern_graph: Graph,
) -> bool:
    for n in match.nodes_map.values():
        if _is_conv(n):
            return len(n.args) > 2 and n.args[2] is not None
    raise ValueError("Could not find conv node in matched conv + bn pattern")

def _no_conv_bias_filter(
    match: "InternalMatch",
    original_graph: Graph,
    pattern_graph: Graph,
) -> bool:
    return not _has_conv_bias_filter(match, original_graph, pattern_graph)

def _is_quantize(n: Node) -> bool:
    return n.target in [
        torch.ops.quantized_decomposed.quantize_per_tensor.default,
        torch.ops.quantized_decomposed.quantize_per_tensor.tensor,
        torch.ops.quantized_decomposed.quantize_per_channel.default,
    ]

def _is_dequantize(n: Node) -> bool:
    return n.target in [
        torch.ops.quantized_decomposed.dequantize_per_tensor.default,
        torch.ops.quantized_decomposed.dequantize_per_tensor.tensor,
        torch.ops.quantized_decomposed.dequantize_per_channel.default,
    ]

def _get_conv_bn_pattern_nodes(r: ReplacedPatterns) -> Dict[str, Tuple[Node, Node]]:
    def _get_nodes(nodes: List[Node]) -> Tuple[Node, Node, Node]:
        conv_node, bn_node, getitem_node = None, None, None
        for n in nodes:
            if n.op != "call_function":
                continue
            if _is_conv(n):
                assert conv_node is None
                conv_node = n
            if _is_bn_node(n):
                assert bn_node is None
                bn_node = n
            if n.target == operator.getitem:
                assert getitem_node is None
                getitem_node = n
        assert conv_node is not None
        assert bn_node is not None
        assert getitem_node is not None
        return (conv_node, bn_node, getitem_node)

    def _get_q_dq_nodes(n: Node) -> Tuple[Node, Node, Node]:
        assert _is_dequantize(n)
        q_node = n.args[0]
        assert isinstance(q_node, Node)
        assert _is_quantize(q_node)
        orig_node = q_node.args[0]
        assert isinstance(orig_node, Node)
        return (orig_node, q_node, n)

    original_nodes = list(_filter_nodes_map(r.nodes_map).values())
    o_conv, o_bn, o_getitem = _get_nodes(original_nodes)
    r_conv, r_bn, r_getitem = _get_nodes(r.replacements)

    mapping = {
        "conv": (o_conv, r_conv),
        "bn": (o_bn, r_bn),
        "getitem": (o_getitem, r_getitem),
    }

    (p_conv, _, _) = _get_nodes(list(r.nodes_map.keys()))
    (p_conv_input, p_conv_weight, *_) = p_conv.args
    (r_conv_input, r_conv_weight, *_) = r_conv.args
    assert isinstance(p_conv_input, Node)
    assert isinstance(p_conv_weight, Node)
    assert isinstance(r_conv_input, Node)
    assert isinstance(r_conv_weight, Node)
    o_conv_input = r.nodes_map[p_conv_input]
    o_conv_weight = r.nodes_map[p_conv_weight]

    if _is_dequantize(p_conv_weight):
        p_conv_weight, p_conv_weight_q, p_conv_weight_dq = _get_q_dq_nodes(p_conv_weight)
        r_conv_weight, r_conv_weight_q, r_conv_weight_dq = _get_q_dq_nodes(r_conv_weight)
        o_conv_weight = r.nodes_map[p_conv_weight]
        o_conv_weight_q = r.nodes_map[p_conv_weight_q]
        o_conv_weight_dq = r.nodes_map[p_conv_weight_dq]
        mapping["conv_weight_q"] = (o_conv_weight_q, r_conv_weight_q)
        mapping["conv_weight_dq"] = (o_conv_weight_dq, r_conv_weight_dq)
    mapping["conv_input"] = (o_conv_input, r_conv_input)
    mapping["conv_weight"] = (o_conv_weight, r_conv_weight)

    if len(p_conv.args) > 2 and len(r_conv.args) > 2:
        p_conv_bias = p_conv.args[2]
        r_conv_bias = r_conv.args[2]
        assert isinstance(p_conv_bias, Node)
        assert isinstance(r_conv_bias, Node)
        o_conv_bias = r.nodes_map[p_conv_bias]

        if _is_dequantize(p_conv_bias):
            p_conv_bias, p_conv_bias_q, p_conv_bias_dq = _get_q_dq_nodes(p_conv_bias)
            r_conv_bias, r_conv_bias_q, r_conv_bias_dq = _get_q_dq_nodes(r_conv_bias)
            o_conv_bias = r.nodes_map[p_conv_bias]
            o_conv_bias_q = r.nodes_map[p_conv_bias_q]
            o_conv_bias_dq = r.nodes_map[p_conv_bias_dq]
            mapping["conv_bias_q"] = (o_conv_bias_q, r_conv_bias_q)
            mapping["conv_bias_dq"] = (o_conv_bias_dq, r_conv_bias_dq)
        mapping["conv_bias"] = (o_conv_bias, r_conv_bias)
    return mapping

def _filter_nodes_map(nodes_map: Dict[Node, Node]) -> Dict[Node, Node]:
    new_nodes_map: Dict[Node, Node] = {}
    for pattern_node, graph_node in nodes_map.items():
        if graph_node is None:
            continue
        if pattern_node.op == "placeholder":
            continue
        new_nodes_map[pattern_node] = graph_node
    return new_nodes_map

def _copy_over_literal_conv_args(original_node: Node, new_node: Node):
    assert _is_conv(original_node)
    assert _is_conv(new_node)
    new_args = list(new_node.args)
    if len(new_args) < 3:
        new_args.append(None)
    new_node.args = tuple(new_args[:3]) + original_node.args[3:]

def _update_conv_input_qspec_map_after_replacement(original_node: Node, replacement_node: Node):
    assert _is_conv(original_node)
    assert _is_conv(replacement_node)
    if "quantization_annotation" not in original_node.meta:
        return
    original_input_qspec_map = original_node.meta["quantization_annotation"].input_qspec_map
    input_qspec_map = {}
    all_configs = list(original_input_qspec_map.items())
    input_qspec_map[replacement_node.args[0]] = all_configs[0][1]
    input_qspec_map[replacement_node.args[1]] = all_configs[1][1]
    if len(replacement_node.args) > 2 and len(all_configs) > 2:
        input_qspec_map[replacement_node.args[2]] = all_configs[2][1]
    replacement_node.meta["quantization_annotation"].input_qspec_map = input_qspec_map

def _update_special_qspecs_after_replacement(
    node: Node,
    original_to_replacement_node: Dict[Node, Node],
):
    def _get_new_edge_or_node(edge_or_node: EdgeOrNode):
        if isinstance(edge_or_node, Node):
            _node = edge_or_node
            return original_to_replacement_node.get(_node, _node)
        elif isinstance(edge_or_node, tuple) and len(edge_or_node) == 2 and all(isinstance(x, Node) for x in edge_or_node):
            src, dest = edge_or_node
            return (
                original_to_replacement_node.get(src, src),
                original_to_replacement_node.get(dest, dest),
            )
        else:
            raise ValueError("unexpected type for edge_or_node: ", type(edge_or_node))

    def _get_new_qspec(qspec: QuantizationSpecBase):
        if isinstance(qspec, SharedQuantizationSpec):
            new_edge_or_node = _get_new_edge_or_node(qspec.edge_or_node)
            return SharedQuantizationSpec(new_edge_or_node)
        elif isinstance(qspec, DerivedQuantizationSpec):
            new_derived_from = [_get_new_edge_or_node(x) for x in qspec.derived_from]
            return dataclasses.replace(qspec, derived_from=new_derived_from)
        else:
            return qspec

    if "quantization_annotation" not in node.meta:
        return
    annotation = node.meta["quantization_annotation"]
    for input_node, qspec in annotation.input_qspec_map.items():
        annotation.input_qspec_map[input_node] = _get_new_qspec(qspec)
    annotation.output_qspec = _get_new_qspec(annotation.output_qspec)

def _fuse_conv_bn_qat(m: GraphModule) -> GraphModule:
    has_bn = any(_is_bn_node(n) for n in m.graph.nodes)
    if not has_bn:
        return m
    m = _fuse_conv_bn_qat_helper(m, F.conv1d, _conv1d_bn_example_inputs, is_cuda=False)
    m = _fuse_conv_bn_qat_helper(m, F.conv2d, _conv2d_bn_example_inputs, is_cuda=False)
    if torch.cuda.is_available():
        m = _fuse_conv_bn_qat_helper(m, F.conv1d, _conv1d_bn_example_inputs, is_cuda=True)
        m = _fuse_conv_bn_qat_helper(m, F.conv2d, _conv2d_bn_example_inputs, is_cuda=True)
    return m

def _fuse_conv_bn_qat_helper(
    m: GraphModule,
    conv_fn: Callable,
    example_inputs: Tuple[Any, ...],
    is_cuda: bool,
) -> GraphModule:
    m.graph.eliminate_dead_code()
    m.recompile()
    conv_bn_pattern = _get_conv_bn_pattern(conv_fn)
    match_pattern = get_aten_graph_module(conv_bn_pattern, example_inputs, is_cuda)


    qat_conv_bn_pattern = _get_qat_conv_bn_pattern(conv_fn)
    replacement_pattern_with_conv_bias = get_aten_graph_module(
        qat_conv_bn_pattern,
        example_inputs,
        is_cuda,
    )
    replacements_with_conv_bias = replace_pattern_with_filters(
        m,
        match_pattern,
        replacement_pattern_with_conv_bias,
        match_filters=[_has_conv_bias_filter],
        ignore_literals=True,
    )
    m.recompile()


    qat_conv_bn_pattern_no_conv_bias = _get_qat_conv_bn_pattern_no_conv_bias(conv_fn)
    replacement_pattern_no_conv_bias = get_aten_graph_module(
        qat_conv_bn_pattern_no_conv_bias,
        example_inputs,
        is_cuda,
    )
    replacements_no_conv_bias = replace_pattern_with_filters(
        m,
        match_pattern,
        replacement_pattern_no_conv_bias,
        match_filters=[_no_conv_bias_filter],
        ignore_literals=True,
    )
    m.recompile()


    all_original_to_replacement_nodes = {}
    for r in replacements_with_conv_bias + replacements_no_conv_bias:
        for original_node, replacement_node in _get_conv_bn_pattern_nodes(r).values():
            replacement_node.meta = original_node.meta
            if _is_conv(original_node):
                _copy_over_literal_conv_args(original_node, replacement_node)
                _update_conv_input_qspec_map_after_replacement(original_node, replacement_node)
            all_original_to_replacement_nodes[original_node] = replacement_node

    for n in m.graph.nodes:
        _update_special_qspecs_after_replacement(n, all_original_to_replacement_nodes)

    return m

def _duplicate_dequantize_node(m: GraphModule):
    dq_op = torch.ops.quantized_decomposed.dequantize_per_tensor
    for n in m.graph.nodes:
        if n.op != "call_function" or n.target != dq_op or len(n.users) == 1:
            continue
        for user in list(n.users):
            with m.graph.inserting_before(n):
                new_node = m.graph.create_node("call_function", dq_op, n.args, n.kwargs)
            user.replace_input_with(n, new_node)
        m.graph.erase_node(n)
    m.recompile()

def _remove_extra_dequantize(m: GraphModule):
    dq_op = torch.ops.quantized_decomposed.dequantize_per_tensor
    for n in m.graph.nodes:
        dq_users = [user for user in n.users if user.op == "call_function" and user.target == dq_op]
        if len(dq_users) > 1:
            with m.graph.inserting_after(dq_users[0]):
                new_node = m.graph.create_node("call_function", dq_op, dq_users[0].args, {})
            for dq_user in dq_users:
                dq_user.replace_all_uses_with(new_node)
                m.graph.erase_node(dq_user)
    m.recompile()

def _copy_over_q_dq_args(original_node: Node, replacement_node: Node):
    assert original_node.target == replacement_node.target
    if original_node.target in (
        torch.ops.quantized_decomposed.quantize_per_tensor.default,
        torch.ops.quantized_decomposed.dequantize_per_tensor.default,
    ):
        start_copy_arg_index = 1
    elif original_node.target in (
        torch.ops.quantized_decomposed.quantize_per_channel.default,
        torch.ops.quantized_decomposed.dequantize_per_channel.default,
    ):
        start_copy_arg_index = 3
    else:
        raise ValueError("Expected quantize/dequantize nodes, got '%s'" % original_node.target)
    replacement_node.args = (
        replacement_node.args[:start_copy_arg_index] + original_node.args[start_copy_arg_index:]
    )

def _fold_conv_bn_qat(m: GraphModule) -> GraphModule:
    has_bn = any(_is_bn_node(n) for n in m.graph.nodes)
    if not has_bn:
        return m
    m = _fold_conv_bn_qat_helper(m, F.conv1d, _quantized_conv1d_bn_example_inputs, is_cuda=False)
    m = _fold_conv_bn_qat_helper(m, F.conv2d, _quantized_conv2d_bn_example_inputs, is_cuda=False)
    if torch.cuda.is_available():
        m = _fold_conv_bn_qat_helper(m, F.conv1d, _quantized_conv1d_bn_example_inputs, is_cuda=True)
        m = _fold_conv_bn_qat_helper(m, F.conv2d, _quantized_conv2d_bn_example_inputs, is_cuda=True)
    return m

def _fold_conv_bn_qat_helper(
    m: GraphModule,
    conv_fn: Callable,
    example_inputs: Tuple[Any, ...],
    is_cuda: bool,
) -> GraphModule:
    m.graph.eliminate_dead_code()
    m.recompile()
    _duplicate_dequantize_node(m)

    replacements = []
    replacement_options = itertools.product(
        [True, False],  # is_per_channel
        [True, False],  # has_bias
        [True, False],  # bias_is_quantized
        [True, False],  # bn_is_training
    )
    for is_per_channel, has_bias, bias_is_quantized, bn_is_training in replacement_options:
        if not has_bias and bias_is_quantized:
            continue
        kwargs = _get_quantized_conv_bn_example_inputs_kwargs(is_per_channel, has_bias, is_cuda)
        match_pattern = _get_quantized_qat_conv_bn_pattern(
            is_per_channel, has_bias, bias_is_quantized, conv_fn, bn_is_training
        )
        match_pattern = get_aten_graph_module(match_pattern, example_inputs, is_cuda, **kwargs)
        replacement_pattern = _get_folded_quantized_qat_conv_bn_pattern(
            is_per_channel, has_bias, bias_is_quantized, conv_fn, bn_is_training
        )
        replacement_pattern = get_aten_graph_module(replacement_pattern, example_inputs, is_cuda, **kwargs)
        replacements.extend(
            replace_pattern_with_filters(
                m,
                match_pattern,
                replacement_pattern,
                ignore_literals=True,
            )
        )
    m.recompile()
    _remove_extra_dequantize(m)

    for r in replacements:
        node_map = _get_conv_bn_pattern_nodes(r)

        for original_node, replacement_node in node_map.values():
            replacement_node.meta = original_node.meta

        _copy_over_q_dq_args(*node_map["conv_weight_q"])
        _copy_over_q_dq_args(*node_map["conv_weight_dq"])
        if "conv_bias_q" in node_map:
            assert "conv_bias_dq" in node_map
            _copy_over_q_dq_args(*node_map["conv_bias_q"])
            _copy_over_q_dq_args(*node_map["conv_bias_dq"])

        conv_bias = None
        (_, conv_node) = node_map["conv"]
        (_, bn_node) = node_map["bn"]
        (_, conv_weight) = node_map["conv_weight"]
        if "conv_bias" in node_map:
            (_, conv_bias) = node_map["conv_bias"]
        fold_bn_weights_into_conv_node(conv_node, conv_weight, conv_bias, bn_node, m)

        for original_node in _filter_nodes_map(r.nodes_map).values():
            if _is_conv(original_node):
                _copy_over_literal_conv_args(original_node, conv_node)

    m.graph.eliminate_dead_code()
    m.recompile()
    return m

<END>

<START>
from __future__ import annotations

import contextlib

from typing import Callable, Mapping, Optional

import torch
import torch._ops
import torch.fx
from torch._dispatch import python as python_dispatch
from torch._subclasses import fake_tensor
from torch.fx.experimental import proxy_tensor
from torch.onnx._internal import _beartype
from torch.onnx._internal.fx import _pass, diagnostics
from torch.onnx._internal.fx.passes import _utils


class Decompose(_pass.Transform):
    def __init__(
        self,
        diagnostic_context: diagnostics.DiagnosticContext,
        module: torch.fx.GraphModule,
        decomposition_table: Mapping[torch._ops.OpOverload, Callable],
        enable_dynamic_axes: bool,
        allow_fake_constant: Optional[bool] = False,
    ):
        super().__init__(diagnostic_context, module)
        self.decomposition_table = decomposition_table
        self.enable_dynamic_axes = enable_dynamic_axes
        self.allow_fake_constant = allow_fake_constant

    @_beartype.beartype
    def _run(self, *args, **kwargs) -> torch.fx.GraphModule:
        assert not kwargs, "kwargs is not supported in Decompose."

        module = _utils.wrap_graph_module_for_node_meta_preservation(self.module)




        fake_mode: Optional[fake_tensor.FakeTensorMode] = self.fake_mode
        maybe_fake_args = self._maybe_fakefy_args(fake_mode, *args)
        if fake_mode is not None:
            tracing_mode = "real"
        else:
            fake_mode = contextlib.nullcontext()  # type: ignore[assignment]
            tracing_mode = "symbolic" if self.enable_dynamic_axes else "fake"

        assert fake_mode is not None  # for mypy
        with proxy_tensor.maybe_disable_fake_tensor_mode(), python_dispatch.enable_python_dispatcher(), (
            fake_mode
        ):
            decomposed_module = proxy_tensor.make_fx(
                module,
                decomposition_table=self.decomposition_table,
                tracing_mode=tracing_mode,
                _allow_non_fake_inputs=True,
                _allow_fake_constant=self.allow_fake_constant,
            )(*maybe_fake_args)

        _utils.replace_placeholder_name_and_target(decomposed_module, self.module)

        return decomposed_module

<END>

<START>
from ._sfdp_pattern_1 import (_sfdp_pattern_1_training, _sfdp_pattern_1_inference, _sfdp_pattern_1_training_half, _sfdp_pattern_1_inference_half)
from ._sfdp_pattern_2 import (_sfdp_pattern_2_training, _sfdp_pattern_2_inference, _sfdp_pattern_2_training_half, _sfdp_pattern_2_inference_half)
from ._sfdp_pattern_3 import (_sfdp_pattern_3_training, _sfdp_pattern_3_inference, _sfdp_pattern_3_training_half, _sfdp_pattern_3_inference_half)
from ._sfdp_pattern_4 import (_sfdp_pattern_4_training, _sfdp_pattern_4_inference, _sfdp_pattern_4_training_half, _sfdp_pattern_4_inference_half)
from ._sfdp_pattern_5 import (_sfdp_pattern_5_training, _sfdp_pattern_5_inference, _sfdp_pattern_5_training_half, _sfdp_pattern_5_inference_half)
from ._sfdp_pattern_6 import (_sfdp_pattern_6_training, _sfdp_pattern_6_inference, _sfdp_pattern_6_training_half, _sfdp_pattern_6_inference_half)
from ._sfdp_pattern_7 import (_sfdp_pattern_7_training, _sfdp_pattern_7_inference, _sfdp_pattern_7_training_half, _sfdp_pattern_7_inference_half)
from ._sfdp_pattern_8 import (_sfdp_pattern_8_training, _sfdp_pattern_8_inference, _sfdp_pattern_8_training_half, _sfdp_pattern_8_inference_half)
from ._sfdp_pattern_9 import (_sfdp_pattern_9_training, _sfdp_pattern_9_inference, _sfdp_pattern_9_training_half, _sfdp_pattern_9_inference_half)
from ._sfdp_pattern_10 import (_sfdp_pattern_10_training, _sfdp_pattern_10_inference, _sfdp_pattern_10_training_half, _sfdp_pattern_10_inference_half)
from ._sfdp_pattern_11 import (_sfdp_pattern_11_training, _sfdp_pattern_11_inference, _sfdp_pattern_11_training_half, _sfdp_pattern_11_inference_half)
from ._sfdp_pattern_12 import (_sfdp_pattern_12_training, _sfdp_pattern_12_inference, _sfdp_pattern_12_training_half, _sfdp_pattern_12_inference_half)
from ._sfdp_pattern_13 import (_sfdp_pattern_13_training, _sfdp_pattern_13_inference, _sfdp_pattern_13_training_half, _sfdp_pattern_13_inference_half)

central_index = {
    '_sfdp_pattern_1_training': _sfdp_pattern_1_training,
    '_sfdp_pattern_1_inference': _sfdp_pattern_1_inference,
    '_sfdp_pattern_2_training': _sfdp_pattern_2_training,
    '_sfdp_pattern_2_inference': _sfdp_pattern_2_inference,
    '_sfdp_pattern_3_training': _sfdp_pattern_3_training,
    '_sfdp_pattern_3_inference': _sfdp_pattern_3_inference,
    '_sfdp_pattern_4_training': _sfdp_pattern_4_training,
    '_sfdp_pattern_4_inference': _sfdp_pattern_4_inference,
    '_sfdp_pattern_5_training': _sfdp_pattern_5_training,
    '_sfdp_pattern_5_inference': _sfdp_pattern_5_inference,
    '_sfdp_pattern_6_training': _sfdp_pattern_6_training,
    '_sfdp_pattern_6_inference': _sfdp_pattern_6_inference,
    '_sfdp_pattern_7_training': _sfdp_pattern_7_training,
    '_sfdp_pattern_7_inference': _sfdp_pattern_7_inference,
    '_sfdp_pattern_8_training': _sfdp_pattern_8_training,
    '_sfdp_pattern_8_inference': _sfdp_pattern_8_inference,
    '_sfdp_pattern_9_training': _sfdp_pattern_9_training,
    '_sfdp_pattern_9_inference': _sfdp_pattern_9_inference,
    '_sfdp_pattern_10_training': _sfdp_pattern_10_training,
    '_sfdp_pattern_10_inference': _sfdp_pattern_10_inference,
    '_sfdp_pattern_11_training': _sfdp_pattern_11_training,
    '_sfdp_pattern_11_inference': _sfdp_pattern_11_inference,
    '_sfdp_pattern_12_training': _sfdp_pattern_12_training,
    '_sfdp_pattern_12_inference': _sfdp_pattern_12_inference,
    '_sfdp_pattern_13_training': _sfdp_pattern_13_training,
    '_sfdp_pattern_13_inference': _sfdp_pattern_13_inference,
    '_sfdp_pattern_1_training_half': _sfdp_pattern_1_training_half,
    '_sfdp_pattern_1_inference_half': _sfdp_pattern_1_inference_half,
    '_sfdp_pattern_2_training_half': _sfdp_pattern_2_training_half,
    '_sfdp_pattern_2_inference_half': _sfdp_pattern_2_inference_half,
    '_sfdp_pattern_3_training_half': _sfdp_pattern_3_training_half,
    '_sfdp_pattern_3_inference_half': _sfdp_pattern_3_inference_half,
    '_sfdp_pattern_4_training_half': _sfdp_pattern_4_training_half,
    '_sfdp_pattern_4_inference_half': _sfdp_pattern_4_inference_half,
    '_sfdp_pattern_5_training_half': _sfdp_pattern_5_training_half,
    '_sfdp_pattern_5_inference_half': _sfdp_pattern_5_inference_half,
    '_sfdp_pattern_6_training_half': _sfdp_pattern_6_training_half,
    '_sfdp_pattern_6_inference_half': _sfdp_pattern_6_inference_half,
    '_sfdp_pattern_7_training_half': _sfdp_pattern_7_training_half,
    '_sfdp_pattern_7_inference_half': _sfdp_pattern_7_inference_half,
    '_sfdp_pattern_8_training_half': _sfdp_pattern_8_training_half,
    '_sfdp_pattern_8_inference_half': _sfdp_pattern_8_inference_half,
    '_sfdp_pattern_9_training_half': _sfdp_pattern_9_training_half,
    '_sfdp_pattern_9_inference_half': _sfdp_pattern_9_inference_half,
    '_sfdp_pattern_10_training_half': _sfdp_pattern_10_training_half,
    '_sfdp_pattern_10_inference_half': _sfdp_pattern_10_inference_half,
    '_sfdp_pattern_11_training_half': _sfdp_pattern_11_training_half,
    '_sfdp_pattern_11_inference_half': _sfdp_pattern_11_inference_half,
    '_sfdp_pattern_12_training_half': _sfdp_pattern_12_training_half,
    '_sfdp_pattern_12_inference_half': _sfdp_pattern_12_inference_half,
    '_sfdp_pattern_13_training_half': _sfdp_pattern_13_training_half,
    '_sfdp_pattern_13_inference_half': _sfdp_pattern_13_inference_half,
}


def get_serialized_pattern(key):
    import torch._inductor  # noqa: F401
    from torch._inductor import config
    if config.fallback_random:
        return None

    return central_index.get(key)

<END>

<START>
from typing import Dict, Tuple

from torch.fx._compatibility import compatibility
from torch.fx.graph import Graph

from torch.fx.graph_module import GraphModule
from torch.fx.passes.utils.matcher_utils import SubgraphMatcher
from torch.nn import Module


__all__ = ["HolderModule", "lift_subgraph_as_module", "compare_graphs"]


@compatibility(is_backward_compatible=False)
class HolderModule(Module):

    def __init__(self, d):
        super().__init__()
        for k, v in d.items():
            self.add_module(k, v)


@compatibility(is_backward_compatible=False)
def lift_subgraph_as_module(
    gm: GraphModule,
    subgraph: Graph,
    comp_name: str = "",
    class_name: str = "GraphModule",
) -> Tuple[GraphModule, Dict[str, str]]:

    submodule = HolderModule({})
    orig_to_split_fqn_mapping: Dict[str, str] = {}
    for n in subgraph.nodes:
        if n.op not in ("call_module", "get_attr"):
            continue

        target = n.target
        assert isinstance(target, str)
        target_name_parts = target.split(".")
        curr = submodule
        orig_gm = gm

        for name in target_name_parts[:-1]:
            if not hasattr(curr, name):
                curr.add_module(name, HolderModule({}))

            curr = getattr(curr, name)
            orig_gm = getattr(orig_gm, name)

        leaf_node_name = target_name_parts[-1]
        leaf_node = getattr(orig_gm, leaf_node_name)

        orig_to_split_fqn_mapping[target] = f"{comp_name}.{target}"
        setattr(curr, leaf_node_name, leaf_node)

    return GraphModule(submodule, subgraph, class_name), orig_to_split_fqn_mapping


@compatibility(is_backward_compatible=False)
def compare_graphs(left: Graph, right: Graph) -> bool:

    matcher = SubgraphMatcher(left, match_output=True, match_placeholder=True)
    matches = matcher.match(right)

    return len(matches) > 0

<END>

<START>
from typing import Optional, Tuple, Union
from numbers import Number
import torch
from torch.utils.benchmark import FuzzedTensor
import math

class FuzzedSparseTensor(FuzzedTensor):
    def __init__(
        self,
        name: str,
        size: Tuple[Union[str, int], ...],
        min_elements: Optional[int] = None,
        max_elements: Optional[int] = None,
        dim_parameter: Optional[str] = None,
        sparse_dim: Optional[str] = None,
        nnz: Optional[str] = None,
        density: Optional[str] = None,
        coalesced: Optional[str] = None,
        dtype=torch.float32,
        cuda=False
    ):
        super().__init__(name=name, size=size, min_elements=min_elements,
                         max_elements=max_elements, dim_parameter=dim_parameter, dtype=dtype, cuda=cuda)
        self._density = density
        self._coalesced = coalesced
        self._sparse_dim = sparse_dim

    @staticmethod
    def sparse_tensor_constructor(size, dtype, sparse_dim, nnz, is_coalesced):
        if isinstance(size, Number):
            size = [size] * sparse_dim
        assert all(size[d] > 0 for d in range(sparse_dim)) or nnz == 0, 'invalid arguments'
        v_size = [nnz] + list(size[sparse_dim:])
        if dtype.is_floating_point:
            v = torch.rand(size=v_size, dtype=dtype, device="cpu")
        else:
            v = torch.randint(1, 127, size=v_size, dtype=dtype, device="cpu")

        i = torch.rand(sparse_dim, nnz, device="cpu")
        i.mul_(torch.tensor(size[:sparse_dim]).unsqueeze(1).to(i))
        i = i.to(torch.long)

        if not is_coalesced:
            v = torch.cat([v, torch.randn_like(v)], 0)
            i = torch.cat([i, i], 1)

        x = torch.sparse_coo_tensor(i, v, torch.Size(size))
        if is_coalesced:
            x = x.coalesce()
        return x

    def _make_tensor(self, params, state):
        size, _, _ = self._get_size_and_steps(params)
        density = params['density']
        nnz = math.ceil(sum(size) * density)
        assert nnz <= sum(size)

        is_coalesced = params['coalesced']
        sparse_dim = params['sparse_dim'] if self._sparse_dim else len(size)
        sparse_dim = min(sparse_dim, len(size))
        tensor = self.sparse_tensor_constructor(size, self._dtype, sparse_dim, nnz, is_coalesced)

        if self._cuda:
            tensor = tensor.cuda()
        sparse_dim = tensor.sparse_dim()
        dense_dim = tensor.dense_dim()
        is_hybrid = len(size[sparse_dim:]) > 0

        properties = {
            "numel": int(tensor.numel()),
            "shape": tensor.size(),
            "is_coalesced": tensor.is_coalesced(),
            "density": density,
            "sparsity": 1.0 - density,
            "sparse_dim": sparse_dim,
            "dense_dim": dense_dim,
            "is_hybrid": is_hybrid,
            "dtype": str(self._dtype),
        }
        return tensor, properties

<END>

<START>

import signal
import threading
from . import IS_WINDOWS

from torch._C import _set_worker_pids, _remove_worker_pids  # noqa: F401
from torch._C import _error_if_any_worker_fails, _set_worker_signal_handlers  # noqa: F401

_SIGCHLD_handler_set = False


def _set_SIGCHLD_handler():
    if IS_WINDOWS:
        return
    if not isinstance(threading.current_thread(), threading._MainThread):  # type: ignore[attr-defined]
        return
    global _SIGCHLD_handler_set
    if _SIGCHLD_handler_set:
        return
    previous_handler = signal.getsignal(signal.SIGCHLD)
    if not callable(previous_handler):
        previous_handler = None

    def handler(signum, frame):
        _error_if_any_worker_fails()
        if previous_handler is not None:
            assert callable(previous_handler)
            previous_handler(signum, frame)

    signal.signal(signal.SIGCHLD, handler)
    _SIGCHLD_handler_set = True

<END>

<START>
import warnings
from collections import defaultdict
from typing import Any, Callable, DefaultDict, Iterator, List, Optional, Sized, TypeVar

import torch.utils.data.datapipes.iter.sharding

from torch.utils.data.datapipes._decorator import functional_datapipe
from torch.utils.data.datapipes.datapipe import DataChunk, IterDataPipe
from torch.utils.data.datapipes.utils.common import _check_unpickable_fn

__all__ = [
    "BatcherIterDataPipe",
    "GrouperIterDataPipe",
    "UnBatcherIterDataPipe",
]

T_co = TypeVar("T_co", covariant=True)

def __getattr__(name: str):
    if name in ["SHARDING_PRIORITIES", "ShardingFilterIterDataPipe"]:
        warnings.warn(f"`{name}` from `torch.utils.data.datapipes.iter.grouping` is going to be removed in PyTorch 2.1"
                      f"Please use `{name}` from the `torch.utils.data.datapipes.iter.sharding`",
                      category=FutureWarning, stacklevel=2)

        return getattr(torch.utils.data.datapipes.iter.sharding, name)

    raise AttributeError(f"module {__name__} has no attribute {name}")

@functional_datapipe('batch')
class BatcherIterDataPipe(IterDataPipe[DataChunk]):

    datapipe: IterDataPipe
    batch_size: int
    drop_last: bool

    def __init__(self,
                 datapipe: IterDataPipe,
                 batch_size: int,
                 drop_last: bool = False,
                 wrapper_class=DataChunk,
                 ) -> None:
        assert batch_size > 0, "Batch size is required to be larger than 0!"
        super().__init__()
        self.datapipe = datapipe
        self.batch_size = batch_size
        self.drop_last = drop_last
        self.wrapper_class = wrapper_class

    def __iter__(self) -> Iterator[DataChunk]:
        batch: List = []
        for x in self.datapipe:
            batch.append(x)
            if len(batch) == self.batch_size:
                yield self.wrapper_class(batch)
                batch = []
        if len(batch) > 0:
            if not self.drop_last:
                yield self.wrapper_class(batch)

    def __len__(self) -> int:
        if isinstance(self.datapipe, Sized):
            if self.drop_last:
                return len(self.datapipe) // self.batch_size
            else:
                return (len(self.datapipe) + self.batch_size - 1) // self.batch_size
        else:
            raise TypeError(f"{type(self).__name__} instance doesn't have valid length")


@functional_datapipe('unbatch')
class UnBatcherIterDataPipe(IterDataPipe):

    def __init__(self,
                 datapipe: IterDataPipe,
                 unbatch_level: int = 1):
        self.datapipe = datapipe
        self.unbatch_level = unbatch_level

    def __iter__(self):
        for element in self.datapipe:
            yield from self._dive(element, unbatch_level=self.unbatch_level)

    def _dive(self, element, unbatch_level):
        if unbatch_level < -1:
            raise ValueError("unbatch_level must be -1 or >= 0")
        if unbatch_level == -1:
            if isinstance(element, (list, DataChunk)):
                for item in element:
                    yield from self._dive(item, unbatch_level=-1)
            else:
                yield element
        elif unbatch_level == 0:
            yield element
        else:
            if isinstance(element, (list, DataChunk)):
                for item in element:
                    yield from self._dive(item, unbatch_level=unbatch_level - 1)
            else:
                raise IndexError(f"unbatch_level {self.unbatch_level} exceeds the depth of the DataPipe")


@functional_datapipe('groupby')
class GrouperIterDataPipe(IterDataPipe[DataChunk]):

    def __init__(self,
                 datapipe: IterDataPipe[T_co],
                 group_key_fn: Callable[[T_co], Any],
                 *,
                 keep_key: bool = False,
                 buffer_size: int = 10000,
                 group_size: Optional[int] = None,
                 guaranteed_group_size: Optional[int] = None,
                 drop_remaining: bool = False):
        _check_unpickable_fn(group_key_fn)
        self.datapipe = datapipe
        self.group_key_fn = group_key_fn

        self.keep_key = keep_key
        self.max_buffer_size = buffer_size
        self.buffer_elements: DefaultDict[Any, List] = defaultdict(list)
        self.curr_buffer_size = 0
        self.group_size = group_size
        self.guaranteed_group_size = None
        if group_size is not None and buffer_size is not None:
            assert 0 < group_size <= buffer_size
            self.guaranteed_group_size = group_size
        if guaranteed_group_size is not None:
            assert group_size is not None and 0 < guaranteed_group_size <= group_size
            self.guaranteed_group_size = guaranteed_group_size
        self.drop_remaining = drop_remaining
        self.wrapper_class = DataChunk

    def _remove_biggest_key(self):
        biggest_key = None
        biggest_size = 0
        result_to_yield = None
        for findkey in self.buffer_elements.keys():
            if len(self.buffer_elements[findkey]) > biggest_size:
                biggest_size = len(self.buffer_elements[findkey])
                biggest_key = findkey

        if self.guaranteed_group_size is not None and biggest_size < self.guaranteed_group_size and not self.drop_remaining:
            raise RuntimeError('Failed to group items', str(self.buffer_elements[biggest_key]))

        if self.guaranteed_group_size is None or biggest_size >= self.guaranteed_group_size:
            result_to_yield = self.buffer_elements[biggest_key]

        self.curr_buffer_size -= biggest_size
        del self.buffer_elements[biggest_key]

        return result_to_yield

    def __iter__(self):
        for x in self.datapipe:
            key = self.group_key_fn(x)

            self.buffer_elements[key].append(x)
            self.curr_buffer_size += 1

            if self.group_size is not None and self.group_size == len(self.buffer_elements[key]):
                result: DataChunk[Any] = self.wrapper_class(self.buffer_elements[key])
                yield (key, result) if self.keep_key else result
                self.curr_buffer_size -= len(self.buffer_elements[key])
                del self.buffer_elements[key]

            if self.curr_buffer_size == self.max_buffer_size:
                result_to_yield = self._remove_biggest_key()
                if result_to_yield is not None:
                    result = self.wrapper_class(result_to_yield)
                    yield (key, result) if self.keep_key else result

        for key in tuple(self.buffer_elements.keys()):
            result = self.wrapper_class(self.buffer_elements.pop(key))
            self.curr_buffer_size -= len(result)
            yield (key, result) if self.keep_key else result

    def reset(self) -> None:
        self.curr_buffer_size = 0
        self.buffer_elements = defaultdict(list)

    def __getstate__(self):
        state = (
            self.datapipe,
            self.group_key_fn,
            self.keep_key,
            self.max_buffer_size,
            self.group_size,
            self.guaranteed_group_size,
            self.drop_remaining,
            self.wrapper_class,
            self._valid_iterator_id,
            self._number_of_samples_yielded,
        )
        if IterDataPipe.getstate_hook is not None:
            return IterDataPipe.getstate_hook(state)
        return state

    def __setstate__(self, state):
        (
            self.datapipe,
            self.group_key_fn,
            self.keep_key,
            self.max_buffer_size,
            self.group_size,
            self.guaranteed_group_size,
            self.drop_remaining,
            self.wrapper_class,
            self._valid_iterator_id,
            self._number_of_samples_yielded,
        ) = state
        self.curr_buffer_size = 0
        self.buffer_elements = defaultdict(list)

    def __del__(self):
        self.buffer_elements.clear()

<END>

<START>
import logging
from typing import cast, List

from ...._dynamo.utils import counters

from ... import config, ir
from ...codecache import code_hash, get_path
from ...ir import ComputedBuffer, CUDATemplateBuffer, Pointwise
from ...scheduler import (
    BaseSchedulerNode,
    BaseScheduling,
    FusedSchedulerNode,
    Scheduler,
    SchedulerNode,
)
from ...utils import get_fused_kernel_name, get_kernel_metadata, sympy_product
from ...virtualized import V
from ..common import IndentedBuffer

from .cutlass_epilogue_gen import CUTLASSEVTOpNotImplementedError

log = logging.getLogger(__name__)


class CUDACPPScheduling(BaseScheduling):

    def __init__(self, scheduler: Scheduler):
        super().__init__()
        self.scheduler = scheduler

    def group_fn(self, sizes):
        return tuple(V.graph.sizevars.simplify(sympy_product(s)) for s in sizes)

    def is_cuda_cpp_template(self, node: BaseSchedulerNode) -> bool:
        return isinstance(node, SchedulerNode) and isinstance(
            node.node, CUDATemplateBuffer
        )

    def is_cuda_cpp_fused_template(self, node: BaseSchedulerNode) -> bool:
        return isinstance(node, FusedSchedulerNode) and self.is_cuda_cpp_template(
            node.get_template_node()
        )

    def _can_fuse_epilogue_impl(
        self,
        cuda_template_buffer: CUDATemplateBuffer,
        epilogue_nodes: List[ir.IRNode],
        additional_node: ir.IRNode,
    ) -> bool:
        if not isinstance(cuda_template_buffer, CUDATemplateBuffer):
            return False
        if not cuda_template_buffer.template.can_fuse_epilogue:
            return False
        if not isinstance(additional_node, ComputedBuffer):
            return False
        if not isinstance(additional_node.data, Pointwise):
            return False
        node_name = additional_node.get_computed_buffer_name()
        if node_name is None:
            return False

        if len(epilogue_nodes) == 0:
            if cuda_template_buffer.name not in additional_node.get_read_names():
                return False
        else:
            last_epilogue_node = epilogue_nodes[-1]
            assert isinstance(last_epilogue_node, ir.ComputedBuffer)  # for mypy
            last_epilogue_name = (
                last_epilogue_node.name
                if last_epilogue_node.name is not None
                else last_epilogue_node.data.name  # type: ignore[attr-defined]
            )
            if last_epilogue_name not in additional_node.get_read_names():
                return False
        if additional_node.layout != cuda_template_buffer.layout:
            return False
        try:
            from torch._inductor.codegen.cuda.cutlass_epilogue_gen import (
                CutlassEVTEpilogueArgumentFormatter,
                CutlassEVTEpilogueTypeFormatter,
            )

            CutlassEVTEpilogueTypeFormatter.ir_to_evt_string(
                cast(str, cuda_template_buffer.name), "anything", [additional_node]
            )
            CutlassEVTEpilogueArgumentFormatter.ir_to_evt_argument_string(
                cast(str, cuda_template_buffer.name), [additional_node]
            )
        except CUTLASSEVTOpNotImplementedError as e:
            not_implemented_op = str(e)
            if not_implemented_op.startswith("_op_"):
                not_implemented_op = not_implemented_op[4:]
                log.warning(
                    f"Cannot fuse epilogue node {additional_node} into {cuda_template_buffer.name}, likely due to unsupported operation: {not_implemented_op}"  # noqa: G004, B950
                )
                return False
            else:
                log.warning(
                    f"Cannot fuse epilogue node {additional_node} into {cuda_template_buffer.name}. Reason: {not_implemented_op}"  # noqa: G004, B950
                )
                return False
        return True

    @staticmethod
    def _unwrap_epilogue_nodes(fused_node: FusedSchedulerNode) -> List[ir.IRNode]:
        nodes = fused_node.get_nodes()
        template_node = fused_node.get_template_node()
        nodes.remove(template_node)
        return [n.node for n in nodes]

    def can_fuse_vertical(
        self, node1: BaseSchedulerNode, node2: BaseSchedulerNode
    ) -> bool:
        if self.is_cuda_cpp_template(node1) and isinstance(node2, SchedulerNode):
            return self._can_fuse_epilogue_impl(
                cast(CUDATemplateBuffer, node1.node), [], node2.node
            )
        elif self.is_cuda_cpp_fused_template(node1) and isinstance(
            node2, SchedulerNode
        ):
            fnode1 = cast(FusedSchedulerNode, node1)
            return self._can_fuse_epilogue_impl(
                fnode1.get_template_node().node,
                self._unwrap_epilogue_nodes(fnode1),
                node2.node,
            )
        return False

    def define_kernel(self, src_code: str, node_schedule) -> str:
        wrapper = V.graph.wrapper_code
        if src_code in wrapper.src_to_kernel:
            kernel_name = wrapper.src_to_kernel[src_code]
        else:
            fused_name = (
                get_fused_kernel_name(node_schedule, config.triton.descriptive_names)
                if config.triton.descriptive_names
                else ""
            )
            kernel_name = "_".join(["cuda", fused_name, wrapper.next_kernel_suffix()])
            wrapper.src_to_kernel[src_code] = kernel_name
            src_code = src_code.replace("KERNEL_NAME", kernel_name)

            _, _, kernel_path = get_path(code_hash(src_code), "py")

            compile_wrapper = IndentedBuffer()

            metadata_comment = f"# kernel path: {kernel_path}"
            origins, detailed_origins = get_kernel_metadata(node_schedule, wrapper)
            metadata_comment += "\n" + origins + "\n" + detailed_origins
            wrapper.define_kernel(
                kernel_name, compile_wrapper.getvalue(), metadata_comment
            )
        return kernel_name

    def codegen_template(
        self, template_node: BaseSchedulerNode, epilogue_nodes: List[SchedulerNode]
    ):
        counters["inductor"]["cuda_epilogue_fusion_counter"] += len(epilogue_nodes)
        assert self.is_cuda_cpp_template(
            template_node
        ), "Template node passed to CUDAScheduler.codegen_template must be a SchedulerNode that wraps a CUDATemplateBuffer"
        template_node = cast(SchedulerNode, template_node)
        _, (numel, rnumel) = template_node.group
        assert rnumel == 1
        ctb: CUDATemplateBuffer = cast(CUDATemplateBuffer, template_node.node)
        epilogue_ir_nodes: List[ir.Buffer] = [n.node for n in epilogue_nodes]
        assert all(
            isinstance(n, ir.ComputedBuffer) for n in epilogue_ir_nodes
        ), "Epilogue nodes must all be instances of ir.ComputedBuffer"
        kernel, render = ctb.make_kernel_render(ctb, epilogue_nodes=epilogue_ir_nodes)
        with kernel:
            for node in [template_node, *epilogue_nodes]:
                node.mark_run()
            src_code = render()

        with V.set_kernel_handler(kernel):
            node_schedule = [template_node, *epilogue_nodes]
            kernel_name = self.define_kernel(src_code, node_schedule)
        kernel.call_kernel(kernel_name, ctb, epilogue_ir_nodes)
        V.graph.removed_buffers |= kernel.removed_buffers
        self.scheduler.free_buffers()

<END>

<START>
from torch._C import DispatchKey
from torch._higher_order_ops.utils import autograd_not_implemented

from torch._ops import HigherOrderOperator
from torch._subclasses import FakeTensorMode

from torch.fx.experimental.proxy_tensor import ProxyTorchDispatchMode, track_tensor_tree
from torch.utils._python_dispatch import _get_current_dispatch_mode


__all__ = ["trace_wrapped"]




def trace_wrapped(*args, fn):
    return _trace_wrapped_op(*args, fn=fn)


_trace_wrapped_op = HigherOrderOperator("trace_wrapped")


def _assert_meta(grad, size, stride, dtype):
    assert grad.size() == size, "size mismatch"
    assert grad.stride() == stride, "stride mismatch"
    assert grad.dtype == dtype, "dtype mismatch"
    return grad


@_trace_wrapped_op.py_impl(ProxyTorchDispatchMode)
def inner_trace(mode, *args, fn):
    import torch

    assert len(args) == 1
    grad = args[0]
    assert isinstance(grad, torch.Tensor)

    def self_invoke(*args):
        return _trace_wrapped_op(*args, fn=fn)

    proxy_args = (mode.tracer.unwrap_proxy(grad),)
    out_proxy = mode.tracer.create_proxy(
        "call_function", self_invoke, proxy_args, {}, name="trace_wrapped"
    )
    grad = torch.zeros_like(grad)
    grad = track_tensor_tree(grad, out_proxy, constant=None, tracer=mode.tracer)

    proxy_args = (
        mode.tracer.unwrap_proxy(grad),
        grad.size(),
        grad.stride(),
        grad.dtype,
    )
    out_proxy = mode.tracer.create_proxy(
        "call_function",
        _assert_meta,
        proxy_args,
        {},
        name="assert",
    )
    grad = torch.empty_like(grad)
    grad = track_tensor_tree(grad, out_proxy, constant=None, tracer=mode.tracer)
    return grad


@_trace_wrapped_op.py_impl(FakeTensorMode)
def inner_fake(*args, fn):
    raise RuntimeError("This op should never be invoked here")


@_trace_wrapped_op.py_impl(DispatchKey.CompositeExplicitAutograd)
def _trace_wrapped_op_dense(*args, fn):
    mode = _get_current_dispatch_mode()
    assert mode is None, "Mode should never be enabled for CPU/CUDA key"
    return fn(*args)


_trace_wrapped_op.py_impl(DispatchKey.Autograd)(
    autograd_not_implemented(_trace_wrapped_op, deferred_error=True)
)


@_trace_wrapped_op.py_functionalize_impl
def _trace_wrapped_functionalized(ctx, *args, fn):
    unwrapped_args = ctx.unwrap_tensors(args)
    with ctx.redispatch_to_next():
        return ctx.wrap_tensors(_trace_wrapped_op(*unwrapped_args, fn=fn))

<END>

<START>
import math
from typing import List, Optional

import torch
from torch import Tensor

from .optimizer import (
    Optimizer,
    _default_to_fused_or_foreach,
    _differentiable_doc,
    _dispatch_sqrt,
    _foreach_doc,
    _get_scalar_dtype,
    _get_value,
    _stack_if_compiling,
    _use_grad_for_differentiable,
    _view_as_real,
)

__all__ = ["RAdam", "radam"]


class RAdam(Optimizer):
    def __init__(
        self,
        params,
        lr=1e-3,
        betas=(0.9, 0.999),
        eps=1e-8,
        weight_decay=0,
        decoupled_weight_decay: bool = False,
        *,
        foreach: Optional[bool] = None,
        differentiable: bool = False,
    ):
        if not 0.0 <= lr:
            raise ValueError(f"Invalid learning rate: {lr}")
        if not 0.0 <= eps:
            raise ValueError(f"Invalid epsilon value: {eps}")
        if not 0.0 <= betas[0] < 1.0:
            raise ValueError(f"Invalid beta parameter at index 0: {betas[0]}")
        if not 0.0 <= betas[1] < 1.0:
            raise ValueError(f"Invalid beta parameter at index 1: {betas[1]}")
        if not 0.0 <= weight_decay:
            raise ValueError(f"Invalid weight_decay value: {weight_decay}")
        defaults = dict(
            lr=lr,
            betas=betas,
            eps=eps,
            weight_decay=weight_decay,
            foreach=foreach,
            decoupled_weight_decay=decoupled_weight_decay,
            differentiable=differentiable,
        )
        super().__init__(params, defaults)

    def __setstate__(self, state):
        super().__setstate__(state)
        for group in self.param_groups:
            group.setdefault("foreach", None)
            group.setdefault("differentiable", False)
            group.setdefault("decoupled_weight_decay", False)
        state_values = list(self.state.values())
        step_is_tensor = (len(state_values) != 0) and torch.is_tensor(
            state_values[0]["step"]
        )
        if not step_is_tensor:
            for s in state_values:
                s["step"] = torch.tensor(float(s["step"]), dtype=_get_scalar_dtype())

    def _init_group(self, group, params_with_grad, grads, exp_avgs, exp_avg_sqs, state_steps):
        has_complex = False
        for p in group["params"]:
            if p.grad is not None:
                has_complex |= torch.is_complex(p)
                params_with_grad.append(p)
                if p.grad.is_sparse:
                    raise RuntimeError("RAdam does not support sparse gradients")
                grads.append(p.grad)

                state = self.state[p]
                if len(state) == 0:
                    state["step"] = torch.tensor(0.0, dtype=_get_scalar_dtype())
                    state["exp_avg"] = torch.zeros_like(
                        p, memory_format=torch.preserve_format
                    )
                    state["exp_avg_sq"] = torch.zeros_like(
                        p, memory_format=torch.preserve_format
                    )

                exp_avgs.append(state["exp_avg"])
                exp_avg_sqs.append(state["exp_avg_sq"])
                state_steps.append(state["step"])

        return has_complex

    @_use_grad_for_differentiable
    def step(self, closure=None):
        loss = None
        if closure is not None:
            with torch.enable_grad():
                loss = closure()

        for group in self.param_groups:
            params_with_grad = []
            grads = []
            exp_avgs = []
            exp_avg_sqs = []
            state_steps = []
            beta1, beta2 = group["betas"]

            has_complex = self._init_group(group, params_with_grad, grads, exp_avgs, exp_avg_sqs, state_steps)

            radam(
                params_with_grad,
                grads,
                exp_avgs,
                exp_avg_sqs,
                state_steps,
                beta1=beta1,
                beta2=beta2,
                lr=group["lr"],
                weight_decay=group["weight_decay"],
                eps=group["eps"],
                foreach=group["foreach"],
                differentiable=group["differentiable"],
                decoupled_weight_decay=group["decoupled_weight_decay"],
                has_complex=has_complex,
            )

        return loss


    Args:
        params (iterable): iterable of parameters to optimize or dicts defining
            parameter groups
        lr (float, optional): learning rate (default: 1e-3)
        betas (Tuple[float, float], optional): coefficients used for computing
            running averages of gradient and its square (default: (0.9, 0.999))
        eps (float, optional): term added to the denominator to improve
            numerical stability (default: 1e-8)
        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)
        decoupled_weight_decay (bool, optional): whether to use decoupled weight
            decay as in AdamW to obtain RAdamW (default: False)
        {_foreach_doc}
        {_differentiable_doc}

    .. _On the variance of the adaptive learning rate and beyond:
        https://arxiv.org/abs/1908.03265
    .. _author's implementation:
        https://github.com/LiyuanLucasLiu/RAdam
    .. _Decoupled Weight Decay Regularization:
        https://arxiv.org/abs/1711.05101


    See :class:`~torch.optim.RAdam` for details.

<END>

<START>
from enum import Enum

import torch

from torch._export.db.case import export_case


class Animal(Enum):
    COW = "moo"


@export_case(
    example_inputs=(torch.ones(3, 2),),
)
class SpecializedAttribute(torch.nn.Module):

    def __init__(self):
        super().__init__()
        self.a = "moo"
        self.b = 4

    def forward(self, x):
        if self.a == Animal.COW.value:
            return x * x + self.b
        else:
            raise ValueError("bad")

<END>

<START>
from torch.fx import GraphModule, Node

__all__ = ["generate_numeric_debug_handle"]


def generate_numeric_debug_handle(graph_module: GraphModule) -> None:
    unique_id = 0
    for node in graph_module.graph.nodes:
        if node.op == "call_function":
            node.meta["numeric_debug_handle"] = {}
            for arg in node.args:
                if isinstance(arg, Node):
                    node.meta["numeric_debug_handle"][arg] = unique_id
                    unique_id += 1

            node.meta["numeric_debug_handle"]["output"] = unique_id
            unique_id += 1

<END>

<START>
import inspect
import logging
from queue import Queue
from functools import wraps
from typing import Callable, Dict, List

import torch.nn as nn
from torch.fx.graph_module import GraphModule
from torch.fx._compatibility import compatibility
from torch.fx.passes.infra.pass_base import PassResult

logger = logging.getLogger(__name__)
logger.setLevel(logging.WARNING)

__all__ = ['pass_result_wrapper', 'this_before_that_pass_constraint', 'PassManager']

@compatibility(is_backward_compatible=False)
def pass_result_wrapper(fn: Callable) -> Callable:
    if fn is None:
        return None

    @wraps(fn)
    def wrapped_fn(gm):
        res = fn(gm)
        if res is None:
            return PassResult(gm, True)
        if isinstance(res, PassResult):
            return res
        elif isinstance(res, nn.Module):
            return PassResult(res, True)

    if not inspect.isfunction(fn):
        wrapped_fn.__name__ = type(fn).__name__

    return wrapped_fn

def _validate_pass_schedule_constraint(
    constraint: Callable[[Callable, Callable], bool], passes: List[Callable]
) -> None:
    for i, a in enumerate(passes):
        for j, b in enumerate(passes[i + 1 :]):
            if constraint(a, b):
                continue
            raise RuntimeError(
                f"pass schedule constraint violated. Expected {a} before {b}"
                f" but found {a} at index {i} and {b} at index{j} in pass"
                f" list."
            )

def _topological_sort_passes(
    passes: List[Callable], constraints: List[Callable]
) -> List[Callable]:
    if len(constraints) == 0:
        return passes

    graph: Dict[Callable, List[Callable]] = {p : [] for p in passes}
    indegree_map: Dict[Callable, int] = {p : 0 for p in passes}
    candidates: Queue = Queue()
    for a in passes:
        for b in passes:
            if a == b:
                continue

            for constraint in constraints:
                if not constraint(a, b):
                    graph[b].append(a)
                    indegree_map[a] += 1

        if indegree_map[a] == 0:
            candidates.put(a)

    visited: Dict[Callable, bool] = {p : False for p in passes}
    sorted_passes: List[Callable] = []

    while not candidates.empty():
        p = candidates.get()
        sorted_passes.append(p)
        visited[p] = True

        for n in graph[p]:
            if not visited[n]:
                indegree_map[n] -= 1
                if indegree_map[n] == 0:
                    candidates.put(n)

    cycle_passes = list(filter(lambda p: indegree_map[p] != 0, indegree_map.keys()))
    if len(cycle_passes) != 0:
        error = f"Circular dependency detected within the following passes: {cycle_passes}"
        raise RuntimeError(error)

    return sorted_passes

@compatibility(is_backward_compatible=False)
def this_before_that_pass_constraint(this: Callable, that: Callable) -> Callable:

    def depends_on(a: Callable, b: Callable):
        if a == that and b == this:
            return False
        return True

    return depends_on


@compatibility(is_backward_compatible=False)
class PassManager:

    passes: List[Callable[[nn.Module], PassResult]]
    constraints: List[Callable[[Callable, Callable], bool]]
    _validated: bool = False
    steps: int = 1

    def __init__(
        self,
        passes=None,
        constraints=None,
        steps=None,
        run_checks_after_each_pass: bool = False,
        suppress_check_failures: bool = False,
    ):
        self.passes = passes or []
        self.constraints = constraints or []
        if steps:
            self.steps = steps

        self.run_checks_after_each_pass = run_checks_after_each_pass
        self.suppress_check_failures = suppress_check_failures

    def add_pass(self, _pass: Callable):
        self.passes.append(_pass)
        self._validated = False

    def add_constraint(self, constraint: Callable):
        self.constraints.append(constraint)
        self._validated = False

    def validate_constraints(self):
        if self._validated:
            return
        for constraint in self.constraints:
            _validate_pass_schedule_constraint(constraint, self.passes)
        self._validated = True

    def solve_constraints(self):
        self.passes = _topological_sort_passes(self.passes, self.constraints)
        self._validated = True

    def add_checks(self, check: Callable) -> None:
        sig = inspect.signature(check)

        if len(list(sig.parameters.values())) != 1:
            raise TypeError("PassManager check function should only take in one variable, a module")

        setattr(self, "check", check)  # noqa: B010

    def check(self, module: nn.Module) -> None:
        pass

    def __call__(self, module: nn.Module) -> PassResult:
        if not self._validated:
            self.solve_constraints()

        self.check(module)

        overall_modified = False
        for _ in range(self.steps):
            modified = False

            for i, fn in enumerate(self.passes):
                fn_name = fn.__name__ if inspect.isfunction(fn) else type(fn).__name__
                logger.debug("Running pass '%s'", fn_name)

                try:
                    res = fn(module)

                    if not isinstance(res, PassResult) and not hasattr(
                        res, "graph_module"
                    ):
                        raise TypeError(
                            f"The result of the pass {fn_name} should be type PassResult."
                            + "Please wrap it with pass_result_wrapper()"
                        )
                    module = res.graph_module
                    modified = modified or res.modified

                    if isinstance(module, GraphModule):
                        logger.debug("Graph after pass '%s': %s", fn_name, module.graph)
                        module.recompile()

                    if self.run_checks_after_each_pass:
                        self.check(module)

                except Exception as e:
                    prev_pass_names = [
                        p.__name__ if inspect.isfunction(p) else type(p).__name__
                        for p in self.passes[:i]
                    ]
                    msg = f"An error occurred when running the '{fn_name}' pass after the following passes: {prev_pass_names}"
                    raise Exception(msg) from e

            overall_modified = overall_modified or modified
            if not modified:
                break

        return PassResult(module, overall_modified)

<END>

<START>
import torch
import unittest
from copy import deepcopy
from enum import Enum
from functools import wraps, partial
from itertools import chain, product
import itertools
import math
import torch.nn.functional as F
from torch.nn.utils.rnn import pack_padded_sequence
from torch.testing import make_tensor
from torch.testing._internal.common_cuda import TEST_CUDNN
from torch.testing._internal.common_dtype import (
    floating_types, floating_and_complex_types_and, get_all_fp_dtypes, complex_types_and)
from torch.testing._internal.common_device_type import (
    _TestParametrizer, _update_param_kwargs, toleranceOverride, tol,
    skipCUDAIfCudnnVersionLessThan, skipCUDAIfRocm, precisionOverride, skipMeta, skipMPS, skipCUDAVersionIn)
from torch.testing._internal.common_methods_invocations import DecorateInfo
from torch.testing._internal.common_nn import (
    cosineembeddingloss_reference, cross_entropy_loss_reference, ctcloss_reference,
    hingeembeddingloss_reference, huberloss_reference, kldivloss_reference,
    marginrankingloss_reference, multimarginloss_reference, multilabelmarginloss_reference,
    nllloss_reference, nlllossNd_reference, smoothl1loss_reference, softmarginloss_reference, get_reduction)
from torch.testing._internal.common_utils import (
    freeze_rng_state, set_single_threaded_if_parallel_tbb, skipIfMps, GRADCHECK_NONDET_TOL, TEST_WITH_ROCM, IS_WINDOWS)
from types import ModuleType
from typing import List, Tuple, Type, Set, Dict

MODULE_NAMESPACES: List[ModuleType] = [
    torch.nn.modules,
    torch.ao.nn.qat.modules,
    torch.ao.nn.quantizable.modules,
    torch.ao.nn.quantized.modules,
    torch.ao.nn.quantized.modules,
]

MODULES_TO_SKIP: Set[Type] = {
    torch.nn.Module,  # abstract base class
    torch.nn.Container,  # deprecated
    torch.nn.NLLLoss2d,  # deprecated
    torch.ao.nn.quantized.MaxPool2d,  # aliases to nn.MaxPool2d
    torch.ao.nn.quantized.MaxPool2d,  # aliases to nn.MaxPool2d
}

MODULE_CLASSES: List[Type] = list(chain(*[
    [getattr(namespace, module_name) for module_name in namespace.__all__]  # type: ignore[attr-defined]
    for namespace in MODULE_NAMESPACES]))
MODULE_CLASSES = [cls for cls in MODULE_CLASSES if cls not in MODULES_TO_SKIP]

MODULE_CLASS_NAMES: Dict[Type, str] = {}
for namespace in MODULE_NAMESPACES:
    for module_name in namespace.__all__:  # type: ignore[attr-defined]
        module_cls = getattr(namespace, module_name)

    def __init__(self, module_info_iterable, allowed_dtypes=None, train_eval_mode=TrainEvalMode.train_and_eval):
        self.module_info_list = list(module_info_iterable)
        self.allowed_dtypes = set(allowed_dtypes) if allowed_dtypes is not None else None
        self.train_eval_mode = train_eval_mode

    def _get_training_flags(self, module_info):
        training_flags = []
        if (self.train_eval_mode == TrainEvalMode.train_only or
                self.train_eval_mode == TrainEvalMode.train_and_eval):
            training_flags.append(True)

        if (self.train_eval_mode == TrainEvalMode.eval_only or
                self.train_eval_mode == TrainEvalMode.train_and_eval):
            training_flags.append(False)

        if not module_info.train_and_eval_differ:
            training_flags = training_flags[:1]

        return training_flags

    def _parametrize_test(self, test, generic_cls, device_cls):
        if device_cls is None:
            raise RuntimeError('The @modules decorator is only intended to be used in a device-specific '
                               'context; use it with instantiate_device_type_tests() instead of '
                               'instantiate_parametrized_tests()')

        for module_info in self.module_info_list:
            dtypes = set(module_info.dtypes)
            if self.allowed_dtypes is not None:
                dtypes = dtypes.intersection(self.allowed_dtypes)

            training_flags = self._get_training_flags(module_info)
            for (training, dtype) in product(training_flags, dtypes):
                test_name = module_info.formatted_name
                if len(training_flags) > 1:
                    test_name += f"_{'train_mode' if training else 'eval_mode'}"

                param_kwargs = {'module_info': module_info}
                _update_param_kwargs(param_kwargs, 'dtype', dtype)
                _update_param_kwargs(param_kwargs, 'training', training)

                try:

                    @wraps(test)
                    def test_wrapper(*args, **kwargs):
                        return test(*args, **kwargs)

                    decorator_fn = partial(module_info.get_decorators, generic_cls.__name__,
                                           test.__name__, device_cls.device_type, dtype)

                    yield (test_wrapper, test_name, param_kwargs, decorator_fn)
                except Exception as ex:
                    print(f"Failed to instantiate {test_name} for module {module_info.name}!")
                    raise ex


def get_module_common_name(module_cls):
    if module_cls in MODULE_CLASS_NAMES:
        return MODULE_CLASS_NAMES[module_cls]
    else:
        return module_cls.__name__


class FunctionInput:
    __slots__ = ['constructor_input', 'forward_input', 'desc', 'reference_fn']

    CONSTRUCTION_ERROR = 0
    FORWARD_ERROR = 1

class ErrorModuleInput:

    __slots__ = ["module_error_input", "error_on", "error_type", "error_regex"]

    def __init__(self,
                 module_error_input,
                 *,
                 error_on=ModuleErrorEnum.CONSTRUCTION_ERROR,
                 error_type=RuntimeError,
                 error_regex):
        self.module_error_input = module_error_input
        self.error_on = error_on
        self.error_type = error_type
        self.error_regex = error_regex


class ModuleInfo:
        ('reduction_sum', {'reduction': 'sum'}),
        ('reduction_batchmean', {'reduction': 'batchmean'}),
        ('reduction_none', {'reduction': 'none'}),
        ('log_target', {'log_target': True})
    ]

    module_inputs = []
    for desc, constructor_kwargs in cases:
        def reference_fn(m, p, i, t, constructor_kwargs=constructor_kwargs):
            return kldivloss_reference(i, t, **constructor_kwargs)

        input = make_input((10, 10)).log()
        target = make_input((10, 10)) if kwargs.get('log_target', False) else make_input((10, 10)).log()
        module_inputs.append(
            ModuleInput(constructor_input=FunctionInput(**constructor_kwargs),
                        forward_input=FunctionInput(input, target),
                        desc=desc,
                        reference_fn=reference_fn)
        )

        scalar_input = make_input(()).log()
        scalar_target = make_input(()) if kwargs.get('log_target', False) else make_input(()).log()
        module_inputs.append(
            ModuleInput(constructor_input=FunctionInput(**constructor_kwargs),
                        forward_input=FunctionInput(scalar_input, scalar_input),
                        desc='scalar_' + desc,
                        reference_fn=reference_fn)
        )

    return module_inputs


def module_inputs_torch_nn_NLLLoss(module_info, device, dtype, requires_grad, training, **kwargs):
    def make_input(shape, device=device, dtype=dtype, requires_grad=requires_grad):
        return make_tensor(shape, device=device, dtype=dtype,
                           requires_grad=False).log_softmax(dim=1).requires_grad_(requires_grad)
    make_weight = partial(make_tensor, device=device, dtype=dtype, requires_grad=False)

    cases: List[Tuple[str, dict]] = [
        ('reduction_sum', {'reduction': 'sum'}),
        ('reduction_mean', {'reduction': 'mean'}),
        ('reduction_none', {'reduction': 'none'}),
    ]

    module_inputs = []
    for desc, constructor_kwargs in cases:
        module_inputs.append(
            ModuleInput(constructor_input=FunctionInput(**constructor_kwargs),
                        forward_input=FunctionInput(make_input(3),
                                                    make_target(3),
                                                    make_input(1).abs()),
                        desc=desc,
                        reference_fn=no_batch_dim_reference_fn)
        )

    return module_inputs


def module_inputs_torch_nn_PoissonNLLLoss(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    make_target = partial(make_tensor, device=device, dtype=dtype, requires_grad=False)

    cases: List[Tuple[str, dict]] = [
        ('reduction_sum', {'reduction': 'sum'}),
        ('reduction_mean', {'reduction': 'mean'}),
        ('reduction_none', {'reduction': 'none'}),
    ]

    def mse_loss_reference_fn(m, p, i, t, reduction='mean'):
        if reduction == 'none':
            return (i - t).pow(2)
        elif reduction == 'mean':
            return (i - t).pow(2).sum() / i.numel()
        else:
            return (i - t).pow(2).sum()

    module_inputs = []
    for desc, constructor_kwargs in cases:
        module_inputs.append(
            ModuleInput(constructor_input=FunctionInput(**constructor_kwargs),
                        forward_input=FunctionInput(make_input((2, 3, 4, 5)),
                                                    make_target((2, 3, 4, 5))),
                        desc=desc,
                        reference_fn=partial(mse_loss_reference_fn, **constructor_kwargs))
        )
        module_inputs.append(
            ModuleInput(constructor_input=FunctionInput(**constructor_kwargs),
                        forward_input=FunctionInput(make_input(()),
                                                    make_target(())),
                        desc=f'{desc}_scalar',
                        reference_fn=partial(mse_loss_reference_fn, **constructor_kwargs))
        )

    return module_inputs


def no_batch_dim_reference_fn(m, p, *args, **kwargs):
    def get_and_pop(key, default):
        v = kwargs.get(key, default)
        if key in kwargs:
            kwargs.pop(key)
        return v

    batch_dim = 0 if get_and_pop('batch_first', True) else 1
    kwargs_to_batchify = get_and_pop('kwargs_to_batchify', None)
    is_criterion = get_and_pop('is_criterion', False)

    if kwargs_to_batchify is not None:
        assert isinstance(kwargs_to_batchify, dict)
        for k, v in kwargs.items():
            if k in kwargs_to_batchify and v is not None:
                bdim = kwargs_to_batchify[k]
                kwargs[k] = v.unsqueeze(bdim)

    single_batch_input_args = [input.unsqueeze(batch_dim) for input in args]
    with freeze_rng_state():
        output = m(*single_batch_input_args, **kwargs).squeeze(batch_dim)

    if is_criterion:
        reduction = get_reduction(m)
        if reduction == 'none':
            return output.squeeze(0)
    return output


def no_batch_dim_reference_mha(m, p, *args, **kwargs):
    batch_dim = 0 if kwargs.get('batch_first', True) else 1
    if 'batch_first' in kwargs:
        kwargs.pop('batch_first')
    if 'key_padding_mask' in kwargs and kwargs['key_padding_mask'] is not None:
        kwargs['key_padding_mask'] = kwargs['key_padding_mask'].unsqueeze(0)
    single_batch_input_args = [input.unsqueeze(batch_dim) for input in args]
    with freeze_rng_state():
        output = m(*single_batch_input_args, **kwargs)
        return (output[0].squeeze(batch_dim), output[1].squeeze(0))


def no_batch_dim_reference_rnn_gru(m, p, *args, **kwargs):
    if len(args) == 1:
        inp, = args
        h = None
    elif len(args) == 2:
        inp, h = args
        h = h.unsqueeze(1)

    batch_dim = 0 if kwargs['batch_first'] else 1
    kwargs.pop('batch_first')
    inp = inp.unsqueeze(batch_dim)
    single_batch_input_args = (inp, h)
    with freeze_rng_state():
        output = m(*single_batch_input_args, **kwargs)
        return (output[0].squeeze(batch_dim), output[1].squeeze(1))


def no_batch_dim_reference_lstm(m, p, *args, **kwargs):
    if len(args) == 1:
        inp, = args
        h = None
    elif len(args) == 2:
        inp, h = args
        h = (h[0].unsqueeze(1), h[1].unsqueeze(1))

    batch_dim = 0 if kwargs['batch_first'] else 1
    kwargs.pop('batch_first')
    inp = inp.unsqueeze(batch_dim)
    single_batch_input_args = (inp, h)
    with freeze_rng_state():
        output = m(*single_batch_input_args, **kwargs)
        return (output[0].squeeze(batch_dim), (output[1][0].squeeze(1), output[1][1].squeeze(1)))


def no_batch_dim_reference_lstmcell(m, p, *args, **kwargs):
    inp, (h, c) = args
    single_batch_input_args = (inp.unsqueeze(0), (h.unsqueeze(0), c.unsqueeze(0)))
    with freeze_rng_state():
        output = m(*single_batch_input_args, **kwargs)
        return (output[0].squeeze(0), output[1].squeeze(0))


def generate_regression_criterion_inputs(make_input):
    return [
        ModuleInput(
            constructor_input=FunctionInput(reduction=reduction),
            forward_input=FunctionInput(make_input((4, )), make_input(4,)),
            reference_fn=partial(no_batch_dim_reference_fn, is_criterion=True),
            desc=f'no_batch_dim_{reduction}'
        ) for reduction in ['none', 'mean', 'sum']]


def module_inputs_torch_nn_AvgPool1d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(kernel_size=2),
                    forward_input=FunctionInput(make_input((3, 6))),
                    desc='no_batch_dim',
                    reference_fn=no_batch_dim_reference_fn),
        ModuleInput(constructor_input=FunctionInput(2),
                    forward_input=FunctionInput(make_input((2, 3, 6)))),
        ModuleInput(constructor_input=FunctionInput((2,), (2,)),
                    forward_input=FunctionInput(make_input((2, 3, 6))),
                    desc='stride'),
        ModuleInput(constructor_input=FunctionInput(2, 2, 1),
                    forward_input=FunctionInput(make_input((2, 3, 6))),
                    desc='stride_pad')]


def module_inputs_torch_nn_AvgPool2d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput((2, 2)),
                    forward_input=FunctionInput(make_input((3, 6, 6))),
                    desc='no_batch_dim',
                    reference_fn=no_batch_dim_reference_fn),
        ModuleInput(constructor_input=FunctionInput((2, 2)),
                    forward_input=FunctionInput(make_input((2, 3, 6, 6)))),
        ModuleInput(constructor_input=FunctionInput((2, 2), (2, 2)),
                    forward_input=FunctionInput(make_input((2, 3, 6, 6))),
                    desc='stride'),
        ModuleInput(constructor_input=FunctionInput((2, 2), (2, 2), (1, 1)),
                    forward_input=FunctionInput(make_input((2, 3, 6, 6))),
                    desc='stride_pad'),
        ModuleInput(constructor_input=FunctionInput((2, 2), divisor_override=1),
                    forward_input=FunctionInput(make_input((2, 3, 6, 6))),
                    desc='divisor'),
        ModuleInput(constructor_input=FunctionInput((2, 2), (2, 2), divisor_override=1),
                    forward_input=FunctionInput(make_input((2, 3, 6, 6))),
                    desc='divisor_stride'),
        ModuleInput(constructor_input=FunctionInput((2, 2), (2, 2), (1, 1), divisor_override=1),
                    forward_input=FunctionInput(make_input((2, 3, 6, 6))),
                    desc='divisor_stride_pad')]



def module_inputs_torch_nn_AvgPool3d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput((2, 2, 2)),
                    forward_input=FunctionInput(make_input((3, 4, 4, 4))),
                    desc='no_batch_dim',
                    reference_fn=no_batch_dim_reference_fn),
        ModuleInput(constructor_input=FunctionInput((2, 2, 2)),
                    forward_input=FunctionInput(make_input((2, 3, 4, 4, 4)))),
        ModuleInput(constructor_input=FunctionInput(2, (2, 2, 2)),
                    forward_input=FunctionInput(make_input((2, 3, 5, 5, 5))),
                    desc='stride'),
        ModuleInput(constructor_input=FunctionInput(2, 2, (1, 1, 1)),
                    forward_input=FunctionInput(make_input((2, 3, 5, 5, 5))),
                    desc='stride_pad'),
        ModuleInput(constructor_input=FunctionInput(4, 2, (1, 2, 1)),
                    forward_input=FunctionInput(make_input((2, 3, 5, 5, 5))),
                    desc='stride_pad_gpu_fixedkw_output'),
        ModuleInput(constructor_input=FunctionInput((2, 4, 8), 1, (1, 1, 2)),
                    forward_input=FunctionInput(make_input((2, 3, 2, 4, 8))),
                    desc='stride_pad_gpu_general_output'),
        ModuleInput(constructor_input=FunctionInput(3, 1, 0),
                    forward_input=FunctionInput(make_input((2, 3, 4, 4, 4))),
                    desc='stride1_pad0_gpu_input'),
        ModuleInput(constructor_input=FunctionInput(2, 2, (1, 1, 1)),
                    forward_input=FunctionInput(make_input((2, 3, 4, 4, 4))),
                    desc='stride_pad_gpu_input_nooverlap'),
        ModuleInput(constructor_input=FunctionInput((2, 2, 2), divisor_override=1),
                    forward_input=FunctionInput(make_input((2, 3, 4, 4, 4))),
                    desc='divisor'),
        ModuleInput(constructor_input=FunctionInput(2, (2, 2, 2), divisor_override=1),
                    forward_input=FunctionInput(make_input((2, 3, 5, 5, 5))),
                    desc='divisor_stride'),
        ModuleInput(constructor_input=FunctionInput(2, 2, (1, 1, 1), divisor_override=1),
                    forward_input=FunctionInput(make_input((2, 3, 5, 5, 5))),
                    desc='divisor_stride_pad'),
        ModuleInput(constructor_input=FunctionInput(4, 2, (1, 2, 1), divisor_override=1),
                    forward_input=FunctionInput(make_input((2, 3, 5, 5, 5))),
                    desc='divisor_stride_pad_gpu_fixedkw_output'),
        ModuleInput(constructor_input=FunctionInput((2, 4, 8), 1, (1, 1, 2), divisor_override=1),
                    forward_input=FunctionInput(make_input((2, 3, 2, 4, 8))),
                    desc='divisor_stride_pad_gpu_general_output'),
        ModuleInput(constructor_input=FunctionInput(3, 1, 0, divisor_override=1),
                    forward_input=FunctionInput(make_input((2, 3, 4, 4, 4))),
                    desc='divisor_stride1_pad0_gpu_input'),
        ModuleInput(constructor_input=FunctionInput(2, 2, (1, 1, 1), divisor_override=1),
                    forward_input=FunctionInput(make_input((2, 3, 4, 4, 4))),
                    desc='divisor_stride_pad_gpu_input_nooverlap')]



def module_inputs_torch_nn_AdaptiveAvgPool1d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(3,),
                    forward_input=FunctionInput(make_input((1, 3, 5))),
                    desc='single'),
        ModuleInput(constructor_input=FunctionInput(3,),
                    forward_input=FunctionInput(make_input((3, 5))),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim'),
        ModuleInput(constructor_input=FunctionInput(1,),
                    forward_input=FunctionInput(make_input((1, 3, 5))),
                    desc='one_output')]


def module_inputs_torch_nn_AdaptiveAvgPool2d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(3,),
                    forward_input=FunctionInput(make_input((1, 3, 5, 6))),
                    desc='single'),
        ModuleInput(constructor_input=FunctionInput(3,),
                    forward_input=FunctionInput(make_input((3, 5, 6))),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim'),
        ModuleInput(constructor_input=FunctionInput(1,),
                    forward_input=FunctionInput(make_input((1, 3, 5, 6))),
                    desc='single_1x1output'),
        ModuleInput(constructor_input=FunctionInput((3, 4)),
                    forward_input=FunctionInput(make_input((1, 3, 5, 6))),
                    desc='tuple'),
        ModuleInput(constructor_input=FunctionInput((3, None)),
                    forward_input=FunctionInput(make_input((1, 3, 5, 6))),
                    desc='tuple_none')]

def module_inputs_torch_nn_AdaptiveAvgPool3d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(3,),
                    forward_input=FunctionInput(make_input((2, 3, 5, 2, 7))),
                    desc='single'),
        ModuleInput(constructor_input=FunctionInput(3,),
                    forward_input=FunctionInput(make_input((3, 5, 2, 7))),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim'),
        ModuleInput(constructor_input=FunctionInput((3, 4, 5)),
                    forward_input=FunctionInput(make_input((2, 3, 5, 3, 7))),
                    desc='tuple'),
        ModuleInput(constructor_input=FunctionInput((None, 4, 5)),
                    forward_input=FunctionInput(make_input((2, 3, 5, 3, 7))),
                    desc='tuple_none'),
        ModuleInput(constructor_input=FunctionInput((3, 2, 2)),
                    forward_input=FunctionInput(make_input((1, 1, 3, 2, 6))),
                    desc='last_dim')]


def module_inputs_torch_nn_AdaptiveMaxPool1d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(3,),
                    forward_input=FunctionInput(make_input((1, 3, 5))),
                    desc='single'),
        ModuleInput(constructor_input=FunctionInput(3,),
                    forward_input=FunctionInput(make_input((3, 5))),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim')]


def module_inputs_torch_nn_AdaptiveMaxPool2d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(3,),
                    forward_input=FunctionInput(make_input((1, 3, 5, 6))),
                    desc='single'),
        ModuleInput(constructor_input=FunctionInput(3,),
                    forward_input=FunctionInput(make_input((3, 5, 6))),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim'),
        ModuleInput(constructor_input=FunctionInput((3, 4)),
                    forward_input=FunctionInput(make_input((1, 3, 5, 6))),
                    desc='tuple'),
        ModuleInput(constructor_input=FunctionInput((3, None)),
                    forward_input=FunctionInput(make_input((1, 3, 5, 6))),
                    desc='tuple_none')]


def module_inputs_torch_nn_AdaptiveMaxPool3d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(3,),
                    forward_input=FunctionInput(make_input((2, 3, 5, 6, 7))),
                    desc='single'),
        ModuleInput(constructor_input=FunctionInput(3,),
                    forward_input=FunctionInput(make_input((3, 5, 6, 7))),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim'),
        ModuleInput(constructor_input=FunctionInput((3, 4, 5)),
                    forward_input=FunctionInput(make_input((2, 3, 5, 6, 7))),
                    desc='tuple'),
        ModuleInput(constructor_input=FunctionInput((3, None, 5)),
                    forward_input=FunctionInput(make_input((2, 3, 5, 6, 7))),
                    desc='tuple_none'),
        ModuleInput(constructor_input=FunctionInput(3),
                    forward_input=FunctionInput(make_input((2, 3, 12, 9, 3))),
                    desc='single_nonatomic'),
        ModuleInput(constructor_input=FunctionInput((3, 4, 5)),
                    forward_input=FunctionInput(make_input((2, 3, 6, 4, 10))),
                    desc='tuple_nonatomic')]


def module_inputs_torch_nn_BatchNorm1d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(10,),
                    forward_input=FunctionInput(make_input((4, 10))),
                    desc='affine'),
        ModuleInput(constructor_input=FunctionInput(5,),
                    forward_input=FunctionInput(make_input((4, 5, 3))),
                    desc='3d_input'),
        ModuleInput(constructor_input=FunctionInput(10, 1e-3, None),
                    forward_input=FunctionInput(make_input((4, 10))),
                    desc='affine_simple_average'),
        ModuleInput(constructor_input=FunctionInput(10, 1e-3, 0.3, False),
                    forward_input=FunctionInput(make_input((4, 10))),
                    desc='not_affine'),
        ModuleInput(constructor_input=FunctionInput(10, 1e-3, 0.3, True, False),
                    forward_input=FunctionInput(make_input((4, 10))),
                    desc='not_tracking_stats'),
        ModuleInput(constructor_input=FunctionInput(5, 1e-3, 0.3, False),
                    forward_input=FunctionInput(make_input((4, 5, 3))),
                    desc='3d_input_not_affine'),
        ModuleInput(constructor_input=FunctionInput(5, 1e-3, 0.3, False),
                    forward_input=FunctionInput(make_input((0, 5, 9))),
                    desc='zero_batch')]


def module_inputs_torch_nn_BatchNorm2d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(3,),
                    forward_input=FunctionInput(make_input((2, 3, 6, 6)))),
        ModuleInput(constructor_input=FunctionInput(3, 1e-3, None),
                    forward_input=FunctionInput(make_input((2, 3, 6, 6))),
                    desc='2d_simple_average'),
        ModuleInput(constructor_input=FunctionInput(3, 1e-3, 0.8),
                    forward_input=FunctionInput(make_input((2, 3, 6, 6))),
                    desc='momentum'),
        ModuleInput(constructor_input=FunctionInput(3, 1e-3, 0.8, False),
                    forward_input=FunctionInput(make_input((2, 3, 6, 6))),
                    desc='not_affine'),
        ModuleInput(constructor_input=FunctionInput(3, 1e-3, 0.8, True, False),
                    forward_input=FunctionInput(make_input((2, 3, 6, 6))),
                    desc='not_tracking_stats'),
        ModuleInput(constructor_input=FunctionInput(5, 1e-3, 0.3, False),
                    forward_input=FunctionInput(make_input((0, 5, 2, 2))),
                    desc='zero_batch')]


def module_inputs_torch_nn_BatchNorm3d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(3,),
                    forward_input=FunctionInput(make_input((2, 3, 4, 4, 4)))),
        ModuleInput(constructor_input=FunctionInput(3, 1e-3, None),
                    forward_input=FunctionInput(make_input((2, 3, 4, 4, 4))),
                    desc='3d_simple_average'),
        ModuleInput(constructor_input=FunctionInput(3, 1e-3, 0.7),
                    forward_input=FunctionInput(make_input((2, 3, 4, 4, 4))),
                    desc='momentum'),
        ModuleInput(constructor_input=FunctionInput(3, 1e-3, 0.7, False),
                    forward_input=FunctionInput(make_input((2, 3, 4, 4, 4))),
                    desc='not_affine'),
        ModuleInput(constructor_input=FunctionInput(3, 1e-3, 0.7, True, False),
                    forward_input=FunctionInput(make_input((2, 3, 4, 4, 4))),
                    desc='not_tracking_stats'),
        ModuleInput(constructor_input=FunctionInput(5, 1e-3, 0.3, False),
                    forward_input=FunctionInput(make_input((0, 5, 2, 2, 2))),
                    desc='zero_batch')]


def module_inputs_torch_nn_ConvNd(module_info, device, dtype, requires_grad, training, **kwargs):
    N = kwargs['N']
    lazy = kwargs.get('lazy', False)
    transposed = kwargs.get('transposed', False)
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    conv_kwargs_list = [{}] if transposed else [{}, {'padding': 'same'}]
    kernel_size, C_in, C_out = 3, 4, 5
    input_no_batch_shape = (C_in,) + tuple(i + 3 for i in range(N))
    input_batch_shape = (2,) + input_no_batch_shape
    return [
        ModuleInput(constructor_input=(FunctionInput(C_out, kernel_size, **conv_kwargs) if lazy else
                                       FunctionInput(C_in, C_out, kernel_size, **conv_kwargs)),
                    forward_input=FunctionInput(make_input(
                        input_batch_shape if with_batch else input_no_batch_shape)),
        ('reduction_sum', {'reduction': 'sum'}),
        ('reduction_mean', {'reduction': 'mean'}),
        ('reduction_none', {'reduction': 'none'}),
        ('margin', {'margin': 0.7})
    ]

    module_inputs = []
    for desc, constructor_kwargs in cases:
        def reference_fn(m, p, i1, i2, t, constructor_kwargs=constructor_kwargs):
            return cosineembeddingloss_reference(i1, i2, t, **constructor_kwargs)

        module_inputs.append(
            ModuleInput(constructor_input=FunctionInput(**constructor_kwargs),
                        forward_input=FunctionInput(make_input((15, 10)), make_input((15, 10)),
                                                    make_target((15,)).sign()),
                        desc=desc,
                        reference_fn=reference_fn)
        )

    return module_inputs


def module_inputs_torch_nn_ELU(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(alpha=2.),
                    forward_input=FunctionInput(make_input((3, 2, 5))),
                    reference_fn=lambda m, p, i: torch.where(i >= 0, i, 2 * (i.exp() - 1))),
        ModuleInput(constructor_input=FunctionInput(alpha=2.),
                    forward_input=FunctionInput(make_input(())),
                    desc='scalar'),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((3,))),
                    desc='no_batch_dim',
                    reference_fn=no_batch_dim_reference_fn),
        ModuleInput(constructor_input=FunctionInput(alpha=2.),
                    forward_input=FunctionInput(make_input((2, 3, 2, 5))),
                    desc='4d_input')]


def module_inputs_torch_nn_CELU(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(alpha=2.),
                    forward_input=FunctionInput(make_input((3, 2, 5))),
                    reference_fn=lambda m, p, i: torch.where(i >= 0, i, 2. * ((.5 * i).exp() - 1))),
        ModuleInput(constructor_input=FunctionInput(alpha=2.),
                    forward_input=FunctionInput(make_input(())),
                    reference_fn=lambda m, p, i: torch.where(i >= 0, i, 2. * ((.5 * i).exp() - 1)),
                    desc='scalar'),
        ModuleInput(constructor_input=FunctionInput(alpha=2.),
                    forward_input=FunctionInput(make_input((3,))),
                    desc='no_batch_dim',
                    reference_fn=no_batch_dim_reference_fn)]


def module_inputs_torch_nn_GLU(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((5, 6)))),
        ModuleInput(constructor_input=FunctionInput(1),
                    forward_input=FunctionInput(make_input((5, 6, 7))),
                    desc='dim'),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((4,))),
                    desc='no_batch_dim',
                    reference_fn=no_batch_dim_reference_fn)]


def module_inputs_torch_nn_GELU(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput('none'),
                    forward_input=FunctionInput(make_input(())),
                    reference_fn=lambda m, p, x, *_: x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0))),
                    desc='scalar'),
        ModuleInput(constructor_input=FunctionInput('none'),
                    forward_input=FunctionInput(make_input((3, 2, 5))),
                    reference_fn=lambda m, p, x, *_: x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((3,))),
                    desc='no_batch_dim',
                    reference_fn=no_batch_dim_reference_fn)]


def module_inputs_torch_nn_ReLU(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(())),
                    desc='scalar'),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(4)),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim'),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((2, 3, 4, 5))),
                    desc='channels_last_mem_format'),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((2, 3, 3, 4, 5))),
                    desc='channels_last_3d_mem_format')]


def module_inputs_torch_nn_ReLU6(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(())),
                    desc='scalar'),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(4)),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim'),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((2, 3, 4, 5))),
                    desc='channels_last_mem_format'),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((2, 3, 3, 4, 5))),
                    desc='channels_last_3d_mem_format')]


def module_inputs_torch_nn_LeakyReLU(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((3, 2, 5)))),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(4)),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim'),
        ModuleInput(constructor_input=FunctionInput(0.5),
                    forward_input=FunctionInput(make_input((3, 2, 5))),
                    desc='with_negval'),
        ModuleInput(constructor_input=FunctionInput(0.0),
                    forward_input=FunctionInput(make_input((10, 10))),
                    desc='with_zero_negval'),
        ModuleInput(constructor_input=FunctionInput(0.5),
                    forward_input=FunctionInput(make_input(())),
                    desc='with_negval_scalar')]


def module_inputs_torch_nn_PReLU(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(())),
                    desc='scalar'),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(4)),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim'),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((2, 3, 4))),
                    reference_fn=lambda m, p, i: torch.clamp(i, min=0) + torch.clamp(i, max=0) * p[0][0],
                    desc='1d'),
        ModuleInput(constructor_input=FunctionInput(3),
                    forward_input=FunctionInput(make_input((2, 3, 4))),
                    reference_fn=lambda m, p, i: torch.clamp(i, min=0) + torch.clamp(i, max=0) * p[0][0],
                    desc='1d_multiparam'),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((2, 3, 4, 5))),
                    reference_fn=lambda m, p, i: torch.clamp(i, min=0) + torch.clamp(i, max=0) * p[0][0],
                    desc='2d'),
        ModuleInput(constructor_input=FunctionInput(3),
                    forward_input=FunctionInput(make_input((2, 3, 4, 5))),
                    reference_fn=lambda m, p, i: torch.clamp(i, min=0) + torch.clamp(i, max=0) * p[0][0],
                    desc='2d_multiparam'),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((2, 3, 4, 5, 6))),
                    reference_fn=lambda m, p, i: torch.clamp(i, min=0) + torch.clamp(i, max=0) * p[0][0],
                    desc='3d'),
        ModuleInput(constructor_input=FunctionInput(3),
                    forward_input=FunctionInput(make_input((2, 3, 4, 5, 6))),
                    reference_fn=lambda m, p, i: torch.clamp(i, min=0) + torch.clamp(i, max=0) * p[0][0],
                    desc='3d_multiparam')]


def module_inputs_torch_nn_SELU(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((3, 2, 5)))),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(4)),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim'),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(())),
                    desc='scalar')]


def module_inputs_torch_nn_SiLU(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(())),
                    reference_fn=lambda m, p, x, *_: x * torch.sigmoid(x),
                    desc='scalar'),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(4)),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim'),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((5, 6, 7))),
                    reference_fn=lambda m, p, x, *_: x * torch.sigmoid(x))]


def module_inputs_torch_nn_Softmax(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(1),
                    forward_input=FunctionInput(make_input((10, 20))),
                    reference_fn=lambda m, p, i: torch.exp(i).div(torch.exp(i).sum(1, True).expand(10, 20))),
        ModuleInput(constructor_input=FunctionInput(0),
                    forward_input=FunctionInput(make_input(())),
                    reference_fn=lambda m, p, i: torch.exp(i).div(torch.exp(i).sum(0, True)),
                    desc='scalar'),
        ModuleInput(constructor_input=FunctionInput(-1),
                    forward_input=FunctionInput(make_input((4, 5))),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim')]


def module_inputs_torch_nn_Softmax2d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((1, 3, 10, 20))),
                    reference_fn=lambda m, p, i: torch.exp(i).div(torch.exp(i).sum(1, False))),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((3, 4, 5))),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim')]


def module_inputs_torch_nn_LogSoftmax(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(1),
                    forward_input=FunctionInput(make_input((10, 20))),
                    reference_fn=lambda m, p, i: torch.exp(i).div_(torch.exp(i).sum(1, True).expand(10, 20)).log_()),
        ModuleInput(constructor_input=FunctionInput(1),
                    forward_input=FunctionInput(make_input((1, 3, 10, 20))),
                    reference_fn=lambda m, p, i: torch.exp(i).div_(torch.exp(i).sum(1, False)).log_(),
                    desc='multiparam'),
        ModuleInput(constructor_input=FunctionInput(0),
                    forward_input=FunctionInput(make_input(())),
                    reference_fn=lambda m, p, i: torch.exp(i).div_(torch.exp(i).sum(0, False)).log_(),
                    desc='multiparam_scalar'),
        ModuleInput(constructor_input=FunctionInput(-1),
                    forward_input=FunctionInput(make_input((4, 5))),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim')]


def module_inputs_torch_nn_Softmin(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(1),
                    forward_input=FunctionInput(make_input((10, 20)))),
        ModuleInput(constructor_input=FunctionInput(1),
                    forward_input=FunctionInput(make_input((2, 3, 5, 10))),
                    desc='multidim'),
        ModuleInput(constructor_input=FunctionInput(0),
                    forward_input=FunctionInput(make_input(())),
                    desc='scalar'),
        ModuleInput(constructor_input=FunctionInput(-1),
                    forward_input=FunctionInput(make_input((3, 4, 10))),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim')]


def module_inputs_torch_nn_Softplus(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((10, 20))),
                    reference_fn=lambda m, p, i: torch.log(1 + torch.exp(i))),
        ModuleInput(constructor_input=FunctionInput(2),
                    forward_input=FunctionInput(make_input((10, 20))),
                    reference_fn=lambda m, p, i: 1. / 2. * torch.log(1 + torch.exp(2 * i)),
                    desc='beta'),
        ModuleInput(constructor_input=FunctionInput(2, -100),
                    forward_input=FunctionInput(make_input((10, 20))),
                    reference_fn=(
                        lambda m, p, i: ((i * 2) > -100).type_as(i) * i
                        + ((i * 2) <= -100).type_as(i) * 1. / 2. * torch.log(1 + torch.exp(2 * i))),
                    desc='beta_threshold'),
        ModuleInput(constructor_input=FunctionInput(2, -100),
                    forward_input=FunctionInput(make_input(())),
                    reference_fn=(
                        lambda m, p, i: ((i * 2) > -100).type_as(i) * i
                        + ((i * 2) <= -100).type_as(i) * 1. / 2. * torch.log(1 + torch.exp(2 * i))),
                    desc='beta_threshold_scalar'),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(4)),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim')]


def module_inputs_torch_nn_Softshrink(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((3, 2, 5)))),
        ModuleInput(constructor_input=FunctionInput(1,),
                    forward_input=FunctionInput(make_input((3, 2, 5))),
                    desc='lambda'),
        ModuleInput(constructor_input=FunctionInput(1,),
                    forward_input=FunctionInput(make_input(())),
                    desc='lambda_scalar'),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(4)),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim')]


def module_inputs_torch_nn_Softsign(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((3, 2, 5))),
                    reference_fn=lambda m, p, i: i.div(1 + torch.abs(i))),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(())),
                    reference_fn=lambda m, p, i: i.div(1 + torch.abs(i)),
                    desc='scalar'),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(4)),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim')]


def module_inputs_torch_nn_Tanh(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((2, 3, 4, 5)))),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(())),
                    desc='scalar'),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(4)),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim')]



def module_inputs_torch_nn_Tanhshrink(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((2, 3, 4, 5)))),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(())),
                    desc='scalar'),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(4)),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim')]


def module_inputs_torch_nn_Threshold(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(2., 1.),
                    forward_input=FunctionInput(make_input((2, 3, 4, 5))),
                    desc='threshold_value'),
        ModuleInput(constructor_input=FunctionInput(2., 10.),
                    forward_input=FunctionInput(make_input((2, 3, 4, 5))),
                    desc='large_value'),
        ModuleInput(constructor_input=FunctionInput(2., 1.),
                    forward_input=FunctionInput(make_input(())),
                    desc='threshold_value_scalar'),
        ModuleInput(constructor_input=FunctionInput(2., 1.),
                    forward_input=FunctionInput(make_input(4)),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim')]


def module_inputs_torch_nn_Mish(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((5, 6, 7))),
                    reference_fn=lambda m, p, i: i * torch.tanh(F.softplus(i))),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(())),
                    reference_fn=lambda m, p, i: i * torch.tanh(F.softplus(i)),
                    desc='scalar'),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(4)),
                    reference_fn=no_batch_dim_reference_fn,
                    desc='no_batch_dim')]


def module_inputs_torch_nn_L1Loss(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input((2, 3, 4)),
                                                make_input((2, 3, 4))),
                    reference_fn=lambda m, p, i, t: 1. / i.numel() * sum((a - b).abs().sum()
                                                                         for a, b in zip(i, t))),
        ModuleInput(constructor_input=FunctionInput(),
                    forward_input=FunctionInput(make_input(()), make_input(())),
                    reference_fn=lambda m, p, i, t: 1. / i.numel() * (i - t).abs().sum(),
                    desc='scalar')] + generate_regression_criterion_inputs(make_input)


def module_inputs_torch_nn_SmoothL1Loss(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)


    cases: List[Tuple[str, dict]] = [
        ('reduction_sum', {'reduction': 'sum'}),
        ('reduction_mean', {'reduction': 'mean'}),
        ('reduction_none', {'reduction': 'none'}),
        ('weights', {'weight': make_weight((10,))}),
    ]

    def bce_loss_reference_fn(m, p, i, t, reduction='mean', weight=None):
        result = -(t * i.log() + (1 - t) * (1 - i).log())

        if weight is not None:
            result = result * weight

        if reduction == 'none':
            return result
        elif reduction == 'mean':
            return result.sum() / i.numel()
        else:
            return result.sum()

    module_inputs = []
    for desc, constructor_kwargs in cases:
        module_inputs.append(
            ModuleInput(constructor_input=FunctionInput(**constructor_kwargs),
                        forward_input=FunctionInput(make_input((15, 10), low=1e-2, high=1 - 1e-2),
                                                    make_target((15, 10)).gt(0).to(dtype)),
                        desc=desc,
                        reference_fn=partial(bce_loss_reference_fn, **constructor_kwargs))
        )

    scalar_weight = make_weight(())
    module_inputs.append(
        ModuleInput(constructor_input=FunctionInput(weight=scalar_weight),
                    forward_input=FunctionInput(make_input((), low=1e-2, high=1 - 1e-2),
                                                make_target(()).gt(0).to(dtype)),
                    desc='scalar_weight',
                    reference_fn=partial(bce_loss_reference_fn, weight=scalar_weight))
    )

    return module_inputs


def module_inputs_torch_nn_BCEWithLogitsLoss(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    make_target = partial(make_tensor, device=device, dtype=dtype, requires_grad=False)
    make_weight = partial(make_tensor, device=device, dtype=dtype, requires_grad=False)

    cases: List[Tuple[str, dict]] = [
        ('weights', {'weight': make_weight((3,))}),
        ('ignore_index', {'ignore_index': 1}),
        ('label_smoothing', {'label_smoothing': 0.15}),
        ('ignore_index_label_smoothing', {'ignore_index': 1, 'label_smoothing': 0.15})
    ]

    module_inputs = []
    for reduction, (desc, constructor_kwargs) in product(reductions, cases):
        def reference_fn(m, p, i, t, reduction=reduction, constructor_kwargs=constructor_kwargs):
            return cross_entropy_loss_reference(i, t, reduction=reduction, **constructor_kwargs)

        module_inputs.append(
            ModuleInput(constructor_input=FunctionInput(reduction=reduction, **constructor_kwargs),
                        forward_input=FunctionInput(make_input((2, 3, 5, 5)),
                                                    make_target((2, 5, 5), low=0, high=3)),
                        desc=f"4d_{desc}_{reduction}",
                        reference_fn=reference_fn)
        )
        module_inputs.append(
            ModuleInput(constructor_input=FunctionInput(reduction=reduction, **constructor_kwargs),
                        forward_input=FunctionInput(make_input((2, 3, 5)),
                                                    make_target((2, 5), low=0, high=3)),
                        desc=f"3d_{desc}_{reduction}",
                        reference_fn=reference_fn)
        )
        module_inputs.append(
            ModuleInput(constructor_input=FunctionInput(reduction=reduction, **constructor_kwargs),
                        forward_input=FunctionInput(make_input((2, 3)),
                                                    make_target((2), low=0, high=3)),
                        desc=f"2d_{desc}_{reduction}",
                        reference_fn=reference_fn)
        )
        module_inputs.append(
            ModuleInput(constructor_input=FunctionInput(reduction=reduction, **constructor_kwargs),
                        forward_input=FunctionInput(make_input((2, 3, 5, 5, 2, 2)),
                                                    make_target((2, 5, 5, 2, 2), low=0, high=3)),
                        desc=f"higher_dim_{desc}_{reduction}",
                        reference_fn=reference_fn)
        )

        if constructor_kwargs.get('ignore_index', None) is None:
            module_inputs.append(
                ModuleInput(constructor_input=FunctionInput(reduction=reduction, **constructor_kwargs),
                            forward_input=FunctionInput(make_input((5, 3, 4, 2)),
                                                        make_input((5, 3, 4, 2)).softmax(dim=1)),
                            desc=f"4d_prob_target_{desc}_{reduction}",
                            reference_fn=reference_fn)
            )
            module_inputs.append(
                ModuleInput(constructor_input=FunctionInput(reduction=reduction, **constructor_kwargs),
                            forward_input=FunctionInput(make_input((5, 3, 4)),
                                                        make_input((5, 3, 4)).softmax(dim=1)),
                            desc=f"3d_prob_target_{desc}_{reduction}",
                            reference_fn=reference_fn)
            )
            module_inputs.append(
                ModuleInput(constructor_input=FunctionInput(reduction=reduction, **constructor_kwargs),
                            forward_input=FunctionInput(make_input((5, 3)),
                                                        make_input((5, 3)).softmax(dim=1)),
                            desc=f"2d_prob_target_{desc}_{reduction}",
                            reference_fn=reference_fn)
            )
            module_inputs.append(
                ModuleInput(constructor_input=FunctionInput(reduction=reduction, **constructor_kwargs),
                            forward_input=FunctionInput(make_input((2, 3, 5, 5, 2, 2)),
                                                        make_input((2, 3, 5, 5, 2, 2)).softmax(dim=1)),
                            desc=f"higher_dim_prob_target_{desc}_{reduction}",
                            reference_fn=reference_fn)
            )
            module_inputs.append(
                ModuleInput(constructor_input=FunctionInput(reduction=reduction, **constructor_kwargs),
                            forward_input=FunctionInput(make_input((3,)),
                                                        make_target((), low=0, high=3)),
                            desc=f"no_batch_dim_{desc}_{reduction}",
                            reference_fn=partial(no_batch_dim_reference_fn, is_criterion=True))
            )

    return module_inputs



def module_inputs_torch_nn_CTCLoss(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    make_target = partial(make_tensor, device=device, requires_grad=False)

    cases: List[Tuple[str, dict]] = [
        ('reduction_sum', {'reduction': 'sum'}),
        ('reduction_mean', {'reduction': 'mean'}),
        ('reduction_none', {'reduction': 'none'}),
        ('margin', {'margin': 0.5})
    ]

    module_inputs = []
    for desc, constructor_kwargs in cases:
        def reference_fn(m, p, i, t, constructor_kwargs=constructor_kwargs):
            return hingeembeddingloss_reference(i, t, **constructor_kwargs)

        module_inputs.append(
            ModuleInput(constructor_input=FunctionInput(**constructor_kwargs),
                        forward_input=FunctionInput(make_input((10,)),
                                                    make_target((10,)).gt(0).to(dtype).mul_(2).sub_(1)),
                        desc=desc,
                        reference_fn=reference_fn)
        )
        module_inputs.append(
            ModuleInput(constructor_input=FunctionInput(**constructor_kwargs),
                        forward_input=FunctionInput(make_input(()),
                                                    make_target(()).gt(0).to(dtype).mul_(2).sub_(1)),
                        desc=f'scalar_{desc}',
                        reference_fn=reference_fn)
        )

    return module_inputs


def module_inputs_torch_nn_HuberLoss(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases: List[Tuple[str, dict]] = [
        ('reduction_sum', {'reduction': 'sum'}),
        ('reduction_mean', {'reduction': 'mean'}),
        ('reduction_none', {'reduction': 'none'}),
        ('margin', {'margin': 0.5})
    ]

    module_inputs = []
    for desc, constructor_kwargs in cases:
        def reference_fn(m, p, i1, i2, t, constructor_kwargs=constructor_kwargs):
            return marginrankingloss_reference(i1, i2, t, **constructor_kwargs)

        module_inputs.append(
            ModuleInput(constructor_input=FunctionInput(**constructor_kwargs),
                        forward_input=FunctionInput(make_input((50,)), make_input((50,)),
                                                    make_target((50,)).sign()),
                        desc=desc,
                        reference_fn=reference_fn)
        )

    return module_inputs


def module_inputs_torch_nn_MultiLabelMarginLoss(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    make_target = partial(make_tensor, device=device, dtype=torch.long, requires_grad=False)

    cases: List[Tuple[str, dict]] = [
        ('reduction_sum', {'reduction': 'sum'}),
        ('reduction_mean', {'reduction': 'mean'}),
        ('reduction_none', {'reduction': 'none'}),
        ('p', {'p': 2}),
        ('margin', {'margin': 0.5}),
        ('weights', {'weight': make_weight(10)})
    ]

    module_inputs = []
    for desc, constructor_kwargs in cases:
        def reference_fn(m, p, i, t, constructor_kwargs=constructor_kwargs):
            return multimarginloss_reference(i, t, **constructor_kwargs)

        module_inputs.append(
            ModuleInput(constructor_input=FunctionInput(**constructor_kwargs),
                        forward_input=FunctionInput(make_input((5, 10)),
                                                    make_target((5), low=0, high=10)),
                        desc=desc,
                        reference_fn=reference_fn)
        )

    return module_inputs


def module_inputs_torch_nn_MultiLabelSoftMarginLoss(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    make_target = partial(make_tensor, device=device, dtype=torch.long, requires_grad=False)
    make_weight = partial(make_tensor, device=device, dtype=dtype, requires_grad=False)

    cases: List[Tuple[str, dict]] = [
        ('reduction_sum', {'reduction': 'sum'}),
        ('reduction_mean', {'reduction': 'mean'}),
        ('reduction_none', {'reduction': 'none'}),
    ]

    module_inputs = []
    for desc, constructor_kwargs in cases:
        def reference_fn(m, p, i, t, constructor_kwargs=constructor_kwargs):
            return softmarginloss_reference(i, t, **constructor_kwargs)

        module_inputs.append(
            ModuleInput(constructor_input=FunctionInput(**constructor_kwargs),
                        forward_input=FunctionInput(make_input((5, 5)),
                                                    make_target((5, 5)).sign()),
                        desc=desc,
                        reference_fn=reference_fn)
        )

    return module_inputs


def module_inputs_torch_nn_TransformerEncoder(module_info, device, dtype, requires_grad, training, **kwargs):
    samples = []
    for layer_module_input in module_inputs_torch_nn_TransformerEncoderLayer(
            None, device, dtype, requires_grad, training):
        l_args, l_kwargs = (layer_module_input.constructor_input.args,
                            layer_module_input.constructor_input.kwargs)
        l_kwargs['device'] = device
        l_kwargs['dtype'] = dtype
        encoder_layer = torch.nn.TransformerEncoderLayer(*l_args, **l_kwargs)
        num_layers = 2
        forward_input = layer_module_input.forward_input
        if 'src_mask' in forward_input.kwargs:
            forward_input.kwargs['mask'] = forward_input.kwargs['src_mask']
            del forward_input.kwargs['src_mask']
        samples.append(ModuleInput(
            constructor_input=FunctionInput(encoder_layer, num_layers),
            forward_input=forward_input,
            desc=layer_module_input.desc
        ))
    return samples

def module_inputs_torch_nn_TransformerEncoderLayer(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    samples = [
        ModuleInput(
            constructor_input=FunctionInput(4, 2, 16, 0.0),
            forward_input=FunctionInput(
                make_input((2, 3, 4))
            ),
            desc='relu_activation'
        ),
        ModuleInput(
            constructor_input=FunctionInput(4, 2, 8, 0.0, F.gelu),
            forward_input=FunctionInput(
                make_input((2, 3, 4))
            ),
            desc='gelu_activation'
        ), ]

    key_padding_masks = (None, torch.tensor([False, False, True], device=device, dtype=torch.bool))
    attn_masks = (None, torch.tensor([False, False, True], device=device, dtype=torch.bool).expand((3, 3)))
    for src_mask, src_key_padding_mask, norm_first in itertools.product(attn_masks, key_padding_masks, (True, False)):
        samples.append(
            ModuleInput(
                constructor_input=FunctionInput(d_model=4, nhead=2, dim_feedforward=8,
                                                dropout=0.0, batch_first=True, norm_first=norm_first),
                forward_input=FunctionInput(
                    make_input((3, 4)), src_mask=src_mask, src_key_padding_mask=src_key_padding_mask
                ),
                reference_fn=partial(no_batch_dim_reference_fn,
                                     batch_first=True, kwargs_to_batchify={'src_key_padding_mask': 0}),
                desc='no_batch_dim_batch_first'
            ))

        samples.append(
            ModuleInput(
                constructor_input=FunctionInput(4, 2, 8, dropout=0.0, batch_first=False, norm_first=norm_first),
                forward_input=FunctionInput(
                    make_input((3, 4)), src_mask=src_mask, src_key_padding_mask=src_key_padding_mask
                ),
                reference_fn=partial(no_batch_dim_reference_fn,
                                     batch_first=False, kwargs_to_batchify={'src_key_padding_mask': 0}),
                desc='no_batch_dim'
            ))

    def fast_path_reference_fn(module, parameters, *args, **kwargs):
        assert not module.training
        module = module.train(True)
        output = module(*args, **kwargs)
        module = module.train(False)
        return output

    if not training:
        for norm_first in (True, False):
            samples.append(
                ModuleInput(
                    constructor_input=FunctionInput(4, 2, 8, dropout=0.0, batch_first=True, norm_first=norm_first),
                    forward_input=FunctionInput(
                        make_input((2, 3, 4)),
                    ),
                    reference_fn=fast_path_reference_fn,
                    desc="fast_path_norm_first" if norm_first else "fast_path"
                )
            )

    return samples


def module_inputs_torch_nn_TransformerDecoderLayer(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    samples = [
        ModuleInput(
            constructor_input=FunctionInput(4, 2, 16, 0.0),
            forward_input=FunctionInput(
                make_input((2, 3, 4)), make_input((2, 3, 4))
            ),
            desc='relu_activation'
        ),
        ModuleInput(
            constructor_input=FunctionInput(4, 2, 8, 0.0, F.gelu),
            forward_input=FunctionInput(
                make_input((2, 3, 4)), make_input((2, 3, 4))
            ),
            desc='gelu_activation'
        ), ]

    key_padding_masks = (None, torch.tensor([False, False, True], device=device, dtype=torch.bool))
    attn_masks = (None, torch.tensor([False, False, True], device=device, dtype=torch.bool).expand((3, 3)))
    for tgt_mask, tgt_key_padding_mask, norm_first in itertools.product(attn_masks, key_padding_masks, (True, False)):
        memory_mask = tgt_mask
        memory_key_padding_mask = tgt_key_padding_mask
        samples.append(
            ModuleInput(
                constructor_input=FunctionInput(d_model=4, nhead=2, dim_feedforward=8,
                                                dropout=0.0, batch_first=True, norm_first=norm_first),
                forward_input=FunctionInput(
                    make_input((3, 4)), make_input((3, 4)), tgt_mask=tgt_mask, memory_mask=memory_mask,
                    tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask
                ),
                reference_fn=partial(no_batch_dim_reference_fn,
                                     batch_first=True,
                                     kwargs_to_batchify={'tgt_key_padding_mask': 0, 'memory_key_padding_mask': 0}),
                desc='no_batch_dim_batch_first'
            ))

        samples.append(
            ModuleInput(
                constructor_input=FunctionInput(4, 2, 8, dropout=0.0, batch_first=False, norm_first=norm_first),
                forward_input=FunctionInput(
                    make_input((3, 4)), make_input((3, 4)), tgt_mask=tgt_mask, memory_mask=memory_mask,
                    tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask
                ),
                reference_fn=partial(no_batch_dim_reference_fn,
                                     batch_first=False,
                                     kwargs_to_batchify={'tgt_key_padding_mask': 0, 'memory_key_padding_mask': 0}),
                desc='no_batch_dim'
            ))

    return samples


def module_inputs_torch_nn_Transformer(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    samples = []
    key_padding_masks = (None, torch.tensor([False, False, True], device=device, dtype=torch.bool))
    attn_masks = (None, torch.tensor([False, False, True], device=device, dtype=torch.bool).expand((3, 3)))
    for mask, key_padding_mask, norm_first, bias in \
            itertools.product(attn_masks, key_padding_masks, (True, False), (True, False)):
        src_mask , tgt_mask = (mask,) * 2
        src_key_padding_mask, tgt_key_padding_mask = (key_padding_mask,) * 2
        samples.append(
            ModuleInput(
                constructor_input=FunctionInput(d_model=4, nhead=2, dim_feedforward=8,
                                                num_encoder_layers=1, num_decoder_layers=1,
                                                dropout=0.0, batch_first=True, norm_first=norm_first, bias=bias),
                forward_input=FunctionInput(
                    make_input((3, 4)), make_input((3, 4)), tgt_mask=tgt_mask, src_mask=src_mask,
                    tgt_key_padding_mask=tgt_key_padding_mask, src_key_padding_mask=src_key_padding_mask
                ),
                reference_fn=partial(no_batch_dim_reference_fn,
                                     batch_first=True,
                                     kwargs_to_batchify={'tgt_key_padding_mask': 0, 'src_key_padding_mask': 0}),
                desc='no_batch_dim_batch_first'
            ))

        samples.append(
            ModuleInput(
                constructor_input=FunctionInput(d_model=4, nhead=2, dim_feedforward=8,
                                                num_encoder_layers=1, num_decoder_layers=1,
                                                dropout=0.0, batch_first=False, norm_first=norm_first),
                forward_input=FunctionInput(
                    make_input((3, 4)), make_input((3, 4)), tgt_mask=tgt_mask, src_mask=src_mask,
                    tgt_key_padding_mask=tgt_key_padding_mask, src_key_padding_mask=src_key_padding_mask
                ),
                reference_fn=partial(no_batch_dim_reference_fn,
                                     batch_first=False,
                                     kwargs_to_batchify={'tgt_key_padding_mask': 0, 'src_key_padding_mask': 0}),
                desc='no_batch_dim'
            ))

    return samples


def module_inputs_torch_nn_Embedding(module_info, device, dtype, requires_grad, training, **kwargs):
    make_empty = partial(torch.empty, device=device, dtype=torch.long, requires_grad=False)
    return [
        ModuleInput(
            constructor_input=FunctionInput(num_embeddings=4, embedding_dim=3),
            forward_input=FunctionInput(make_empty(2, 3).random_(4))
        ),
        ModuleInput(
            constructor_input=FunctionInput(num_embeddings=4, embedding_dim=3),
            forward_input=FunctionInput(make_empty(1, 512).random_(4).expand(7, 512)),
            desc='discontiguous'
        ),
    ]


def module_inputs_torch_nn_MultiheadAttention(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    samples = []
    bool_vals = (True, False)
    key_padding_masks = (None, torch.tensor([False, False, True], device=device, dtype=torch.bool))
    attn_masks = (None, torch.tensor([False, False, True], device=device, dtype=torch.bool).expand((3, 3, 3)))
    products = itertools.product(bool_vals, bool_vals, bool_vals, key_padding_masks, attn_masks)
    for bias, add_bias_kv, add_zero_attn, key_padding_mask, attn_mask in products:
        samples.append(
            ModuleInput(
                constructor_input=FunctionInput(embed_dim=3, num_heads=3, batch_first=True,
                                                bias=bias, add_bias_kv=add_bias_kv, add_zero_attn=add_zero_attn),
                forward_input=FunctionInput(make_input((3, 3)), make_input((3, 3)), make_input((3, 3)),
                                            key_padding_mask=key_padding_mask, attn_mask=attn_mask),
                reference_fn=no_batch_dim_reference_mha,
            )
        )
        samples.append(
            ModuleInput(
                constructor_input=FunctionInput(embed_dim=3, num_heads=3, batch_first=False,
                                                bias=bias, add_bias_kv=add_bias_kv, add_zero_attn=add_zero_attn),
                forward_input=FunctionInput(make_input((3, 3)), make_input((3, 3)), make_input((3, 3)),
                                            key_padding_mask=key_padding_mask, attn_mask=attn_mask),
                reference_fn=partial(no_batch_dim_reference_mha, batch_first=False),
            )
        )

    return samples


def module_inputs_torch_nn_RNN_GRU_Cell(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    samples = [
        ModuleInput(
            constructor_input=FunctionInput(5, 10),
            forward_input=FunctionInput(make_input(5), make_input(10)),
            reference_fn=no_batch_dim_reference_fn,
        ),
        ModuleInput(
            constructor_input=FunctionInput(5, 10, bias=True),
            forward_input=FunctionInput(make_input(5), make_input(10)),
            reference_fn=no_batch_dim_reference_fn,
        )
    ]

    is_rnn = kwargs.get('is_rnn', False)
    if is_rnn:
        samples.append(
            ModuleInput(
                constructor_input=FunctionInput(5, 10, bias=True, nonlinearity='relu'),
                forward_input=FunctionInput(make_input(5), make_input(10)),
                reference_fn=no_batch_dim_reference_fn,
            )
        )

    return samples


def module_inputs_torch_nn_LSTMCell(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    samples = (
        ModuleInput(
            constructor_input=FunctionInput(5, 10),
            forward_input=FunctionInput(make_input(5), (make_input(10), make_input(10))),
            reference_fn=no_batch_dim_reference_lstmcell,
        ),
        ModuleInput(
            constructor_input=FunctionInput(5, 10, bias=True),
            forward_input=FunctionInput(make_input(5), (make_input(10), make_input(10))),
            reference_fn=no_batch_dim_reference_lstmcell,
        ),
    )

    return samples

def make_packed_sequence(inp, batch_sizes):
    required_grad = inp.requires_grad
    inp.requires_grad_(False)  # user won't have access to inp so won't be able to get its grads
    seq = pack_padded_sequence(inp, batch_sizes)
    seq.data.requires_grad_(required_grad)
    return seq


def module_inputs_torch_nn_RNN_GRU(module_info, device, dtype, requires_grad, training, with_packed_sequence=False, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    is_rnn = kwargs['is_rnn']
    nonlinearity = ('relu', 'tanh')
    bias = (False, True)
    batch_first = (False, True)
    bidirectional = (False, True)

    samples = []
    if is_rnn:
        prod_gen = product(nonlinearity, bias, batch_first, bidirectional)
    else:
        prod_gen = product(bias, batch_first, bidirectional)

    for args in prod_gen:
        if is_rnn:
            nl, b, b_f, bidir = args
        else:
            b, b_f, bidir = args

        cons_args = {'input_size': 2, 'hidden_size': 2, 'num_layers': 2,
                     'batch_first': b_f, 'bias': b, 'bidirectional': bidir}
        cons_args_hidden = {'input_size': 2, 'hidden_size': 3, 'num_layers': 2,
                            'batch_first': b_f, 'bias': b, 'bidirectional': bidir}

        if is_rnn:
            cons_args['nonlinearity'] = nl
            cons_args_hidden['nonlinearity'] = nl
        samples.append(
            ModuleInput(
                constructor_input=FunctionInput(**cons_args),
                forward_input=FunctionInput(make_input((3, 2))),
                reference_fn=partial(no_batch_dim_reference_rnn_gru, batch_first=b_f),
            )
        )
        samples.append(
            ModuleInput(
                constructor_input=FunctionInput(**cons_args_hidden),
                forward_input=FunctionInput(make_input((3, 2)), make_input((4 if bidir else 2, 3))),
                reference_fn=partial(no_batch_dim_reference_rnn_gru, batch_first=b_f),
            )
        )
        if with_packed_sequence:
            samples.append(
                ModuleInput(
                    constructor_input=FunctionInput(**cons_args),
                    forward_input=FunctionInput(make_packed_sequence(make_input((5, 2, 2)), torch.tensor([5, 3]))),
                    reference_fn=partial(no_batch_dim_reference_rnn_gru, batch_first=b_f),
                )
            )
            samples.append(
                ModuleInput(
                    constructor_input=FunctionInput(**cons_args),
                    forward_input=FunctionInput(make_packed_sequence(make_input((5, 5, 2)), torch.tensor([5, 3, 3, 2, 2]))),
                    reference_fn=partial(no_batch_dim_reference_rnn_gru, batch_first=b_f),
                )
            )

    return samples


def module_inputs_torch_nn_LSTM(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    bias = (False, True)
    batch_first = (False, True)
    bidirectional = (False, True)
    proj_sizes = (0, 2)

    samples = []
    prod_gen = product(bias, batch_first, bidirectional, proj_sizes)

    for args in prod_gen:
        b, b_f, bidir, proj_size = args
        hidden_size = 3
        cons_args = {'input_size': 2, 'hidden_size': hidden_size, 'num_layers': 2, 'proj_size': proj_size,
                     'batch_first': b_f, 'bias': b, 'bidirectional': bidir}
        cons_args_hidden = {'input_size': 2, 'hidden_size': hidden_size, 'num_layers': 2, 'proj_size': proj_size,
                            'batch_first': b_f, 'bias': b, 'bidirectional': bidir}

        samples.append(
            ModuleInput(
                constructor_input=FunctionInput(**cons_args),
                forward_input=FunctionInput(make_input((2, 2))),
                reference_fn=partial(no_batch_dim_reference_lstm, batch_first=b_f),
            )
        )

        h_out = proj_size if proj_size > 0 else hidden_size
        hx = (make_input((4 if bidir else 2, h_out)), make_input((4 if bidir else 2, hidden_size)))
        samples.append(
            ModuleInput(
                constructor_input=FunctionInput(**cons_args_hidden),
                forward_input=FunctionInput(make_input((3, 2)), hx),
                reference_fn=partial(no_batch_dim_reference_lstm, batch_first=b_f),
            )
        )


    return samples



def module_inputs_torch_nn_ReflectionPad1d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(
            constructor_input=FunctionInput(1),
            forward_input=FunctionInput(make_input((2, 3))),
            reference_fn=no_batch_dim_reference_fn,
        ),
        ModuleInput(
            constructor_input=FunctionInput((1, 2)),
            forward_input=FunctionInput(make_input((2, 3, 4))),
        ),
    ]

def module_inputs_torch_nn_ReflectionPad2d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(
            constructor_input=FunctionInput(1),
            forward_input=FunctionInput(make_input((3, 4, 5))),
            reference_fn=no_batch_dim_reference_fn,
        ),
        ModuleInput(
            constructor_input=FunctionInput((1, 2, 3, 4)),
            forward_input=FunctionInput(make_input((3, 4, 5, 6))),
        ),
    ]

def module_inputs_torch_nn_ReflectionPad3d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(
            constructor_input=FunctionInput(1),
            forward_input=FunctionInput(make_input((2, 3, 4, 5))),
            reference_fn=no_batch_dim_reference_fn
        ),
        ModuleInput(
            constructor_input=FunctionInput((1, 2, 1, 2, 1, 2)),
            forward_input=FunctionInput(make_input((3, 3, 3, 3, 3))),
        ),
    ]

def module_inputs_torch_nn_ReplicationPad1d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(
            constructor_input=FunctionInput(1),
            forward_input=FunctionInput(make_input((3, 4))),
            reference_fn=no_batch_dim_reference_fn
        ),
        ModuleInput(
            constructor_input=FunctionInput((1, 2)),
            forward_input=FunctionInput(make_input((3, 4, 5))),
        ),
    ]

def module_inputs_torch_nn_ReplicationPad2d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(
            constructor_input=FunctionInput(1),
            forward_input=FunctionInput(make_input((3, 4, 5))),
            reference_fn=no_batch_dim_reference_fn,
        ),
        ModuleInput(
            constructor_input=FunctionInput((1, 2, 3, 4)),
            forward_input=FunctionInput(make_input((3, 4, 5, 6))),
        ),
    ]

def module_inputs_torch_nn_ReplicationPad3d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(
            constructor_input=FunctionInput(1),
            forward_input=FunctionInput(make_input((3, 4, 5, 6))),
            reference_fn=no_batch_dim_reference_fn,
        ),
        ModuleInput(
            constructor_input=FunctionInput((1, 2, 3, 4, 5, 6)),
            forward_input=FunctionInput(make_input((3, 4, 5, 6, 7))),
        ),
    ]

def module_inputs_torch_nn_ZeroPad1d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(
            constructor_input=FunctionInput(1),
            forward_input=FunctionInput(make_input((3, 4))),
            reference_fn=no_batch_dim_reference_fn,
        ),
        ModuleInput(
            constructor_input=FunctionInput((1, 2)),
            forward_input=FunctionInput(make_input((3, 4, 5))),
        ),
    ]

def module_inputs_torch_nn_ZeroPad2d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(
            constructor_input=FunctionInput(1),
            forward_input=FunctionInput(make_input((1, 2, 3))),
            reference_fn=no_batch_dim_reference_fn
        ),
        ModuleInput(
            constructor_input=FunctionInput((1, 2, 3, 4)),
            forward_input=FunctionInput(make_input((1, 2, 3, 4))),
        ),
    ]

def module_inputs_torch_nn_ZeroPad3d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(
            constructor_input=FunctionInput(1),
            forward_input=FunctionInput(make_input((3, 4, 5, 6))),
            reference_fn=no_batch_dim_reference_fn,
        ),
        ModuleInput(
            constructor_input=FunctionInput((1, 2, 3, 4, 5, 6)),
            forward_input=FunctionInput(make_input((1, 2, 3, 4, 5))),
        ),
    ]

def module_inputs_torch_nn_ConstantPad1d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(
            constructor_input=FunctionInput(1, 2),
            forward_input=FunctionInput(make_input((3, 4))),
            reference_fn=no_batch_dim_reference_fn,
        ),
        ModuleInput(
            constructor_input=FunctionInput((1, 2), 3),
            forward_input=FunctionInput(make_input((3, 4, 5))),
        ),
    ]

def module_inputs_torch_nn_ConstantPad2d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(
            constructor_input=FunctionInput(1, 3),
            forward_input=FunctionInput(make_input((3, 4, 5))),
            reference_fn=no_batch_dim_reference_fn
        ),
        ModuleInput(
            constructor_input=FunctionInput((1, 2, 3, 4), 5),
            forward_input=FunctionInput(make_input((1, 2, 3, 4))),
        ),
    ]

def module_inputs_torch_nn_ConstantPad3d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    return [
        ModuleInput(
            constructor_input=FunctionInput(1, 3),
            forward_input=FunctionInput(make_input((3, 4, 5, 6))),
            reference_fn=no_batch_dim_reference_fn,
        ),
        ModuleInput(
            constructor_input=FunctionInput((1, 2, 3, 4, 5, 6), 7),
            forward_input=FunctionInput(make_input((1, 2, 1, 2, 1))),
        ),
    ]

def module_inputs_torch_nn_CircularPad1d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    def padding1d_circular_ref(inp, pad):
        return torch.cat([inp[:, :, -pad[0]:], inp, inp[:, :, :pad[1]]], dim=2)

    return [
        ModuleInput(
            constructor_input=FunctionInput(1),
            forward_input=FunctionInput(make_input((3, 4))),
            reference_fn=no_batch_dim_reference_fn
        ),
        ModuleInput(
            constructor_input=FunctionInput((1, 2)),
            forward_input=FunctionInput(make_input((1, 2, 3))),
            reference_fn=lambda m, p, i: padding1d_circular_ref(i, m.padding),
        ),
        ModuleInput(
            constructor_input=FunctionInput((3, 1)),
            forward_input=FunctionInput(make_input((1, 2, 3))),
            reference_fn=lambda m, p, i: padding1d_circular_ref(i, m.padding),
        ),
        ModuleInput(
            constructor_input=FunctionInput((3, 3)),
            forward_input=FunctionInput(make_input((1, 2, 3))),
            reference_fn=lambda m, p, i: padding1d_circular_ref(i, m.padding),
        ),
    ]

def module_inputs_torch_nn_CircularPad2d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    def padding2d_circular_ref(inp, pad):
        inp = torch.cat([inp[:, :, -pad[2]:], inp, inp[:, :, :pad[3]]], dim=2)
        return torch.cat([inp[:, :, :, -pad[0]:], inp, inp[:, :, :, :pad[1]]], dim=3)

    return [
        ModuleInput(
            constructor_input=FunctionInput(1),
            forward_input=FunctionInput(make_input((3, 4, 5))),
            reference_fn=no_batch_dim_reference_fn,
        ),
        ModuleInput(
            constructor_input=FunctionInput((1, 2, 2, 1)),
            forward_input=FunctionInput(make_input((1, 1, 2, 3))),
            reference_fn=lambda m, p, i: padding2d_circular_ref(i, m.padding),
        ),
        ModuleInput(
            constructor_input=FunctionInput((2, 3, 2, 2)),
            forward_input=FunctionInput(make_input((1, 1, 2, 3))),
            reference_fn=lambda m, p, i: padding2d_circular_ref(i, m.padding),
        ),
        ModuleInput(
            constructor_input=FunctionInput((3, 3, 3, 1)),
            forward_input=FunctionInput(make_input((1, 1, 3, 3))),
            reference_fn=lambda m, p, i: padding2d_circular_ref(i, m.padding),
        ),
    ]

def module_inputs_torch_nn_CircularPad3d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)


    def padding3d_circular_ref(inp, pad):
        inp = torch.cat([inp[:, :, -pad[4]:], inp, inp[:, :, :pad[5]]], dim=2)
        inp = torch.cat([inp[:, :, :, -pad[2]:], inp, inp[:, :, :, :pad[3]]], dim=3)
        return torch.cat([inp[:, :, :, :, -pad[0]:], inp, inp[:, :, :, :, :pad[1]]], dim=4)

    return [
        ModuleInput(
            constructor_input=FunctionInput(1),
            forward_input=FunctionInput(make_input((3, 4, 5, 6))),
            reference_fn=no_batch_dim_reference_fn,
        ),
        ModuleInput(
            constructor_input=FunctionInput((1, 2, 1, 2, 1, 2)),
            forward_input=FunctionInput(make_input((1, 1, 2, 2, 3))),
            reference_fn=lambda m, p, i: padding3d_circular_ref(i, m.padding)
        ),
        ModuleInput(
            constructor_input=FunctionInput((3, 2, 2, 1, 1, 2)),
            forward_input=FunctionInput(make_input((1, 1, 2, 2, 3))),
            reference_fn=lambda m, p, i: padding3d_circular_ref(i, m.padding)
        ),
        ModuleInput(
            constructor_input=FunctionInput((3, 3, 2, 1, 2, 2)),
            forward_input=FunctionInput(make_input((1, 1, 2, 2, 3))),
            reference_fn=lambda m, p, i: padding3d_circular_ref(i, m.padding)
        ),
    ]


rnn_gru_lstm_module_info_decorators = (
    DecorateInfo(
        unittest.expectedFailure, "TestModule", "test_grad",
        active_if=(TEST_CUDNN and not TEST_WITH_ROCM), device_type='cuda'
    ),
    DecorateInfo(
        unittest.expectedFailure, "TestModule", "test_gradgrad",
        active_if=(TEST_CUDNN and not TEST_WITH_ROCM), device_type='cuda'
    ),
    DecorateInfo(
        unittest.expectedFailure, "TestModule", "test_non_contiguous_tensors",
        active_if=(TEST_CUDNN and not TEST_WITH_ROCM), device_type='cuda'
    ),
    DecorateInfo(
        unittest.expectedFailure, "TestModule", "test_non_contiguous_tensors",
        active_if=(TEST_CUDNN and TEST_WITH_ROCM), dtypes=(torch.float,), device_type='cuda'
    ),
    DecorateInfo(
        skipCUDAVersionIn([(11, 7)]), "TestExpandedWeightModule", "test_module",
        device_type='cuda'
    ),
    DecorateInfo(
        skipCUDAVersionIn([(11, 7)]), "TestDecomp", "test_rnn_decomp_module",
        device_type='cuda'
    )
)


def module_error_inputs_torch_nn_RNN_GRU_Cell(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    samples = [
        ErrorModuleInput(
            ModuleInput(
                constructor_input=FunctionInput(10, 20),
                forward_input=FunctionInput(make_input(3, 11), make_input(3, 20)),
            ),
            error_on=ModuleErrorEnum.FORWARD_ERROR,
            error_type=RuntimeError,
            error_regex="input has inconsistent input_size: got 11 expected 10"
        ),
        ErrorModuleInput(
            ModuleInput(
                constructor_input=FunctionInput(10, 20),
                forward_input=FunctionInput(make_input(3, 10), make_input(3, 21)),
            ),
            error_on=ModuleErrorEnum.FORWARD_ERROR,
            error_type=RuntimeError,
            error_regex="hidden0 has inconsistent hidden_size: got 21, expected 20"
        ),
        ErrorModuleInput(
            ModuleInput(
                constructor_input=FunctionInput(10, 20),
                forward_input=FunctionInput(make_input(3, 10), make_input(5, 20)),
            ),
            error_on=ModuleErrorEnum.FORWARD_ERROR,
            error_type=RuntimeError,
            error_regex="Input batch size 3 doesn't match hidden0 batch size 5"
        ),
        ErrorModuleInput(
            ModuleInput(
                constructor_input=FunctionInput(10, 20),
                forward_input=FunctionInput(make_input(3, 10), make_input(3, 1, 1, 20)),
            ),
            error_on=ModuleErrorEnum.FORWARD_ERROR,
            error_type=ValueError,
            error_regex="Expected hidden to be 1D or 2D, got 4D instead"
        ),
        ErrorModuleInput(
            ModuleInput(
                constructor_input=FunctionInput(10, 20, 'relu'),
                forward_input=FunctionInput(make_input(3, 10), make_input(3, 21)),
            ),
            error_on=ModuleErrorEnum.FORWARD_ERROR,
            error_type=RuntimeError,
            error_regex="hidden0 has inconsistent hidden_size: got 21, expected 20"
        ),
        ErrorModuleInput(
            ModuleInput(
                constructor_input=FunctionInput(10, 20, 'tanh'),
                forward_input=FunctionInput(make_input(3, 10), make_input(3, 21)),
            ),
            error_on=ModuleErrorEnum.FORWARD_ERROR,
            error_type=RuntimeError,
            error_regex="hidden0 has inconsistent hidden_size: got 21, expected 20"
        ),
    ]
    return samples

def module_error_inputs_torch_nn_LSTMCell(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    samples = [
        ErrorModuleInput(
            ModuleInput(
                constructor_input=FunctionInput(10, 20),
                forward_input=FunctionInput(make_input(3, 11), (make_input(3, 20), make_input(3, 20))),
            ),
            error_on=ModuleErrorEnum.FORWARD_ERROR,
            error_type=RuntimeError,
            error_regex="input has inconsistent input_size: got 11 expected 10"
        ),
        ErrorModuleInput(
            ModuleInput(
                constructor_input=FunctionInput(10, 20),
                forward_input=FunctionInput(make_input(3, 10), (make_input(3, 21), make_input(3, 21))),
            ),
            error_on=ModuleErrorEnum.FORWARD_ERROR,
            error_type=RuntimeError,
            error_regex="hidden0 has inconsistent hidden_size: got 21, expected 20"
        ),
        ErrorModuleInput(
            ModuleInput(
                constructor_input=FunctionInput(10, 20),
                forward_input=FunctionInput(make_input(3, 10), (make_input(5, 20), make_input(5, 20))),
            ),
            error_on=ModuleErrorEnum.FORWARD_ERROR,
            error_type=RuntimeError,
            error_regex="Input batch size 3 doesn't match hidden0 batch size 5"
        ),
        ErrorModuleInput(
            ModuleInput(
                constructor_input=FunctionInput(10, 20),
                forward_input=FunctionInput(make_input(3, 10), (make_input(3, 1, 1, 20), make_input(3, 1, 1, 20))),
            ),
            error_on=ModuleErrorEnum.FORWARD_ERROR,
            error_type=ValueError,
            error_regex="Expected hx\\[0\\] to be 1D or 2D, got 4D instead"
        ),
    ]
    return samples


def module_error_inputs_torch_nn_RNN_GRU(module_info, device, dtype, requires_grad, training, **kwargs):
    samples = [
        ErrorModuleInput(
            ModuleInput(constructor_input=FunctionInput(10, 0, 1)),
            error_on=ModuleErrorEnum.CONSTRUCTION_ERROR,
            error_type=ValueError,
            error_regex="hidden_size must be greater than zero"
        ),
        ErrorModuleInput(
            ModuleInput(constructor_input=FunctionInput(10, 10, 0)),
            error_on=ModuleErrorEnum.CONSTRUCTION_ERROR,
            error_type=ValueError,
            error_regex="num_layers must be greater than zero"
        ),
    ]
    return samples

def module_error_inputs_torch_nn_Pad1d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    is_constant = kwargs.get('is_constant', False)

    return [
        ErrorModuleInput(
            ModuleInput(
                constructor_input=FunctionInput(1, 3) if is_constant else FunctionInput(3),
                forward_input=FunctionInput(make_input((2, 3, 4, 5))),
            ),
            error_on=ModuleErrorEnum.FORWARD_ERROR,
            error_type=ValueError,
            error_regex=r"expected 2D or 3D input \(got 4D input\)",

        ),
    ]

def module_error_inputs_torch_nn_Pad2d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    is_constant = kwargs.get('is_constant', False)

    return [
        ErrorModuleInput(
            ModuleInput(
                constructor_input=FunctionInput(1, 3) if is_constant else FunctionInput(3),
                forward_input=FunctionInput(make_input((2, 3))),
            ),
            error_on=ModuleErrorEnum.FORWARD_ERROR,
            error_type=ValueError,
            error_regex=r"expected 3D or 4D input \(got 2D input\)",

        ),
    ]

def module_error_inputs_torch_nn_Pad3d(module_info, device, dtype, requires_grad, training, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    is_constant = kwargs.get('is_constant', False)

    return [
        ErrorModuleInput(
            ModuleInput(
                constructor_input=FunctionInput(1, 3) if is_constant else FunctionInput(3),
                forward_input=FunctionInput(make_input((2, 3))),
            ),
            error_on=ModuleErrorEnum.FORWARD_ERROR,
            error_type=ValueError,
            error_regex=r"expected 4D or 5D input \(got 2D input\)",

        ),
    ]


module_db: List[ModuleInfo] = [
    ModuleInfo(torch.nn.AdaptiveAvgPool1d,
               module_inputs_func=module_inputs_torch_nn_AdaptiveAvgPool1d,
               skips=(
                   DecorateInfo(skipMPS),)
               ),
    ModuleInfo(torch.nn.AdaptiveAvgPool2d,
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               module_inputs_func=module_inputs_torch_nn_AdaptiveAvgPool2d,
               skips=(
                   DecorateInfo(skipMPS),
                   DecorateInfo(
                       unittest.expectedFailure,
                       'TestModule',
                       'test_memory_format',
                       active_if=lambda p: p['training'],
                   ),)
               ),
    ModuleInfo(torch.nn.AdaptiveAvgPool3d,
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               module_inputs_func=module_inputs_torch_nn_AdaptiveAvgPool3d,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipMPS),)
               ),
    ModuleInfo(torch.nn.AdaptiveMaxPool1d,
               module_inputs_func=module_inputs_torch_nn_AdaptiveMaxPool1d,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.AdaptiveMaxPool2d,
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               module_inputs_func=module_inputs_torch_nn_AdaptiveMaxPool2d,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.AdaptiveMaxPool3d,
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               module_inputs_func=module_inputs_torch_nn_AdaptiveMaxPool3d,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipMPS),)
               ),
    ModuleInfo(torch.nn.AvgPool1d,
               module_inputs_func=module_inputs_torch_nn_AvgPool1d,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.AvgPool2d,
               module_inputs_func=module_inputs_torch_nn_AvgPool2d,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(
                       unittest.expectedFailure,
                       'TestModule',
                       'test_memory_format',
                       active_if=lambda p: p['training'],
                       device_type='cuda',
                   ),),
               ),
    ModuleInfo(torch.nn.AvgPool3d,
               module_inputs_func=module_inputs_torch_nn_AvgPool3d,
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipMPS),)
               ),
    ModuleInfo(torch.nn.BatchNorm1d,
               train_and_eval_differ=True,
               module_inputs_func=module_inputs_torch_nn_BatchNorm1d,
               skips=(
                   DecorateInfo(skipMPS),
                   DecorateInfo(
                       unittest.expectedFailure, 'TestEagerFusionModuleInfo',
                       'test_aot_autograd_symbolic_module_exhaustive',
                       active_if=lambda p: p['training']
                   ),
                   DecorateInfo(
                       unittest.expectedFailure, 'TestEagerFusionModuleInfo',
                       'test_aot_autograd_module_exhaustive',
                       active_if=lambda p: p['training']
                   ))
               ),
    ModuleInfo(torch.nn.BatchNorm2d,
               train_and_eval_differ=True,
               module_inputs_func=module_inputs_torch_nn_BatchNorm2d,
               skips=(
                   DecorateInfo(skipMPS),
                   DecorateInfo(
                       unittest.expectedFailure, 'TestEagerFusionModuleInfo',
                       'test_aot_autograd_symbolic_module_exhaustive',
                       active_if=lambda p: p['training']
                   ),
                   DecorateInfo(
                       unittest.expectedFailure, 'TestEagerFusionModuleInfo',
                       'test_aot_autograd_module_exhaustive',
                       active_if=lambda p: p['training']
                   ),)
               ),
    ModuleInfo(torch.nn.BatchNorm3d,
               train_and_eval_differ=True,
               module_inputs_func=module_inputs_torch_nn_BatchNorm3d,
               skips=(
                   DecorateInfo(skipMPS),
                   DecorateInfo(
                       unittest.expectedFailure, 'TestEagerFusionModuleInfo',
                       'test_aot_autograd_symbolic_module_exhaustive',
                       active_if=lambda p: p['training']
                   ),
                   DecorateInfo(
                       unittest.expectedFailure, 'TestEagerFusionModuleInfo',
                       'test_aot_autograd_module_exhaustive',
                       active_if=lambda p: p['training']
                   ),)
               ),
    ModuleInfo(torch.nn.CELU,
               module_inputs_func=module_inputs_torch_nn_CELU,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.Conv1d,
               module_inputs_func=partial(module_inputs_torch_nn_ConvNd, N=1, lazy=False),
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               module_memformat_affects_out=True,
               skips=(
                   DecorateInfo(skipCUDAIfCudnnVersionLessThan(version=7603), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipCUDAIfRocm, 'TestModule', 'test_memory_format', dtypes=[torch.float32]),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64])
               ),
               decorators=(
                   DecorateInfo(precisionOverride({torch.float32: 1e-04}), 'TestModule', 'test_memory_format'),
               )),
    ModuleInfo(torch.nn.Conv2d,
               module_inputs_func=partial(module_inputs_torch_nn_ConvNd, N=2, lazy=False),
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               module_memformat_affects_out=True,
               skips=(
                   DecorateInfo(skipCUDAIfCudnnVersionLessThan(version=7603), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipCUDAIfRocm, 'TestModule', 'test_memory_format', dtypes=[torch.float32]),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(unittest.expectedFailure, "TestModule", "test_memory_format",
                                device_type='cuda', dtypes=[torch.float64]),
                   DecorateInfo(unittest.expectedFailure, "TestModule", "test_memory_format",
                                device_type='mps', dtypes=[torch.float32]),
               ),
               decorators=(
                   DecorateInfo(precisionOverride({torch.float32: 1e-04}), 'TestModule', 'test_memory_format'),
               )),
    ModuleInfo(torch.nn.Conv3d,
               module_inputs_func=partial(module_inputs_torch_nn_ConvNd, N=3, lazy=False),
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               module_memformat_affects_out=True,
               skips=(
                   DecorateInfo(skipCUDAIfCudnnVersionLessThan(version=8005), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipCUDAIfRocm, 'TestModule', 'test_memory_format', dtypes=[torch.float32]),
                   DecorateInfo(skipMPS),
                   DecorateInfo(unittest.expectedFailure, "TestModule", "test_memory_format"),
               ),
               decorators=(
                   DecorateInfo(precisionOverride({torch.float32: 1e-04}), 'TestModule', 'test_memory_format'),
               )),
    ModuleInfo(torch.nn.ConvTranspose1d,
               module_inputs_func=partial(module_inputs_torch_nn_ConvNd, N=1, lazy=False, transposed=True),
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               module_memformat_affects_out=True,
               dtypes=floating_and_complex_types_and(torch.chalf),
               skips=(
                   DecorateInfo(skipCUDAIfCudnnVersionLessThan(version=7603), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipCUDAIfRocm, 'TestModule', 'test_memory_format', dtypes=[torch.float32]),
                   DecorateInfo(skipIfMps, 'TestModule',
                                dtypes=complex_types_and(torch.chalf, torch.float64, torch.complex128)),
                   DecorateInfo(unittest.expectedFailure, 'TestModule', 'test_cpu_gpu_parity',
                                dtypes=(torch.chalf,), device_type='cuda'),
                   DecorateInfo(unittest.expectedFailure, 'TestModule', 'test_pickle', dtypes=(torch.chalf,)),
               ),
               decorators=(
                   DecorateInfo(precisionOverride({torch.float32: 1e-04}), 'TestModule', 'test_memory_format'),
                   DecorateInfo(precisionOverride({torch.chalf: 5e-03}), 'TestModule', 'test_memory_format'),
               )),
    ModuleInfo(torch.nn.ConvTranspose2d,
               module_inputs_func=partial(module_inputs_torch_nn_ConvNd, N=2, lazy=False, transposed=True),
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               module_memformat_affects_out=True,
               dtypes=floating_and_complex_types_and(torch.chalf),
               skips=(
                   DecorateInfo(skipCUDAIfCudnnVersionLessThan(version=7603), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipCUDAIfRocm, 'TestModule', 'test_memory_format', dtypes=[torch.float32]),
                   DecorateInfo(skipIfMps, 'TestModule',
                                dtypes=complex_types_and(torch.chalf, torch.float64, torch.complex128)),
                   DecorateInfo(unittest.expectedFailure, 'TestModule', 'test_memory_format',
                                dtypes=(torch.complex32, torch.complex64, torch.complex128)),
                   DecorateInfo(unittest.expectedFailure, "TestModule", "test_memory_format", device_type='cuda',
                                dtypes=[torch.float64, torch.complex128]),
                   DecorateInfo(unittest.expectedFailure, "TestModule", "test_memory_format",
                                device_type='mps', dtypes=[torch.float32]),
                   DecorateInfo(unittest.expectedFailure, 'TestModule', 'test_cpu_gpu_parity',
                                dtypes=(torch.chalf,), device_type='cuda'),
                   DecorateInfo(unittest.expectedFailure, 'TestModule', 'test_pickle', dtypes=(torch.chalf,)),
               ),
               decorators=(
                   DecorateInfo(precisionOverride({torch.float32: 1e-04}), 'TestModule', 'test_memory_format'),
                   DecorateInfo(precisionOverride({torch.chalf: 5e-03}), 'TestModule', 'test_memory_format'),
               )),
    ModuleInfo(torch.nn.ConvTranspose3d,
               module_inputs_func=partial(module_inputs_torch_nn_ConvNd, N=3, lazy=False, transposed=True),
               dtypes=floating_and_complex_types_and(torch.chalf),
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               module_memformat_affects_out=True,
               skips=(
                   DecorateInfo(skipCUDAIfCudnnVersionLessThan(version=8005), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipCUDAIfRocm, 'TestModule', 'test_memory_format', dtypes=[torch.float32]),
                   DecorateInfo(skipMPS),
                   DecorateInfo(unittest.expectedFailure, "TestModule", "test_memory_format"),
                   DecorateInfo(unittest.expectedFailure, "TestModule", "test_memory_format", device_type='cuda',
                                dtypes=[torch.complex32, torch.complex64], active_if=TEST_WITH_ROCM),
                   DecorateInfo(unittest.expectedFailure, 'TestModule', 'test_cpu_gpu_parity',
                                dtypes=(torch.chalf,), device_type='cuda'),
                   DecorateInfo(unittest.expectedFailure, 'TestModule', 'test_pickle', dtypes=(torch.chalf,)),
               ),
               decorators=(
                   DecorateInfo(precisionOverride({torch.float32: 1e-04}), 'TestModule', 'test_memory_format'),
                   DecorateInfo(precisionOverride({torch.complex64: 1e-04}), 'TestModule', 'test_cpu_gpu_parity'),
                   DecorateInfo(precisionOverride({torch.chalf: 5e-03}), 'TestModule', 'test_memory_format'),
               )),
    ModuleInfo(torch.nn.CosineEmbeddingLoss,
               module_inputs_func=module_inputs_torch_nn_CosineEmbeddingLoss,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.ELU,
               module_inputs_func=module_inputs_torch_nn_ELU,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.FractionalMaxPool2d,
               module_inputs_func=module_inputs_torch_nn_FractionalMaxPool2d,
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               skips=(
                   DecorateInfo(skipMPS),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),)
               ),
    ModuleInfo(torch.nn.FractionalMaxPool3d,
               module_inputs_func=module_inputs_torch_nn_FractionalMaxPool3d,
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               skips=(
                   DecorateInfo(skipMPS),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),)
               ),
    ModuleInfo(torch.nn.L1Loss,
               module_inputs_func=module_inputs_torch_nn_L1Loss,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.SmoothL1Loss,
               module_inputs_func=module_inputs_torch_nn_SmoothL1Loss,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.LazyConv1d,
               module_inputs_func=partial(module_inputs_torch_nn_ConvNd, N=1, lazy=True),
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               module_memformat_affects_out=True,
               skips=(
                   DecorateInfo(skipCUDAIfCudnnVersionLessThan(version=7603), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipCUDAIfRocm, 'TestModule', 'test_memory_format', dtypes=[torch.float32]),
                   DecorateInfo(skipMeta),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
               ),
               decorators=(
                   DecorateInfo(precisionOverride({torch.float32: 1e-04}), 'TestModule', 'test_memory_format'),
               )),
    ModuleInfo(torch.nn.LazyConv2d,
               module_inputs_func=partial(module_inputs_torch_nn_ConvNd, N=2, lazy=True),
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               module_memformat_affects_out=True,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(skipCUDAIfCudnnVersionLessThan(version=7603), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipCUDAIfRocm, 'TestModule', 'test_memory_format', dtypes=[torch.float32]),
                   DecorateInfo(skipMeta),
                   DecorateInfo(unittest.expectedFailure, "TestModule", "test_memory_format",
                                device_type='cuda', dtypes=[torch.float64]),
                   DecorateInfo(unittest.expectedFailure, "TestModule", "test_memory_format",
                                device_type='mps', dtypes=[torch.float32]),
               ),
               decorators=(
                   DecorateInfo(precisionOverride({torch.float32: 1e-04}), 'TestModule', 'test_memory_format'),
               )),
    ModuleInfo(torch.nn.LazyConv3d,
               module_inputs_func=partial(module_inputs_torch_nn_ConvNd, N=3, lazy=True),
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               module_memformat_affects_out=True,
               skips=(
                   DecorateInfo(skipCUDAIfCudnnVersionLessThan(version=8005), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipCUDAIfRocm, 'TestModule', 'test_memory_format', dtypes=[torch.float32]),
                   DecorateInfo(skipMeta),
                   DecorateInfo(skipMPS),
                   DecorateInfo(unittest.expectedFailure, "TestModule", "test_memory_format"),
               ),
               decorators=(
                   DecorateInfo(precisionOverride({torch.float32: 1e-04}), 'TestModule', 'test_memory_format'),
               )),
    ModuleInfo(torch.nn.LazyConvTranspose1d,
               module_inputs_func=partial(module_inputs_torch_nn_ConvNd, N=1, lazy=True, transposed=True),
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               module_memformat_affects_out=True,
               skips=(
                   DecorateInfo(skipCUDAIfCudnnVersionLessThan(version=7603), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipCUDAIfRocm, 'TestModule', 'test_memory_format', dtypes=[torch.float32]),
                   DecorateInfo(skipMeta),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
               ),
               decorators=(
                   DecorateInfo(precisionOverride({torch.float32: 1e-04}), 'TestModule', 'test_memory_format'),
               )),
    ModuleInfo(torch.nn.LazyConvTranspose2d,
               module_inputs_func=partial(module_inputs_torch_nn_ConvNd, N=2, lazy=True, transposed=True),
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               module_memformat_affects_out=True,
               skips=(
                   DecorateInfo(skipCUDAIfCudnnVersionLessThan(version=7603), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipCUDAIfRocm, 'TestModule', 'test_memory_format', dtypes=[torch.float32]),
                   DecorateInfo(skipMeta),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(unittest.expectedFailure, "TestModule", "test_memory_format", device_type='cuda',
                                dtypes=[torch.float64]),
                   DecorateInfo(unittest.expectedFailure, "TestModule", "test_memory_format",
                                device_type='mps', dtypes=[torch.float32]),
               ),
               decorators=(
                   DecorateInfo(precisionOverride({torch.float32: 1e-04}), 'TestModule', 'test_memory_format'),
               )),
    ModuleInfo(torch.nn.LazyConvTranspose3d,
               module_inputs_func=partial(module_inputs_torch_nn_ConvNd, N=3, lazy=True, transposed=True),
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               module_memformat_affects_out=True,
               skips=(
                   DecorateInfo(skipCUDAIfCudnnVersionLessThan(version=8005), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipCUDAIfRocm, 'TestModule', 'test_memory_format', dtypes=[torch.float32]),
                   DecorateInfo(skipMeta),
                   DecorateInfo(skipMPS),
                   DecorateInfo(unittest.expectedFailure, "TestModule", "test_memory_format"),
               ),
               decorators=(
                   DecorateInfo(precisionOverride({torch.float32: 1e-04}), 'TestModule', 'test_memory_format'),
               )),
    ModuleInfo(torch.nn.Linear,
               module_inputs_func=module_inputs_torch_nn_Linear,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),)
               ),
    ModuleInfo(torch.nn.Bilinear,
               module_inputs_func=module_inputs_torch_nn_Bilinear,
               decorators=[
                   DecorateInfo(
                       toleranceOverride({
                           torch.float32: tol(atol=1e-4, rtol=1e-4),
                           torch.float64: tol(atol=1e-4, rtol=1e-4)}),
                       'TestModule', 'test_forward', device_type='cpu')
               ],
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),)
               ),
    ModuleInfo(torch.nn.LPPool1d,
               module_inputs_func=module_inputs_torch_nn_LPPool1d,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_grad'),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_gradgrad'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.LPPool2d,
               module_inputs_func=module_inputs_torch_nn_LPPool2d,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_grad'),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_gradgrad'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(
                       unittest.expectedFailure,
                       'TestModule',
                       'test_memory_format',
                       active_if=lambda p: p['training'],
                       device_type='mps',
                   ),)
               ),
    ModuleInfo(torch.nn.LPPool3d,
               module_inputs_func=module_inputs_torch_nn_LPPool3d,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_grad'),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_gradgrad'),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps),)
               ),
    ModuleInfo(torch.nn.MaxPool1d,
               module_inputs_func=module_inputs_torch_nn_MaxPool1d,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.MaxPool2d,
               module_inputs_func=module_inputs_torch_nn_MaxPool2d,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.MaxPool3d,
               module_inputs_func=module_inputs_torch_nn_MaxPool3d,
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               skips=(
                   DecorateInfo(skipMPS),)
               ),
    ModuleInfo(torch.nn.KLDivLoss,
               module_inputs_func=module_inputs_torch_nn_KLDivLoss,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_cpu_gpu_parity'),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_grad'),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_gradgrad'),)
               ),
    ModuleInfo(torch.nn.MSELoss,
               module_inputs_func=module_inputs_torch_nn_MSELoss,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.MarginRankingLoss,
               module_inputs_func=module_inputs_torch_nn_MarginRankingLoss,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.MultiLabelMarginLoss,
               module_inputs_func=module_inputs_torch_nn_MultiLabelMarginLoss,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule'),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_gradgrad'),)
               ),
    ModuleInfo(torch.nn.MultiMarginLoss,
               module_inputs_func=module_inputs_torch_nn_MultiMarginLoss,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule'),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_gradgrad'),)
               ),
    ModuleInfo(torch.nn.SoftMarginLoss,
               module_inputs_func=module_inputs_torch_nn_SoftMarginLoss,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.MultiLabelSoftMarginLoss,
               module_inputs_func=module_inputs_torch_nn_MultiLabelSoftMarginLoss,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.NLLLoss,
               module_inputs_func=module_inputs_torch_nn_NLLLoss,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.GaussianNLLLoss,
               module_inputs_func=module_inputs_torch_nn_GaussianNLLLoss,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),)),
    ModuleInfo(torch.nn.PoissonNLLLoss,
               module_inputs_func=module_inputs_torch_nn_PoissonNLLLoss,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),)),
    ModuleInfo(torch.nn.HingeEmbeddingLoss,
               module_inputs_func=module_inputs_torch_nn_HingeEmbeddingLoss,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.HuberLoss,
               module_inputs_func=module_inputs_torch_nn_HuberLoss,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.BCELoss,
               module_inputs_func=module_inputs_torch_nn_BCELoss,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.BCEWithLogitsLoss,
               module_inputs_func=module_inputs_torch_nn_BCEWithLogitsLoss,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.CrossEntropyLoss,
               module_inputs_func=module_inputs_torch_nn_CrossEntropyLoss,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.CTCLoss,
               module_inputs_func=module_inputs_torch_nn_CTCLoss,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule'),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_grad'),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_gradgrad'),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_non_contiguous_tensors'),)
               ),
    ModuleInfo(torch.nn.GELU,
               module_inputs_func=module_inputs_torch_nn_GELU,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.GLU,
               module_inputs_func=module_inputs_torch_nn_GLU,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.GroupNorm,
               module_inputs_func=module_inputs_torch_nn_GroupNorm,
               dtypes=get_all_fp_dtypes(include_bfloat16=True, include_half=True),
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64, torch.bfloat16]),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_cpu_gpu_parity'),
                   DecorateInfo(toleranceOverride({torch.float32: tol(atol=1e-4, rtol=1e-4)}),
                                'TestModule', 'test_memory_format', device_type='cpu'),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format', device_type='cuda'),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format', device_type='mps'),
                   DecorateInfo(unittest.skip("Skipped!"), "TestModule", "test_grad",
                                active_if=TEST_WITH_ROCM, device_type='cuda'),)
               ),
    ModuleInfo(torch.nn.Hardshrink,
               module_inputs_func=module_inputs_torch_nn_Hardshrink,
               skips=(
                   DecorateInfo(skipMPS),),
               ),
    ModuleInfo(torch.nn.Hardswish,
               module_inputs_func=module_inputs_torch_nn_Hardswish,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(
                       unittest.expectedFailure,
                       'TestModule',
                       'test_memory_format',
                       active_if=lambda p: p['training'],
                       device_type='mps',
                   ),),
               supports_gradgrad=False),
    ModuleInfo(torch.nn.Hardtanh,
               module_inputs_func=module_inputs_torch_nn_Hardtanh,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),),
               ),
    ModuleInfo(torch.nn.InstanceNorm1d,
               module_inputs_func=partial(module_inputs_torch_nn_InstanceNormNd, N=1),
               train_and_eval_differ=True,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),)
               ),
    ModuleInfo(torch.nn.InstanceNorm2d,
               module_inputs_func=partial(module_inputs_torch_nn_InstanceNormNd, N=2),
               train_and_eval_differ=True,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),)
               ),
    ModuleInfo(torch.nn.InstanceNorm3d,
               module_inputs_func=partial(module_inputs_torch_nn_InstanceNormNd, N=3),
               train_and_eval_differ=True,
               skips=(
                   DecorateInfo(skipMPS),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),)
               ),
    ModuleInfo(torch.nn.LocalResponseNorm,
               module_inputs_func=module_inputs_torch_nn_LocalResponseNorm,
               skips=(
                   DecorateInfo(skipMPS),)
               ),
    ModuleInfo(torch.nn.LayerNorm,
               module_inputs_func=module_inputs_torch_nn_LayerNorm,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),)
               ),
    ModuleInfo(torch.nn.TransformerEncoder,
               train_and_eval_differ=True,
               module_inputs_func=module_inputs_torch_nn_TransformerEncoder,
               decorators=[
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_gradgrad',
                                device_type='cpu'),
               ],
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(unittest.expectedFailure, 'TestModule', 'test_factory_kwargs'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.TransformerEncoderLayer,
               train_and_eval_differ=True,
               module_inputs_func=module_inputs_torch_nn_TransformerEncoderLayer,
               decorators=[
                   DecorateInfo(toleranceOverride({torch.float32: tol(atol=1e-4, rtol=1e-4)}),
                                'TestModule', 'test_non_contiguous_tensors',
                                device_type='cpu', active_if=IS_WINDOWS),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_gradgrad',
                                device_type='cpu'),
               ],
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.TransformerDecoderLayer,
               module_inputs_func=module_inputs_torch_nn_TransformerDecoderLayer,
               decorators=[
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_gradgrad',
                                device_type='cpu'),
               ],
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.Transformer,
               module_inputs_func=module_inputs_torch_nn_Transformer,
               decorators=[
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_gradgrad',
                                device_type='cpu'),
               ],
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.MultiheadAttention,
               train_and_eval_differ=True,
               module_inputs_func=module_inputs_torch_nn_MultiheadAttention,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.Embedding,
               module_inputs_func=module_inputs_torch_nn_Embedding,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.ReLU,
               module_inputs_func=module_inputs_torch_nn_ReLU,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(
                       unittest.expectedFailure,
                       'TestModule',
                       'test_memory_format',
                       active_if=lambda p: p['training'],
                       device_type='mps',
                   ),)
               ),
    ModuleInfo(torch.nn.LeakyReLU,
               module_inputs_func=module_inputs_torch_nn_LeakyReLU,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.ReLU6,
               module_inputs_func=module_inputs_torch_nn_ReLU6,
               skips=(
                   DecorateInfo(skipMPS),)
               ),
    ModuleInfo(torch.nn.PReLU,
               module_inputs_func=module_inputs_torch_nn_PReLU,
               skips=(
                   DecorateInfo(skipMPS),)
               ),
    ModuleInfo(torch.nn.RNNCell,
               module_inputs_func=partial(module_inputs_torch_nn_RNN_GRU_Cell, is_rnn=True),
               module_error_inputs_func=module_error_inputs_torch_nn_RNN_GRU_Cell,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.GRUCell,
               module_inputs_func=module_inputs_torch_nn_RNN_GRU_Cell,
               module_error_inputs_func=module_error_inputs_torch_nn_RNN_GRU_Cell,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.LSTMCell,
               module_inputs_func=module_inputs_torch_nn_LSTMCell,
               module_error_inputs_func=module_error_inputs_torch_nn_LSTMCell,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.Sigmoid,
               module_inputs_func=module_inputs_torch_nn_Sigmoid,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(
                       unittest.expectedFailure,
                       'TestModule',
                       'test_memory_format',
                       active_if=lambda p: p['training'],
                       device_type='mps',
                   ),)
               ),
    ModuleInfo(torch.nn.LogSigmoid,
               module_inputs_func=module_inputs_torch_nn_LogSigmoid,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.SiLU,
               module_inputs_func=module_inputs_torch_nn_SiLU,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.Softmax,
               module_inputs_func=module_inputs_torch_nn_Softmax,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.Softmax2d,
               module_inputs_func=module_inputs_torch_nn_Softmax2d,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),)
               ),
    ModuleInfo(torch.nn.LogSoftmax,
               module_inputs_func=module_inputs_torch_nn_LogSoftmax,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),)
               ),
    ModuleInfo(torch.nn.Softmin,
               module_inputs_func=module_inputs_torch_nn_Softmin,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format'),)
               ),
    ModuleInfo(torch.nn.Softplus,
               module_inputs_func=module_inputs_torch_nn_Softplus,
               skips=(
                   DecorateInfo(skipMPS),)
               ),
    ModuleInfo(torch.nn.Softshrink,
               module_inputs_func=module_inputs_torch_nn_Softshrink,
               skips=(
                   DecorateInfo(skipMPS),)
               ),
    ModuleInfo(torch.nn.Softsign,
               module_inputs_func=module_inputs_torch_nn_Softsign,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.Tanh,
               module_inputs_func=module_inputs_torch_nn_Tanh,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(
                       unittest.expectedFailure,
                       'TestModule',
                       'test_memory_format',
                       active_if=lambda p: p['training'],
                       device_type='mps',
                   ),)
               ),
    ModuleInfo(torch.nn.Tanhshrink,
               module_inputs_func=module_inputs_torch_nn_Tanhshrink,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(
                       unittest.expectedFailure,
                       'TestModule',
                       'test_memory_format',
                       active_if=lambda p: p['training'],
                       device_type='mps',
                   ),)
               ),
    ModuleInfo(torch.nn.Threshold,
               module_inputs_func=module_inputs_torch_nn_Threshold,
               skips=(
                   DecorateInfo(skipMPS),)
               ),
    ModuleInfo(torch.nn.Mish,
               module_inputs_func=module_inputs_torch_nn_Mish,
               skips=(
                   DecorateInfo(skipMPS),)
               ),
    ModuleInfo(torch.nn.RNN,
               train_and_eval_differ=True,
               module_inputs_func=partial(module_inputs_torch_nn_RNN_GRU, is_rnn=True),
               module_error_inputs_func=module_error_inputs_torch_nn_RNN_GRU,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),),
               decorators=rnn_gru_lstm_module_info_decorators
               ),
    ModuleInfo(torch.nn.GRU,
               train_and_eval_differ=True,
               module_inputs_func=partial(module_inputs_torch_nn_RNN_GRU, is_rnn=False),
               module_error_inputs_func=module_error_inputs_torch_nn_RNN_GRU,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),),
               decorators=rnn_gru_lstm_module_info_decorators),
    ModuleInfo(torch.nn.LSTM,
               train_and_eval_differ=True,
               module_inputs_func=module_inputs_torch_nn_LSTM,
               module_error_inputs_func=module_error_inputs_torch_nn_RNN_GRU,
               skips=(
                   DecorateInfo(skipMPS),),
               decorators=rnn_gru_lstm_module_info_decorators),
    ModuleInfo(torch.nn.ReflectionPad1d,
               module_inputs_func=module_inputs_torch_nn_ReflectionPad1d,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.ReflectionPad2d,
               module_inputs_func=module_inputs_torch_nn_ReflectionPad2d,
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format',
                                device_type='cuda'),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format',
                                device_type='mps'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.ReflectionPad3d,
               module_inputs_func=module_inputs_torch_nn_ReflectionPad3d,
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format',
                                device_type='cuda'),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format',
                                device_type='mps'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.ReplicationPad1d,
               module_inputs_func=module_inputs_torch_nn_ReplicationPad1d,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.ReplicationPad2d,
               module_inputs_func=module_inputs_torch_nn_ReplicationPad2d,
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format',
                                device_type='cuda'),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format',
                                device_type='mps'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.ReplicationPad3d,
               module_inputs_func=module_inputs_torch_nn_ReplicationPad3d,
               gradcheck_nondet_tol=GRADCHECK_NONDET_TOL,
               skips=(
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format',
                                device_type='cuda'),
                   DecorateInfo(unittest.skip("Skipped!"), 'TestModule', 'test_memory_format',
                                device_type='mps'),
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.SELU,
               module_inputs_func=module_inputs_torch_nn_SELU,
               skips=(
                   DecorateInfo(skipMPS),)
               ),
    ModuleInfo(torch.nn.ZeroPad1d,
               module_inputs_func=module_inputs_torch_nn_ZeroPad1d,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.ZeroPad2d,
               module_inputs_func=module_inputs_torch_nn_ZeroPad2d,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(unittest.expectedFailure, "TestModule", "test_memory_format", device_type='mps'),)
               ),
    ModuleInfo(torch.nn.ZeroPad3d,
               module_inputs_func=module_inputs_torch_nn_ZeroPad3d,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(unittest.expectedFailure, "TestModule", "test_memory_format", device_type='mps'),)
               ),
    ModuleInfo(torch.nn.CircularPad1d,
               module_inputs_func=module_inputs_torch_nn_CircularPad1d,
               module_error_inputs_func=module_error_inputs_torch_nn_Pad1d,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.CircularPad2d,
               module_inputs_func=module_inputs_torch_nn_CircularPad2d,
               module_error_inputs_func=module_error_inputs_torch_nn_Pad2d,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.CircularPad3d,
               module_inputs_func=module_inputs_torch_nn_CircularPad3d,
               module_error_inputs_func=module_error_inputs_torch_nn_Pad3d,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(unittest.expectedFailure, "TestModule", "test_memory_format"),)
               ),
    ModuleInfo(torch.nn.ConstantPad1d,
               module_inputs_func=module_inputs_torch_nn_ConstantPad1d,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),)
               ),
    ModuleInfo(torch.nn.ConstantPad2d,
               module_inputs_func=module_inputs_torch_nn_ConstantPad2d,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(unittest.expectedFailure, "TestModule", "test_memory_format", device_type='mps'),)
               ),
    ModuleInfo(torch.nn.ConstantPad3d,
               module_inputs_func=module_inputs_torch_nn_ConstantPad3d,
               skips=(
                   DecorateInfo(skipIfMps, 'TestModule', dtypes=[torch.float64]),
                   DecorateInfo(unittest.expectedFailure, "TestModule", "test_memory_format", device_type='mps'),)
               )
]

<END>

<START>
import torch.fx as fx

def set_trace(gm: fx.GraphModule) -> fx.GraphModule:
    def insert_pdb(body):
        return ["import pdb; pdb.set_trace()\n", *body]

    with gm.graph.on_generate_code(
        make_transformer=lambda cur_transform: (
            lambda body: (
                insert_pdb(
                    cur_transform(body) if cur_transform
                    else body
                )
            )
        )
    ):
        gm.recompile()

    return gm

<END>

<START>
import warnings
from typing import Any, Dict, Optional

import torch
import torch.distributed as dist
from torch.distributed.checkpoint.stateful import Stateful

from .default_planner import DefaultLoadPlanner
from .planner import LoadPlanner
from .storage import StorageReader
from .utils import _all_gather_keys, _DistWrapper, _profile

__all__ = ["load_state_dict", "load"]


def load_state_dict(
    state_dict: Dict[str, Any],
    storage_reader: StorageReader,
    process_group: Optional[dist.ProcessGroup] = None,
    coordinator_rank: int = 0,
    no_dist: bool = False,
    planner: Optional[LoadPlanner] = None,
) -> None:
    Load a distributed ``state_dict`` in SPMD style.

    Each rank will try to read the least amount of data necessary
    to fullfill the requested `state_dict`. When loading :class:`ShardedTensor`
    or :class:`DTensor` instances, each rank only reads data for their local shards.

    For each ``Stateful`` object (having both a ``state_dict`` and a ``load_state_dict``),
    load will first call ``state_dict`` before attempting deserialization, followed by
    ``load_state_dict`` once the deserialization is complete.

    .. warning::
        All tensors in ``state_dict`` must be allocated on their
        destination device *prior to* calling this function.

        All non-tensor data is loaded using `torch.load()` and modified in place
        on state_dict.

    .. warning::
        Users must call `load_state_dict` on the root module to ensure load
        pos-processing and non-tensor data properly propagates.

    .. note:
        This function can be used for local inference and load a checkpoint
        produced by ``save_state_dict`` without having a process group initialized
        by passing ``no_dist=True`` and by using Tensors instead of ShardedTensors.

    Args:
        state_dict (Dict[str, Any]) : The state_dict to load. Note that this
            state dict will updated in place.
        storage_reader (StorageReader): StorageReader used to load data from.
        process_group (ProcessGroup):
            ProcessGroup to be used for cross-rank synchronization.
        coordinator_rank (int):
            Rank to use to coordinate the checkpoint.
            rank0 is used by default.
        no_dist (bool): If ``True``, distributed checkpoint will not load
            in SPMD style. (Default: ``False``)

    Returns:
        None.

    Examples
        >>> # xdoctest: +SKIP
        >>> my_model = MyModule()
        >>> optimizer = Adagrad(my_model.parameters())
        >>> model_state_dict = my_model.state_dict()
        >>> fs_storage_reader = torch.distributed.checkpoint.FileSystemReader("/checkpoint/1")

        >>> torch.distributed.checkpoint.load_state_dict(
        >>>     state_dict=model_state_dict,
        >>>     storage_reader=fs_storage_reader,
        >>> )

        >>> # module.load_state_dict() function might have customized steps
        >>> # to flush the state_dict, must call it to
        >>> # ensure correct behavior.
        >>> my_model.load_state_dict(model_state_dict)

    .. note::
        load_state_dict uses collectives to coordinate reads across ranks.
        For NCCL-based process groups, internal tensor representations of
        objects must be moved to the GPU device before communication takes place.
        In this case, the device used is given by ``torch.cuda.current_device()``
        and it is the user's responsibility to ensure that this is set so that each
        rank has an individual GPU, via ``torch.cuda.set_device()``.

<END>

<START>
import inspect
from typing import Any, Callable, Dict, List, Optional, Set
from collections import OrderedDict
import logging

import torch
from torch.fx._compatibility import compatibility
from torch.fx.graph_module import GraphModule
from torch.fx.node import Node

__all__ = ["Partition", "split_module"]
_LOGGER = logging.getLogger(__name__)

@compatibility(is_backward_compatible=True)
class Partition:
    def __init__(self, name: str):
        self.name: str = name
        self.submod_name = f"submod_{name}"
        self.node_names: List[str] = []
        self.inputs: Dict[str, None] = {}
        self.outputs: Dict[str, None] = {}
        self.dependencies: Dict[str, None] = {}
        self.dependents: Dict[str, None] = {}
        self.graph: torch.fx.graph.Graph = torch.fx.graph.Graph()
        self.environment: Dict[Node, Node] = {}
        self.targets: Dict[str, Any] = {}

    def __repr__(self) -> str:
        return (
            f"name: {self.name},\n"
            f" nodes: {self.node_names},\n"
            f" inputs: {self.inputs},\n"
            f" outputs: {self.outputs},\n"
            f" partitions depended on: {self.dependencies},\n"
            f" partition dependents: {self.dependents}"
        )


@compatibility(is_backward_compatible=True)
def split_module(
    m: GraphModule,
    root_m: torch.nn.Module,
    split_callback: Callable[[Node], int],
    qualname_map: Optional[Dict[str, str]] = None,
    keep_original_order: Optional[bool] = False,
):

    def construct_graph(
        node: Node,
        base_mod_env: Dict[str, Node],
        base_mod_attrs: Dict[str, torch.fx.graph_module.GraphModule],
    ):
        if node.op == "placeholder":
            default_value = (
                node.args[0] if len(node.args) > 0 else inspect.Signature.empty
            )
            base_mod_env[node.name] = base_mod_graph.placeholder(
                node.target, type_expr=node.type, default_value=default_value
            )
            base_mod_env[node.name].meta = node.meta.copy()
        elif node.op == "get_attr":
            base_mod_env[node.name] = base_mod_graph.get_attr(node.target)
            base_mod_env[node.name].meta = node.meta.copy()
            attr_val = m
            for atom in node.target.split("."):  # type: ignore[union-attr]
                if not hasattr(attr_val, atom):
                    raise AttributeError(f"Node target {node.target} not found!")
                attr_val = getattr(attr_val, atom)
            base_mod_attrs[node.target] = attr_val  # type: ignore[index]
        return base_mod_env, base_mod_attrs

    partitions: Dict[str, Partition] = {}
    orig_nodes: Dict[str, Node] = {}

    def record_cross_partition_use(
        def_node: Node, use_node: Optional[Node]
    ):  # noqa: B950
        defined = getattr(def_node, "_fx_partition", None)
        used = getattr(use_node, "_fx_partition", None)
        if defined != used:
            if defined is not None:
                def_partition = partitions[defined]
                def_partition.outputs.setdefault(def_node.name)
                if used is not None:
                    def_partition.dependents.setdefault(used)

            if used is not None:
                use_partition = partitions[used]
                use_partition.inputs.setdefault(def_node.name)
                if defined is not None:
                    use_partition.dependencies.setdefault(defined)

    def instantiate_node_partition_mapping(node):
        partition_name = str(split_callback(node))

        partition = partitions.get(partition_name)
        if partition is None:
            partitions[partition_name] = partition = Partition(partition_name)

        partition.node_names.append(node.name)
        node._fx_partition = partition_name

    GLOBAL_STATE_NODES = [
        torch.amp._enter_autocast,
        torch.amp._exit_autocast,
        torch._C._set_grad_enabled
    ]

    grad_regions: OrderedDict[Node, Set[int]] = OrderedDict()

    autocast_regions: OrderedDict[Node, Set[int]] = OrderedDict()
    autocast_exits: Dict[Node, Optional[Node]] = {}

    active_grad = None
    active_autocasts = set()

    for node in m.graph.nodes:
        if node.op in ["placeholder", "get_attr", "output"]:
            continue

        instantiate_node_partition_mapping(node)

        if node.op == "call_function" and node.target in GLOBAL_STATE_NODES:
            if node.target == torch._C._set_grad_enabled:
                assert len(node.args) == 1
                assert isinstance(node.args[0], bool)
                active_grad = node
                grad_regions[active_grad] = set({split_callback(node)})
            elif node.target == torch.amp._enter_autocast:
                assert all(not isinstance(arg, Node) for arg in node.args)
                active_autocasts.add(node)
                autocast_regions[node] = set({split_callback(node)})
                autocast_exits[node] = None
            elif node.target == torch.amp._exit_autocast:
                assert len(node.args) == 1
                autocast_regions[node.args[0]].add(split_callback(node))
                active_autocasts.remove(node.args[0])
                autocast_exits[node.args[0]] = node

        if active_grad is not None:
            grad_regions[active_grad].add(split_callback(node))

        for a in active_autocasts:
            autocast_regions[a].add(split_callback(node))

    assert all(v is not None for v in autocast_exits.values()), "autocast must exit"

    autocast_regions = {k: sorted(v) for k, v in autocast_regions.items()}
    grad_regions = {k: sorted(v) for k, v in grad_regions.items()}

    if _LOGGER.isEnabledFor(logging.DEBUG):
        _LOGGER.debug("autocast_regions: %s", autocast_regions)
        _LOGGER.debug("grad_regions: %s", grad_regions)

    assert_monotonically_increasing = bool(autocast_regions) or bool(grad_regions)

    highest_partition = -1
    for node in m.graph.nodes:
        orig_nodes[node.name] = node

        if node.op in ["placeholder", "get_attr"]:
            continue
        if node.op == "output":
            torch.fx.graph.map_arg(
                node.args[0], lambda n: record_cross_partition_use(n, None)
            )
            continue

        if assert_monotonically_increasing:
            pid = split_callback(node)
            assert highest_partition <= pid,\
                ("autocast or set_grad_enabled require monotonically increasing partitions:"
                 f"highest: {highest_partition}, this node's: {pid}")
            highest_partition = pid

        if node.target not in GLOBAL_STATE_NODES:
            torch.fx.graph.map_arg(
                node.args, lambda def_node: record_cross_partition_use(def_node, node)
            )
            torch.fx.graph.map_arg(
                node.kwargs, lambda def_node: record_cross_partition_use(def_node, node)
            )  # noqa: B950

    original_partition_order = list(partitions.keys())
    root_partitions: List[str] = []
    for partition_name, partition in partitions.items():
        if not len(partition.dependencies):
            root_partitions.append(partition_name)

    sorted_partitions: List[str] = []
    while root_partitions:
        root_partition = root_partitions.pop()
        sorted_partitions.append(root_partition)
        for dependent in partitions[root_partition].dependents:
            partitions[dependent].dependencies.pop(root_partition)
            if not partitions[dependent].dependencies:
                root_partitions.append(dependent)
    if len(sorted_partitions) != len(partitions):
        raise RuntimeError("cycle exists between partitions!")

    for regions_mapping in [autocast_regions, grad_regions]:
        for node, regions in regions_mapping.items():
            assert len(regions) > 0
            partitions[str(regions[0])].environment[node] = node
            for r in regions[1:]:
                partition = partitions[str(r)]
                new_node = partition.graph.create_node(
                    op=node.op,
                    target=node.target,
                    args=tuple(arg for arg in node.args),
                    kwargs={},
                    type_expr=node.type,
                )
                new_node.meta = node.meta.copy()  # is it really a good idea to copy this?
                partition.environment[node] = new_node

    for partition_name in sorted_partitions:
        partition = partitions[partition_name]
        for inp in partition.inputs:
            placeholder = partition.graph.placeholder(
                inp,
                type_expr=orig_nodes[inp].type,
            )
            placeholder.meta = orig_nodes[inp].meta.copy()
            partition.environment[orig_nodes[inp]] = placeholder

    for node in m.graph.nodes:
        if hasattr(node, "_fx_partition"):
            partition = partitions[node._fx_partition]

            environment = partition.environment
            gathered_args = torch.fx.graph.map_arg(node.args, lambda n: environment[n])
            gathered_kwargs = torch.fx.graph.map_arg(
                node.kwargs, lambda n: environment[n]
            )

            if node.op not in ["call_module", "get_attr"]:
                target = node.target
            else:
                target_atoms = node.target.split(".")
                target_attr = m
                for atom in target_atoms:
                    if not hasattr(target_attr, atom):
                        raise AttributeError(f"Operator target {node.target} not found!")
                    target_attr = getattr(target_attr, atom)
                target = "_".join(target_atoms)
                partition.targets[target] = target_attr
                if qualname_map is not None:
                    qualname = f"{partition.submod_name}.{target}"
                    qualname_map[qualname] = node.target

            assert isinstance(gathered_args, tuple)
            assert isinstance(gathered_kwargs, dict)
            new_node = partition.graph.create_node(
                op=node.op,
                target=target,
                args=gathered_args,
                kwargs=gathered_kwargs,
                type_expr=node.type,
            )
            new_node.meta = node.meta.copy()
            partition.environment[node] = new_node

    for regions_mapping in [autocast_regions]:
        for node in reversed(regions_mapping):
            regions = regions_mapping[node]
            assert len(regions) > 0
            for r in regions[:-1]:
                partition = partitions[str(r)]
                exit_node = autocast_exits[node]
                assert exit_node is not None, "Missing exit node"
                new_node = partition.graph.create_node(
                    op=exit_node.op,
                    target=exit_node.target,
                    args=(partition.environment[node],),
                    kwargs={},
                    type_expr=exit_node.type,
                )
                new_node.meta = exit_node.meta.copy()  # is it really a good idea to copy this?

    orig_mod_env: Dict[str, Node] = {}
    base_mod_env: Dict[str, Node] = {}
    base_mod_graph: torch.fx.graph.Graph = torch.fx.graph.Graph()
    base_mod_attrs: Dict[str, torch.fx.graph_module.GraphModule] = {}
    if not keep_original_order:
        for node in m.graph.nodes:
            base_mod_env, base_mod_attrs = construct_graph(
                node, base_mod_env, base_mod_attrs
            )

    else:
        for node in m.graph.nodes:
            orig_mod_env[node.name] = node


    construct_order_partitions = (
        sorted_partitions if not keep_original_order else original_partition_order
    )

    already_constructed_attr_nodes = set()
    for partition_name in construct_order_partitions:
        partition = partitions[partition_name]

        output_vals = tuple(
            partition.environment[orig_nodes[name]] for name in partition.outputs
        )

        num_output_vals = len(output_vals)
        if num_output_vals == 1:
            partition.graph.output(output_vals[0])
        elif num_output_vals > 1:
            partition.graph.output(output_vals)

        if keep_original_order:
            orig_mod_attr_nodes: List[Node] = [
                orig_mod_env[key] for key in partition.inputs
            ]
            for node in orig_mod_attr_nodes:  # type: ignore[attr-defined]
                if node in already_constructed_attr_nodes:
                    continue
                base_mod_env, base_mod_attrs = construct_graph(
                    node, base_mod_env, base_mod_attrs
                )
                already_constructed_attr_nodes.add(node)

        base_mod_attrs[partition.submod_name] = torch.fx.graph_module.GraphModule(
            partition.targets, partition.graph
        )  # noqa: B950

        output_val = base_mod_graph.call_module(
            partition.submod_name,
            tuple(base_mod_env[name] for name in partition.inputs),
        )

        num_outputs = len(partition.outputs)
        if num_outputs > 1:
            output_val_proxy = torch.fx.proxy.Proxy(output_val)
            for i, output_name in enumerate(partition.outputs):
                base_mod_env[output_name] = output_val_proxy[i].node  # type: ignore[index]
        elif num_outputs == 1:
            base_mod_env[next(iter(partition.outputs))] = output_val

    for node in m.graph.nodes:
        if node.op == "output":
            base_mod_graph.output(
                torch.fx.graph.map_arg(node.args[0], lambda n: base_mod_env[n.name])
            )  # noqa: B950

    return torch.fx.graph_module.GraphModule(base_mod_attrs, base_mod_graph)

<END>

<START>
import copy
import glob
import importlib
import importlib.abc
import os
import re
import shlex
import shutil
import setuptools
import subprocess
import sys
import sysconfig
import warnings
import collections
from pathlib import Path
import errno

import torch
import torch._appdirs
from .file_baton import FileBaton
from ._cpp_extension_versioner import ExtensionVersioner
from .hipify import hipify_python
from .hipify.hipify_python import GeneratedFileCleaner
from typing import Dict, List, Optional, Union, Tuple
from torch.torch_version import TorchVersion, Version

from setuptools.command.build_ext import build_ext

IS_WINDOWS = sys.platform == 'win32'
IS_MACOS = sys.platform.startswith('darwin')
IS_LINUX = sys.platform.startswith('linux')
LIB_EXT = '.pyd' if IS_WINDOWS else '.so'
CLIB_EXT = '.dll' if IS_WINDOWS else '.so'
SHARED_FLAG = '/DLL' if IS_WINDOWS else '-shared'

_HERE = os.path.abspath(__file__)
_TORCH_PATH = os.path.dirname(os.path.dirname(_HERE))
TORCH_LIB_PATH = os.path.join(_TORCH_PATH, 'lib')


SUBPROCESS_DECODE_ARGS = ('oem',) if IS_WINDOWS else ()
MINIMUM_GCC_VERSION = (5, 0, 0)
MINIMUM_MSVC_VERSION = (19, 0, 24215)

VersionRange = Tuple[Tuple[int, ...], Tuple[int, ...]]
VersionMap = Dict[str, VersionRange]
CUDA_GCC_VERSIONS: VersionMap = {
    '11.0': (MINIMUM_GCC_VERSION, (10, 0)),
    '11.1': (MINIMUM_GCC_VERSION, (11, 0)),
    '11.2': (MINIMUM_GCC_VERSION, (11, 0)),
    '11.3': (MINIMUM_GCC_VERSION, (11, 0)),
    '11.4': ((6, 0, 0), (12, 0)),
    '11.5': ((6, 0, 0), (12, 0)),
    '11.6': ((6, 0, 0), (12, 0)),
    '11.7': ((6, 0, 0), (12, 0)),
}

MINIMUM_CLANG_VERSION = (3, 3, 0)
CUDA_CLANG_VERSIONS: VersionMap = {
    '11.1': (MINIMUM_CLANG_VERSION, (11, 0)),
    '11.2': (MINIMUM_CLANG_VERSION, (12, 0)),
    '11.3': (MINIMUM_CLANG_VERSION, (12, 0)),
    '11.4': (MINIMUM_CLANG_VERSION, (13, 0)),
    '11.5': (MINIMUM_CLANG_VERSION, (13, 0)),
    '11.6': (MINIMUM_CLANG_VERSION, (14, 0)),
    '11.7': (MINIMUM_CLANG_VERSION, (14, 0)),
}

__all__ = ["get_default_build_root", "check_compiler_ok_for_platform", "get_compiler_abi_compatibility_and_version", "BuildExtension",
           "CppExtension", "CUDAExtension", "include_paths", "library_paths", "load", "load_inline", "is_ninja_available",
           "verify_ninja_availability", "remove_extension_h_precompiler_headers", "get_cxx_compiler", "check_compiler_is_gcc"]
def _nt_quote_args(args: Optional[List[str]]) -> List[str]:
    if not args:
        return []
    return [f'"{arg}"' if ' ' in arg else arg for arg in args]

def _find_cuda_home() -> Optional[str]:
                else:
                    cuda_home = cuda_homes[0]
            else:
                cuda_home = '/usr/local/cuda'
            if not os.path.exists(cuda_home):
                cuda_home = None
    if cuda_home and not torch.cuda.is_available():
        print(f"No CUDA runtime is found, using CUDA_HOME='{cuda_home}'",
              file=sys.stderr)
    return cuda_home

def _find_rocm_home() -> Optional[str]:
    Join paths with ROCM_HOME, or raises an error if it ROCM_HOME is not set.

    This is basically a lazy way of raising an error for missing $ROCM_HOME
    only once we need to get any ROCm-specific path.

                               !! WARNING !!

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Your compiler ({}) may be ABI-incompatible with PyTorch!
Please use a compiler that is ABI-compatible with GCC 5.0 and above.
See https://gcc.gnu.org/onlinedocs/libstdc++/manual/abi.html.

See https://gist.github.com/goldsborough/d466f43e8ffc948ff92de7486c5216d6
for instructions on how to install GCC 5 or higher.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

                              !! WARNING !!

                               !! WARNING !!

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Your compiler ({user_compiler}) is not compatible with the compiler Pytorch was
built with for this platform, which is {pytorch_compiler} on {platform}. Please
use {pytorch_compiler} to to compile your extension. Alternatively, you may
compile PyTorch from source using {user_compiler}, and then you can also use
{user_compiler} to compile your extension.

See https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md for help
with compiling PyTorch from source.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

                              !! WARNING !!
The detected CUDA version ({0}) mismatches the version that was used to compile
PyTorch ({1}). Please make sure to use the same CUDA versions.
CUDA was not found on the system, please set the CUDA_HOME or the CUDA_PATH
environment variable or add NVCC to your system PATH. The extension compilation will fail.
    Equivalent to writing the content into the file but will not touch the file
    if it already had the right content (to avoid triggering recompile).
    Return the path to the root folder under which extensions will built.

    For each extension module built, there will be one folder underneath the
    folder returned by this function. For example, if ``p`` is the path
    returned by this function and ``ext`` the name of an extension, the build
    folder for the extension will be ``p/ext``.

    This directory is **user-specific** so that multiple users on the same
    machine won't meet permission issues.
    Verify that the compiler is the expected one for the current platform.

    Args:
        compiler (str): The compiler executable to check.

    Returns:
        True if the compiler is gcc/g++ on Linux or clang/clang++ on macOS,
        and always True for Windows.
    Determine if the given compiler is ABI-compatible with PyTorch alongside its version.

    Args:
        compiler (str): The compiler executable name to check (e.g. ``g++``).
            Must be executable in a shell process.

    Returns:
        A tuple that contains a boolean that defines if the compiler is (likely) ABI-incompatible with PyTorch,
        followed by a `TorchVersion` string that contains the compiler version separated by dots.
    A custom :mod:`setuptools` build extension .

    This :class:`setuptools.build_ext` subclass takes care of passing the
    minimum required compiler flags (e.g. ``-std=c++17``) as well as mixed
    C++/CUDA compilation (and support for CUDA files in general).

    When using :class:`BuildExtension`, it is allowed to supply a dictionary
    for ``extra_compile_args`` (rather than the usual list) that maps from
    languages (``cxx`` or ``nvcc``) to a list of additional compiler flags to
    supply to the compiler. This makes it possible to supply different flags to
    the C++ and CUDA compiler during mixed compilation.

    ``use_ninja`` (bool): If ``use_ninja`` is ``True`` (default), then we
    attempt to build using the Ninja backend. Ninja greatly speeds up
    compilation compared to the standard ``setuptools.build_ext``.
    Fallbacks to the standard distutils backend if Ninja is not available.

    .. note::
        By default, the Ninja backend uses #CPUS + 2 workers to build the
        extension. This may use up too many resources on some systems. One
        can control the number of workers by setting the `MAX_JOBS` environment
        variable to a non-negative number.
        class cls_with_options(cls):  # type: ignore[misc, valid-type]
            def __init__(self, *args, **kwargs):
                kwargs.update(options)
                super().__init__(*args, **kwargs)

        return cls_with_options

    def __init__(self, *args, **kwargs) -> None:
        super().__init__(*args, **kwargs)
        self.no_python_abi_suffix = kwargs.get("no_python_abi_suffix", False)

        self.use_ninja = kwargs.get('use_ninja', True)
        if self.use_ninja:
            msg = ('Attempted to use ninja as the BuildExtension backend but '
                   '{}. Falling back to using the slow distutils backend.')
            if not is_ninja_available():
                warnings.warn(msg.format('we could not find ninja.'))
                self.use_ninja = False

    def finalize_options(self) -> None:
        super().finalize_options()
        if self.use_ninja:
            self.force = True

    def build_extensions(self) -> None:
        compiler_name, compiler_version = self._check_abi()

        cuda_ext = False
        extension_iter = iter(self.extensions)
        extension = next(extension_iter, None)
        while not cuda_ext and extension:
            for source in extension.sources:
                _, ext = os.path.splitext(source)
                if ext == '.cu':
                    cuda_ext = True
                    break
            extension = next(extension_iter, None)

        if cuda_ext and not IS_HIP_EXTENSION:
            _check_cuda_version(compiler_name, compiler_version)

        for extension in self.extensions:
            if isinstance(extension.extra_compile_args, dict):
                for ext in ['cxx', 'nvcc']:
                    if ext not in extension.extra_compile_args:
                        extension.extra_compile_args[ext] = []

            self._add_compile_flag(extension, '-DTORCH_API_INCLUDE_EXTENSION_H')
            for name in ["COMPILER_TYPE", "STDLIB", "BUILD_ABI"]:
                val = getattr(torch._C, f"_PYBIND11_{name}")
                if val is not None and not IS_WINDOWS:
                    self._add_compile_flag(extension, f'-DPYBIND11_{name}="{val}"')
            self._define_torch_extension_name(extension)
            self._add_gnu_cpp_abi_flag(extension)

            if 'nvcc_dlink' in extension.extra_compile_args:
                assert self.use_ninja, f"With dlink=True, ninja is required to build cuda extension {extension.name}."

        self.compiler.src_extensions += ['.cu', '.cuh', '.hip']
        if torch.backends.mps.is_built():
            self.compiler.src_extensions += ['.mm']
        if self.compiler.compiler_type == 'msvc':
            self.compiler._cpp_extensions += ['.cu', '.cuh']
            original_compile = self.compiler.compile
            original_spawn = self.compiler.spawn
        else:
            original_compile = self.compiler._compile

        def append_std17_if_no_std_present(cflags) -> None:
            cpp_format_prefix = '/{}:' if self.compiler.compiler_type == 'msvc' else '-{}='
            cpp_flag_prefix = cpp_format_prefix.format('std')
            cpp_flag = cpp_flag_prefix + 'c++17'
            if not any(flag.startswith(cpp_flag_prefix) for flag in cflags):
                cflags.append(cpp_flag)

        def unix_cuda_flags(cflags):
            cflags = (COMMON_NVCC_FLAGS +
                      ['--compiler-options', "'-fPIC'"] +
                      cflags + _get_cuda_arch_flags(cflags))

            _ccbin = os.getenv("CC")
            if (
                _ccbin is not None
                and not any(flag.startswith(('-ccbin', '--compiler-bindir')) for flag in cflags)
            ):
                cflags.extend(['-ccbin', _ccbin])

            return cflags

        def convert_to_absolute_paths_inplace(paths):
            if paths is not None:
                for i in range(len(paths)):
                    if not os.path.isabs(paths[i]):
                        paths[i] = os.path.abspath(paths[i])

        def unix_wrap_single_compile(obj, src, ext, cc_args, extra_postargs, pp_opts) -> None:
            cflags = copy.deepcopy(extra_postargs)
            try:
                original_compiler = self.compiler.compiler_so
                if _is_cuda_file(src):
                    nvcc = [_join_rocm_home('bin', 'hipcc') if IS_HIP_EXTENSION else _join_cuda_home('bin', 'nvcc')]
                    self.compiler.set_executable('compiler_so', nvcc)
                    if isinstance(cflags, dict):
                        cflags = cflags['nvcc']
                    if IS_HIP_EXTENSION:
                        cflags = COMMON_HIPCC_FLAGS + cflags + _get_rocm_arch_flags(cflags)
                    else:
                        cflags = unix_cuda_flags(cflags)
                elif isinstance(cflags, dict):
                    cflags = cflags['cxx']
                if IS_HIP_EXTENSION:
                    cflags = COMMON_HIP_FLAGS + cflags
                append_std17_if_no_std_present(cflags)

                original_compile(obj, src, ext, cc_args, cflags, pp_opts)
            finally:
                self.compiler.set_executable('compiler_so', original_compiler)

        def unix_wrap_ninja_compile(sources,
                                    output_dir=None,
                                    macros=None,
                                    include_dirs=None,
                                    debug=0,
                                    extra_preargs=None,
                                    extra_postargs=None,
                                    depends=None):
    Create a :class:`setuptools.Extension` for C++.

    Convenience method that creates a :class:`setuptools.Extension` with the
    bare minimum (but often sufficient) arguments to build a C++ extension.

    All arguments are forwarded to the :class:`setuptools.Extension`
    constructor.

    Example:
        >>> # xdoctest: +SKIP
        >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CPP_EXT)
        >>> from setuptools import setup
        >>> from torch.utils.cpp_extension import BuildExtension, CppExtension
        >>> setup(
        ...     name='extension',
        ...     ext_modules=[
        ...         CppExtension(
        ...             name='extension',
        ...             sources=['extension.cpp'],
        ...             extra_compile_args=['-g']),
        ...     ],
        ...     cmdclass={
        ...         'build_ext': BuildExtension
        ...     })
    Create a :class:`setuptools.Extension` for CUDA/C++.

    Convenience method that creates a :class:`setuptools.Extension` with the
    bare minimum (but often sufficient) arguments to build a CUDA/C++
    extension. This includes the CUDA include path, library path and runtime
    library.

    All arguments are forwarded to the :class:`setuptools.Extension`
    constructor.

    Example:
        >>> # xdoctest: +SKIP
        >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CPP_EXT)
        >>> from setuptools import setup
        >>> from torch.utils.cpp_extension import BuildExtension, CUDAExtension
        >>> setup(
        ...     name='cuda_extension',
        ...     ext_modules=[
        ...         CUDAExtension(
        ...                 name='cuda_extension',
        ...                 sources=['extension.cpp', 'extension_kernel.cu'],
        ...                 extra_compile_args={'cxx': ['-g'],
        ...                                     'nvcc': ['-O2']})
        ...     ],
        ...     cmdclass={
        ...         'build_ext': BuildExtension
        ...     })

    Compute capabilities:

    By default the extension will be compiled to run on all archs of the cards visible during the
    building process of the extension, plus PTX. If down the road a new card is installed the
    extension may need to be recompiled. If a visible card has a compute capability (CC) that's
    newer than the newest version for which your nvcc can build fully-compiled binaries, Pytorch
    will make nvcc fall back to building kernels with the newest version of PTX your nvcc does
    support (see below for details on PTX).

    You can override the default behavior using `TORCH_CUDA_ARCH_LIST` to explicitly specify which
    CCs you want the extension to support:

    ``TORCH_CUDA_ARCH_LIST="6.1 8.6" python build_my_extension.py``
    ``TORCH_CUDA_ARCH_LIST="5.2 6.0 6.1 7.0 7.5 8.0 8.6+PTX" python build_my_extension.py``

    The +PTX option causes extension kernel binaries to include PTX instructions for the specified
    CC. PTX is an intermediate representation that allows kernels to runtime-compile for any CC >=
    the specified CC (for example, 8.6+PTX generates PTX that can runtime-compile for any GPU with
    CC >= 8.6). This improves your binary's forward compatibility. However, relying on older PTX to
    provide forward compat by runtime-compiling for newer CCs can modestly reduce performance on
    those newer CCs. If you know exact CC(s) of the GPUs you want to target, you're always better
    off specifying them individually. For example, if you want your extension to run on 8.0 and 8.6,
    "8.0+PTX" would work functionally because it includes PTX that can runtime-compile for 8.6, but
    "8.0 8.6" would be better.

    Note that while it's possible to include all supported archs, the more archs get included the
    slower the building process will be, as it will build a separate kernel image for each arch.

    Note that CUDA-11.5 nvcc will hit internal compiler error while parsing torch/extension.h on Windows.
    To workaround the issue, move python binding logic to pure C++ file.

    Example use:
        at::Tensor SigmoidAlphaBlendForwardCuda(....)

    Instead of:
        torch::Tensor SigmoidAlphaBlendForwardCuda(...)

    Currently open issue for nvcc bug: https://github.com/pytorch/pytorch/issues/69460
    Complete workaround code example: https://github.com/facebookresearch/pytorch3d/commit/cb170ac024a949f1f9614ffe6af1c38d972f7d48

    Relocatable device code linking:

    If you want to reference device symbols across compilation units (across object files),
    the object files need to be built with `relocatable device code` (-rdc=true or -dc).
    An exception to this rule is "dynamic parallelism" (nested kernel launches)  which is not used a lot anymore.
    `Relocatable device code` is less optimized so it needs to be used only on object files that need it.
    Using `-dlto` (Device Link Time Optimization) at the device code compilation step and `dlink` step
    help reduce the protentional perf degradation of `-rdc`.
    Note that it needs to be used at both steps to be useful.

    If you have `rdc` objects you need to have an extra `-dlink` (device linking) step before the CPU symbol linking step.
    There is also a case where `-dlink` is used without `-rdc`:
    when an extension is linked against a static lib containing rdc-compiled objects
    like the [NVSHMEM library](https://developer.nvidia.com/nvshmem).

    Note: Ninja is required to build a CUDA Extension with RDC linking.

    Example:
        >>> # xdoctest: +SKIP
        >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CPP_EXT)
        >>> CUDAExtension(
        ...        name='cuda_extension',
        ...        sources=['extension.cpp', 'extension_kernel.cu'],
        ...        dlink=True,
        ...        dlink_libraries=["dlink_lib"],
        ...        extra_compile_args={'cxx': ['-g'],
        ...                            'nvcc': ['-O2', '-rdc=true']})
    Get the include paths required to build a C++ or CUDA extension.

    Args:
        cuda: If `True`, includes CUDA-specific include paths.

    Returns:
        A list of include path strings.
    Get the library paths required to build a C++ or CUDA extension.

    Args:
        cuda: If `True`, includes CUDA-specific library paths.

    Returns:
        A list of library path strings.
    Load a PyTorch C++ extension just-in-time (JIT).

    To load an extension, a Ninja build file is emitted, which is used to
    compile the given sources into a dynamic library. This library is
    subsequently loaded into the current Python process as a module and
    returned from this function, ready for use.

    By default, the directory to which the build file is emitted and the
    resulting library compiled to is ``<tmp>/torch_extensions/<name>``, where
    ``<tmp>`` is the temporary folder on the current platform and ``<name>``
    the name of the extension. This location can be overridden in two ways.
    First, if the ``TORCH_EXTENSIONS_DIR`` environment variable is set, it
    replaces ``<tmp>/torch_extensions`` and all extensions will be compiled
    into subfolders of this directory. Second, if the ``build_directory``
    argument to this function is supplied, it overrides the entire path, i.e.
    the library will be compiled into that folder directly.

    To compile the sources, the default system compiler (``c++``) is used,
    which can be overridden by setting the ``CXX`` environment variable. To pass
    additional arguments to the compilation process, ``extra_cflags`` or
    ``extra_ldflags`` can be provided. For example, to compile your extension
    with optimizations, pass ``extra_cflags=['-O3']``. You can also use
    ``extra_cflags`` to pass further include directories.

    CUDA support with mixed compilation is provided. Simply pass CUDA source
    files (``.cu`` or ``.cuh``) along with other sources. Such files will be
    detected and compiled with nvcc rather than the C++ compiler. This includes
    passing the CUDA lib64 directory as a library directory, and linking
    ``cudart``. You can pass additional flags to nvcc via
    ``extra_cuda_cflags``, just like with ``extra_cflags`` for C++. Various
    heuristics for finding the CUDA install directory are used, which usually
    work fine. If not, setting the ``CUDA_HOME`` environment variable is the
    safest option.

    Args:
        name: The name of the extension to build. This MUST be the same as the
            name of the pybind11 module!
        sources: A list of relative or absolute paths to C++ source files.
        extra_cflags: optional list of compiler flags to forward to the build.
        extra_cuda_cflags: optional list of compiler flags to forward to nvcc
            when building CUDA sources.
        extra_ldflags: optional list of linker flags to forward to the build.
        extra_include_paths: optional list of include directories to forward
            to the build.
        build_directory: optional path to use as build workspace.
        verbose: If ``True``, turns on verbose logging of load steps.
        with_cuda: Determines whether CUDA headers and libraries are added to
            the build. If set to ``None`` (default), this value is
            automatically determined based on the existence of ``.cu`` or
            ``.cuh`` in ``sources``. Set it to `True`` to force CUDA headers
            and libraries to be included.
        is_python_module: If ``True`` (default), imports the produced shared
            library as a Python module. If ``False``, behavior depends on
            ``is_standalone``.
        is_standalone: If ``False`` (default) loads the constructed extension
            into the process as a plain dynamic library. If ``True``, build a
            standalone executable.

    Returns:
        If ``is_python_module`` is ``True``:
            Returns the loaded PyTorch extension as a Python module.

        If ``is_python_module`` is ``False`` and ``is_standalone`` is ``False``:
            Returns nothing. (The shared library is loaded into the process as
            a side effect.)

        If ``is_standalone`` is ``True``.
            Return the path to the executable. (On Windows, TORCH_LIB_PATH is
            added to the PATH environment variable as a side effect.)

    Example:
        >>> # xdoctest: +SKIP
        >>> from torch.utils.cpp_extension import load
        >>> module = load(
        ...     name='extension',
        ...     sources=['extension.cpp', 'extension_kernel.cu'],
        ...     extra_cflags=['-O2'],
        ...     verbose=True)
    Precompiled Headers(PCH) can pre-build the same headers and reduce build time for pytorch load_inline modules.
    GCC offical manual: https://gcc.gnu.org/onlinedocs/gcc-4.0.4/gcc/Precompiled-Headers.html
    PCH only works when built pch file(header.h.gch) and build target have the same build parameters. So, We need
    add a signature file to record PCH file parameters. If the build parameters(signature) changed, it should rebuild
    PCH file.

    Note:
    1. Windows and MacOS have different PCH mechanism. We only support Linux currently.
    2. It only works on GCC/G++.
                {compiler} -x c++-header {head_file} -o {head_file_pch} {torch_include_dirs} {extra_include_paths} {extra_cflags} {common_cflags}
    Load a PyTorch C++ extension just-in-time (JIT) from string sources.

    This function behaves exactly like :func:`load`, but takes its sources as
    strings rather than filenames. These strings are stored to files in the
    build directory, after which the behavior of :func:`load_inline` is
    identical to :func:`load`.

    See `the
    tests <https://github.com/pytorch/pytorch/blob/master/test/test_cpp_extensions_jit.py>`_
    for good examples of using this function.

    Sources may omit two required parts of a typical non-inline C++ extension:
    the necessary header includes, as well as the (pybind11) binding code. More
    precisely, strings passed to ``cpp_sources`` are first concatenated into a
    single ``.cpp`` file. This file is then prepended with ``#include
    <torch/extension.h>``.

    Furthermore, if the ``functions`` argument is supplied, bindings will be
    automatically generated for each function specified. ``functions`` can
    either be a list of function names, or a dictionary mapping from function
    names to docstrings. If a list is given, the name of each function is used
    as its docstring.

    The sources in ``cuda_sources`` are concatenated into a separate ``.cu``
    file and  prepended with ``torch/types.h``, ``cuda.h`` and
    ``cuda_runtime.h`` includes. The ``.cpp`` and ``.cu`` files are compiled
    separately, but ultimately linked into a single library. Note that no
    bindings are generated for functions in ``cuda_sources`` per  se. To bind
    to a CUDA kernel, you must create a C++ function that calls it, and either
    declare or define this C++ function in one of the ``cpp_sources`` (and
    include its name in ``functions``).

    See :func:`load` for a description of arguments omitted below.

    Args:
        cpp_sources: A string, or list of strings, containing C++ source code.
        cuda_sources: A string, or list of strings, containing CUDA source code.
        functions: A list of function names for which to generate function
            bindings. If a dictionary is given, it should map function names to
            docstrings (which are otherwise just the function names).
        with_cuda: Determines whether CUDA headers and libraries are added to
            the build. If set to ``None`` (default), this value is
            automatically determined based on whether ``cuda_sources`` is
            provided. Set it to ``True`` to force CUDA headers
            and libraries to be included.
        with_pytorch_error_handling: Determines whether pytorch error and
            warning macros are handled by pytorch instead of pybind. To do
            this, each function ``foo`` is called via an intermediary ``_safe_foo``
            function. This redirection might cause issues in obscure cases
            of cpp. This flag should be set to ``False`` when this redirect
            causes issues.

    Example:
        >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CPP_EXT)
        >>> from torch.utils.cpp_extension import load_inline
        >>> module = load_inline(name='inline_extension',
        ...                      cpp_sources=[source],
        ...                      functions=['sin_add'])

    .. note::
        By default, the Ninja backend uses #CPUS + 2 workers to build the
        extension. This may use up too many resources on some systems. One
        can control the number of workers by setting the `MAX_JOBS` environment
        variable to a non-negative number.
    try:
        subprocess.check_output('ninja --version'.split())
    except Exception:
        return False
    else:
        return True


def verify_ninja_availability():
    Determine CUDA arch flags to use.

    For an arch, say "6.1", the added compile flag will be
    ``-gencode=arch=compute_61,code=sm_61``.
    For an added "+PTX", an additional
    ``-gencode=arch=compute_xx,code=compute_xx`` is added.

    See select_compute_arch.cmake for corresponding named and supported arches
    when building with CMake.
        torch_lib_in_path = any(
            os.path.exists(p) and os.path.samefile(p, TORCH_LIB_PATH)
    return os.path.join(path, f'{module_name}{EXEC_EXT}')


def _import_module_from_library(module_name, path, is_python_module):
    filepath = os.path.join(path, f"{module_name}{LIB_EXT}")
    if is_python_module:
        spec = importlib.util.spec_from_file_location(module_name, filepath)
        assert spec is not None
        module = importlib.util.module_from_spec(spec)
        assert isinstance(spec.loader, importlib.abc.Loader)
        spec.loader.exec_module(module)
        return module
    else:
        torch.ops.load_library(filepath)


def _write_ninja_file_to_build_library(path,
                                       name,
                                       sources,
                                       extra_cflags,
                                       extra_cuda_cflags,
                                       extra_ldflags,
                                       extra_include_paths,
                                       with_cuda,
                                       is_standalone) -> None:
    extra_cflags = [flag.strip() for flag in extra_cflags]
    extra_cuda_cflags = [flag.strip() for flag in extra_cuda_cflags]
    extra_ldflags = [flag.strip() for flag in extra_ldflags]
    extra_include_paths = [flag.strip() for flag in extra_include_paths]

    user_includes = [os.path.abspath(file) for file in extra_include_paths]

    system_includes = include_paths(with_cuda)
    python_include_path = sysconfig.get_path('include', scheme='nt' if IS_WINDOWS else 'posix_prefix')
    if python_include_path is not None:
        system_includes.append(python_include_path)

    if IS_WINDOWS:
        user_includes += system_includes
        system_includes.clear()

    common_cflags = []
    if not is_standalone:
        common_cflags.append(f'-DTORCH_EXTENSION_NAME={name}')
        common_cflags.append('-DTORCH_API_INCLUDE_EXTENSION_H')

    common_cflags += [f"{x}" for x in _get_pybind11_abi_build_flags()]

    common_cflags += [f'-I{include}' for include in user_includes]
    common_cflags += [f'-isystem {include}' for include in system_includes]

    common_cflags += [f"{x}" for x in _get_glibcxx_abi_build_flags()]

    if IS_WINDOWS:
        cflags = common_cflags + COMMON_MSVC_FLAGS + ['/std:c++17'] + extra_cflags
        cflags = _nt_quote_args(cflags)
    else:
        cflags = common_cflags + ['-fPIC', '-std=c++17'] + extra_cflags

    if with_cuda and IS_HIP_EXTENSION:
        cuda_flags = ['-DWITH_HIP'] + cflags + COMMON_HIP_FLAGS + COMMON_HIPCC_FLAGS
        cuda_flags += extra_cuda_cflags
        cuda_flags += _get_rocm_arch_flags(cuda_flags)
    elif with_cuda:
        cuda_flags = common_cflags + COMMON_NVCC_FLAGS + _get_cuda_arch_flags()
        if IS_WINDOWS:
            for flag in COMMON_MSVC_FLAGS:
                cuda_flags = ['-Xcompiler', flag] + cuda_flags
            for ignore_warning in MSVC_IGNORE_CUDAFE_WARNINGS:
                cuda_flags = ['-Xcudafe', '--diag_suppress=' + ignore_warning] + cuda_flags
            cuda_flags = cuda_flags + ['-std=c++17']
            cuda_flags = _nt_quote_args(cuda_flags)
            cuda_flags += _nt_quote_args(extra_cuda_cflags)
        else:
            cuda_flags += ['--compiler-options', "'-fPIC'"]
            cuda_flags += extra_cuda_cflags
            if not any(flag.startswith('-std=') for flag in cuda_flags):
                cuda_flags.append('-std=c++17')
            cc_env = os.getenv("CC")
            if cc_env is not None:
                cuda_flags = ['-ccbin', cc_env] + cuda_flags
    else:
        cuda_flags = None

    def object_file_path(source_file: str) -> str:
        file_name = os.path.splitext(os.path.basename(source_file))[0]
        if _is_cuda_file(source_file) and with_cuda:
            target = f'{file_name}.cuda.o'
        else:
            target = f'{file_name}.o'
        return target

    objects = [object_file_path(src) for src in sources]
    ldflags = ([] if is_standalone else [SHARED_FLAG]) + extra_ldflags

    if IS_MACOS:
        ldflags.append('-undefined dynamic_lookup')
    elif IS_WINDOWS:
        ldflags = _nt_quote_args(ldflags)

    ext = EXEC_EXT if is_standalone else LIB_EXT
    library_target = f'{name}{ext}'

    _write_ninja_file(
        path=path,
        cflags=cflags,
        post_cflags=None,
        cuda_cflags=cuda_flags,
        cuda_post_cflags=None,
        cuda_dlink_post_cflags=None,
        sources=sources,
        objects=objects,
        ldflags=ldflags,
        library_target=library_target,
        with_cuda=with_cuda)


def _write_ninja_file(path,
                      cflags,
                      post_cflags,
                      cuda_cflags,
                      cuda_post_cflags,
                      cuda_dlink_post_cflags,
                      sources,
                      objects,
                      ldflags,
                      library_target,
                      with_cuda) -> None:
    def sanitize_flags(flags):
        if flags is None:
            return []
        else:
            return [flag.strip() for flag in flags]

    cflags = sanitize_flags(cflags)
    post_cflags = sanitize_flags(post_cflags)
    cuda_cflags = sanitize_flags(cuda_cflags)
    cuda_post_cflags = sanitize_flags(cuda_post_cflags)
    cuda_dlink_post_cflags = sanitize_flags(cuda_dlink_post_cflags)
    ldflags = sanitize_flags(ldflags)

    assert len(sources) == len(objects)
    assert len(sources) > 0

    compiler = get_cxx_compiler()

    config = ['ninja_required_version = 1.3']
    config.append(f'cxx = {compiler}')
    if with_cuda or cuda_dlink_post_cflags:
        if "PYTORCH_NVCC" in os.environ:
            nvcc = os.getenv("PYTORCH_NVCC")    # user can set nvcc compiler with ccache using the environment variable here
        else:
            if IS_HIP_EXTENSION:
                nvcc = _join_rocm_home('bin', 'hipcc')
            else:
                nvcc = _join_cuda_home('bin', 'nvcc')
        config.append(f'nvcc = {nvcc}')

    if IS_HIP_EXTENSION:
        post_cflags = COMMON_HIP_FLAGS + post_cflags
    flags = [f'cflags = {" ".join(cflags)}']
    flags.append(f'post_cflags = {" ".join(post_cflags)}')
    if with_cuda:
        flags.append(f'cuda_cflags = {" ".join(cuda_cflags)}')
        flags.append(f'cuda_post_cflags = {" ".join(cuda_post_cflags)}')
    flags.append(f'cuda_dlink_post_cflags = {" ".join(cuda_dlink_post_cflags)}')
    flags.append(f'ldflags = {" ".join(ldflags)}')

    sources = [os.path.abspath(file) for file in sources]

    compile_rule = ['rule compile']
    if IS_WINDOWS:
        compile_rule.append(
            '  command = cl /showIncludes $cflags -c $in /Fo$out $post_cflags')
        compile_rule.append('  deps = msvc')
    else:
        compile_rule.append(
            '  command = $cxx -MMD -MF $out.d $cflags -c $in -o $out $post_cflags')
        compile_rule.append('  depfile = $out.d')
        compile_rule.append('  deps = gcc')

    if with_cuda:
        cuda_compile_rule = ['rule cuda_compile']
    Join paths with CUDA_HOME, or raises an error if it CUDA_HOME is not set.

    This is basically a lazy way of raising an error for missing $CUDA_HOME
    only once we need to get any CUDA-specific path.

<END>

<START>

from __future__ import annotations

import dataclasses
from typing import List, Optional

from torch.onnx._internal.diagnostics.infra.sarif import (
    _edge,
    _message,
    _node,
    _property_bag,
)


@dataclasses.dataclass
class Graph(object):

<END>

<START>

from __future__ import annotations

import dataclasses
from typing import List, Optional

from torch.onnx._internal.diagnostics.infra.sarif import (
    _artifact_location,
    _property_bag,
    _replacement,
)


@dataclasses.dataclass
class ArtifactChange(object):

<END>

<START>

import ast
import builtins
import collections
import contextlib
import enum
import inspect
import io
import pickle
import sys
import threading
import types
import typing
import warnings
import weakref
from textwrap import dedent
from typing import (  # noqa: F401
    Any,
    Callable,
    Dict,
    Final,
    ForwardRef,
    Generic,
    get_args,  # new in 3.8
    get_origin,  # new in 3.8
    List,
    Optional,
    Tuple,
    Type,
    TypeVar,
    Union,
)

import torch

import torch.distributed.rpc
import torch.package._mangling as package_mangling
from torch._awaits import _Await
from torch._C import _Await as CAwait, Future as CFuture
from torch._sources import fake_range, get_source_lines_and_file, parse_def
from torch.futures import Future

IS_PY39_PLUS: Final[bool] = sys.version_info >= (3, 9)
IS_PY310_PLUS: Final[bool] = sys.version_info >= (3, 10)

BuiltinUnionType: Union[Type, Tuple[Type, ...]]
if sys.version_info >= (3, 10):
    BuiltinUnionType = types.UnionType
else:
    BuiltinUnionType = ()  # trick: this makes isinstance short circuit.

LockType: Type
try:
    import _thread

    LockType = _thread.LockType
except ImportError:
    import _dummy_thread

    LockType = _dummy_thread.LockType

boolean_dispatched: "weakref.WeakKeyDictionary[Callable, Dict[str, Callable]]" = (
    weakref.WeakKeyDictionary()
)  # noqa: T484


FAKE_FILENAME_PREFIX = "__torch_jit_dataclass"


class SourceLoader:
    def __init__(self):
        self.content = {}

    def cache(self, fn, source):
        self.content[fn] = source

    def get_source(self, fn):
        return self.content.get(fn)


loader = SourceLoader()


def createResolutionCallbackFromEnv(lookup_base):

    def lookupInModule(qualified_name, module):
        if "." in qualified_name:
            parts = qualified_name.split(".")
            base = parts[0]
            remaining_pieces = ".".join(parts[1:])
            module_value = getattr(module, base)
            return lookupInModule(remaining_pieces, module_value)
        else:
            return getattr(module, qualified_name)

    def parseNestedExpr(expr, module) -> Tuple[Any, int]:
        i = 0
        while i < len(expr) and expr[i] not in (",", "[", "]"):
            i += 1

        if expr[:i] == "()":
            return (), i

        base = lookupInModule(expr[:i].strip(), module)
        assert base is not None, f"Unresolvable type {expr[:i]}"
        if i == len(expr) or expr[i] != "[":
            return base, i

        assert expr[i] == "["
        parts = []
        while expr[i] != "]":
            part_len = 0
            i += 1
            part, part_len = parseNestedExpr(expr[i:], module)
            parts.append(part)
            i += part_len
        if len(parts) > 1:
            return base[tuple(parts)], i + 1
        else:
            return base[parts[0]], i + 1

    def parseExpr(expr, module):
        try:
            value, len_parsed = parseNestedExpr(expr, module)
            assert len_parsed == len(
                expr
            ), "whole expression was not parsed, falling back to c++ parser"
            return value
        except Exception:
            return None

    return lambda expr: parseExpr(expr, lookup_base)


def createResolutionCallbackFromFrame(frames_up: int = 0):
    frame = inspect.currentframe()
    i = 0
    while i < frames_up + 1:
        assert frame is not None
        frame = frame.f_back
        i += 1

    assert frame is not None
    f_locals = frame.f_locals
    f_globals = frame.f_globals

    class env:
        def __getattr__(self, key):
            if key in f_locals:
                return f_locals[key]
            elif key in f_globals:
                return f_globals[key]
            elif key in dir(builtins):
                return getattr(builtins, key)

    return createResolutionCallbackFromEnv(env())


def get_closure(fn):
    captures = {}
    captures.update(fn.__globals__)

    for index, captured_name in enumerate(fn.__code__.co_freevars):
        captures[captured_name] = fn.__closure__[index].cell_contents

    return captures




def createResolutionCallbackFromClosure(fn):
    closure = get_closure(fn)

    class closure_lookup:
        def __getattr__(self, key):
            if key in closure:
                return closure[key]
            elif hasattr(typing, key):
                return getattr(typing, key)
            elif hasattr(builtins, key):
                return getattr(builtins, key)
            return None

    return createResolutionCallbackFromEnv(closure_lookup())


def can_compile_class(cls) -> bool:
    if is_ignored_fn(cls):
        return False

    ignored_builtin_classes = (torch.nn.Module, tuple, list, Exception)
    if issubclass(cls, ignored_builtin_classes):
        return False

    names = cls.__dict__
    fns = [
        getattr(cls, name)
        for name in names
        if inspect.isroutine(getattr(cls, name, None))
    ]
    has_code = [hasattr(fn, "__code__") for fn in fns]
    return all(has_code)


def get_callable_argument_names(fn) -> List[str]:
    try:
        callable_signature = inspect.signature(fn)
    except Exception:
        return []

    argument_names = []
    for name, param in callable_signature.parameters.items():
        if not param.kind == param.POSITIONAL_OR_KEYWORD:
            continue

        argument_names.append(name)

    return argument_names


def get_annotation_str(annotation):
    if isinstance(annotation, ast.Name):
        return annotation.id
    elif isinstance(annotation, ast.Attribute):
        return ".".join([get_annotation_str(annotation.value), annotation.attr])
    elif isinstance(annotation, ast.Subscript):
        subscript_slice = annotation.slice if IS_PY39_PLUS else annotation.slice.value  # type: ignore[attr-defined]
        return f"{get_annotation_str(annotation.value)}[{get_annotation_str(subscript_slice)}]"
    elif isinstance(annotation, ast.Tuple):
        return ",".join([get_annotation_str(elt) for elt in annotation.elts])
    elif isinstance(annotation, (ast.Constant, ast.NameConstant)):
        return f"{annotation.value}"

    return None


def get_type_hint_captures(fn):
    src = loader.get_source(fn)
    if src is None:
        src = inspect.getsource(fn)

    signature = inspect.signature(fn)
    name_to_type = {
        name: parameter.annotation
        for name, parameter in signature.parameters.items()
        if parameter.annotation is not inspect.Parameter.empty
        and not isinstance(parameter.annotation, str)
    }

    a = ast.parse(dedent(src))
    if len(a.body) != 1 or not isinstance(a.body[0], ast.FunctionDef):
        raise RuntimeError(f"Expected {fn} to be a function")
    f = a.body[0]

    annotation_to_type = {}

    for arg in f.args.args:
        arg_annotation_str = (
            get_annotation_str(arg.annotation) if arg.annotation else None
        )

        if arg_annotation_str is None:
            continue

        arg_name = arg.arg
        if arg_name in name_to_type:
            annotation_to_type[arg_annotation_str] = name_to_type[arg_name]

    literal_return_annotation = get_annotation_str(f.returns)
    valid_literal_annotation = literal_return_annotation is not None
    return_annotation = signature.return_annotation
    valid_return_annotation_type = (
        return_annotation is not inspect.Parameter.empty
        and not isinstance(return_annotation, str)
    )
    if valid_literal_annotation and valid_return_annotation_type:
        annotation_to_type[literal_return_annotation] = return_annotation

    return annotation_to_type


def createResolutionCallbackForClassMethods(cls):
    fns = [
        getattr(cls, name)
        for name in cls.__dict__
        if inspect.isroutine(getattr(cls, name))
    ]
    fns = [fn for fn in fns if not inspect.isbuiltin(fn) and hasattr(fn, "__globals__")]
    captures = {}

    for fn in fns:
        captures.update(get_closure(fn))
        captures.update(get_type_hint_captures(fn))

    def lookup_in_class(key):
        if key in captures:
            return captures[key]
        else:
            return getattr(builtins, key, None)

    return lookup_in_class


def boolean_dispatch(
    arg_name, arg_index, default, if_true, if_false, module_name, func_name
):

    def fn(*args, **kwargs):
        dispatch_flag = default
        if arg_name in kwargs:
            dispatch_flag = kwargs[arg_name]
        elif arg_index < len(args):
            dispatch_flag = args[arg_index]

        if dispatch_flag:
            return if_true(*args, **kwargs)
        else:
            return if_false(*args, **kwargs)

    if if_true.__doc__ is None and if_false.__doc__ is not None:
        doc = if_false.__doc__
        if_true.__doc__ = doc
    elif if_false.__doc__ is None and if_true.__doc__ is not None:
        doc = if_true.__doc__
        if_false.__doc__ = doc
    elif if_false.__doc__ is None and if_true.__doc__ is None:
        doc = None
    else:
        raise RuntimeError("only one function can have a docstring")
    fn.__doc__ = doc

    if module_name is not None:
        fn.__module__ = module_name
    if func_name is not None:
        fn.__name__ = func_name

    boolean_dispatched[fn] = {
        "if_true": if_true,
        "if_false": if_false,
        "index": arg_index,
        "default": default,
        "arg_name": arg_name,
    }
    return fn


class FunctionModifiers:

    UNUSED = "unused (ignored and replaced with raising of an exception)"
    IGNORE = "ignore (leave as a call to Python, cannot be torch.jit.save'd)"
    EXPORT = "export (compile this function even if nothing calls it)"
    DEFAULT = "default (compile if called from a exported function / forward)"
    COPY_TO_SCRIPT_WRAPPER = (
        "if this method is not scripted, copy the python method onto the scripted model"
    )
    _DROP = "_drop (function is fully ignored, declaration can be unscriptable)"


def export(fn):
    fn._torchscript_modifier = FunctionModifiers.EXPORT
    return fn


def unused(fn):
    if isinstance(fn, property):
        prop = fn
        setattr(  # noqa: B010
            prop.fget, "_torchscript_modifier", FunctionModifiers.UNUSED
        )

        if prop.fset:
            setattr(  # noqa: B010
                prop.fset, "_torchscript_modifier", FunctionModifiers.UNUSED
            )

        return prop

    fn._torchscript_modifier = FunctionModifiers.UNUSED
    return fn


class _IgnoreContextManager(contextlib.AbstractContextManager):
    def __init__(self, **kwargs):
        pass

    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:
        pass


def ignore(drop=False, **kwargs):

    if callable(drop):
        fn = drop
        fn._torchscript_modifier = FunctionModifiers.IGNORE
        return fn

    if not isinstance(drop, bool):
        raise RuntimeError(
            "Argument to @torch.jit.ignore must be a bool or "
            f"a function but got {drop}"
        )

    drop_on_export = kwargs.pop("drop_on_export", None)
    if drop_on_export:
        warnings.warn(
            "ignore(drop_on_export=True) has been deprecated. TorchScript will now drop the function "
            "call on compilation. Use torch.jit.unused now. {}",
            category=FutureWarning,
        )

        drop = drop_on_export
    elif drop:
        warnings.warn(
            "ignore(True) has been deprecated. TorchScript will now drop the function "
            "call on compilation. Use torch.jit.unused now. {}",
            category=FutureWarning,
        )

    def decorator(fn):
        if drop:
            fn._torchscript_modifier = FunctionModifiers.UNUSED
        else:
            fn._torchscript_modifier = FunctionModifiers.IGNORE
        return fn

    return decorator


def _drop(fn):
    fn._torchscript_modifier = FunctionModifiers._DROP
    return fn


def _copy_to_script_wrapper(fn):
    fn._torchscript_modifier = FunctionModifiers.COPY_TO_SCRIPT_WRAPPER
    return fn


def module_has_exports(mod):
    for name in dir(mod):
        if hasattr(mod, name):
            item = getattr(mod, name)
            if callable(item):
                if get_torchscript_modifier(item) is FunctionModifiers.EXPORT:
                    return True
    return False


def should_drop(fn) -> bool:
    attr = get_torchscript_modifier(fn)
    if attr is None:
        return False
    return attr is FunctionModifiers.UNUSED or attr is FunctionModifiers._DROP


def is_ignored_fn(fn) -> bool:
    mod = get_torchscript_modifier(fn)
    return (
        mod is FunctionModifiers.UNUSED
        or mod is FunctionModifiers.IGNORE
        or mod is FunctionModifiers._DROP
    )


def _is_drop_fn(fn) -> bool:
    mod = get_torchscript_modifier(fn)
    return mod is FunctionModifiers._DROP


def is_static_fn(cls, fn) -> bool:
    return isinstance(inspect.getattr_static(cls, fn, default=None), staticmethod)


def get_static_fn(cls, fn):
    return inspect.getattr_static(cls, fn).__func__


def get_torchscript_modifier(fn):
    if not callable(fn):
        return None
    if hasattr(fn, "__func__"):
        fn = fn.__func__
    return getattr(fn, "_torchscript_modifier", FunctionModifiers.DEFAULT)


def copy_torchscript_modifier(orig, new) -> None:
    attr = get_torchscript_modifier(orig)
    if attr is None:
        return
    new._torchscript_modifier = attr



_overloaded_fns: Dict[str, List[Callable]] = {}  # noqa: T484




def get_overload_no_implementation_error_message(kind, obj):
    sourcelines, file_lineno, filename = get_source_lines_and_file(obj)
    return (
        f'Implementation for the {kind} "{_qualified_name(obj)}" is missing. Please make '
        f"sure a definition is provided and defined after all overload declarations.\n"
        f'File "{filename}", line {file_lineno}:\n'
        + "".join(sourcelines)
        + "\n"
        + _OVERLOAD_EXAMPLE
    )


def _check_overload_body(func):
    try:
        parsed_def = parse_def(func)
    except OSError as e:
        warnings.warn(
            f"Unable to retrieve source for @torch.jit._overload function: {func}."
        )
        return

    body = parsed_def.ast.body[0].body

    def is_pass(x):
        return isinstance(x, ast.Pass)

    def is_ellipsis(x):
        return isinstance(x, ast.Expr) and isinstance(x.value, ast.Ellipsis)

    if len(body) != 1 or not (is_pass(body[0]) or is_ellipsis(body[0])):
        msg = (
            "Only `pass` statement or `...` can be the body of overload declaration:\n"
        )
        msg += "\n".join(parsed_def.source.split("\n")[:3])
        msg += " <- Expecting `pass` or `...` here!\n" + _OVERLOAD_EXAMPLE
        raise RuntimeError(msg)


def _overload(func):
    _check_overload_body(func)
    qual_name = _qualified_name(func)
    global _overloaded_fns
    fn_overload_list = _overloaded_fns.get(qual_name)
    if fn_overload_list is None:
        fn_overload_list = []
        _overloaded_fns[qual_name] = fn_overload_list
    fn_overload_list.append(func)
    return func


def _get_fn_overloads(qual_name):
    return _overloaded_fns.get(qual_name)


def _clear_fn_overloads(qual_name) -> None:
    del _overloaded_fns[qual_name]


def get_class_name_lineno(method) -> Tuple[str, int]:
    current_frame = inspect.currentframe()

    for i in range(2):
        assert (
            current_frame is not None
        )  # assert current frame is not an Optional[FrameType]
        current_frame = current_frame.f_back

    assert current_frame is not None  # same here
    class_name = current_frame.f_code.co_name
    line_no = current_frame.f_code.co_firstlineno
    return class_name, line_no



_overloaded_methods: Dict[str, Dict[str, List[Callable]]] = {}  # noqa: T484


_overloaded_method_class_fileno = {}


def _overload_method(func):
    _check_overload_body(func)
    qual_name = _qualified_name(func)
    global _overloaded_methods
    class_name_map = _overloaded_methods.get(qual_name, None)
    if class_name_map is None:
        class_name_map = {}
        _overloaded_methods[qual_name] = class_name_map

    class_name, line_no = get_class_name_lineno(func)
    method_overloads = class_name_map.get(class_name, None)
    if method_overloads is None:
        method_overloads = []
        class_name_map[class_name] = method_overloads
        _overloaded_method_class_fileno[(qual_name, class_name)] = line_no
    else:
        existing_lineno = _overloaded_method_class_fileno[(qual_name, class_name)]
        if existing_lineno != line_no:
            raise RuntimeError(
                "Cannot currently overload the same method name in two different"
                " classes with the same name in the same module"
            )

    method_overloads.append(func)
    return func


def _get_overloaded_methods(method, mod_class):
    if not hasattr(method, "__name__"):
        return None
    qual_name = _qualified_name(method)
    class_name_map = _overloaded_methods.get(qual_name, None)
    if class_name_map is None:
        return None
    overloads = class_name_map.get(mod_class.__name__, None)
    if overloads is None:
        return None

    method_line_no = get_source_lines_and_file(method)[1]
    mod_class_fileno = get_source_lines_and_file(mod_class)[1]
    mod_end_fileno = mod_class_fileno + len(get_source_lines_and_file(mod_class)[0])
    if not (method_line_no >= mod_class_fileno and method_line_no <= mod_end_fileno):
        raise Exception(
            "Overloads are not useable when a module is redeclared within the same file: "
            + str(method)
        )
    return overloads


def is_tuple(ann) -> bool:
    if ann is Tuple:
        raise_error_container_parameter_missing("Tuple")

    if not hasattr(ann, "__module__"):
        return False

    ann_origin = get_origin(ann)
    if IS_PY39_PLUS and ann.__module__ == "builtins" and ann_origin is tuple:
        return True
    return ann.__module__ == "typing" and (ann_origin is Tuple or ann_origin is tuple)


def is_list(ann) -> bool:
    if ann is List:
        raise_error_container_parameter_missing("List")

    if not hasattr(ann, "__module__"):
        return False

    ann_origin = get_origin(ann)
    if IS_PY39_PLUS and ann.__module__ == "builtins" and ann_origin is list:
        return True
    return ann.__module__ == "typing" and (ann_origin is List or ann_origin is list)


def is_dict(ann) -> bool:
    if ann is Dict:
        raise_error_container_parameter_missing("Dict")

    if not hasattr(ann, "__module__"):
        return False

    ann_origin = get_origin(ann)
    if IS_PY39_PLUS and ann.__module__ == "builtins" and ann_origin is dict:
        return True
    return ann.__module__ == "typing" and (ann_origin is Dict or ann_origin is dict)


def is_union(ann):
    if ann is Union:
        raise_error_container_parameter_missing("Union")

    return isinstance(ann, BuiltinUnionType) or (
        hasattr(ann, "__module__")
        and ann.__module__ == "typing"
        and (get_origin(ann) is Union)
    )


def is_optional(ann):
    if ann is Optional:
        raise_error_container_parameter_missing("Optional")

    def is_optional_as_optional(ann):
        return (
            hasattr(ann, "__module__")
            and ann.__module__ == "typing"
            and (get_origin(ann) is Optional)
        )

    def is_union_as_optional(ann):
        ann_args = get_args(ann)
        return len(ann_args) == 2 and (None in ann_args or type(None) in ann_args)

    return is_optional_as_optional(ann) or (is_union(ann) and is_union_as_optional(ann))


def is_future(ann) -> bool:
    if ann is Future:
        raise RuntimeError(
            "Attempted to use Future without a "
            "contained type. Please add a contained type, e.g. "
            "Future[int]"
        )
    return get_origin(ann) is Future


def is_await(ann) -> bool:
    if ann is _Await:
        return True
    return get_origin(ann) is _Await


if torch.distributed.rpc.is_available():
    from torch._C._distributed_rpc import PyRRef
    from torch.distributed.rpc import RRef

    def is_rref(ann) -> bool:
        if ann is RRef:
            raise RuntimeError(
                "Attempted to use RRef without a "
                "contained type. Please add a contained type, e.g. "
                "RRef[int]"
            )
        return get_origin(ann) is RRef

    def is_rref_instance(obj) -> bool:
        return isinstance(obj, PyRRef)

else:

    def is_rref_instance(obj) -> bool:
        return False


def is_final(ann) -> bool:
    return ann.__module__ in {"typing", "typing_extensions"} and (
        get_origin(ann) is Final or isinstance(ann, type(Final))
    )


class BroadcastingListCls:
    def __getitem__(self, types):
        return


BroadcastingList1 = BroadcastingListCls()
for i in range(2, 7):
    globals()[f"BroadcastingList{i}"] = BroadcastingList1


def is_scripting() -> bool:
    return False


def _qualified_name(obj, mangle_name=True) -> str:
    if hasattr(obj, "_jit_override_qualname"):
        return obj._jit_override_qualname
    if isinstance(obj, torch._C.ScriptFunction):
        return obj.qualified_name

    if getattr(obj, "__name__", None):
        name = obj.__name__
    elif isinstance(obj, enum.Enum):
        name = obj.name
    else:
        raise RuntimeError("Could not get name of python class object")

    if name == "<lambda>":
        name = "_lambda"  # make name a valid identifier

    module_name = obj.__module__

    if module_name == "torch._classes":
        return obj.qualified_name

    if module_name is None:
        raise RuntimeError(
            f"Could not get qualified name for class '{name}': "
            "__module__ can't be None."
        )


    if package_mangling.is_mangled(module_name):
        module_name = module_name.replace("<", "_")
        module_name = module_name.replace(">", "_")

    if mangle_name:
        if module_name == "__main__":
            module_name = "__torch__"
        else:
            module_name = "__torch__." + module_name

    if "." in name:
        raise RuntimeError(
            f"Could not get qualified name for class '{name}': "
            f"'{name}' is not a valid identifier"
        )

    return module_name + "." + name


def _try_get_dispatched_fn(fn):
    if not callable(fn):
        return None
    return boolean_dispatched.get(fn)


def _get_named_tuple_properties(
    obj, loc: Optional[torch._C._jit_tree_views.SourceRange] = None, rcb=None
):
    if loc is None:
        loc = fake_range()

    assert issubclass(obj, tuple) and hasattr(obj, "_fields")
    if hasattr(obj, "_field_defaults"):
        defaults = [
            obj._field_defaults[field]
            for field in obj._fields
            if field in obj._field_defaults
        ]
    else:
        defaults = []
    if sys.version_info[:2] < (3, 10):
        obj_annotations = getattr(obj, "__annotations__", {})
    else:
        obj_annotations = inspect.get_annotations(obj)
        if len(obj_annotations) == 0 and hasattr(obj, "__base__"):
            obj_annotations = inspect.get_annotations(obj.__base__)

    annotations = []
    for field in obj._fields:
        if field in obj_annotations:
            field_type = obj_annotations[field]
            if isinstance(field_type, ForwardRef) and rcb is not None:
                rcb_type = rcb(field_type.__forward_arg__)
                if rcb_type is None:
                    raise ValueError(
                        f"Unknown type annotation: '{field_type}' in NamedTuple {obj.__name__}."
                        f" Likely due to partial support for ForwardRef parameters in NamedTuples, see #95858."
                        f" Issue occurred at {loc.highlight()}"
                    )
                field_type = rcb_type
            the_type = torch.jit.annotations.ann_to_type(field_type, loc, rcb)
            annotations.append(the_type)
        else:
            annotations.append(torch._C.TensorType.getInferred())
    return type(obj).__name__, obj._fields, annotations, defaults


def _create_named_tuple(
    t, unqual_name: str, field_names: List[str], defaults: Tuple[Any, ...]
):
    TupleType = collections.namedtuple(unqual_name, field_names, defaults=defaults)  # type: ignore[call-arg, no-redef, misc]
    return TupleType(*t)


@contextlib.contextmanager
def _disable_emit_hooks():
    hooks = torch._C._jit_get_emit_hooks()
    torch._C._jit_set_emit_hooks(None, None)
    try:
        yield
    finally:
        torch._C._jit_set_emit_hooks(hooks[0], hooks[1])


def _disable_emit_hooks_decorator(_DecoratorContextManager) -> None:  # noqa: F811
    def __enter__(self) -> None:
        self.hooks = torch._C._jit_get_emit_hooks()
        torch._C._jit_set_emit_hooks(None, None)

    def __exit__(self, *args) -> None:
        torch._C._jit_set_emit_hooks(self.hooks[0], self.hooks[1])


def _is_exception(obj) -> bool:
    if not inspect.isclass(obj):
        return False
    return issubclass(obj, Exception)


def raise_error_container_parameter_missing(target_type) -> None:
    if target_type == "Dict":
        raise RuntimeError(
            "Attempted to use Dict without "
            "contained types. Please add contained type, e.g. "
            "Dict[int, int]"
        )
    raise RuntimeError(
        f"Attempted to use {target_type} without a "
        "contained type. Please add a contained type, e.g. "
        f"{target_type}[int]"
    )


def check_args_exist(target_type) -> None:
    if target_type is List or target_type is list:
        raise_error_container_parameter_missing("List")
    elif target_type is Tuple or target_type is tuple:
        raise_error_container_parameter_missing("Tuple")
    elif target_type is Dict or target_type is dict:
        raise_error_container_parameter_missing("Dict")
    elif target_type is None or target_type is Optional:
        raise_error_container_parameter_missing("Optional")


def check_empty_containers(obj) -> None:
    if obj == [] or obj == {} or obj == ():
        warnings.warn(
            "The inner type of a container is lost when "
            "calling torch.jit.isinstance in eager mode. For "
            "example, List[int] would become list and "
            "therefore falsely return True for List[float] or"
            " List[str]."
        )


def container_checker(obj, target_type) -> bool:
    origin_type = get_origin(target_type)
    check_args_exist(target_type)
    if origin_type is None:
        return False
    elif origin_type is list or origin_type is List:
        check_empty_containers(obj)
        if not isinstance(obj, list):
            return False
        arg_type = get_args(target_type)[0]
        arg_origin = get_origin(arg_type)
        for el in obj:
            if arg_origin:  # processes nested container, ex: List[List[str]]
                if not container_checker(el, arg_type):
                    return False
            elif not isinstance(el, arg_type):
                return False
        return True
    elif origin_type is Dict or origin_type is dict:
        check_empty_containers(obj)
        if not isinstance(obj, dict):
            return False
        key_type = get_args(target_type)[0]
        val_type = get_args(target_type)[1]
        for key, val in obj.items():
            if not isinstance(key, key_type):
                return False
            val_origin = get_origin(val_type)
            if val_origin:
                if not container_checker(val, val_type):
                    return False
            elif not isinstance(val, val_type):
                return False
        return True
    elif origin_type is Tuple or origin_type is tuple:
        check_empty_containers(obj)
        if not isinstance(obj, tuple):
            return False
        arg_types = get_args(target_type)
        if len(obj) != len(arg_types):
            return False
        for el, el_type in zip(obj, arg_types):
            el_origin = get_origin(el_type)
            if el_origin:
                if not container_checker(el, el_type):
                    return False
            elif not isinstance(el, el_type):
                return False
        return True
    elif origin_type is Union or issubclass(
        origin_type, BuiltinUnionType
    ):  # also handles Optional
        if obj is None:  # check before recursion because None is always fine
            return True
        inner_types = get_args(target_type)
        for t in inner_types:
            t_origin = get_origin(t)
            if t_origin:
                return container_checker(obj, t)
            elif isinstance(obj, t):
                return True
    return False


def _isinstance(obj, target_type) -> bool:
    if isinstance(target_type, collections.abc.Container):
        if not isinstance(target_type, tuple):
            raise RuntimeError(
                "The second argument to "
                "`torch.jit.isinstance` must be a type "
                "or a tuple of types"
            )
        for t_type in target_type:
            if _isinstance(obj, t_type):
                return True
        return False

    origin_type = get_origin(target_type)
    if origin_type:
        return container_checker(obj, target_type)

    check_args_exist(target_type)

    return isinstance(obj, target_type)


class _TensorExtractor(pickle.Pickler):
    def __init__(self, *args, tensors: List[torch.Tensor], **kwargs):
        super().__init__(*args, **kwargs)
        self.tensors = tensors

    def persistent_id(self, obj):
        if isinstance(obj, torch.Tensor):
            self.tensors.append(obj)
            return ""
        if isinstance(obj, LockType):
            return ""
        if isinstance(obj, CFuture) or is_rref_instance(obj):
            return ""
        if isinstance(obj, CAwait):
            return ""
        if isinstance(obj, torch.cuda.Event):
            return ""
        if isinstance(obj, threading.Thread):
            return ""
        return None


def _extract_tensors(obj):
    tensors: List[torch.Tensor] = []
    extractor = _TensorExtractor(io.BytesIO(), protocol=-1, tensors=tensors)
    extractor.dump(obj)
    return tensors



if sys.version_info > (3, 10):
    _drop(enum.Enum.__new__)
    _drop(enum.Enum.__format__)
    _drop(enum.Enum.__repr__)
    _drop(enum.Enum.__str__)

<END>

<START>
from torch.ao.quantization.utils import Pattern, QuantizerCls

<END>

<START>
import collections
import functools
import inspect
import sys
import textwrap
import types
import warnings
from typing import Dict, List, Set, Type

import torch

import torch._jit_internal as _jit_internal
from torch._sources import fake_range
from torch.jit._builtins import _find_builtin
from torch.jit._check import AttributeTypeIsSupportedChecker
from torch.jit._state import _add_script_class, _get_script_class, _python_cu
from torch.jit.frontend import (
    get_class_properties,
    get_default_args,
    get_jit_class_def,
    get_jit_def,
)
from torch.nn import Module


ScriptMethodStub = collections.namedtuple(
    "ScriptMethodStub", ("resolution_callback", "def_", "original_method")
)
PropertyStub = collections.namedtuple("PropertyStub", ("resolution_callback", "def_"))


ignored_attributes = [
    "_version",
    "_parameters",
    "_buffers",
    "_non_persistent_buffers_set",
    "_backward_hooks",
    "_backward_pre_hooks",
    "_forward_hooks",
    "_forward_hooks_with_kwargs",
    "_forward_pre_hooks",
    "_forward_pre_hooks_with_kwargs",
    "_forward_hooks_always_called",
    "_state_dict_hooks",
    "_state_dict_pre_hooks",
    "_load_state_dict_pre_hooks",
    "_load_state_dict_post_hooks",
    "_modules",
    "_initializing",
    "dump_patches",
]


def _compile_and_register_class(obj, rcb, qualified_name):
    script_class = _get_script_class(obj)

    if not script_class:
        ast = get_jit_class_def(obj, obj.__name__)
        defaults = torch.jit.frontend.get_default_args_for_class(obj)
        script_class = torch._C._jit_script_class_compile(
            qualified_name, ast, defaults, rcb
        )
        _add_script_class(obj, script_class)

    return script_class


def make_stub(func, name):
    rcb = _jit_internal.createResolutionCallbackFromClosure(func)
    ast = get_jit_def(func, name, self_name="RecursiveScriptModule")
    return ScriptMethodStub(rcb, ast, func)


def make_stub_from_method(nn_module, method_name):
    func = getattr(nn_module, method_name)
    if isinstance(func, ScriptMethodStub):
        return func
    return make_stub(func, method_name)


def make_stubs_from_exported_methods(mod):
    stubs = []
    for name in dir(mod):
        item = getattr(mod, name, None)
        if (
            _jit_internal.get_torchscript_modifier(item)
            is _jit_internal.FunctionModifiers.EXPORT
        ):
            stubs.append(make_stub_from_method(mod, name))

    return stubs


def jit_ignored_properties(module):
    user_annotated_ignored_attributes = getattr(
        module, "__jit_ignored_attributes__", list()
    )

    def get_properties_names(module):
        return {k for k, v in vars(module).items() if isinstance(v, property)}

    properties = get_properties_names(type(module))
    user_annoted_ignored_properties = set()

    for ignored_attr in user_annotated_ignored_attributes:
        if ignored_attr in properties:
            user_annoted_ignored_properties.add(ignored_attr)
    return user_annoted_ignored_properties


_constant_types = (
    bool,
    float,
    int,
    str,
    type(None),
    torch.device,
    torch.layout,
    torch.dtype,
)


def _get_valid_constant(attr, v, owner_type):
    if isinstance(v, _constant_types):
        return v
    elif isinstance(v, (tuple, list)):
        return tuple(_get_valid_constant(attr, x, owner_type) for x in v)
    constants = ", ".join(torch.typename(typ) for typ in _constant_types)
    raise TypeError(
        textwrap.dedent(
        )
    )


class SourceContext(torch._C._jit_tree_views.SourceRangeFactory):
    def __init__(self, source, filename, file_lineno, leading_whitespace_len):
        super().__init__(source, filename, file_lineno, leading_whitespace_len)


def get_annotations(obj):
    if sys.version_info < (3, 10):
        return getattr(obj, "__annotations__", {})
    annotations = inspect.get_annotations(obj)
    if annotations:
        return annotations

    def get_cls_annotations(cls):
        cls_annotations = inspect.get_annotations(cls)
        if cls_annotations:
            return cls_annotations
        for base in cls.__bases__:
            cls_annotations = get_cls_annotations(base)
            if cls_annotations:
                return cls_annotations
        return {}

    cls = obj if isinstance(obj, type) else type(obj)
    return get_cls_annotations(cls)


def infer_concrete_type_builder(nn_module, share_types=True):
    concrete_type_builder = torch._C.ConcreteModuleTypeBuilder(type(nn_module))
    if isinstance(nn_module, (torch.nn.ModuleDict)):
        concrete_type_builder.set_module_dict()
    if isinstance(nn_module, (torch.nn.ModuleList, torch.nn.Sequential)):
        concrete_type_builder.set_module_list()
    if isinstance(nn_module, (torch.nn.ParameterList)):
        concrete_type_builder.set_parameter_list()
    if isinstance(nn_module, (torch.nn.ParameterDict)):
        concrete_type_builder.set_parameter_dict()

    class_annotations = get_annotations(nn_module)
    if isinstance(nn_module, (torch.ao.quantization.QuantWrapper)):
        class_annotations = {}

    user_annotated_ignored_attributes = getattr(
        nn_module, "__jit_ignored_attributes__", list()
    )
    concrete_type_builder.add_ignored_attributes(user_annotated_ignored_attributes)
    ignored_properties = jit_ignored_properties(nn_module)

    def infer_type(name, item):
        inferred = False
        try:
            if (
                name in class_annotations
                and class_annotations[name]
                != torch.nn.Module.__annotations__["forward"]
            ):
                ann_to_type = torch.jit.annotations.ann_to_type(
                    class_annotations[name], fake_range()
                )
                attr_type = torch._C.InferredType(ann_to_type)
            elif isinstance(item, torch.jit.Attribute):
                ann_to_type = torch.jit.annotations.ann_to_type(item.type, fake_range())
                attr_type = torch._C.InferredType(ann_to_type)
            else:
                attr_type = torch._C._jit_try_infer_type(item)
                inferred = True
        except RuntimeError as re:
            raise RuntimeError(f"Error inferring type for {name}: {item}: {re}") from re

        return attr_type, inferred

    added_names = set()

    for name, item in nn_module._parameters.items():
        if name in user_annotated_ignored_attributes:
            continue

        assert item is None or isinstance(item, torch.Tensor)
        attr_type, _ = infer_type(name, item)
        concrete_type_builder.add_attribute(name, attr_type.type(), True, False)
        added_names.add(name)

    for name, item in nn_module._buffers.items():
        if name in user_annotated_ignored_attributes:
            continue

        assert item is None or isinstance(item, torch.Tensor)
        attr_type, _ = infer_type(name, item)
        concrete_type_builder.add_attribute(name, attr_type.type(), False, True)
        added_names.add(name)

    for name, item in nn_module._modules.items():
        if name in user_annotated_ignored_attributes:
            continue

        attr_type, _ = infer_type(name, item)
        if item is None:
            concrete_type_builder.add_attribute(name, attr_type.type(), False, False)
            continue
        if attr_type.success():
            assert attr_type.type().is_interface_type()
            sub_concrete_type = torch._C.ConcreteModuleType.from_jit_type(
                attr_type.type()
            )
        else:
            sub_concrete_type = get_module_concrete_type(item, share_types)
        concrete_type_builder.add_module(name, sub_concrete_type)

        added_names.add(name)

    constants_set = set(getattr(nn_module, "__constants__", ()))

    for name, ann in class_annotations.items():
        if torch._jit_internal.is_final(ann):
            constants_set.add(name)

    for name in constants_set:
        if name in added_names:
            if name in nn_module._modules:
                hint = "submodule"
            elif name in nn_module._buffers:
                hint = "buffer"
            elif name in nn_module._parameters:
                hint = "parameter"
            else:
                raise AssertionError(
                    "added_names must be submodule, parameter, or buffer"
                )

            warnings.warn(
                f"'{name}' was found in ScriptModule constants, "
                f" but it is a non-constant {hint}. Consider removing it."
            )
            continue
        if not hasattr(nn_module, name):
            warnings.warn(
                f"'{name}' was found in ScriptModule constants, "
                "but was not actually set in __init__. "
                "Consider removing it."
            )
            continue
        value = getattr(nn_module, name)
        concrete_type_builder.add_constant(
            name, _get_valid_constant(name, value, type(nn_module).__name__)
        )
        added_names.add(name)

    overloads = getattr(nn_module, "__overloads__", {})
    overloads.update(
        get_overload_name_mapping(
            get_overload_annotations(nn_module, ignored_properties)
        )
    )
    for name, overloaded_names in overloads.items():
        concrete_type_builder.add_overload(name, overloaded_names)

    for name, value in nn_module.__dict__.items():
        if name in ignored_attributes or name.startswith("__"):
            continue

        if name in user_annotated_ignored_attributes:
            continue

        if name in added_names:
            continue

        isoverloadpacket = isinstance(value, torch._ops.OpOverloadPacket)
        if isoverloadpacket:
            value = value.op
        if inspect.isfunction(value):
            try:
                scripted_fn = torch.jit.script(value)
                concrete_type_builder.add_function_attribute(
                    name, torch._C._jit_try_infer_type(scripted_fn).type(), value
                )
            except Exception as e:
                hint = (
                    "(This function exists as an attribute on the Python module, "
                    "but we failed to compile it to a TorchScript function. "
                    f"\nThe error stack is reproduced here:\n{e}"
                )
                concrete_type_builder.add_failed_attribute(name, hint)
                pass

            continue

        builtin_symbol_name = _find_builtin(value)
        if builtin_symbol_name:
            concrete_type_builder.add_builtin_function(name, builtin_symbol_name)
            continue

        if isinstance(value, torch.jit.ScriptFunction):
            concrete_type_builder.add_function_attribute(
                name, torch._C._jit_try_infer_type(value).type(), value
            )
            continue

        attr_type, inferred = infer_type(name, value)
        if attr_type.success():
            concrete_type_builder.add_attribute(name, attr_type.type(), False, False)
        else:
            inferred_msg = (
                "Its type was inferred; try adding a type annotation for the attribute."
                if inferred
                else ""
            )
            additional_info = f"{attr_type.reason()}. {inferred_msg}"
            hint = (
                "(This attribute exists on the Python module, "
                f"but we failed to convert Python type: '{torch.typename(type(value))}' "
                f"to a TorchScript type. {additional_info})"
            )
            concrete_type_builder.add_failed_attribute(name, hint)

    for hook in nn_module._forward_hooks.values():
        concrete_type_builder.add_forward_hook(hook)
    for pre_hook in nn_module._forward_pre_hooks.values():
        concrete_type_builder.add_forward_pre_hook(pre_hook)

    return concrete_type_builder


class ConcreteTypeStore:
    type_store: Dict[Type[Module], List[torch._C.ConcreteModuleType]]
    methods_compiled: Set[torch._C.ConcreteModuleType]

    def __init__(self):
        self.type_store = {}
        self.methods_compiled = set()

    def get_or_create_concrete_type(self, nn_module):
    Get a concrete type for nn_modules.

    If share_types is True, the concrete type is fetched from concrete_type_store.
    If it is False, a new concrete type is created without first searching concrete_type_store.

    Args:
        nn_module:  The original Python nn.Module that we are creating a ScriptModule for.
        share_types = Whether to share underlying JIT types between modules (if possible).

    Returns:
        A concrete type for nn_module.
    Create and return a RecursiveScriptClass instance from a Python object.

    Arguments:
        obj: A Python object.
    Create a new ScriptModule from an nn.Module.

    Args:
        nn_module:  The original Python nn.Module that we are creating a ScriptModule for.
        stubs_fn:  Lambda that takes an nn.Module and generates a list of ScriptMethodStubs to compile.
        share_types:  Whether to share underlying JIT types between modules (if possible).
            NOTE: Only set to False this when we cannot guarantee type sharing will work
                correctly. This only happens today for traced modules, where the same
                module can produce different traced methods depending on the inputs.
        is_tracing: Whether this function is called during tracing or scripting. If tracing,
                we don't need to do AttributeTypeIsSupportedChecker because all the unsupported
                attributes will be baked as constant in the tracing graph. In addition,
                this check significantly slows down the traced modules when the module size is big.
    Convert an nn.Module to a RecursiveScriptModule.

    Args:
        nn_module:  The original Python nn.Module that we are creating a ScriptModule for.
        concrete_type:  The fully initialized ConcreteType of the module.
        stubs_fn:  Lambda that takes an nn.Module and generates a list of ScriptMethodStubs to compile.

    (TODO add a link when the rules are published).
    check_module_initialized(nn_module)
    hook_map: Dict = {}

    hook_stubs = []
    for hook in nn_module._forward_hooks.values():
        if hook.__name__ in hook_map:
            if id(hook) != id(hook_map[hook.__name__]):
                raise RuntimeError(
                    f"Hook '{hook.__name__}' on {type(nn_module).__name__} "
                    "has at least two different python definitions."
                    " Please use unique names for all hooks."
                )
        else:
            hook_map[hook.__name__] = hook
        hook_stubs.append(make_stub(hook, hook.__name__))

    pre_hook_stubs = []
    for pre_hook in nn_module._forward_pre_hooks.values():
        if pre_hook.__name__ in hook_map:
            if id(pre_hook) != id(hook_map[pre_hook.__name__]):
                raise RuntimeError(
                    f"Pre-hook '{pre_hook.__name__}' on {type(nn_module).__name__} "
                    "has at least two different python definitions."
                    " Please use unique names for all hooks."
                )
        else:
            hook_map[pre_hook.__name__] = pre_hook
        pre_hook_stubs.append(make_stub(pre_hook, pre_hook.__name__))

    return hook_stubs, pre_hook_stubs


def get_property_stubs(nn_module):
    Make a ScriptModule from an nn.Module, using the interface methods rule for determining which methods to compile.

    Args:
        mod_interface: the interface type that the module have
        nn_module:  The original Python nn.Module that we are creating a ScriptModule for.

        It is used to know which methods need to act as starting points for compilation.
    return torch.jit.RecursiveScriptClass(cpp_class)


def wrap_cpp_module(cpp_module):
    Return a function that lazily binds `unbound_method` to a provided Module IValue, then invokes the method.

    We do this so that any Python shenanigans that
    will poison type sharing are impossible at compile time.

<END>

<START>
import torch._C._lazy
import torch._C._lazy_ts_backend


def get_tensors_ts_device_data_node(tensors):
    return torch._C._lazy_ts_backend._get_tensors_ts_device_data_node(tensors)


def get_graph_hash(tensors):

    TODO: This API is currently ts backend specific. We are working on
    generalizing it to all backends including XLA.

<END>

<START>
import torch
import torch.ao.nn.intrinsic
import torch.ao.nn.intrinsic.qat
import torch.nn.functional as F
import torch.ao.nn.quantized as nnq

_reverse_repeat_padding = nnq.modules.conv._reverse_repeat_padding

class ConvAdd2d(nnq.Conv2d):
    _FLOAT_MODULE = torch.ao.nn.intrinsic.ConvAdd2d  # type: ignore[assignment]

    def __init__(self, in_channels, out_channels, kernel_size, stride=1,
                 padding=0, dilation=1, groups=1, bias=True,
                 padding_mode='zeros', device=None, dtype=None):
        super().__init__(
            in_channels, out_channels, kernel_size, stride=stride,
            padding=padding, dilation=dilation, groups=groups, bias=bias,
            padding_mode=padding_mode, device=device, dtype=dtype)

    def forward(self, input, extra_input):
        if len(input.shape) != 4:
            raise ValueError("Input shape must be `(N, C, H, W)`!")
        if self.padding_mode != 'zeros':
            _reversed_padding_repeated_twice = _reverse_repeat_padding(self.padding)
            input = F.pad(input, _reversed_padding_repeated_twice,
                          mode=self.padding_mode)
        return torch.ops.quantized.conv2d_add(
            input, extra_input, self._packed_params, self.scale, self.zero_point)

    def _get_name(self):
        return 'QuantizedConvAdd2d'

    @classmethod
    def from_float(cls, mod):
        return super().from_float(mod)

    @classmethod
    def from_reference(cls, ref_qconv, output_scale, output_zero_point):
        return super().from_reference(ref_qconv[0], output_scale, output_zero_point)

class ConvAddReLU2d(nnq.Conv2d):
    _FLOAT_MODULE = torch.ao.nn.intrinsic.ConvAddReLU2d  # type: ignore[assignment]

    def __init__(self, in_channels, out_channels, kernel_size, stride=1,
                 padding=0, dilation=1, groups=1, bias=True,
                 padding_mode='zeros', device=None, dtype=None):
        super().__init__(
            in_channels, out_channels, kernel_size, stride=stride,
            padding=padding, dilation=dilation, groups=groups, bias=bias,
            padding_mode=padding_mode, device=device, dtype=dtype)

    def forward(self, input, extra_input):
        if len(input.shape) != 4:
            raise ValueError("Input shape must be `(N, C, H, W)`!")
        if self.padding_mode != 'zeros':
            _reversed_padding_repeated_twice = _reverse_repeat_padding(self.padding)
            input = F.pad(input, _reversed_padding_repeated_twice,
                          mode=self.padding_mode)
        return torch.ops.quantized.conv2d_add_relu(
            input, extra_input, self._packed_params, self.scale, self.zero_point)

    def _get_name(self):
        return 'QuantizedConvAddReLU2d'

    @classmethod
    def from_float(cls, mod):
        return super().from_float(mod)

    @classmethod
    def from_reference(cls, ref_qconv, output_scale, output_zero_point):
        return super().from_reference(ref_qconv[0], output_scale, output_zero_point)

<END>

<START>

import os
from argparse import Action


class env(Action):

    def __init__(self, dest, default=None, required=False, **kwargs) -> None:
        env_name = f"PET_{dest.upper()}"
        default = os.environ.get(env_name, default)

        if default:
            required = False

        super().__init__(dest=dest, default=default, required=required, **kwargs)

    def __call__(self, parser, namespace, values, option_string=None):
        setattr(namespace, self.dest, values)


class check_env(Action):

    def __init__(self, dest, default=False, **kwargs) -> None:
        env_name = f"PET_{dest.upper()}"
        default = bool(int(os.environ.get(env_name, "1" if default else "0")))
        super().__init__(dest=dest, const=True, default=default, nargs=0, **kwargs)

    def __call__(self, parser, namespace, values, option_string=None):
        setattr(namespace, self.dest, self.const)

<END>

<START>
__all__ = ["get_meta", "tune_bsr_dense_addmm"]

import inspect
import itertools
import re
import warnings
from typing import Any, Dict

import torch
from torch.hub import tqdm
from torch.testing import make_tensor


def get_meta(op, key, device_name=None, version=(0, torch.float16, 0.5), exact=False):
    if device_name is None:
        device_name = torch.cuda.get_device_name()
    op_data = _operation_device_version_data.get((op, device_name, version))
    if op_data is None and not exact:
        if re.match(r"NVIDIA A100[^\d]", device_name) is not None:
            device_name = "NVIDIA A100-SXM4-80GB"
        else:
            return
        op_data = _operation_device_version_data.get((op, device_name, version))
    if op_data is None:
        return
    values = op_data.get(key)
    if values is not None:
        if op == "scatter_mm":
            names = (
                "GROUP_SIZE",
                "SPLIT_N",
                "TILE_M",
                "TILE_N",
                "num_stages",
                "num_warps",
            )
            return dict(zip(names, values))
        elif op == "bsr_dense_addmm":
            return dict(
                zip(("GROUP_SIZE_ROW", "SPLIT_N", "num_stages", "num_warps"), values)
            )
        raise NotImplementedError(f"names for {op=}")


def update(op, device_name, version, key, value):
    current_file = inspect.getfile(dump)
    f = open(current_file)
    current_content = f.read()
    f.close()
    begin_data_str = "# BEGIN GENERATED DATA\n"
    begin_data_index = current_content.find(begin_data_str)
    end_data_index = current_content.find("    # END GENERATED DATA\n")
    if begin_data_index == -1 or end_data_index == -1:
        warnings.warn(
            f"{current_file} cannot be updated:"
            " BEGIN/END GENERATED DATA comment blocks appear to be corrupted"
        )
        return

    def sort_key(key):
        op, device_name, version = key
        version = tuple(
            (str(item) if isinstance(item, torch.dtype) else item) for item in version
        )
        return (op, device_name, version)

    part1 = current_content[: begin_data_index + len(begin_data_str)]
    part2 = current_content[end_data_index:]
    data_part = []
    for op_key in sorted(_operation_device_version_data, key=sort_key):
        data_part.append("    " + repr(op_key).replace("'", '"') + ": {")
        op_data = _operation_device_version_data[op_key]
        for key in sorted(op_data):
            data_part.append(f"        {key}: {op_data[key]},")
        data_part.append("    },")
    new_content = part1 + "\n".join(data_part) + "\n" + part2
    if current_content != new_content:
        f = open(current_file, "w")
        f.write(new_content)
        f.close()


def minimize(
    target_func,
    initial_parameters,
    reference_parameters,
    step_func,
    max_step=2,
    verbose=False,
    all_values=None,
):

    def to_key(parameters):
        return tuple(parameters[k] for k in sorted(parameters))

    def from_key(key, parameters):
        return dict(zip(sorted(parameters), key))

    if all_values is None:
        all_values = dict()

    directions = list(range(-max_step, max_step + 1))
    names = sorted(initial_parameters)
    all_directions = []
    for d_tuple in itertools.product(*((directions,) * len(names))):
        dist = sum(map(abs, d_tuple))
        if dist > 0 and dist <= max_step:
            all_directions.append((dist, d_tuple))
    all_directions.sort()

    try:
        reference_target = target_func(reference_parameters)
    except Exception as msg:
        if verbose and "out of resource" not in str(msg):
            print(f"{reference_parameters=} lead to failure: {msg}.")
        reference_target = None
    if reference_target is not None:
        all_values[to_key(reference_parameters)] = reference_target

    parameters = initial_parameters
    try:
        initial_target = target_func(parameters)
    except Exception as msg:
        if reference_target is None:
            if verbose:
                print(
                    f"{initial_parameters=} lead to failure: {msg}. Optimization failed!"
                )
            return {}, -1, -1, f"{msg}"
        if verbose and "out of resource" not in str(msg):
            print(
                f"{initial_parameters=} lead to failure: {msg}. Using reference parameters instead of initial parameters."
            )
        parameters = reference_parameters
        initial_target = reference_target

    if reference_target is None:
        if verbose:
            print("Using initial parameters instead of reference parameters.")
        reference_target = initial_target

    initial_key = to_key(parameters)
    minimal_target = all_values[initial_key] = initial_target
    pbar = tqdm(
        total=len(all_directions),
        desc="Tuning...",
        disable=not verbose,
        ncols=75,
    )
    while True:
        for i, (_, d_tuple) in enumerate(all_directions):
            pbar.update(1)
            next_parameters = parameters.copy()
            for name, direction in zip(names, d_tuple):
                value = next_parameters[name]
                if direction == 0:
                    continue
                next_value = step_func(name, value, direction, parameters)
                if next_value == value:
                    break
                next_parameters[name] = next_value
            else:
                next_key = to_key(next_parameters)
                if next_key in all_values:
                    continue
                try:
                    next_target = target_func(next_parameters)
                except Exception as msg:
                    all_values[next_key] = str(msg)
                    if verbose and "out of resource" not in str(msg):
                        print(f"{next_parameters=} lead to failure: {msg}. Skipping.")
                    continue
                all_values[next_key] = next_target

                if next_target < minimal_target:
                    minimal_target = next_target
                    parameters = next_parameters
                    pbar.total += i + 1
                    break
        else:
            minimizer_keys = {
                k
                for k, v in all_values.items()
                if isinstance(v, float) and abs(1 - v / minimal_target) < 0.001
            }
            minimizer_key = (
                initial_key if initial_key in minimizer_keys else min(minimizer_keys)
            )
            minimizer_target = all_values[minimizer_key]
            parameters = from_key(minimizer_key, parameters)
            speedup_incr = (1 - minimal_target / reference_target) * 100
            if speedup_incr < 0:
                if verbose:
                    print(
                        f"{speedup_incr=} is negative. Rerunning minimize with reference parameters as initial parameters."
                    )
                return minimize(
                    target_func,
                    reference_parameters,
                    reference_parameters,
                    step_func,
                    max_step=max_step,
                    verbose=verbose,
                    all_values=all_values,
                )
            sensitivity = []
            for name in parameters:
                value = parameters[name]
                rel_diffs = []
                for direction in range(-max_step, max_step + 1):
                    if direction == 0:
                        continue
                    next_value = step_func(name, value, direction, parameters)
                    if next_value == value:
                        rel_diffs.append(0)
                        continue
                    next_parameters = parameters.copy()
                    next_parameters[name] = next_value
                    next_key = to_key(next_parameters)
                    next_target = all_values.get(next_key)
                    if next_target is None or isinstance(next_target, str):
                        rel_diffs.append(0)
                        continue
                    rel_diff = (next_target / minimal_target - 1) * 100
                    rel_diffs.append(rel_diff)
                sensitivity.append((max(rel_diffs), rel_diffs, name))

            sensitivity_message = [f"timing0={initial_target:.3f}"]
            for _, rel_diffs, name in sorted(sensitivity, reverse=True):
                left_diffs = "|".join(
                    [f"{rel_diff:.1f}" for rel_diff in rel_diffs[:max_step]]
                )
                right_diffs = "|".join(
                    [f"{rel_diff:.1f}" for rel_diff in rel_diffs[max_step:]]
                )
                sensitivity_message.append(
                    f"{name}={parameters[name]} ({left_diffs}...{right_diffs} %)"
                )
            sensitivity_message = ", ".join(sensitivity_message)
            return parameters, speedup_incr, minimal_target, sensitivity_message


def create_blocked_tensor(B, M, N, blocksize, sparsity, dtype, device):
    assert (
        sparsity <= 1.0 and sparsity >= 0.0
    ), "sparsity should be a value between 0 and 1"
    assert M % blocksize[0] == 0
    assert N % blocksize[1] == 0
    shape = (B, M // blocksize[0], N // blocksize[1])[int(B == 0) :]
    A = torch.bernoulli(torch.full(shape, 1 - sparsity, dtype=dtype, device=device))
    expected_nnz = int((1 - sparsity) * M * N / (blocksize[0] * blocksize[1]))
    nonzero_indices = A.flatten().nonzero()
    actual_nnz = nonzero_indices.shape[0]
    if actual_nnz > expected_nnz:
        selected_nonzeros = torch.randperm(actual_nnz)[: actual_nnz - expected_nnz]
        A.flatten()[nonzero_indices[selected_nonzeros]] = 0
    elif actual_nnz < expected_nnz:
        zero_indices = (A == 0).flatten().nonzero()
        selected_zeros = torch.randperm(zero_indices.shape[0])[
            : expected_nnz - actual_nnz
        ]
        A.flatten()[zero_indices[selected_zeros]] = 1
    A = torch.repeat_interleave(A, blocksize[0], dim=-2)
    A = torch.repeat_interleave(A, blocksize[1], dim=-1)
    return A


def optimize_scatter_mm(
    m, k, n, bm, bk, dtype=torch.float16, device="cuda", sparsity=0.5, force=False
):
    import triton

    from torch.sparse._triton_ops import bsr_scatter_mm, bsr_scatter_mm_indices_data

    key = (m, k, n, bm, bk)

    version = (0, dtype, sparsity)
    device_name = torch.cuda.get_device_name()

    reference_meta = dict(
        GROUP_SIZE=1,
        TILE_M=16,
        TILE_N=16,
        SPLIT_N=n // 16,
        num_stages=1,
        num_warps=1,
    )

    initial_meta = get_meta(
        "scatter_mm", key, device_name=device_name, version=version, exact=True
    )

    if initial_meta is None:
        initial_meta = get_meta(
            "bsr_dense_addmm",
            key,
            device_name=device_name,
            version=(0, dtype, 0.5),
            exact=True,
        )
        if initial_meta is None:
            initial_meta = reference_meta
    elif not force:
        return

    print(f"{m, k, n, bm, bk, initial_meta, reference_meta=}")
    torch.manual_seed(0)
    bsr = create_blocked_tensor(
        0, m, k, (bm, bk), sparsity, dtype, device
    ).to_sparse_bsr((bm, bk))
    dense = make_tensor(k, n, dtype=dtype, device=device)

    def bench(meta, bsr=bsr, dense=dense):
        indices_data = bsr_scatter_mm_indices_data(
            bsr, dense, indices_format="bsr_strided_mm_compressed", **meta
        )

        def test_func():
            return bsr_scatter_mm(bsr, dense, indices_data=indices_data)

        ms_min = triton.testing.do_bench(
            test_func, warmup=500, rep=100, fast_flush=False
        )

        return ms_min

    def step_meta_parameter(name, value, direction, meta, m=m, n=n, k=k, bm=bm, bk=bk):

        is_log = name in {"SPLIT_N", "TILE_M", "TILE_N", "num_warps"}
        min_value = dict(
            SPLIT_N=1, TILE_M=16, TILE_N=16, num_warps=1, num_stages=1, GROUP_SIZE=1
        )[name]
        max_value = dict(
            SPLIT_N=n // meta["TILE_N"], TILE_M=bm, TILE_N=n // meta["SPLIT_N"]
        ).get(name)
        value_step = dict(
            SPLIT_N=2, TILE_M=2, TILE_N=2, num_warps=2, num_stages=1, GROUP_SIZE=1
        )[name]
        if is_log:
            next_value = (
                value * value_step**direction
                if direction > 0
                else value // (value_step ** abs(direction))
            )
        else:
            next_value = value + value_step * direction
        if min_value is not None:
            next_value = max(next_value, min_value)
        if max_value is not None:
            next_value = min(next_value, max_value)
        if name == "SPLIT_N" and n % next_value != 0:
            return value
        if (dtype, name, next_value, m, n, k, bm, bk) in {
            (torch.float32, "num_warps", 32, 256, 256, 256, 16, 16),
            (torch.float32, "num_warps", 16, 256, 256, 256, 32, 32),
            (torch.float32, "num_warps", 16, 256, 256, 256, 64, 64),
            (torch.float32, "num_warps", 16, 256, 256, 256, 128, 128),
            (torch.float32, "num_warps", 16, 512, 512, 256, 128, 128),
        } and re.match(r"NVIDIA A100[^\d]", device_name) is not None:
            return value
        return next_value

    meta, speedup, timing, sensitivity_message = minimize(
        bench, initial_meta, reference_meta, step_meta_parameter
    )
    if initial_meta is not reference_meta and initial_meta == meta and not force:
        return
    print(f"{meta=} {speedup=:.1f} % {timing=:.3f} ms")
    if speedup < 0:
        return
    device_name = torch.cuda.get_device_name()

    update(
        "scatter_mm", device_name, version, key, tuple(meta[k] for k in sorted(meta))
    )


def tune_bsr_dense_addmm(
    input,
    bsr,
    dense,
    *,
    beta=1,
    alpha=1,
    out=None,
    store=False,
    verbose=False,
    force=False,
):
    import triton

    from torch.sparse._triton_ops import bsr_dense_addmm

    N = dense.shape[-1]
    values = bsr.values()
    crow_indices = bsr.crow_indices()
    batch_ndim = crow_indices.dim() - 1
    M, K = bsr.shape[batch_ndim : batch_ndim + 2]
    BM, BK = values.shape[batch_ndim + 1 : batch_ndim + 3]

    reference_meta = dict(
        GROUP_SIZE_ROW=1, num_stages=1, num_warps=4, SPLIT_N=max(N // BM, 1)
    )

    sparsity = round(1 - bsr._nnz() * BM * BK / (M * K), 2)
    dtype = bsr.dtype
    version = (0, dtype, sparsity)
    key = (M, K, N, BM, BK, beta == 0, beta == 1, alpha == 1)

    initial_meta = get_meta("bsr_dense_addmm", key, version=version, exact=True)
    if initial_meta is None:
        may_skip_update = False
        initial_meta = get_meta(
            "bsr_dense_addmm", key, version=(0, dtype, 0.5), exact=True
        )
        if initial_meta is None:
            initial_meta = reference_meta
    elif not force:
        return initial_meta
    else:
        may_skip_update = True

    def bench(meta, input=input, bsr=bsr, dense=dense, alpha=alpha, out=out):
        def test_func():
            return bsr_dense_addmm(
                input, bsr, dense, beta=beta, alpha=alpha, meta=meta, out=out
            )

        return triton.testing.do_bench(test_func, warmup=500, rep=100, fast_flush=False)

    def step_meta_parameter(name, value, direction, meta, M=M, N=N, K=K, BM=BM, BK=BK):
        is_log = name in {"SPLIT_N", "num_warps"}
        min_value = dict(SPLIT_N=1, num_warps=1, num_stages=1, GROUP_SIZE_ROW=1)[name]
        max_value = dict(SPLIT_N=max(N // BM, 1)).get(name)
        value_step = dict(SPLIT_N=2, num_warps=2, num_stages=1, GROUP_SIZE_ROW=1)[name]
        if is_log:
            next_value = (
                value * value_step**direction
                if direction > 0
                else value // (value_step ** abs(direction))
            )
        else:
            next_value = value + value_step * direction
        if min_value is not None:
            next_value = max(next_value, min_value)
        if max_value is not None:
            next_value = min(next_value, max_value)
        if name == "SPLIT_N" and N % next_value != 0:
            return value
        return next_value

    meta, speedup, timing, sensitivity_message = minimize(
        bench,
        initial_meta,
        reference_meta,
        step_meta_parameter,
        max_step=2,
        verbose=verbose,
    )
    if verbose:
        print(f"-> {sensitivity_message}, {speedup=:.1f} %, {timing=:.3f} ms")

    if store and not (
        may_skip_update and meta == initial_meta and initial_meta is not reference_meta
    ):
        device_name = torch.cuda.get_device_name()
        update(
            "bsr_dense_addmm",
            device_name,
            version,
            key,
            tuple(meta[k] for k in sorted(meta)),
        )

    return meta


def optimize_bsr_dense_addmm(
    m,
    k,
    n,
    bm,
    bk,
    beta=1,
    alpha=1,
    dtype=torch.float16,
    device="cuda",
    sparsity=0.5,
    force=False,
    verbose=False,
):
    torch.manual_seed(0)
    bsr = create_blocked_tensor(
        0, m, k, (bm, bk), sparsity, dtype, device
    ).to_sparse_bsr((bm, bk))
    dense = make_tensor(k, n, dtype=dtype, device=device)
    input = make_tensor(m, n, dtype=dtype, device=device)
    tune_bsr_dense_addmm(
        input,
        bsr,
        dense,
        beta=beta,
        alpha=alpha,
        store=True,
        force=force,
        verbose=verbose,
    )


def main(op="scatter_mm", force=False, dtype=torch.float16, verbose=True):
    import itertools

    sizes_lst = [256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536, 131072]
    shapes_lst = [(sz, sz) for sz in sizes_lst[:-3]]
    blocksize_lst = [(16, 16), (32, 32), (64, 64), (128, 128)]
    sparsity_lst = [0.5, 0.7, 0.3][:1]
    for sparsity in sparsity_lst:
        print(f"{op, dtype, sparsity=}")
        try:
            for (M, K), N, (BM, BK) in itertools.product(
                shapes_lst, sizes_lst, blocksize_lst
            ):
                if op == "scatter_mm":
                    optimize_scatter_mm(
                        M, K, N, BM, BK, force=force, sparsity=sparsity, dtype=dtype
                    )
                elif op == "bsr_dense_addmm":
                    for alpha, beta in [(1, 1), (1, 0)]:
                        optimize_bsr_dense_addmm(
                            M,
                            K,
                            N,
                            BM,
                            BK,
                            beta=beta,
                            alpha=alpha,
                            force=force,
                            sparsity=sparsity,
                            dtype=dtype,
                            verbose=verbose,
                        )
                else:
                    raise NotImplementedError(op)
        except KeyboardInterrupt:
            break
        except Exception as msg:
            dump()
            raise
    dump()

    if 0:
        for (M, K), N, (BM, BK) in itertools.product(
            shapes_lst, sizes_lst, blocksize_lst
        ):
            meta_lst: list = []
            key = (M, K, N, BM, BK)
            for sparsity1 in sparsity_lst:
                torch.manual_seed(0)
                bsr = create_blocked_tensor(
                    0, M, K, (BM, BK), sparsity1, dtype, device="cuda"
                ).to_sparse_bsr((BM, BK))
                dense = make_tensor(K, N, dtype=dtype, device="cuda")
                meta_lst = []
                for sparsity in sparsity_lst:
                    meta = get_meta(op, key, version=(0, dtype, sparsity), exact=True)
                    if meta is None:
                        continue

                    def bench(meta, bsr=bsr, dense=dense):
                        import triton

                        if op == "scatter_mm":
                            from torch.sparse._triton_ops import (
                                bsr_scatter_mm,
                                bsr_scatter_mm_indices_data,
                            )

                            indices_data = bsr_scatter_mm_indices_data(
                                bsr,
                                dense,
                                indices_format="bsr_strided_mm_compressed",
                                **meta,
                            )

                            def test_func():
                                return bsr_scatter_mm(
                                    bsr, dense, indices_data=indices_data
                                )

                        else:
                            raise NotImplementedError(op)

                        ms_min = triton.testing.do_bench(
                            test_func, warmup=500, rep=100, fast_flush=False
                        )

                        return ms_min

                    meta_lst.append(
                        (bench(meta), sparsity, tuple(meta[k] for k in sorted(meta)))
                    )
                if not meta_lst:
                    continue
                meta_lst = sorted(meta_lst)
                index = next(
                    i for i, item in enumerate(meta_lst) if item[1] == sparsity1
                )
                if meta_lst[0][2] == meta_lst[index][2]:
                    continue
                speeddiff = (1 - meta_lst[index][0] / meta_lst[0][0]) * 100
                if abs(speeddiff) < 10:
                    continue

                print(sparsity1, index, key, meta_lst, speeddiff)

                if index > 0:
                    device_name = torch.cuda.get_device_name()
                    meta = get_meta(
                        op, key, version=(0, dtype, meta_lst[0][1]), exact=True
                    )
                    update(
                        op,
                        device_name,
                        (0, dtype, sparsity1),
                        key,
                        tuple(meta[k] for k in sorted(meta)),
                    )
                    print("update")
                    dump()


_operation_device_version_data: Dict[Any, Dict] = {
    ("bsr_dense_addmm", "NVIDIA A100-SXM4-80GB", (0, torch.bfloat16, 0.5)): {
        (16, 16, 16, 16, 16, False, False, False): (2, 1, 1, 2),
        (16, 16, 16, 16, 16, False, False, True): (1, 1, 1, 4),
        (16, 16, 16, 16, 16, False, True, False): (1, 1, 3, 16),
        (16, 16, 16, 16, 16, False, True, True): (1, 1, 1, 8),
        (16, 16, 16, 16, 16, True, False, False): (2, 1, 1, 8),
        (16, 16, 16, 16, 16, True, False, True): (1, 1, 1, 8),
        (16, 16, 32, 16, 16, False, False, False): (1, 2, 1, 8),
        (16, 16, 32, 16, 16, False, False, True): (1, 2, 2, 4),
        (16, 16, 32, 16, 16, False, True, False): (1, 1, 2, 4),
        (16, 16, 32, 16, 16, False, True, True): (1, 1, 2, 4),
        (16, 16, 32, 16, 16, True, False, False): (1, 1, 2, 4),
        (16, 16, 32, 16, 16, True, False, True): (2, 2, 1, 2),
        (16, 16, 64, 16, 16, False, False, False): (1, 4, 2, 4),
        (16, 16, 64, 16, 16, False, False, True): (1, 2, 1, 2),
        (16, 16, 64, 16, 16, False, True, False): (2, 1, 1, 2),
        (16, 16, 64, 16, 16, False, True, True): (1, 4, 1, 8),
        (16, 16, 64, 16, 16, True, False, False): (1, 4, 1, 1),
        (16, 16, 64, 16, 16, True, False, True): (1, 4, 2, 4),
        (16, 32, 16, 16, 16, False, False, False): (1, 1, 2, 2),
        (16, 32, 16, 16, 16, False, False, True): (1, 1, 1, 4),
        (16, 32, 16, 16, 16, False, True, False): (1, 1, 1, 2),
        (16, 32, 16, 16, 16, False, True, True): (1, 1, 1, 1),
        (16, 32, 16, 16, 16, True, False, False): (1, 1, 1, 2),
        (16, 32, 16, 16, 16, True, False, True): (2, 1, 1, 2),
        (16, 32, 16, 16, 32, False, False, False): (1, 1, 1, 4),
        (16, 32, 16, 16, 32, False, False, True): (1, 1, 1, 8),
        (16, 32, 16, 16, 32, False, True, False): (1, 1, 1, 8),
        (16, 32, 16, 16, 32, False, True, True): (1, 1, 2, 4),
        (16, 32, 16, 16, 32, True, False, False): (1, 1, 1, 2),
        (16, 32, 16, 16, 32, True, False, True): (1, 1, 1, 1),
        (16, 32, 32, 16, 16, False, False, False): (2, 2, 1, 4),
        (16, 32, 32, 16, 16, False, False, True): (2, 2, 1, 2),
        (16, 32, 32, 16, 16, False, True, False): (1, 1, 2, 8),
        (16, 32, 32, 16, 16, False, True, True): (1, 2, 1, 1),
        (16, 32, 32, 16, 16, True, False, False): (1, 1, 1, 8),
        (16, 32, 32, 16, 16, True, False, True): (1, 2, 1, 4),
        (16, 32, 32, 16, 32, False, False, False): (1, 1, 2, 8),
        (16, 32, 32, 16, 32, False, False, True): (2, 1, 1, 8),
        (16, 32, 32, 16, 32, False, True, False): (1, 1, 1, 4),
        (16, 32, 32, 16, 32, False, True, True): (1, 1, 1, 4),
        (16, 32, 32, 16, 32, True, False, False): (1, 2, 1, 8),
        (16, 32, 32, 16, 32, True, False, True): (1, 1, 1, 4),
        (16, 32, 64, 16, 16, False, False, False): (1, 4, 3, 8),
        (16, 32, 64, 16, 16, False, False, True): (1, 4, 1, 4),
        (16, 32, 64, 16, 16, False, True, False): (1, 4, 1, 4),
        (16, 32, 64, 16, 16, False, True, True): (2, 4, 1, 4),
        (16, 32, 64, 16, 16, True, False, False): (1, 2, 1, 4),
        (16, 32, 64, 16, 16, True, False, True): (1, 2, 1, 4),
        (16, 32, 64, 16, 32, False, False, False): (1, 4, 1, 8),
        (16, 32, 64, 16, 32, False, False, True): (1, 4, 1, 4),
        (16, 32, 64, 16, 32, False, True, False): (1, 4, 1, 2),
        (16, 32, 64, 16, 32, False, True, True): (1, 2, 1, 4),
        (16, 32, 64, 16, 32, True, False, False): (1, 2, 1, 4),
        (16, 32, 64, 16, 32, True, False, True): (1, 2, 1, 2),
        (16, 64, 16, 16, 32, False, False, False): (1, 1, 1, 2),
        (16, 64, 16, 16, 32, False, False, True): (1, 1, 2, 2),
        (16, 64, 16, 16, 32, False, True, False): (1, 1, 2, 8),
        (16, 64, 16, 16, 32, False, True, True): (1, 1, 1, 4),
        (16, 64, 16, 16, 32, True, False, False): (1, 1, 1, 8),
        (16, 64, 16, 16, 32, True, False, True): (1, 1, 1, 4),
        (16, 64, 32, 16, 32, False, False, False): (1, 2, 1, 2),
        (16, 64, 32, 16, 32, False, False, True): (1, 2, 1, 4),
        (16, 64, 32, 16, 32, False, True, False): (1, 2, 1, 4),
        (16, 64, 32, 16, 32, False, True, True): (2, 2, 1, 4),
        (16, 64, 32, 16, 32, True, False, False): (1, 2, 1, 4),
        (16, 64, 32, 16, 32, True, False, True): (1, 2, 1, 8),
        (16, 64, 64, 16, 32, False, False, False): (1, 2, 1, 4),
        (16, 64, 64, 16, 32, False, False, True): (1, 4, 2, 2),
        (16, 64, 64, 16, 32, False, True, False): (1, 1, 1, 4),
        (16, 64, 64, 16, 32, False, True, True): (1, 4, 1, 2),
        (16, 64, 64, 16, 32, True, False, False): (1, 2, 1, 4),
        (16, 64, 64, 16, 32, True, False, True): (1, 4, 1, 4),
        (32, 16, 16, 16, 16, False, False, False): (1, 1, 1, 8),
        (32, 16, 16, 16, 16, False, False, True): (1, 1, 2, 4),
        (32, 16, 16, 16, 16, False, True, False): (1, 1, 1, 4),
        (32, 16, 16, 16, 16, False, True, True): (1, 1, 2, 4),
        (32, 16, 16, 16, 16, True, False, False): (1, 1, 1, 2),
        (32, 16, 16, 16, 16, True, False, True): (1, 1, 1, 4),
        (32, 16, 32, 16, 16, False, False, False): (1, 1, 1, 4),
        (32, 16, 32, 16, 16, False, False, True): (2, 2, 1, 4),
        (32, 16, 32, 16, 16, False, True, False): (1, 2, 2, 2),
        (32, 16, 32, 16, 16, False, True, True): (2, 2, 1, 4),
        (32, 16, 32, 16, 16, True, False, False): (1, 2, 2, 8),
        (32, 16, 32, 16, 16, True, False, True): (1, 2, 1, 2),
        (32, 16, 64, 16, 16, False, False, False): (1, 4, 1, 4),
        (32, 16, 64, 16, 16, False, False, True): (1, 4, 2, 4),
        (32, 16, 64, 16, 16, False, True, False): (1, 2, 2, 2),
        (32, 16, 64, 16, 16, False, True, True): (3, 4, 1, 4),
        (32, 16, 64, 16, 16, True, False, False): (1, 2, 1, 2),
        (32, 16, 64, 16, 16, True, False, True): (1, 2, 1, 4),
        (32, 32, 16, 16, 16, False, False, False): (1, 1, 3, 4),
        (32, 32, 16, 16, 16, False, False, True): (1, 1, 1, 4),
        (32, 32, 16, 16, 16, False, True, False): (1, 1, 1, 2),
        (32, 32, 16, 16, 16, False, True, True): (1, 1, 1, 4),
        (32, 32, 16, 16, 16, True, False, False): (1, 1, 1, 4),
        (32, 32, 16, 16, 16, True, False, True): (1, 1, 2, 2),
        (32, 32, 16, 16, 32, False, False, False): (2, 1, 1, 4),
        (32, 32, 16, 16, 32, False, False, True): (1, 1, 1, 4),
        (32, 32, 16, 16, 32, False, True, False): (1, 1, 1, 4),
        (32, 32, 16, 16, 32, False, True, True): (3, 1, 2, 4),
        (32, 32, 16, 16, 32, True, False, False): (1, 1, 1, 4),
        (32, 32, 16, 16, 32, True, False, True): (1, 1, 1, 4),
        (32, 32, 16, 32, 32, False, False, False): (1, 1, 1, 8),
        (32, 32, 16, 32, 32, False, False, True): (1, 1, 1, 4),
        (32, 32, 16, 32, 32, False, True, False): (1, 1, 2, 1),
        (32, 32, 16, 32, 32, False, True, True): (2, 1, 2, 2),
        (32, 32, 16, 32, 32, True, False, False): (1, 1, 1, 8),
        (32, 32, 16, 32, 32, True, False, True): (2, 1, 3, 4),
        (32, 32, 32, 16, 16, False, False, False): (1, 2, 1, 4),
        (32, 32, 32, 16, 16, False, False, True): (2, 2, 1, 4),
        (32, 32, 32, 16, 16, False, True, False): (1, 1, 1, 8),
        (32, 32, 32, 16, 16, False, True, True): (2, 2, 1, 4),
        (32, 32, 32, 16, 16, True, False, False): (1, 1, 1, 4),
        (32, 32, 32, 16, 16, True, False, True): (2, 2, 2, 4),
        (32, 32, 32, 16, 32, False, False, False): (2, 2, 1, 8),
        (32, 32, 32, 16, 32, False, False, True): (1, 2, 1, 2),
        (32, 32, 32, 16, 32, False, True, False): (1, 2, 1, 4),
        (32, 32, 32, 16, 32, False, True, True): (1, 2, 1, 4),
        (32, 32, 32, 16, 32, True, False, False): (1, 2, 1, 4),
        (32, 32, 32, 16, 32, True, False, True): (1, 2, 1, 2),
        (32, 32, 32, 32, 32, False, False, False): (1, 1, 3, 8),
        (32, 32, 32, 32, 32, False, False, True): (1, 1, 1, 8),
        (32, 32, 32, 32, 32, False, True, False): (2, 1, 3, 4),
        (32, 32, 32, 32, 32, False, True, True): (2, 1, 1, 2),
        (32, 32, 32, 32, 32, True, False, False): (1, 1, 1, 2),
        (32, 32, 32, 32, 32, True, False, True): (4, 1, 1, 1),
        (32, 32, 64, 16, 16, False, False, False): (1, 4, 1, 4),
        (32, 32, 64, 16, 16, False, False, True): (1, 4, 1, 4),
        (32, 32, 64, 16, 16, False, True, False): (1, 2, 1, 8),
        (32, 32, 64, 16, 16, False, True, True): (1, 4, 1, 2),
        (32, 32, 64, 16, 16, True, False, False): (2, 4, 1, 2),
        (32, 32, 64, 16, 16, True, False, True): (1, 4, 1, 2),
        (32, 32, 64, 16, 32, False, False, False): (1, 2, 1, 8),
        (32, 32, 64, 16, 32, False, False, True): (1, 4, 2, 2),
        (32, 32, 64, 16, 32, False, True, False): (1, 2, 1, 4),
        (32, 32, 64, 16, 32, False, True, True): (1, 4, 1, 4),
        (32, 32, 64, 16, 32, True, False, False): (1, 4, 2, 2),
        (32, 32, 64, 16, 32, True, False, True): (3, 4, 2, 2),
        (32, 32, 64, 32, 32, False, False, False): (2, 2, 1, 4),
        (32, 32, 64, 32, 32, False, False, True): (1, 2, 1, 4),
        (32, 32, 64, 32, 32, False, True, False): (1, 1, 1, 8),
        (32, 32, 64, 32, 32, False, True, True): (1, 1, 1, 4),
        (32, 32, 64, 32, 32, True, False, False): (1, 2, 1, 2),
        (32, 32, 64, 32, 32, True, False, True): (3, 2, 1, 8),
        (32, 64, 16, 16, 32, False, False, False): (1, 1, 2, 2),
        (32, 64, 16, 16, 32, False, False, True): (1, 1, 1, 4),
        (32, 64, 16, 16, 32, False, True, False): (1, 1, 2, 4),
        (32, 64, 16, 16, 32, False, True, True): (1, 1, 1, 4),
        (32, 64, 16, 16, 32, True, False, False): (1, 1, 1, 2),
        (32, 64, 16, 16, 32, True, False, True): (2, 1, 2, 2),
        (32, 64, 16, 32, 32, False, False, False): (1, 1, 1, 1),
        (32, 64, 16, 32, 32, False, False, True): (2, 1, 1, 4),
        (32, 64, 16, 32, 32, False, True, False): (1, 1, 1, 1),
        (32, 64, 16, 32, 32, False, True, True): (1, 1, 2, 2),
        (32, 64, 16, 32, 32, True, False, False): (1, 1, 2, 4),
        (32, 64, 16, 32, 32, True, False, True): (1, 1, 1, 4),
        (32, 64, 32, 16, 32, False, False, False): (2, 2, 1, 4),
        (32, 64, 32, 16, 32, False, False, True): (1, 2, 1, 4),
        (32, 64, 32, 16, 32, False, True, False): (1, 1, 1, 4),
        (32, 64, 32, 16, 32, False, True, True): (2, 2, 3, 4),
        (32, 64, 32, 16, 32, True, False, False): (1, 1, 1, 2),
        (32, 64, 32, 16, 32, True, False, True): (1, 2, 1, 2),
        (32, 64, 32, 32, 32, False, False, False): (1, 1, 1, 2),
        (32, 64, 32, 32, 32, False, False, True): (2, 1, 1, 4),
        (32, 64, 32, 32, 32, False, True, False): (1, 1, 1, 8),
        (32, 64, 32, 32, 32, False, True, True): (1, 1, 2, 4),
        (32, 64, 32, 32, 32, True, False, False): (2, 1, 1, 4),
        (32, 64, 32, 32, 32, True, False, True): (1, 1, 2, 4),
        (32, 64, 64, 16, 32, False, False, False): (1, 4, 1, 4),
        (32, 64, 64, 16, 32, False, False, True): (1, 4, 2, 4),
        (32, 64, 64, 16, 32, False, True, False): (1, 4, 2, 2),
        (32, 64, 64, 16, 32, False, True, True): (1, 4, 1, 4),
        (32, 64, 64, 16, 32, True, False, False): (1, 4, 1, 8),
        (32, 64, 64, 16, 32, True, False, True): (1, 4, 2, 1),
        (32, 64, 64, 32, 32, False, False, False): (1, 1, 1, 4),
        (32, 64, 64, 32, 32, False, False, True): (2, 2, 1, 4),
        (32, 64, 64, 32, 32, False, True, False): (1, 1, 1, 4),
        (32, 64, 64, 32, 32, False, True, True): (2, 2, 1, 4),
        (32, 64, 64, 32, 32, True, False, False): (1, 2, 2, 4),
        (32, 64, 64, 32, 32, True, False, True): (2, 2, 3, 4),
        (64, 32, 16, 32, 32, False, False, False): (1, 1, 1, 4),
        (64, 32, 16, 32, 32, False, False, True): (1, 1, 1, 4),
        (64, 32, 16, 32, 32, False, True, False): (1, 1, 1, 8),
        (64, 32, 16, 32, 32, False, True, True): (1, 1, 1, 4),
        (64, 32, 16, 32, 32, True, False, False): (1, 1, 1, 16),
        (64, 32, 16, 32, 32, True, False, True): (2, 1, 1, 4),
        (64, 32, 32, 32, 32, False, False, False): (1, 1, 3, 4),
        (64, 32, 32, 32, 32, False, False, True): (2, 1, 1, 4),
        (64, 32, 32, 32, 32, False, True, False): (1, 1, 2, 4),
        (64, 32, 32, 32, 32, False, True, True): (2, 1, 1, 4),
        (64, 32, 32, 32, 32, True, False, False): (2, 1, 1, 16),
        (64, 32, 32, 32, 32, True, False, True): (2, 1, 1, 4),
        (64, 32, 64, 32, 32, False, False, False): (1, 2, 1, 4),
        (64, 32, 64, 32, 32, False, False, True): (2, 2, 1, 4),
        (64, 32, 64, 32, 32, False, True, False): (1, 1, 1, 4),
        (64, 32, 64, 32, 32, False, True, True): (2, 2, 1, 4),
        (64, 32, 64, 32, 32, True, False, False): (1, 2, 1, 8),
        (64, 32, 64, 32, 32, True, False, True): (2, 2, 3, 4),
        (64, 64, 16, 32, 32, False, False, False): (1, 1, 2, 16),
        (64, 64, 16, 32, 32, False, False, True): (1, 1, 3, 4),
        (64, 64, 16, 32, 32, False, True, False): (1, 1, 1, 2),
        (64, 64, 16, 32, 32, False, True, True): (2, 1, 1, 4),
        (64, 64, 16, 32, 32, True, False, False): (2, 1, 3, 2),
        (64, 64, 16, 32, 32, True, False, True): (1, 1, 2, 4),
        (64, 64, 32, 32, 32, False, False, False): (1, 1, 1, 8),
        (64, 64, 32, 32, 32, False, False, True): (2, 1, 2, 4),
        (64, 64, 32, 32, 32, False, True, False): (2, 1, 1, 4),
        (64, 64, 32, 32, 32, False, True, True): (1, 1, 2, 4),
        (64, 64, 32, 32, 32, True, False, False): (2, 1, 1, 4),
        (64, 64, 32, 32, 32, True, False, True): (1, 1, 2, 4),
        (64, 64, 64, 32, 32, False, False, False): (1, 2, 2, 4),
        (64, 64, 64, 32, 32, False, False, True): (1, 2, 2, 2),
        (64, 64, 64, 32, 32, False, True, False): (1, 2, 1, 2),
        (64, 64, 64, 32, 32, False, True, True): (1, 2, 1, 4),
        (64, 64, 64, 32, 32, True, False, False): (1, 2, 1, 4),
        (64, 64, 64, 32, 32, True, False, True): (1, 2, 1, 4),
        (256, 256, 256, 16, 16, False, True, True): (4, 8, 5, 1),
        (256, 256, 256, 16, 16, True, False, True): (2, 8, 4, 2),
        (256, 256, 256, 32, 32, False, True, True): (2, 8, 5, 2),
        (256, 256, 256, 32, 32, True, False, True): (1, 8, 5, 4),
        (256, 256, 256, 64, 64, False, True, True): (2, 4, 4, 4),
        (256, 256, 256, 64, 64, True, False, True): (1, 4, 3, 4),
        (256, 256, 256, 128, 128, False, True, True): (4, 2, 2, 8),
        (256, 256, 256, 128, 128, True, False, True): (1, 2, 2, 8),
        (256, 256, 512, 16, 16, False, True, True): (1, 16, 5, 1),
        (256, 256, 512, 16, 16, True, False, True): (3, 16, 3, 2),
        (256, 256, 512, 32, 32, False, True, True): (2, 8, 5, 2),
        (256, 256, 512, 32, 32, True, False, True): (1, 16, 4, 4),
        (256, 256, 512, 64, 64, False, True, True): (1, 8, 4, 4),
        (256, 256, 512, 64, 64, True, False, True): (3, 8, 3, 4),
        (256, 256, 512, 128, 128, False, True, True): (1, 4, 2, 8),
        (256, 256, 512, 128, 128, True, False, True): (1, 4, 2, 8),
        (256, 256, 1024, 16, 16, False, True, True): (1, 16, 5, 4),
        (256, 256, 1024, 16, 16, True, False, True): (5, 16, 4, 2),
        (256, 256, 1024, 32, 32, False, True, True): (1, 32, 5, 2),
        (256, 256, 1024, 32, 32, True, False, True): (2, 16, 5, 2),
        (256, 256, 1024, 64, 64, False, True, True): (1, 16, 4, 4),
        (256, 256, 1024, 64, 64, True, False, True): (1, 16, 4, 4),
        (256, 256, 1024, 128, 128, False, True, True): (1, 8, 2, 8),
        (256, 256, 1024, 128, 128, True, False, True): (1, 8, 2, 8),
        (256, 256, 2048, 16, 16, False, True, True): (1, 16, 4, 4),
        (256, 256, 2048, 16, 16, True, False, True): (2, 32, 5, 1),
        (256, 256, 2048, 32, 32, False, True, True): (1, 64, 4, 1),
        (256, 256, 2048, 32, 32, True, False, True): (2, 32, 4, 2),
        (256, 256, 2048, 64, 64, False, True, True): (8, 16, 5, 4),
        (256, 256, 2048, 64, 64, True, False, True): (1, 16, 4, 4),
        (256, 256, 2048, 128, 128, False, True, True): (2, 16, 2, 8),
        (256, 256, 2048, 128, 128, True, False, True): (1, 16, 2, 8),
        (256, 256, 4096, 16, 16, False, True, True): (1, 64, 1, 4),
        (256, 256, 4096, 16, 16, True, False, True): (1, 16, 3, 2),
        (256, 256, 4096, 32, 32, False, True, True): (6, 32, 3, 2),
        (256, 256, 4096, 32, 32, True, False, True): (4, 32, 4, 2),
        (256, 256, 4096, 64, 64, False, True, True): (6, 64, 3, 4),
        (256, 256, 4096, 64, 64, True, False, True): (2, 64, 3, 4),
        (256, 256, 4096, 128, 128, False, True, True): (1, 32, 2, 8),
        (256, 256, 4096, 128, 128, True, False, True): (1, 32, 2, 8),
        (256, 256, 8192, 16, 16, False, True, True): (2, 32, 3, 4),
        (256, 256, 8192, 16, 16, True, False, True): (4, 64, 3, 2),
        (256, 256, 8192, 32, 32, False, True, True): (1, 64, 3, 4),
        (256, 256, 8192, 32, 32, True, False, True): (3, 128, 1, 2),
        (256, 256, 8192, 64, 64, False, True, True): (9, 128, 1, 4),
        (256, 256, 8192, 64, 64, True, False, True): (8, 128, 1, 4),
        (256, 256, 8192, 128, 128, False, True, True): (7, 64, 1, 4),
        (256, 256, 8192, 128, 128, True, False, True): (1, 32, 1, 16),
        (256, 256, 16384, 16, 16, False, True, True): (3, 128, 3, 2),
        (256, 256, 16384, 16, 16, True, False, True): (5, 64, 3, 2),
        (256, 256, 16384, 32, 32, False, True, True): (3, 128, 3, 2),
        (256, 256, 16384, 32, 32, True, False, True): (1, 128, 3, 2),
        (256, 256, 16384, 64, 64, False, True, True): (3, 128, 1, 4),
        (256, 256, 16384, 64, 64, True, False, True): (2, 128, 1, 4),
        (256, 256, 16384, 128, 128, False, True, True): (7, 128, 1, 4),
        (256, 256, 16384, 128, 128, True, False, True): (1, 128, 2, 8),
        (256, 256, 32768, 16, 16, False, True, True): (2, 128, 3, 2),
        (256, 256, 32768, 16, 16, True, False, True): (1, 128, 3, 2),
        (256, 256, 32768, 32, 32, False, True, True): (1, 256, 3, 4),
        (256, 256, 32768, 32, 32, True, False, True): (3, 256, 3, 2),
        (256, 256, 32768, 64, 64, False, True, True): (1, 256, 1, 4),
        (256, 256, 32768, 64, 64, True, False, True): (3, 256, 1, 4),
        (256, 256, 32768, 128, 128, False, True, True): (9, 256, 1, 4),
        (256, 256, 32768, 128, 128, True, False, True): (2, 256, 1, 4),
        (256, 256, 65536, 16, 16, False, True, True): (1, 256, 3, 2),
        (256, 256, 65536, 16, 16, True, False, True): (1, 256, 3, 2),
        (256, 256, 65536, 32, 32, False, True, True): (2, 512, 3, 2),
        (256, 256, 65536, 32, 32, True, False, True): (2, 512, 3, 2),
        (256, 256, 65536, 64, 64, False, True, True): (2, 512, 1, 4),
        (256, 256, 65536, 64, 64, True, False, True): (1, 512, 1, 4),
        (256, 256, 65536, 128, 128, False, True, True): (7, 512, 1, 4),
        (256, 256, 65536, 128, 128, True, False, True): (2, 512, 1, 4),
        (256, 256, 131072, 16, 16, False, True, True): (1, 512, 3, 2),
        (256, 256, 131072, 16, 16, True, False, True): (1, 512, 3, 2),
        (256, 256, 131072, 32, 32, False, True, True): (1, 1024, 3, 2),
        (256, 256, 131072, 32, 32, True, False, True): (1, 1024, 3, 2),
        (256, 256, 131072, 64, 64, False, True, True): (1, 1024, 1, 4),
        (256, 256, 131072, 64, 64, True, False, True): (1, 1024, 1, 4),
        (256, 256, 131072, 128, 128, False, True, True): (3, 1024, 1, 4),
        (256, 256, 131072, 128, 128, True, False, True): (1, 1024, 1, 4),
        (512, 512, 256, 16, 16, False, True, True): (2, 4, 5, 4),
        (512, 512, 256, 16, 16, True, False, True): (3, 4, 5, 4),
        (512, 512, 256, 32, 32, False, True, True): (1, 4, 5, 2),
        (512, 512, 256, 32, 32, True, False, True): (4, 8, 5, 1),
        (512, 512, 256, 64, 64, False, True, True): (4, 4, 5, 4),
        (512, 512, 256, 64, 64, True, False, True): (5, 4, 5, 4),
        (512, 512, 256, 128, 128, False, True, True): (3, 2, 2, 8),
        (512, 512, 256, 128, 128, True, False, True): (2, 2, 2, 8),
        (512, 512, 512, 16, 16, False, True, True): (1, 8, 5, 4),
        (512, 512, 512, 16, 16, True, False, True): (4, 8, 5, 2),
        (512, 512, 512, 32, 32, False, True, True): (1, 16, 4, 1),
        (512, 512, 512, 32, 32, True, False, True): (1, 8, 5, 2),
        (512, 512, 512, 64, 64, False, True, True): (4, 8, 5, 4),
        (512, 512, 512, 64, 64, True, False, True): (2, 8, 5, 4),
        (512, 512, 512, 128, 128, False, True, True): (2, 4, 2, 8),
        (512, 512, 512, 128, 128, True, False, True): (1, 4, 2, 8),
        (512, 512, 1024, 16, 16, False, True, True): (2, 8, 4, 4),
        (512, 512, 1024, 16, 16, True, False, True): (1, 8, 4, 4),
        (512, 512, 1024, 32, 32, False, True, True): (3, 16, 4, 2),
        (512, 512, 1024, 32, 32, True, False, True): (1, 16, 5, 2),
        (512, 512, 1024, 64, 64, False, True, True): (2, 8, 3, 4),
        (512, 512, 1024, 64, 64, True, False, True): (2, 16, 3, 4),
        (512, 512, 1024, 128, 128, False, True, True): (2, 8, 2, 8),
        (512, 512, 1024, 128, 128, True, False, True): (3, 8, 2, 8),
        (512, 512, 2048, 16, 16, False, True, True): (4, 16, 3, 2),
        (512, 512, 2048, 16, 16, True, False, True): (1, 16, 4, 2),
        (512, 512, 2048, 32, 32, False, True, True): (3, 32, 3, 2),
        (512, 512, 2048, 32, 32, True, False, True): (2, 32, 3, 2),
        (512, 512, 2048, 64, 64, False, True, True): (6, 32, 3, 2),
        (512, 512, 2048, 64, 64, True, False, True): (1, 32, 3, 2),
        (512, 512, 2048, 128, 128, False, True, True): (4, 16, 2, 8),
        (512, 512, 2048, 128, 128, True, False, True): (1, 16, 2, 8),
        (512, 512, 4096, 16, 16, False, True, True): (1, 16, 3, 2),
        (512, 512, 4096, 16, 16, True, False, True): (4, 32, 3, 2),
        (512, 512, 4096, 32, 32, False, True, True): (3, 32, 3, 2),
        (512, 512, 4096, 32, 32, True, False, True): (2, 32, 3, 2),
        (512, 512, 4096, 64, 64, False, True, True): (1, 32, 3, 4),
        (512, 512, 4096, 64, 64, True, False, True): (1, 64, 3, 4),
        (512, 512, 4096, 128, 128, False, True, True): (4, 32, 1, 4),
        (512, 512, 4096, 128, 128, True, False, True): (4, 32, 2, 8),
        (512, 512, 8192, 16, 16, False, True, True): (8, 64, 3, 2),
        (512, 512, 8192, 16, 16, True, False, True): (4, 64, 3, 2),
        (512, 512, 8192, 32, 32, False, True, True): (3, 64, 3, 2),
        (512, 512, 8192, 32, 32, True, False, True): (3, 64, 3, 2),
        (512, 512, 8192, 64, 64, False, True, True): (1, 64, 3, 4),
        (512, 512, 8192, 64, 64, True, False, True): (7, 64, 3, 4),
        (512, 512, 8192, 128, 128, False, True, True): (1, 64, 1, 4),
        (512, 512, 8192, 128, 128, True, False, True): (4, 64, 2, 8),
        (512, 512, 16384, 16, 16, False, True, True): (1, 64, 3, 2),
        (512, 512, 16384, 16, 16, True, False, True): (1, 128, 3, 2),
        (512, 512, 16384, 32, 32, False, True, True): (3, 128, 3, 2),
        (512, 512, 16384, 32, 32, True, False, True): (1, 128, 3, 2),
        (512, 512, 16384, 64, 64, False, True, True): (4, 64, 2, 4),
        (512, 512, 16384, 64, 64, True, False, True): (2, 64, 2, 4),
        (512, 512, 16384, 128, 128, False, True, True): (4, 128, 1, 4),
        (512, 512, 16384, 128, 128, True, False, True): (2, 128, 1, 4),
        (512, 512, 32768, 16, 16, False, True, True): (1, 128, 3, 2),
        (512, 512, 32768, 16, 16, True, False, True): (1, 128, 3, 2),
        (512, 512, 32768, 32, 32, False, True, True): (1, 256, 3, 2),
        (512, 512, 32768, 32, 32, True, False, True): (1, 256, 3, 2),
        (512, 512, 32768, 64, 64, False, True, True): (1, 256, 3, 4),
        (512, 512, 32768, 64, 64, True, False, True): (2, 256, 3, 4),
        (512, 512, 32768, 128, 128, False, True, True): (5, 256, 1, 4),
        (512, 512, 32768, 128, 128, True, False, True): (4, 256, 1, 4),
        (512, 512, 65536, 16, 16, False, True, True): (1, 256, 3, 2),
        (512, 512, 65536, 16, 16, True, False, True): (1, 256, 3, 1),
        (512, 512, 65536, 32, 32, False, True, True): (1, 512, 3, 2),
        (512, 512, 65536, 32, 32, True, False, True): (1, 512, 3, 2),
        (512, 512, 65536, 64, 64, False, True, True): (4, 256, 2, 4),
        (512, 512, 65536, 64, 64, True, False, True): (2, 512, 3, 4),
        (512, 512, 65536, 128, 128, False, True, True): (6, 512, 1, 4),
        (512, 512, 65536, 128, 128, True, False, True): (4, 512, 1, 4),
        (512, 512, 131072, 16, 16, False, True, True): (1, 512, 3, 2),
        (512, 512, 131072, 16, 16, True, False, True): (1, 512, 3, 1),
        (512, 512, 131072, 32, 32, False, True, True): (1, 1024, 3, 2),
        (512, 512, 131072, 32, 32, True, False, True): (1, 1024, 3, 2),
        (512, 512, 131072, 64, 64, False, True, True): (4, 512, 2, 4),
        (512, 512, 131072, 64, 64, True, False, True): (4, 1024, 3, 4),
        (512, 512, 131072, 128, 128, False, True, True): (6, 1024, 1, 4),
        (512, 512, 131072, 128, 128, True, False, True): (4, 1024, 1, 4),
        (1024, 1024, 256, 16, 16, False, True, True): (1, 4, 5, 4),
        (1024, 1024, 256, 16, 16, True, False, True): (3, 4, 4, 4),
        (1024, 1024, 256, 32, 32, False, True, True): (4, 4, 5, 2),
        (1024, 1024, 256, 32, 32, True, False, True): (3, 4, 5, 2),
        (1024, 1024, 256, 64, 64, False, True, True): (1, 4, 5, 4),
        (1024, 1024, 256, 64, 64, True, False, True): (1, 4, 5, 4),
        (1024, 1024, 256, 128, 128, False, True, True): (1, 2, 2, 8),
        (1024, 1024, 256, 128, 128, True, False, True): (2, 2, 2, 8),
        (1024, 1024, 512, 16, 16, False, True, True): (3, 4, 4, 4),
        (1024, 1024, 512, 16, 16, True, False, True): (4, 8, 5, 2),
        (1024, 1024, 512, 32, 32, False, True, True): (1, 8, 4, 2),
        (1024, 1024, 512, 32, 32, True, False, True): (1, 8, 4, 2),
        (1024, 1024, 512, 64, 64, False, True, True): (4, 8, 4, 4),
        (1024, 1024, 512, 64, 64, True, False, True): (2, 8, 3, 4),
        (1024, 1024, 512, 128, 128, False, True, True): (2, 4, 2, 8),
        (1024, 1024, 512, 128, 128, True, False, True): (1, 4, 2, 8),
        (1024, 1024, 1024, 16, 16, False, True, True): (3, 8, 4, 4),
        (1024, 1024, 1024, 16, 16, True, False, True): (4, 8, 4, 2),
        (1024, 1024, 1024, 32, 32, False, True, True): (1, 16, 3, 2),
        (1024, 1024, 1024, 32, 32, True, False, True): (1, 16, 3, 2),
        (1024, 1024, 1024, 64, 64, False, True, True): (1, 16, 3, 4),
        (1024, 1024, 1024, 64, 64, True, False, True): (3, 16, 3, 2),
        (1024, 1024, 1024, 128, 128, False, True, True): (1, 8, 2, 8),
        (1024, 1024, 1024, 128, 128, True, False, True): (2, 8, 2, 8),
        (1024, 1024, 2048, 16, 16, False, True, True): (3, 8, 3, 4),
        (1024, 1024, 2048, 16, 16, True, False, True): (3, 8, 3, 2),
        (1024, 1024, 2048, 32, 32, False, True, True): (5, 16, 3, 4),
        (1024, 1024, 2048, 32, 32, True, False, True): (1, 16, 3, 2),
        (1024, 1024, 2048, 64, 64, False, True, True): (6, 16, 4, 4),
        (1024, 1024, 2048, 64, 64, True, False, True): (5, 16, 3, 4),
        (1024, 1024, 2048, 128, 128, False, True, True): (4, 16, 2, 8),
        (1024, 1024, 2048, 128, 128, True, False, True): (4, 16, 2, 8),
        (1024, 1024, 4096, 16, 16, False, True, True): (8, 32, 3, 2),
        (1024, 1024, 4096, 16, 16, True, False, True): (4, 32, 3, 2),
        (1024, 1024, 4096, 32, 32, False, True, True): (2, 32, 3, 4),
        (1024, 1024, 4096, 32, 32, True, False, True): (3, 32, 3, 2),
        (1024, 1024, 4096, 64, 64, False, True, True): (3, 32, 3, 4),
        (1024, 1024, 4096, 64, 64, True, False, True): (1, 32, 3, 4),
        (1024, 1024, 4096, 128, 128, False, True, True): (4, 32, 2, 8),
        (1024, 1024, 4096, 128, 128, True, False, True): (1, 32, 2, 8),
        (1024, 1024, 8192, 16, 16, False, True, True): (4, 64, 3, 2),
        (1024, 1024, 8192, 16, 16, True, False, True): (4, 64, 3, 2),
        (1024, 1024, 8192, 32, 32, False, True, True): (8, 64, 3, 4),
        (1024, 1024, 8192, 32, 32, True, False, True): (4, 32, 3, 4),
        (1024, 1024, 8192, 64, 64, False, True, True): (4, 64, 3, 4),
        (1024, 1024, 8192, 64, 64, True, False, True): (2, 64, 3, 4),
        (1024, 1024, 8192, 128, 128, False, True, True): (4, 64, 2, 8),
        (1024, 1024, 8192, 128, 128, True, False, True): (4, 64, 1, 4),
        (1024, 1024, 16384, 16, 16, False, True, True): (1, 64, 3, 2),
        (1024, 1024, 16384, 16, 16, True, False, True): (1, 64, 3, 2),
        (1024, 1024, 16384, 32, 32, False, True, True): (1, 128, 3, 2),
        (1024, 1024, 16384, 32, 32, True, False, True): (1, 64, 3, 4),
        (1024, 1024, 16384, 64, 64, False, True, True): (1, 128, 3, 4),
        (1024, 1024, 16384, 64, 64, True, False, True): (1, 128, 3, 4),
        (1024, 1024, 16384, 128, 128, False, True, True): (2, 128, 1, 4),
        (1024, 1024, 16384, 128, 128, True, False, True): (4, 128, 1, 4),
        (1024, 1024, 32768, 16, 16, False, True, True): (1, 128, 3, 2),
        (1024, 1024, 32768, 16, 16, True, False, True): (1, 128, 3, 2),
        (1024, 1024, 32768, 32, 32, False, True, True): (1, 256, 3, 2),
        (1024, 1024, 32768, 32, 32, True, False, True): (1, 128, 3, 4),
        (1024, 1024, 32768, 64, 64, False, True, True): (2, 128, 2, 4),
        (1024, 1024, 32768, 64, 64, True, False, True): (1, 256, 3, 4),
        (1024, 1024, 32768, 128, 128, False, True, True): (2, 256, 1, 4),
        (1024, 1024, 32768, 128, 128, True, False, True): (4, 256, 1, 4),
        (1024, 1024, 65536, 16, 16, False, True, True): (1, 256, 3, 4),
        (1024, 1024, 65536, 16, 16, True, False, True): (1, 256, 3, 4),
        (1024, 1024, 65536, 32, 32, False, True, True): (9, 256, 3, 4),
        (1024, 1024, 65536, 32, 32, True, False, True): (7, 256, 3, 4),
        (1024, 1024, 65536, 64, 64, False, True, True): (2, 256, 2, 4),
        (1024, 1024, 65536, 64, 64, True, False, True): (2, 512, 3, 4),
        (1024, 1024, 65536, 128, 128, False, True, True): (2, 512, 1, 4),
        (1024, 1024, 65536, 128, 128, True, False, True): (4, 512, 1, 4),
        (1024, 1024, 131072, 16, 16, False, True, True): (11, 512, 3, 2),
        (1024, 1024, 131072, 16, 16, True, False, True): (11, 512, 3, 2),
        (1024, 1024, 131072, 32, 32, False, True, True): (4, 512, 3, 4),
        (1024, 1024, 131072, 32, 32, True, False, True): (6, 512, 3, 4),
        (1024, 1024, 131072, 64, 64, False, True, True): (2, 512, 2, 4),
        (1024, 1024, 131072, 64, 64, True, False, True): (2, 1024, 3, 4),
        (1024, 1024, 131072, 128, 128, False, True, True): (4, 1024, 1, 4),
        (1024, 1024, 131072, 128, 128, True, False, True): (4, 1024, 1, 4),
        (2048, 2048, 256, 16, 16, False, True, True): (1, 4, 5, 2),
        (2048, 2048, 256, 16, 16, True, False, True): (4, 4, 5, 2),
        (2048, 2048, 256, 32, 32, False, True, True): (3, 4, 6, 2),
        (2048, 2048, 256, 32, 32, True, False, True): (2, 4, 5, 2),
        (2048, 2048, 256, 64, 64, False, True, True): (2, 4, 4, 4),
        (2048, 2048, 256, 64, 64, True, False, True): (2, 4, 3, 4),
        (2048, 2048, 256, 128, 128, False, True, True): (3, 2, 2, 8),
        (2048, 2048, 256, 128, 128, True, False, True): (3, 2, 2, 8),
        (2048, 2048, 512, 16, 16, False, True, True): (3, 4, 4, 4),
        (2048, 2048, 512, 16, 16, True, False, True): (1, 4, 4, 4),
        (2048, 2048, 512, 32, 32, False, True, True): (1, 4, 3, 4),
        (2048, 2048, 512, 32, 32, True, False, True): (1, 4, 4, 2),
        (2048, 2048, 512, 64, 64, False, True, True): (1, 8, 3, 4),
        (2048, 2048, 512, 64, 64, True, False, True): (1, 8, 3, 4),
        (2048, 2048, 512, 128, 128, False, True, True): (3, 4, 2, 8),
        (2048, 2048, 512, 128, 128, True, False, True): (2, 4, 2, 8),
        (2048, 2048, 1024, 16, 16, False, True, True): (3, 4, 3, 4),
        (2048, 2048, 1024, 16, 16, True, False, True): (4, 8, 3, 2),
        (2048, 2048, 1024, 32, 32, False, True, True): (3, 8, 3, 4),
        (2048, 2048, 1024, 32, 32, True, False, True): (1, 8, 3, 2),
        (2048, 2048, 1024, 64, 64, False, True, True): (1, 8, 3, 4),
        (2048, 2048, 1024, 64, 64, True, False, True): (1, 8, 3, 4),
        (2048, 2048, 1024, 128, 128, False, True, True): (4, 8, 1, 4),
        (2048, 2048, 1024, 128, 128, True, False, True): (2, 8, 1, 4),
        (2048, 2048, 2048, 16, 16, False, True, True): (4, 16, 3, 2),
        (2048, 2048, 2048, 16, 16, True, False, True): (4, 16, 3, 2),
        (2048, 2048, 2048, 32, 32, False, True, True): (1, 16, 3, 2),
        (2048, 2048, 2048, 32, 32, True, False, True): (1, 16, 3, 2),
        (2048, 2048, 2048, 64, 64, False, True, True): (4, 16, 3, 4),
        (2048, 2048, 2048, 64, 64, True, False, True): (4, 16, 3, 4),
        (2048, 2048, 2048, 128, 128, False, True, True): (6, 16, 2, 8),
        (2048, 2048, 2048, 128, 128, True, False, True): (3, 16, 1, 4),
        (2048, 2048, 4096, 16, 16, False, True, True): (4, 32, 4, 2),
        (2048, 2048, 4096, 16, 16, True, False, True): (4, 32, 3, 2),
        (2048, 2048, 4096, 32, 32, False, True, True): (4, 16, 3, 8),
        (2048, 2048, 4096, 32, 32, True, False, True): (4, 16, 3, 8),
        (2048, 2048, 4096, 64, 64, False, True, True): (1, 32, 3, 4),
        (2048, 2048, 4096, 64, 64, True, False, True): (3, 32, 3, 4),
        (2048, 2048, 4096, 128, 128, False, True, True): (2, 32, 1, 4),
        (2048, 2048, 4096, 128, 128, True, False, True): (2, 32, 1, 4),
        (2048, 2048, 8192, 16, 16, False, True, True): (4, 64, 4, 2),
        (2048, 2048, 8192, 16, 16, True, False, True): (4, 64, 4, 2),
        (2048, 2048, 8192, 32, 32, False, True, True): (4, 32, 4, 8),
        (2048, 2048, 8192, 32, 32, True, False, True): (4, 32, 3, 8),
        (2048, 2048, 8192, 64, 64, False, True, True): (4, 64, 3, 4),
        (2048, 2048, 8192, 64, 64, True, False, True): (4, 64, 3, 4),
        (2048, 2048, 8192, 128, 128, False, True, True): (2, 64, 1, 4),
        (2048, 2048, 8192, 128, 128, True, False, True): (2, 64, 1, 4),
        (2048, 2048, 16384, 16, 16, False, True, True): (4, 64, 3, 2),
        (2048, 2048, 16384, 16, 16, True, False, True): (1, 64, 3, 2),
        (2048, 2048, 16384, 32, 32, False, True, True): (4, 64, 3, 4),
        (2048, 2048, 16384, 32, 32, True, False, True): (4, 64, 3, 4),
        (2048, 2048, 16384, 64, 64, False, True, True): (4, 128, 3, 4),
        (2048, 2048, 16384, 64, 64, True, False, True): (4, 128, 3, 4),
        (2048, 2048, 16384, 128, 128, False, True, True): (2, 128, 1, 4),
        (2048, 2048, 16384, 128, 128, True, False, True): (2, 128, 1, 4),
        (2048, 2048, 32768, 16, 16, False, True, True): (8, 128, 3, 2),
        (2048, 2048, 32768, 16, 16, True, False, True): (8, 128, 3, 4),
        (2048, 2048, 32768, 32, 32, False, True, True): (8, 128, 3, 4),
        (2048, 2048, 32768, 32, 32, True, False, True): (8, 128, 3, 4),
        (2048, 2048, 32768, 64, 64, False, True, True): (1, 128, 2, 4),
        (2048, 2048, 32768, 64, 64, True, False, True): (8, 256, 3, 4),
        (2048, 2048, 32768, 128, 128, False, True, True): (2, 256, 1, 4),
        (2048, 2048, 32768, 128, 128, True, False, True): (2, 256, 1, 4),
        (2048, 2048, 65536, 16, 16, False, True, True): (9, 256, 4, 4),
        (2048, 2048, 65536, 16, 16, True, False, True): (7, 256, 4, 4),
        (2048, 2048, 65536, 32, 32, False, True, True): (7, 256, 3, 4),
        (2048, 2048, 65536, 32, 32, True, False, True): (3, 256, 3, 4),
        (2048, 2048, 65536, 64, 64, False, True, True): (2, 256, 2, 4),
        (2048, 2048, 65536, 64, 64, True, False, True): (6, 512, 3, 4),
        (2048, 2048, 65536, 128, 128, False, True, True): (2, 512, 1, 4),
        (2048, 2048, 65536, 128, 128, True, False, True): (2, 512, 1, 4),
        (2048, 2048, 131072, 16, 16, False, True, True): (9, 512, 4, 4),
        (2048, 2048, 131072, 16, 16, True, False, True): (9, 512, 4, 4),
        (2048, 2048, 131072, 32, 32, False, True, True): (7, 512, 4, 4),
        (2048, 2048, 131072, 32, 32, True, False, True): (3, 512, 3, 4),
        (2048, 2048, 131072, 64, 64, False, True, True): (2, 512, 2, 4),
        (2048, 2048, 131072, 64, 64, True, False, True): (4, 1024, 3, 4),
        (2048, 2048, 131072, 128, 128, False, True, True): (1, 1024, 1, 4),
        (2048, 2048, 131072, 128, 128, True, False, True): (2, 1024, 1, 4),
        (4096, 4096, 256, 16, 16, False, True, True): (2, 2, 5, 4),
        (4096, 4096, 256, 16, 16, True, False, True): (2, 2, 4, 2),
        (4096, 4096, 256, 32, 32, False, True, True): (1, 2, 4, 4),
        (4096, 4096, 256, 32, 32, True, False, True): (3, 2, 4, 2),
        (4096, 4096, 256, 64, 64, False, True, True): (3, 4, 3, 4),
        (4096, 4096, 256, 64, 64, True, False, True): (1, 4, 3, 2),
        (4096, 4096, 256, 128, 128, False, True, True): (1, 2, 2, 8),
        (4096, 4096, 256, 128, 128, True, False, True): (1, 2, 2, 8),
        (4096, 4096, 512, 16, 16, False, True, True): (4, 2, 3, 4),
        (4096, 4096, 512, 16, 16, True, False, True): (1, 2, 3, 4),
        (4096, 4096, 512, 32, 32, False, True, True): (1, 4, 3, 4),
        (4096, 4096, 512, 32, 32, True, False, True): (3, 4, 3, 2),
        (4096, 4096, 512, 64, 64, False, True, True): (4, 4, 4, 4),
        (4096, 4096, 512, 64, 64, True, False, True): (3, 4, 3, 4),
        (4096, 4096, 512, 128, 128, False, True, True): (2, 4, 2, 8),
        (4096, 4096, 512, 128, 128, True, False, True): (2, 4, 1, 4),
        (4096, 4096, 1024, 16, 16, False, True, True): (2, 8, 3, 2),
        (4096, 4096, 1024, 16, 16, True, False, True): (2, 8, 3, 2),
        (4096, 4096, 1024, 32, 32, False, True, True): (1, 8, 3, 4),
        (4096, 4096, 1024, 32, 32, True, False, True): (1, 8, 3, 2),
        (4096, 4096, 1024, 64, 64, False, True, True): (1, 8, 3, 4),
        (4096, 4096, 1024, 64, 64, True, False, True): (1, 8, 3, 4),
        (4096, 4096, 1024, 128, 128, False, True, True): (4, 8, 1, 4),
        (4096, 4096, 1024, 128, 128, True, False, True): (2, 8, 2, 8),
        (4096, 4096, 2048, 16, 16, False, True, True): (2, 8, 4, 4),
        (4096, 4096, 2048, 16, 16, True, False, True): (2, 8, 4, 4),
        (4096, 4096, 2048, 32, 32, False, True, True): (4, 8, 3, 8),
        (4096, 4096, 2048, 32, 32, True, False, True): (4, 8, 4, 8),
        (4096, 4096, 2048, 64, 64, False, True, True): (4, 16, 3, 4),
        (4096, 4096, 2048, 64, 64, True, False, True): (4, 16, 3, 4),
        (4096, 4096, 2048, 128, 128, False, True, True): (1, 16, 1, 4),
        (4096, 4096, 2048, 128, 128, True, False, True): (4, 16, 1, 4),
        (4096, 4096, 4096, 16, 16, False, True, True): (4, 32, 4, 4),
        (4096, 4096, 4096, 16, 16, True, False, True): (2, 32, 4, 4),
        (4096, 4096, 4096, 32, 32, False, True, True): (4, 16, 4, 8),
        (4096, 4096, 4096, 32, 32, True, False, True): (4, 16, 4, 8),
        (4096, 4096, 4096, 64, 64, False, True, True): (4, 32, 3, 4),
        (4096, 4096, 4096, 64, 64, True, False, True): (2, 32, 3, 4),
        (4096, 4096, 4096, 128, 128, False, True, True): (2, 32, 1, 4),
        (4096, 4096, 4096, 128, 128, True, False, True): (2, 32, 1, 4),
        (4096, 4096, 8192, 16, 16, False, True, True): (4, 64, 4, 2),
        (4096, 4096, 8192, 16, 16, True, False, True): (4, 64, 4, 2),
        (4096, 4096, 8192, 32, 32, False, True, True): (4, 32, 4, 8),
        (4096, 4096, 8192, 32, 32, True, False, True): (4, 32, 4, 8),
        (4096, 4096, 8192, 64, 64, False, True, True): (4, 64, 3, 4),
        (4096, 4096, 8192, 64, 64, True, False, True): (4, 64, 3, 4),
        (4096, 4096, 8192, 128, 128, False, True, True): (1, 64, 1, 4),
        (4096, 4096, 8192, 128, 128, True, False, True): (1, 64, 1, 4),
        (4096, 4096, 16384, 16, 16, False, True, True): (4, 64, 4, 4),
        (4096, 4096, 16384, 16, 16, True, False, True): (4, 64, 4, 4),
        (4096, 4096, 16384, 32, 32, False, True, True): (4, 64, 4, 8),
        (4096, 4096, 16384, 32, 32, True, False, True): (4, 64, 4, 8),
        (4096, 4096, 16384, 64, 64, False, True, True): (4, 128, 3, 4),
        (4096, 4096, 16384, 64, 64, True, False, True): (4, 128, 3, 4),
        (4096, 4096, 16384, 128, 128, False, True, True): (1, 128, 1, 4),
        (4096, 4096, 16384, 128, 128, True, False, True): (1, 128, 1, 4),
        (4096, 4096, 32768, 16, 16, False, True, True): (8, 128, 4, 4),
        (4096, 4096, 32768, 16, 16, True, False, True): (5, 128, 4, 4),
        (4096, 4096, 32768, 32, 32, False, True, True): (5, 128, 4, 4),
        (4096, 4096, 32768, 32, 32, True, False, True): (3, 128, 4, 8),
        (4096, 4096, 32768, 64, 64, False, True, True): (3, 256, 3, 4),
        (4096, 4096, 32768, 64, 64, True, False, True): (2, 256, 3, 4),
        (4096, 4096, 32768, 128, 128, False, True, True): (1, 256, 1, 4),
        (4096, 4096, 32768, 128, 128, True, False, True): (1, 256, 1, 4),
        (4096, 4096, 65536, 16, 16, False, True, True): (5, 256, 4, 4),
        (4096, 4096, 65536, 16, 16, True, False, True): (5, 256, 4, 4),
        (4096, 4096, 65536, 32, 32, False, True, True): (4, 256, 4, 8),
        (4096, 4096, 65536, 32, 32, True, False, True): (4, 256, 4, 8),
        (4096, 4096, 65536, 64, 64, False, True, True): (1, 512, 3, 4),
        (4096, 4096, 65536, 64, 64, True, False, True): (3, 512, 3, 4),
        (4096, 4096, 65536, 128, 128, False, True, True): (1, 512, 1, 4),
        (4096, 4096, 65536, 128, 128, True, False, True): (1, 512, 1, 4),
        (4096, 4096, 131072, 16, 16, False, True, True): (5, 512, 4, 4),
        (4096, 4096, 131072, 16, 16, True, False, True): (5, 512, 4, 4),
        (4096, 4096, 131072, 32, 32, False, True, True): (4, 512, 4, 4),
        (4096, 4096, 131072, 32, 32, True, False, True): (2, 512, 3, 4),
        (4096, 4096, 131072, 64, 64, False, True, True): (1, 1024, 3, 4),
        (4096, 4096, 131072, 64, 64, True, False, True): (3, 1024, 3, 4),
        (4096, 4096, 131072, 128, 128, False, True, True): (1, 1024, 1, 4),
        (4096, 4096, 131072, 128, 128, True, False, True): (1, 1024, 1, 4),
        (8192, 8192, 256, 16, 16, False, True, True): (1, 1, 3, 4),
        (8192, 8192, 256, 16, 16, True, False, True): (4, 1, 3, 4),
        (8192, 8192, 256, 32, 32, False, True, True): (1, 2, 3, 4),
        (8192, 8192, 256, 32, 32, True, False, True): (1, 2, 3, 4),
        (8192, 8192, 256, 64, 64, False, True, True): (6, 2, 3, 8),
        (8192, 8192, 256, 64, 64, True, False, True): (4, 2, 3, 8),
        (8192, 8192, 256, 128, 128, False, True, True): (1, 2, 1, 4),
        (8192, 8192, 256, 128, 128, True, False, True): (1, 2, 1, 4),
        (8192, 8192, 512, 16, 16, False, True, True): (4, 4, 3, 2),
        (8192, 8192, 512, 16, 16, True, False, True): (4, 4, 3, 4),
        (8192, 8192, 512, 32, 32, False, True, True): (1, 4, 3, 4),
        (8192, 8192, 512, 32, 32, True, False, True): (3, 4, 3, 2),
        (8192, 8192, 512, 64, 64, False, True, True): (1, 4, 3, 4),
        (8192, 8192, 512, 64, 64, True, False, True): (1, 4, 3, 4),
        (8192, 8192, 512, 128, 128, False, True, True): (4, 4, 2, 8),
        (8192, 8192, 512, 128, 128, True, False, True): (4, 4, 2, 8),
        (8192, 8192, 1024, 16, 16, False, True, True): (4, 8, 4, 4),
        (8192, 8192, 1024, 16, 16, True, False, True): (2, 8, 4, 4),
        (8192, 8192, 1024, 32, 32, False, True, True): (2, 4, 4, 8),
        (8192, 8192, 1024, 32, 32, True, False, True): (1, 4, 3, 4),
        (8192, 8192, 1024, 64, 64, False, True, True): (4, 8, 3, 4),
        (8192, 8192, 1024, 64, 64, True, False, True): (2, 8, 3, 4),
        (8192, 8192, 1024, 128, 128, False, True, True): (4, 8, 1, 4),
        (8192, 8192, 1024, 128, 128, True, False, True): (4, 8, 1, 4),
        (8192, 8192, 2048, 16, 16, False, True, True): (2, 8, 4, 4),
        (8192, 8192, 2048, 16, 16, True, False, True): (2, 8, 4, 4),
        (8192, 8192, 2048, 32, 32, False, True, True): (2, 8, 4, 8),
        (8192, 8192, 2048, 32, 32, True, False, True): (2, 8, 4, 8),
        (8192, 8192, 2048, 64, 64, False, True, True): (4, 8, 2, 4),
        (8192, 8192, 2048, 64, 64, True, False, True): (4, 16, 3, 4),
        (8192, 8192, 2048, 128, 128, False, True, True): (4, 16, 1, 4),
        (8192, 8192, 2048, 128, 128, True, False, True): (4, 16, 1, 4),
        (8192, 8192, 4096, 16, 16, False, True, True): (4, 16, 4, 4),
        (8192, 8192, 4096, 16, 16, True, False, True): (4, 32, 4, 2),
        (8192, 8192, 4096, 32, 32, False, True, True): (2, 16, 4, 8),
        (8192, 8192, 4096, 32, 32, True, False, True): (2, 16, 4, 8),
        (8192, 8192, 4096, 64, 64, False, True, True): (4, 32, 3, 4),
        (8192, 8192, 4096, 64, 64, True, False, True): (4, 16, 2, 4),
        (8192, 8192, 4096, 128, 128, False, True, True): (4, 32, 1, 4),
        (8192, 8192, 4096, 128, 128, True, False, True): (4, 32, 1, 4),
        (8192, 8192, 8192, 16, 16, False, True, True): (4, 64, 4, 2),
        (8192, 8192, 8192, 16, 16, True, False, True): (4, 64, 4, 2),
        (8192, 8192, 8192, 32, 32, False, True, True): (2, 32, 4, 8),
        (8192, 8192, 8192, 32, 32, True, False, True): (2, 32, 4, 8),
        (8192, 8192, 8192, 64, 64, False, True, True): (4, 32, 3, 8),
        (8192, 8192, 8192, 64, 64, True, False, True): (4, 32, 2, 4),
        (8192, 8192, 8192, 128, 128, False, True, True): (4, 64, 1, 4),
        (8192, 8192, 8192, 128, 128, True, False, True): (4, 64, 1, 4),
        (8192, 8192, 16384, 16, 16, False, True, True): (4, 64, 4, 4),
        (8192, 8192, 16384, 16, 16, True, False, True): (4, 64, 4, 4),
        (8192, 8192, 16384, 32, 32, False, True, True): (4, 64, 3, 4),
        (8192, 8192, 16384, 32, 32, True, False, True): (4, 64, 4, 8),
        (8192, 8192, 16384, 64, 64, False, True, True): (4, 64, 2, 4),
        (8192, 8192, 16384, 64, 64, True, False, True): (4, 64, 2, 4),
        (8192, 8192, 16384, 128, 128, False, True, True): (4, 128, 1, 4),
        (8192, 8192, 16384, 128, 128, True, False, True): (4, 128, 1, 4),
        (8192, 8192, 32768, 16, 16, False, True, True): (3, 128, 4, 4),
        (8192, 8192, 32768, 16, 16, True, False, True): (3, 128, 4, 4),
        (8192, 8192, 32768, 32, 32, False, True, True): (2, 128, 4, 8),
        (8192, 8192, 32768, 32, 32, True, False, True): (2, 128, 4, 8),
        (8192, 8192, 32768, 64, 64, False, True, True): (2, 128, 2, 4),
        (8192, 8192, 32768, 64, 64, True, False, True): (2, 128, 2, 4),
        (8192, 8192, 32768, 128, 128, False, True, True): (4, 256, 1, 4),
        (8192, 8192, 32768, 128, 128, True, False, True): (4, 256, 1, 4),
        (8192, 8192, 65536, 16, 16, False, True, True): (3, 256, 4, 4),
        (8192, 8192, 65536, 16, 16, True, False, True): (3, 256, 4, 4),
        (8192, 8192, 65536, 32, 32, False, True, True): (2, 256, 3, 4),
        (8192, 8192, 65536, 32, 32, True, False, True): (2, 256, 3, 4),
        (8192, 8192, 65536, 64, 64, False, True, True): (2, 256, 2, 4),
        (8192, 8192, 65536, 64, 64, True, False, True): (2, 256, 3, 8),
        (8192, 8192, 65536, 128, 128, False, True, True): (4, 512, 1, 4),
        (8192, 8192, 65536, 128, 128, True, False, True): (4, 512, 1, 4),
        (8192, 8192, 131072, 16, 16, False, True, True): (3, 512, 4, 4),
        (8192, 8192, 131072, 16, 16, True, False, True): (3, 512, 4, 4),
        (8192, 8192, 131072, 32, 32, False, True, True): (2, 512, 4, 4),
        (8192, 8192, 131072, 32, 32, True, False, True): (2, 512, 3, 4),
        (8192, 8192, 131072, 64, 64, False, True, True): (4, 512, 2, 4),
        (8192, 8192, 131072, 64, 64, True, False, True): (2, 512, 2, 4),
        (8192, 8192, 131072, 128, 128, False, True, True): (4, 1024, 1, 4),
        (8192, 8192, 131072, 128, 128, True, False, True): (4, 1024, 1, 4),
        (16384, 16384, 256, 16, 16, False, True, True): (2, 2, 6, 4),
        (16384, 16384, 256, 16, 16, True, False, True): (2, 2, 6, 4),
        (16384, 16384, 256, 32, 32, False, True, True): (4, 2, 3, 2),
        (16384, 16384, 256, 32, 32, True, False, True): (4, 2, 3, 2),
        (16384, 16384, 256, 64, 64, False, True, True): (2, 2, 4, 4),
        (16384, 16384, 256, 64, 64, True, False, True): (4, 2, 3, 8),
        (16384, 16384, 256, 128, 128, False, True, True): (4, 2, 2, 8),
        (16384, 16384, 256, 128, 128, True, False, True): (4, 2, 2, 8),
        (16384, 16384, 512, 16, 16, False, True, True): (1, 2, 4, 4),
        (16384, 16384, 512, 16, 16, True, False, True): (1, 2, 4, 4),
        (16384, 16384, 512, 32, 32, False, True, True): (2, 2, 4, 8),
        (16384, 16384, 512, 32, 32, True, False, True): (2, 2, 4, 8),
        (16384, 16384, 512, 64, 64, False, True, True): (4, 4, 3, 4),
        (16384, 16384, 512, 64, 64, True, False, True): (4, 4, 3, 4),
        (16384, 16384, 512, 128, 128, False, True, True): (4, 4, 2, 8),
        (16384, 16384, 512, 128, 128, True, False, True): (4, 4, 2, 8),
        (16384, 16384, 1024, 16, 16, False, True, True): (3, 4, 4, 4),
        (16384, 16384, 1024, 16, 16, True, False, True): (2, 8, 4, 4),
        (16384, 16384, 1024, 32, 32, False, True, True): (2, 4, 4, 8),
        (16384, 16384, 1024, 32, 32, True, False, True): (1, 4, 4, 8),
        (16384, 16384, 1024, 64, 64, False, True, True): (2, 8, 3, 4),
        (16384, 16384, 1024, 64, 64, True, False, True): (2, 8, 3, 4),
        (16384, 16384, 1024, 128, 128, False, True, True): (4, 8, 1, 4),
        (16384, 16384, 1024, 128, 128, True, False, True): (4, 8, 1, 4),
        (16384, 16384, 2048, 16, 16, False, True, True): (2, 8, 4, 4),
        (16384, 16384, 2048, 16, 16, True, False, True): (2, 8, 4, 4),
        (16384, 16384, 2048, 32, 32, False, True, True): (1, 8, 4, 8),
        (16384, 16384, 2048, 32, 32, True, False, True): (2, 8, 4, 8),
        (16384, 16384, 2048, 64, 64, False, True, True): (2, 8, 2, 4),
        (16384, 16384, 2048, 64, 64, True, False, True): (2, 8, 2, 4),
        (16384, 16384, 2048, 128, 128, False, True, True): (4, 16, 1, 4),
        (16384, 16384, 2048, 128, 128, True, False, True): (4, 16, 1, 4),
        (16384, 16384, 4096, 16, 16, False, True, True): (2, 16, 4, 4),
        (16384, 16384, 4096, 16, 16, True, False, True): (2, 16, 4, 4),
        (16384, 16384, 4096, 32, 32, False, True, True): (1, 8, 3, 8),
        (16384, 16384, 4096, 32, 32, True, False, True): (2, 16, 3, 4),
        (16384, 16384, 4096, 64, 64, False, True, True): (2, 16, 2, 4),
        (16384, 16384, 4096, 64, 64, True, False, True): (2, 16, 2, 4),
        (16384, 16384, 4096, 128, 128, False, True, True): (4, 32, 1, 4),
        (16384, 16384, 4096, 128, 128, True, False, True): (4, 32, 1, 4),
        (16384, 16384, 8192, 16, 16, False, True, True): (4, 64, 4, 2),
        (16384, 16384, 8192, 16, 16, True, False, True): (4, 64, 4, 2),
        (16384, 16384, 8192, 32, 32, False, True, True): (2, 32, 4, 8),
        (16384, 16384, 8192, 32, 32, True, False, True): (2, 32, 3, 4),
        (16384, 16384, 8192, 64, 64, False, True, True): (2, 32, 4, 8),
        (16384, 16384, 8192, 64, 64, True, False, True): (2, 32, 3, 8),
        (16384, 16384, 8192, 128, 128, False, True, True): (4, 64, 1, 4),
        (16384, 16384, 8192, 128, 128, True, False, True): (4, 64, 1, 4),
        (16384, 16384, 16384, 16, 16, False, True, True): (1, 64, 4, 4),
        (16384, 16384, 16384, 16, 16, True, False, True): (1, 64, 4, 4),
        (16384, 16384, 16384, 32, 32, False, True, True): (1, 64, 3, 8),
        (16384, 16384, 16384, 32, 32, True, False, True): (1, 64, 3, 4),
        (16384, 16384, 16384, 64, 64, False, True, True): (1, 64, 2, 4),
        (16384, 16384, 16384, 64, 64, True, False, True): (1, 64, 4, 8),
        (16384, 16384, 16384, 128, 128, False, True, True): (4, 128, 1, 4),
        (16384, 16384, 16384, 128, 128, True, False, True): (4, 128, 1, 4),
        (16384, 16384, 32768, 16, 16, False, True, True): (1, 128, 4, 4),
        (16384, 16384, 32768, 16, 16, True, False, True): (1, 128, 4, 4),
        (16384, 16384, 32768, 32, 32, False, True, True): (1, 128, 4, 2),
        (16384, 16384, 32768, 32, 32, True, False, True): (1, 128, 3, 8),
        (16384, 16384, 32768, 64, 64, False, True, True): (2, 128, 2, 4),
        (16384, 16384, 32768, 64, 64, True, False, True): (1, 128, 3, 8),
        (16384, 16384, 32768, 128, 128, False, True, True): (4, 256, 1, 4),
        (16384, 16384, 32768, 128, 128, True, False, True): (4, 256, 1, 4),
        (16384, 16384, 65536, 16, 16, False, True, True): (1, 256, 4, 4),
        (16384, 16384, 65536, 16, 16, True, False, True): (1, 256, 4, 4),
        (16384, 16384, 65536, 32, 32, False, True, True): (1, 256, 3, 4),
        (16384, 16384, 65536, 32, 32, True, False, True): (1, 256, 3, 4),
        (16384, 16384, 65536, 64, 64, False, True, True): (1, 256, 2, 4),
        (16384, 16384, 65536, 64, 64, True, False, True): (2, 256, 2, 4),
        (16384, 16384, 65536, 128, 128, False, True, True): (4, 512, 1, 4),
        (16384, 16384, 65536, 128, 128, True, False, True): (4, 512, 1, 4),
        (16384, 16384, 131072, 16, 16, False, True, True): (2, 512, 4, 4),
        (16384, 16384, 131072, 16, 16, True, False, True): (1, 512, 4, 4),
        (16384, 16384, 131072, 32, 32, False, True, True): (1, 512, 4, 8),
        (16384, 16384, 131072, 32, 32, True, False, True): (1, 512, 3, 4),
        (16384, 16384, 131072, 64, 64, False, True, True): (2, 512, 2, 4),
        (16384, 16384, 131072, 64, 64, True, False, True): (1, 512, 2, 4),
        (16384, 16384, 131072, 128, 128, False, True, True): (4, 1024, 1, 4),
        (16384, 16384, 131072, 128, 128, True, False, True): (4, 1024, 1, 4),
    },
    ("bsr_dense_addmm", "NVIDIA A100-SXM4-80GB", (0, torch.float16, 0.5)): {
        (16, 16, 16, 16, 16, False, False, False): (1, 1, 1, 1),
        (16, 16, 16, 16, 16, False, False, True): (1, 1, 2, 2),
        (16, 16, 16, 16, 16, False, True, False): (1, 1, 1, 1),
        (16, 16, 16, 16, 16, False, True, True): (1, 1, 1, 8),
        (16, 16, 16, 16, 16, True, False, False): (3, 1, 3, 4),
        (16, 16, 16, 16, 16, True, False, True): (1, 1, 2, 1),
        (16, 16, 32, 16, 16, False, False, False): (1, 2, 1, 8),
        (16, 16, 32, 16, 16, False, False, True): (1, 2, 1, 2),
        (16, 16, 32, 16, 16, False, True, False): (2, 1, 1, 4),
        (16, 16, 32, 16, 16, False, True, True): (1, 2, 1, 4),
        (16, 16, 32, 16, 16, True, False, False): (1, 1, 1, 4),
        (16, 16, 32, 16, 16, True, False, True): (1, 2, 1, 2),
        (16, 16, 64, 16, 16, False, False, False): (1, 4, 1, 1),
        (16, 16, 64, 16, 16, False, False, True): (1, 2, 2, 4),
        (16, 16, 64, 16, 16, False, True, False): (1, 4, 1, 4),
        (16, 16, 64, 16, 16, False, True, True): (1, 2, 1, 4),
        (16, 16, 64, 16, 16, True, False, False): (1, 4, 1, 2),
        (16, 16, 64, 16, 16, True, False, True): (1, 1, 1, 2),
        (16, 32, 16, 16, 16, False, False, False): (1, 1, 2, 4),
        (16, 32, 16, 16, 16, False, False, True): (1, 1, 1, 4),
        (16, 32, 16, 16, 16, False, True, False): (1, 1, 1, 2),
        (16, 32, 16, 16, 16, False, True, True): (1, 1, 1, 2),
        (16, 32, 16, 16, 16, True, False, False): (1, 1, 2, 16),
        (16, 32, 16, 16, 16, True, False, True): (1, 1, 1, 4),
        (16, 32, 16, 16, 32, False, False, False): (2, 1, 1, 8),
        (16, 32, 16, 16, 32, False, False, True): (2, 1, 1, 8),
        (16, 32, 16, 16, 32, False, True, False): (1, 1, 2, 1),
        (16, 32, 16, 16, 32, False, True, True): (1, 1, 1, 4),
        (16, 32, 16, 16, 32, True, False, False): (2, 1, 1, 8),
        (16, 32, 16, 16, 32, True, False, True): (1, 1, 2, 4),
        (16, 32, 32, 16, 16, False, False, False): (1, 1, 1, 16),
        (16, 32, 32, 16, 16, False, False, True): (1, 2, 1, 2),
        (16, 32, 32, 16, 16, False, True, False): (1, 2, 1, 8),
        (16, 32, 32, 16, 16, False, True, True): (3, 2, 1, 4),
        (16, 32, 32, 16, 16, True, False, False): (1, 2, 1, 4),
        (16, 32, 32, 16, 16, True, False, True): (1, 2, 1, 2),
        (16, 32, 32, 16, 32, False, False, False): (1, 2, 1, 2),
        (16, 32, 32, 16, 32, False, False, True): (1, 1, 1, 4),
        (16, 32, 32, 16, 32, False, True, False): (1, 1, 2, 4),
        (16, 32, 32, 16, 32, False, True, True): (1, 2, 1, 2),
        (16, 32, 32, 16, 32, True, False, False): (1, 2, 1, 2),
        (16, 32, 32, 16, 32, True, False, True): (1, 2, 1, 16),
        (16, 32, 64, 16, 16, False, False, False): (1, 4, 1, 4),
        (16, 32, 64, 16, 16, False, False, True): (2, 4, 1, 4),
        (16, 32, 64, 16, 16, False, True, False): (1, 4, 1, 4),
        (16, 32, 64, 16, 16, False, True, True): (1, 4, 1, 4),
        (16, 32, 64, 16, 16, True, False, False): (3, 4, 1, 2),
        (16, 32, 64, 16, 16, True, False, True): (1, 4, 1, 1),
        (16, 32, 64, 16, 32, False, False, False): (1, 4, 1, 16),
        (16, 32, 64, 16, 32, False, False, True): (1, 2, 1, 2),
        (16, 32, 64, 16, 32, False, True, False): (1, 4, 2, 2),
        (16, 32, 64, 16, 32, False, True, True): (1, 4, 1, 8),
        (16, 32, 64, 16, 32, True, False, False): (1, 4, 1, 8),
        (16, 32, 64, 16, 32, True, False, True): (1, 2, 1, 4),
        (16, 64, 16, 16, 32, False, False, False): (1, 1, 1, 2),
        (16, 64, 16, 16, 32, False, False, True): (1, 1, 1, 4),
        (16, 64, 16, 16, 32, False, True, False): (2, 1, 2, 4),
        (16, 64, 16, 16, 32, False, True, True): (1, 1, 1, 4),
        (16, 64, 16, 16, 32, True, False, False): (1, 1, 1, 4),
        (16, 64, 16, 16, 32, True, False, True): (1, 1, 1, 4),
        (16, 64, 32, 16, 32, False, False, False): (1, 2, 1, 2),
        (16, 64, 32, 16, 32, False, False, True): (1, 1, 1, 4),
        (16, 64, 32, 16, 32, False, True, False): (1, 1, 1, 4),
        (16, 64, 32, 16, 32, False, True, True): (1, 2, 3, 2),
        (16, 64, 32, 16, 32, True, False, False): (1, 1, 1, 4),
        (16, 64, 32, 16, 32, True, False, True): (1, 1, 2, 4),
        (16, 64, 64, 16, 32, False, False, False): (1, 4, 1, 8),
        (16, 64, 64, 16, 32, False, False, True): (1, 4, 1, 4),
        (16, 64, 64, 16, 32, False, True, False): (1, 4, 1, 1),
        (16, 64, 64, 16, 32, False, True, True): (2, 4, 1, 4),
        (16, 64, 64, 16, 32, True, False, False): (1, 4, 1, 4),
        (16, 64, 64, 16, 32, True, False, True): (1, 4, 1, 4),
        (32, 16, 16, 16, 16, False, False, False): (2, 1, 2, 4),
        (32, 16, 16, 16, 16, False, False, True): (2, 1, 1, 2),
        (32, 16, 16, 16, 16, False, True, False): (1, 1, 2, 4),
        (32, 16, 16, 16, 16, False, True, True): (1, 1, 1, 2),
        (32, 16, 16, 16, 16, True, False, False): (1, 1, 1, 4),
        (32, 16, 16, 16, 16, True, False, True): (2, 1, 1, 2),
        (32, 16, 32, 16, 16, False, False, False): (1, 1, 1, 4),
        (32, 16, 32, 16, 16, False, False, True): (1, 1, 1, 4),
        (32, 16, 32, 16, 16, False, True, False): (1, 2, 1, 4),
        (32, 16, 32, 16, 16, False, True, True): (2, 2, 1, 4),
        (32, 16, 32, 16, 16, True, False, False): (2, 1, 1, 4),
        (32, 16, 32, 16, 16, True, False, True): (2, 2, 1, 2),
        (32, 16, 64, 16, 16, False, False, False): (1, 4, 1, 2),
        (32, 16, 64, 16, 16, False, False, True): (1, 4, 1, 4),
        (32, 16, 64, 16, 16, False, True, False): (1, 2, 1, 4),
        (32, 16, 64, 16, 16, False, True, True): (1, 4, 1, 2),
        (32, 16, 64, 16, 16, True, False, False): (1, 4, 2, 8),
        (32, 16, 64, 16, 16, True, False, True): (1, 4, 1, 1),
        (32, 32, 16, 16, 16, False, False, False): (1, 1, 1, 4),
        (32, 32, 16, 16, 16, False, False, True): (2, 1, 1, 4),
        (32, 32, 16, 16, 16, False, True, False): (1, 1, 2, 4),
        (32, 32, 16, 16, 16, False, True, True): (1, 1, 2, 2),
        (32, 32, 16, 16, 16, True, False, False): (1, 1, 1, 8),
        (32, 32, 16, 16, 16, True, False, True): (1, 1, 1, 4),
        (32, 32, 16, 16, 32, False, False, False): (1, 1, 3, 2),
        (32, 32, 16, 16, 32, False, False, True): (2, 1, 1, 4),
        (32, 32, 16, 16, 32, False, True, False): (3, 1, 1, 4),
        (32, 32, 16, 16, 32, False, True, True): (1, 1, 1, 4),
        (32, 32, 16, 16, 32, True, False, False): (2, 1, 1, 8),
        (32, 32, 16, 16, 32, True, False, True): (1, 1, 3, 2),
        (32, 32, 16, 32, 32, False, False, False): (1, 1, 1, 2),
        (32, 32, 16, 32, 32, False, False, True): (2, 1, 1, 8),
        (32, 32, 16, 32, 32, False, True, False): (1, 1, 1, 2),
        (32, 32, 16, 32, 32, False, True, True): (1, 1, 1, 8),
        (32, 32, 16, 32, 32, True, False, False): (1, 1, 2, 4),
        (32, 32, 16, 32, 32, True, False, True): (1, 1, 1, 2),
        (32, 32, 32, 16, 16, False, False, False): (1, 1, 1, 4),
        (32, 32, 32, 16, 16, False, False, True): (1, 2, 1, 4),
        (32, 32, 32, 16, 16, False, True, False): (1, 2, 1, 4),
        (32, 32, 32, 16, 16, False, True, True): (1, 2, 1, 2),
        (32, 32, 32, 16, 16, True, False, False): (1, 2, 1, 4),
        (32, 32, 32, 16, 16, True, False, True): (1, 2, 1, 4),
        (32, 32, 32, 16, 32, False, False, False): (1, 2, 1, 4),
        (32, 32, 32, 16, 32, False, False, True): (1, 2, 1, 2),
        (32, 32, 32, 16, 32, False, True, False): (1, 2, 1, 4),
        (32, 32, 32, 16, 32, False, True, True): (1, 2, 1, 2),
        (32, 32, 32, 16, 32, True, False, False): (1, 2, 1, 1),
        (32, 32, 32, 16, 32, True, False, True): (1, 2, 1, 2),
        (32, 32, 32, 32, 32, False, False, False): (1, 1, 1, 4),
        (32, 32, 32, 32, 32, False, False, True): (2, 1, 1, 4),
        (32, 32, 32, 32, 32, False, True, False): (1, 1, 1, 8),
        (32, 32, 32, 32, 32, False, True, True): (1, 1, 1, 8),
        (32, 32, 32, 32, 32, True, False, False): (1, 1, 3, 4),
        (32, 32, 32, 32, 32, True, False, True): (1, 1, 1, 8),
        (32, 32, 64, 16, 16, False, False, False): (1, 4, 1, 4),
        (32, 32, 64, 16, 16, False, False, True): (1, 4, 1, 2),
        (32, 32, 64, 16, 16, False, True, False): (1, 1, 1, 4),
        (32, 32, 64, 16, 16, False, True, True): (1, 4, 1, 4),
        (32, 32, 64, 16, 16, True, False, False): (1, 4, 1, 8),
        (32, 32, 64, 16, 16, True, False, True): (1, 4, 1, 2),
        (32, 32, 64, 16, 32, False, False, False): (1, 1, 1, 4),
        (32, 32, 64, 16, 32, False, False, True): (1, 4, 1, 4),
        (32, 32, 64, 16, 32, False, True, False): (1, 1, 1, 4),
        (32, 32, 64, 16, 32, False, True, True): (1, 4, 1, 4),
        (32, 32, 64, 16, 32, True, False, False): (2, 2, 1, 8),
        (32, 32, 64, 16, 32, True, False, True): (1, 2, 1, 2),
        (32, 32, 64, 32, 32, False, False, False): (1, 2, 1, 4),
        (32, 32, 64, 32, 32, False, False, True): (1, 2, 1, 1),
        (32, 32, 64, 32, 32, False, True, False): (1, 2, 2, 8),
        (32, 32, 64, 32, 32, False, True, True): (1, 1, 1, 4),
        (32, 32, 64, 32, 32, True, False, False): (1, 2, 1, 4),
        (32, 32, 64, 32, 32, True, False, True): (2, 2, 1, 4),
        (32, 64, 16, 16, 32, False, False, False): (1, 1, 1, 8),
        (32, 64, 16, 16, 32, False, False, True): (1, 1, 1, 4),
        (32, 64, 16, 16, 32, False, True, False): (2, 1, 1, 4),
        (32, 64, 16, 16, 32, False, True, True): (1, 1, 1, 4),
        (32, 64, 16, 16, 32, True, False, False): (1, 1, 2, 4),
        (32, 64, 16, 16, 32, True, False, True): (1, 1, 2, 2),
        (32, 64, 16, 32, 32, False, False, False): (1, 1, 1, 8),
        (32, 64, 16, 32, 32, False, False, True): (2, 1, 1, 4),
        (32, 64, 16, 32, 32, False, True, False): (1, 1, 1, 4),
        (32, 64, 16, 32, 32, False, True, True): (1, 1, 2, 2),
        (32, 64, 16, 32, 32, True, False, False): (1, 1, 1, 2),
        (32, 64, 16, 32, 32, True, False, True): (2, 1, 2, 4),
        (32, 64, 32, 16, 32, False, False, False): (1, 1, 1, 4),
        (32, 64, 32, 16, 32, False, False, True): (1, 2, 1, 2),
        (32, 64, 32, 16, 32, False, True, False): (1, 2, 3, 4),
        (32, 64, 32, 16, 32, False, True, True): (2, 2, 1, 4),
        (32, 64, 32, 16, 32, True, False, False): (1, 1, 1, 4),
        (32, 64, 32, 16, 32, True, False, True): (1, 2, 2, 1),
        (32, 64, 32, 32, 32, False, False, False): (1, 1, 1, 8),
        (32, 64, 32, 32, 32, False, False, True): (1, 1, 1, 4),
        (32, 64, 32, 32, 32, False, True, False): (1, 1, 2, 4),
        (32, 64, 32, 32, 32, False, True, True): (1, 1, 1, 4),
        (32, 64, 32, 32, 32, True, False, False): (2, 1, 1, 2),
        (32, 64, 32, 32, 32, True, False, True): (1, 1, 1, 4),
        (32, 64, 64, 16, 32, False, False, False): (1, 4, 2, 1),
        (32, 64, 64, 16, 32, False, False, True): (3, 4, 1, 4),
        (32, 64, 64, 16, 32, False, True, False): (1, 1, 1, 8),
        (32, 64, 64, 16, 32, False, True, True): (1, 4, 1, 4),
        (32, 64, 64, 16, 32, True, False, False): (1, 4, 1, 4),
        (32, 64, 64, 16, 32, True, False, True): (2, 2, 3, 4),
        (32, 64, 64, 32, 32, False, False, False): (1, 2, 1, 4),
        (32, 64, 64, 32, 32, False, False, True): (1, 2, 1, 4),
        (32, 64, 64, 32, 32, False, True, False): (1, 2, 2, 8),
        (32, 64, 64, 32, 32, False, True, True): (1, 2, 1, 4),
        (32, 64, 64, 32, 32, True, False, False): (1, 2, 2, 4),
        (32, 64, 64, 32, 32, True, False, True): (1, 2, 1, 4),
        (64, 32, 16, 32, 32, False, False, False): (1, 1, 1, 1),
        (64, 32, 16, 32, 32, False, False, True): (1, 1, 2, 4),
        (64, 32, 16, 32, 32, False, True, False): (2, 1, 1, 8),
        (64, 32, 16, 32, 32, False, True, True): (1, 1, 1, 4),
        (64, 32, 16, 32, 32, True, False, False): (2, 1, 1, 2),
        (64, 32, 16, 32, 32, True, False, True): (1, 1, 1, 4),
        (64, 32, 32, 32, 32, False, False, False): (3, 1, 1, 4),
        (64, 32, 32, 32, 32, False, False, True): (1, 1, 1, 4),
        (64, 32, 32, 32, 32, False, True, False): (1, 1, 1, 8),
        (64, 32, 32, 32, 32, False, True, True): (1, 1, 1, 2),
        (64, 32, 32, 32, 32, True, False, False): (1, 1, 1, 2),
        (64, 32, 32, 32, 32, True, False, True): (1, 1, 1, 4),
        (64, 32, 64, 32, 32, False, False, False): (1, 2, 1, 2),
        (64, 32, 64, 32, 32, False, False, True): (3, 2, 1, 4),
        (64, 32, 64, 32, 32, False, True, False): (1, 1, 1, 1),
        (64, 32, 64, 32, 32, False, True, True): (1, 2, 1, 4),
        (64, 32, 64, 32, 32, True, False, False): (1, 1, 3, 4),
        (64, 32, 64, 32, 32, True, False, True): (1, 2, 2, 4),
        (64, 64, 16, 32, 32, False, False, False): (1, 1, 2, 2),
        (64, 64, 16, 32, 32, False, False, True): (1, 1, 3, 2),
        (64, 64, 16, 32, 32, False, True, False): (1, 1, 1, 8),
        (64, 64, 16, 32, 32, False, True, True): (1, 1, 2, 4),
        (64, 64, 16, 32, 32, True, False, False): (1, 1, 2, 4),
        (64, 64, 16, 32, 32, True, False, True): (2, 1, 2, 4),
        (64, 64, 32, 32, 32, False, False, False): (1, 1, 2, 8),
        (64, 64, 32, 32, 32, False, False, True): (1, 1, 2, 4),
        (64, 64, 32, 32, 32, False, True, False): (1, 1, 1, 4),
        (64, 64, 32, 32, 32, False, True, True): (1, 1, 1, 4),
        (64, 64, 32, 32, 32, True, False, False): (1, 1, 1, 4),
        (64, 64, 32, 32, 32, True, False, True): (2, 1, 2, 4),
        (64, 64, 64, 32, 32, False, False, False): (1, 2, 1, 4),
        (64, 64, 64, 32, 32, False, False, True): (1, 2, 1, 4),
        (64, 64, 64, 32, 32, False, True, False): (1, 2, 1, 4),
        (64, 64, 64, 32, 32, False, True, True): (3, 2, 1, 4),
        (64, 64, 64, 32, 32, True, False, False): (1, 2, 1, 8),
        (64, 64, 64, 32, 32, True, False, True): (1, 2, 3, 4),
        (256, 256, 256, 16, 16, False, True, True): (4, 8, 6, 2),
        (256, 256, 256, 16, 16, True, False, True): (5, 16, 5, 1),
        (256, 256, 256, 32, 32, False, True, True): (1, 8, 7, 4),
        (256, 256, 256, 32, 32, True, False, True): (1, 8, 5, 4),
        (256, 256, 256, 64, 64, False, True, True): (1, 4, 5, 4),
        (256, 256, 256, 64, 64, True, False, True): (2, 4, 3, 4),
        (256, 256, 256, 128, 128, False, True, True): (1, 2, 2, 8),
        (256, 256, 256, 128, 128, True, False, True): (1, 2, 2, 8),
        (256, 256, 512, 16, 16, False, True, True): (4, 8, 4, 4),
        (256, 256, 512, 16, 16, True, False, True): (4, 8, 6, 2),
        (256, 256, 512, 32, 32, False, True, True): (3, 8, 5, 4),
        (256, 256, 512, 32, 32, True, False, True): (2, 8, 5, 4),
        (256, 256, 512, 64, 64, False, True, True): (2, 8, 4, 4),
        (256, 256, 512, 64, 64, True, False, True): (1, 8, 7, 4),
        (256, 256, 512, 128, 128, False, True, True): (2, 4, 2, 8),
        (256, 256, 512, 128, 128, True, False, True): (5, 4, 2, 8),
        (256, 256, 1024, 16, 16, False, True, True): (1, 8, 4, 4),
        (256, 256, 1024, 16, 16, True, False, True): (1, 16, 4, 2),
        (256, 256, 1024, 32, 32, False, True, True): (5, 32, 5, 1),
        (256, 256, 1024, 32, 32, True, False, True): (1, 16, 4, 2),
        (256, 256, 1024, 64, 64, False, True, True): (1, 16, 4, 4),
        (256, 256, 1024, 64, 64, True, False, True): (2, 16, 3, 4),
        (256, 256, 1024, 128, 128, False, True, True): (9, 8, 2, 8),
        (256, 256, 1024, 128, 128, True, False, True): (1, 8, 2, 8),
        (256, 256, 2048, 16, 16, False, True, True): (6, 32, 5, 2),
        (256, 256, 2048, 16, 16, True, False, True): (2, 32, 4, 2),
        (256, 256, 2048, 32, 32, False, True, True): (1, 32, 3, 2),
        (256, 256, 2048, 32, 32, True, False, True): (1, 32, 3, 2),
        (256, 256, 2048, 64, 64, False, True, True): (2, 32, 4, 4),
        (256, 256, 2048, 64, 64, True, False, True): (2, 16, 4, 4),
        (256, 256, 2048, 128, 128, False, True, True): (3, 16, 2, 8),
        (256, 256, 2048, 128, 128, True, False, True): (4, 16, 2, 8),
        (256, 256, 4096, 16, 16, False, True, True): (1, 32, 3, 4),
        (256, 256, 4096, 16, 16, True, False, True): (3, 16, 3, 2),
        (256, 256, 4096, 32, 32, False, True, True): (3, 32, 3, 2),
        (256, 256, 4096, 32, 32, True, False, True): (1, 32, 3, 2),
        (256, 256, 4096, 64, 64, False, True, True): (2, 32, 3, 4),
        (256, 256, 4096, 64, 64, True, False, True): (2, 32, 3, 4),
        (256, 256, 4096, 128, 128, False, True, True): (5, 32, 2, 8),
        (256, 256, 4096, 128, 128, True, False, True): (1, 32, 2, 8),
        (256, 256, 8192, 16, 16, False, True, True): (8, 32, 3, 4),
        (256, 256, 8192, 16, 16, True, False, True): (1, 32, 3, 2),
        (256, 256, 8192, 32, 32, False, True, True): (3, 64, 3, 4),
        (256, 256, 8192, 32, 32, True, False, True): (2, 128, 1, 2),
        (256, 256, 8192, 64, 64, False, True, True): (7, 128, 1, 4),
        (256, 256, 8192, 64, 64, True, False, True): (4, 128, 1, 4),
        (256, 256, 8192, 128, 128, False, True, True): (2, 64, 1, 4),
        (256, 256, 8192, 128, 128, True, False, True): (4, 64, 1, 4),
        (256, 256, 16384, 16, 16, False, True, True): (4, 128, 3, 2),
        (256, 256, 16384, 16, 16, True, False, True): (5, 64, 3, 2),
        (256, 256, 16384, 32, 32, False, True, True): (5, 128, 3, 2),
        (256, 256, 16384, 32, 32, True, False, True): (5, 128, 3, 2),
        (256, 256, 16384, 64, 64, False, True, True): (1, 256, 1, 4),
        (256, 256, 16384, 64, 64, True, False, True): (5, 128, 3, 4),
        (256, 256, 16384, 128, 128, False, True, True): (11, 128, 2, 8),
        (256, 256, 16384, 128, 128, True, False, True): (3, 128, 1, 4),
        (256, 256, 32768, 16, 16, False, True, True): (1, 128, 3, 4),
        (256, 256, 32768, 16, 16, True, False, True): (2, 128, 3, 2),
        (256, 256, 32768, 32, 32, False, True, True): (4, 256, 3, 2),
        (256, 256, 32768, 32, 32, True, False, True): (1, 256, 3, 2),
        (256, 256, 32768, 64, 64, False, True, True): (2, 256, 1, 4),
        (256, 256, 32768, 64, 64, True, False, True): (2, 256, 1, 4),
        (256, 256, 32768, 128, 128, False, True, True): (3, 256, 1, 4),
        (256, 256, 32768, 128, 128, True, False, True): (2, 256, 1, 4),
        (256, 256, 65536, 16, 16, False, True, True): (1, 256, 3, 2),
        (256, 256, 65536, 16, 16, True, False, True): (1, 256, 3, 2),
        (256, 256, 65536, 32, 32, False, True, True): (1, 512, 3, 2),
        (256, 256, 65536, 32, 32, True, False, True): (4, 512, 3, 2),
        (256, 256, 65536, 64, 64, False, True, True): (2, 512, 1, 4),
        (256, 256, 65536, 64, 64, True, False, True): (5, 512, 1, 4),
        (256, 256, 65536, 128, 128, False, True, True): (3, 512, 1, 4),
        (256, 256, 65536, 128, 128, True, False, True): (1, 512, 1, 4),
        (256, 256, 131072, 16, 16, False, True, True): (1, 512, 3, 1),
        (256, 256, 131072, 16, 16, True, False, True): (1, 512, 3, 2),
        (256, 256, 131072, 32, 32, False, True, True): (2, 1024, 3, 2),
        (256, 256, 131072, 32, 32, True, False, True): (1, 1024, 3, 2),
        (256, 256, 131072, 64, 64, False, True, True): (1, 1024, 1, 4),
        (256, 256, 131072, 64, 64, True, False, True): (1, 1024, 1, 4),
        (256, 256, 131072, 128, 128, False, True, True): (7, 1024, 1, 4),
        (256, 256, 131072, 128, 128, True, False, True): (1, 1024, 1, 4),
        (512, 512, 256, 16, 16, False, True, True): (1, 8, 5, 1),
        (512, 512, 256, 16, 16, True, False, True): (2, 16, 5, 1),
        (512, 512, 256, 32, 32, False, True, True): (2, 8, 5, 2),
        (512, 512, 256, 32, 32, True, False, True): (4, 4, 5, 2),
        (512, 512, 256, 64, 64, False, True, True): (1, 4, 5, 4),
        (512, 512, 256, 64, 64, True, False, True): (3, 4, 5, 4),
        (512, 512, 256, 128, 128, False, True, True): (1, 2, 2, 8),
        (512, 512, 256, 128, 128, True, False, True): (1, 2, 2, 8),
        (512, 512, 512, 16, 16, False, True, True): (1, 8, 4, 4),
        (512, 512, 512, 16, 16, True, False, True): (4, 16, 5, 1),
        (512, 512, 512, 32, 32, False, True, True): (4, 8, 5, 2),
        (512, 512, 512, 32, 32, True, False, True): (7, 16, 4, 1),
        (512, 512, 512, 64, 64, False, True, True): (3, 8, 5, 4),
        (512, 512, 512, 64, 64, True, False, True): (1, 8, 4, 4),
        (512, 512, 512, 128, 128, False, True, True): (4, 4, 2, 8),
        (512, 512, 512, 128, 128, True, False, True): (4, 4, 2, 8),
        (512, 512, 1024, 16, 16, False, True, True): (2, 8, 4, 4),
        (512, 512, 1024, 16, 16, True, False, True): (2, 16, 4, 2),
        (512, 512, 1024, 32, 32, False, True, True): (3, 16, 4, 2),
        (512, 512, 1024, 32, 32, True, False, True): (3, 16, 3, 2),
        (512, 512, 1024, 64, 64, False, True, True): (5, 8, 5, 4),
        (512, 512, 1024, 64, 64, True, False, True): (4, 16, 3, 4),
        (512, 512, 1024, 128, 128, False, True, True): (6, 8, 2, 8),
        (512, 512, 1024, 128, 128, True, False, True): (4, 8, 2, 8),
        (512, 512, 2048, 16, 16, False, True, True): (2, 16, 3, 4),
        (512, 512, 2048, 16, 16, True, False, True): (1, 16, 4, 2),
        (512, 512, 2048, 32, 32, False, True, True): (2, 32, 3, 2),
        (512, 512, 2048, 32, 32, True, False, True): (2, 32, 3, 2),
        (512, 512, 2048, 64, 64, False, True, True): (1, 32, 3, 4),
        (512, 512, 2048, 64, 64, True, False, True): (1, 32, 3, 2),
        (512, 512, 2048, 128, 128, False, True, True): (3, 16, 2, 8),
        (512, 512, 2048, 128, 128, True, False, True): (1, 16, 2, 8),
        (512, 512, 4096, 16, 16, False, True, True): (4, 32, 3, 2),
        (512, 512, 4096, 16, 16, True, False, True): (1, 32, 3, 2),
        (512, 512, 4096, 32, 32, False, True, True): (3, 32, 3, 2),
        (512, 512, 4096, 32, 32, True, False, True): (3, 32, 3, 2),
        (512, 512, 4096, 64, 64, False, True, True): (1, 32, 3, 4),
        (512, 512, 4096, 64, 64, True, False, True): (1, 64, 1, 4),
        (512, 512, 4096, 128, 128, False, True, True): (7, 32, 2, 8),
        (512, 512, 4096, 128, 128, True, False, True): (1, 32, 2, 8),
        (512, 512, 8192, 16, 16, False, True, True): (4, 64, 3, 2),
        (512, 512, 8192, 16, 16, True, False, True): (1, 64, 3, 2),
        (512, 512, 8192, 32, 32, False, True, True): (3, 64, 3, 2),
        (512, 512, 8192, 32, 32, True, False, True): (1, 64, 3, 2),
        (512, 512, 8192, 64, 64, False, True, True): (1, 64, 3, 4),
        (512, 512, 8192, 64, 64, True, False, True): (1, 64, 3, 4),
        (512, 512, 8192, 128, 128, False, True, True): (7, 64, 2, 8),
        (512, 512, 8192, 128, 128, True, False, True): (1, 64, 1, 4),
        (512, 512, 16384, 16, 16, False, True, True): (1, 128, 3, 2),
        (512, 512, 16384, 16, 16, True, False, True): (1, 64, 3, 2),
        (512, 512, 16384, 32, 32, False, True, True): (1, 128, 3, 2),
        (512, 512, 16384, 32, 32, True, False, True): (1, 128, 3, 2),
        (512, 512, 16384, 64, 64, False, True, True): (1, 128, 3, 4),
        (512, 512, 16384, 64, 64, True, False, True): (4, 128, 3, 4),
        (512, 512, 16384, 128, 128, False, True, True): (5, 128, 2, 8),
        (512, 512, 16384, 128, 128, True, False, True): (2, 128, 1, 4),
        (512, 512, 32768, 16, 16, False, True, True): (1, 128, 3, 4),
        (512, 512, 32768, 16, 16, True, False, True): (1, 128, 3, 2),
        (512, 512, 32768, 32, 32, False, True, True): (1, 256, 3, 2),
        (512, 512, 32768, 32, 32, True, False, True): (1, 256, 3, 2),
        (512, 512, 32768, 64, 64, False, True, True): (1, 256, 3, 4),
        (512, 512, 32768, 64, 64, True, False, True): (1, 256, 3, 4),
        (512, 512, 32768, 128, 128, False, True, True): (5, 256, 1, 4),
        (512, 512, 32768, 128, 128, True, False, True): (1, 256, 1, 4),
        (512, 512, 65536, 16, 16, False, True, True): (1, 256, 3, 2),
        (512, 512, 65536, 16, 16, True, False, True): (1, 256, 3, 1),
        (512, 512, 65536, 32, 32, False, True, True): (1, 512, 3, 2),
        (512, 512, 65536, 32, 32, True, False, True): (1, 512, 3, 2),
        (512, 512, 65536, 64, 64, False, True, True): (2, 256, 2, 4),
        (512, 512, 65536, 64, 64, True, False, True): (1, 512, 3, 4),
        (512, 512, 65536, 128, 128, False, True, True): (7, 512, 1, 4),
        (512, 512, 65536, 128, 128, True, False, True): (5, 512, 1, 4),
        (512, 512, 131072, 16, 16, False, True, True): (1, 512, 3, 1),
        (512, 512, 131072, 16, 16, True, False, True): (1, 512, 3, 1),
        (512, 512, 131072, 32, 32, False, True, True): (1, 1024, 3, 2),
        (512, 512, 131072, 32, 32, True, False, True): (1, 1024, 3, 2),
        (512, 512, 131072, 64, 64, False, True, True): (4, 512, 2, 4),
        (512, 512, 131072, 64, 64, True, False, True): (2, 512, 2, 4),
        (512, 512, 131072, 128, 128, False, True, True): (5, 1024, 1, 4),
        (512, 512, 131072, 128, 128, True, False, True): (4, 1024, 1, 4),
        (1024, 1024, 256, 16, 16, False, True, True): (3, 4, 5, 4),
        (1024, 1024, 256, 16, 16, True, False, True): (3, 4, 5, 4),
        (1024, 1024, 256, 32, 32, False, True, True): (2, 4, 6, 2),
        (1024, 1024, 256, 32, 32, True, False, True): (2, 4, 6, 2),
        (1024, 1024, 256, 64, 64, False, True, True): (1, 4, 4, 4),
        (1024, 1024, 256, 64, 64, True, False, True): (2, 4, 6, 4),
        (1024, 1024, 256, 128, 128, False, True, True): (1, 2, 2, 8),
        (1024, 1024, 256, 128, 128, True, False, True): (1, 2, 2, 8),
        (1024, 1024, 512, 16, 16, False, True, True): (3, 4, 5, 4),
        (1024, 1024, 512, 16, 16, True, False, True): (3, 8, 4, 2),
        (1024, 1024, 512, 32, 32, False, True, True): (1, 8, 4, 2),
        (1024, 1024, 512, 32, 32, True, False, True): (1, 8, 4, 2),
        (1024, 1024, 512, 64, 64, False, True, True): (2, 8, 3, 4),
        (1024, 1024, 512, 64, 64, True, False, True): (1, 4, 4, 4),
        (1024, 1024, 512, 128, 128, False, True, True): (7, 4, 2, 8),
        (1024, 1024, 512, 128, 128, True, False, True): (1, 4, 2, 8),
        (1024, 1024, 1024, 16, 16, False, True, True): (4, 8, 4, 2),
        (1024, 1024, 1024, 16, 16, True, False, True): (3, 8, 5, 2),
        (1024, 1024, 1024, 32, 32, False, True, True): (1, 8, 4, 4),
        (1024, 1024, 1024, 32, 32, True, False, True): (1, 8, 4, 2),
        (1024, 1024, 1024, 64, 64, False, True, True): (1, 16, 3, 4),
        (1024, 1024, 1024, 64, 64, True, False, True): (3, 16, 3, 4),
        (1024, 1024, 1024, 128, 128, False, True, True): (6, 8, 2, 8),
        (1024, 1024, 1024, 128, 128, True, False, True): (4, 8, 2, 8),
        (1024, 1024, 2048, 16, 16, False, True, True): (3, 8, 3, 4),
        (1024, 1024, 2048, 16, 16, True, False, True): (3, 8, 3, 4),
        (1024, 1024, 2048, 32, 32, False, True, True): (1, 16, 3, 4),
        (1024, 1024, 2048, 32, 32, True, False, True): (1, 16, 3, 2),
        (1024, 1024, 2048, 64, 64, False, True, True): (5, 16, 3, 4),
        (1024, 1024, 2048, 64, 64, True, False, True): (5, 16, 3, 4),
        (1024, 1024, 2048, 128, 128, False, True, True): (3, 16, 2, 8),
        (1024, 1024, 2048, 128, 128, True, False, True): (4, 16, 2, 16),
        (1024, 1024, 4096, 16, 16, False, True, True): (4, 32, 3, 2),
        (1024, 1024, 4096, 16, 16, True, False, True): (8, 32, 3, 2),
        (1024, 1024, 4096, 32, 32, False, True, True): (9, 32, 3, 2),
        (1024, 1024, 4096, 32, 32, True, False, True): (1, 32, 3, 2),
        (1024, 1024, 4096, 64, 64, False, True, True): (6, 32, 3, 4),
        (1024, 1024, 4096, 64, 64, True, False, True): (1, 32, 3, 4),
        (1024, 1024, 4096, 128, 128, False, True, True): (4, 32, 2, 8),
        (1024, 1024, 4096, 128, 128, True, False, True): (4, 32, 1, 4),
        (1024, 1024, 8192, 16, 16, False, True, True): (4, 64, 3, 2),
        (1024, 1024, 8192, 16, 16, True, False, True): (4, 64, 3, 2),
        (1024, 1024, 8192, 32, 32, False, True, True): (8, 64, 3, 2),
        (1024, 1024, 8192, 32, 32, True, False, True): (6, 64, 3, 2),
        (1024, 1024, 8192, 64, 64, False, True, True): (2, 64, 3, 4),
        (1024, 1024, 8192, 64, 64, True, False, True): (2, 64, 3, 4),
        (1024, 1024, 8192, 128, 128, False, True, True): (3, 64, 1, 4),
        (1024, 1024, 8192, 128, 128, True, False, True): (2, 64, 1, 4),
        (1024, 1024, 16384, 16, 16, False, True, True): (1, 64, 3, 4),
        (1024, 1024, 16384, 16, 16, True, False, True): (1, 64, 3, 2),
        (1024, 1024, 16384, 32, 32, False, True, True): (1, 128, 3, 4),
        (1024, 1024, 16384, 32, 32, True, False, True): (1, 64, 3, 4),
        (1024, 1024, 16384, 64, 64, False, True, True): (1, 128, 3, 4),
        (1024, 1024, 16384, 64, 64, True, False, True): (1, 128, 3, 4),
        (1024, 1024, 16384, 128, 128, False, True, True): (11, 128, 1, 4),
        (1024, 1024, 16384, 128, 128, True, False, True): (4, 128, 1, 4),
        (1024, 1024, 32768, 16, 16, False, True, True): (1, 128, 3, 4),
        (1024, 1024, 32768, 16, 16, True, False, True): (1, 128, 3, 1),
        (1024, 1024, 32768, 32, 32, False, True, True): (1, 256, 3, 2),
        (1024, 1024, 32768, 32, 32, True, False, True): (1, 128, 3, 4),
        (1024, 1024, 32768, 64, 64, False, True, True): (2, 128, 2, 4),
        (1024, 1024, 32768, 64, 64, True, False, True): (1, 256, 3, 4),
        (1024, 1024, 32768, 128, 128, False, True, True): (7, 256, 1, 4),
        (1024, 1024, 32768, 128, 128, True, False, True): (4, 256, 1, 4),
        (1024, 1024, 65536, 16, 16, False, True, True): (1, 256, 3, 4),
        (1024, 1024, 65536, 16, 16, True, False, True): (1, 256, 3, 1),
        (1024, 1024, 65536, 32, 32, False, True, True): (1, 512, 3, 2),
        (1024, 1024, 65536, 32, 32, True, False, True): (1, 256, 3, 4),
        (1024, 1024, 65536, 64, 64, False, True, True): (2, 256, 2, 4),
        (1024, 1024, 65536, 64, 64, True, False, True): (1, 512, 3, 4),
        (1024, 1024, 65536, 128, 128, False, True, True): (10, 512, 1, 4),
        (1024, 1024, 65536, 128, 128, True, False, True): (4, 512, 1, 4),
        (1024, 1024, 131072, 16, 16, False, True, True): (11, 512, 3, 2),
        (1024, 1024, 131072, 16, 16, True, False, True): (11, 512, 3, 2),
        (1024, 1024, 131072, 32, 32, False, True, True): (7, 1024, 3, 2),
        (1024, 1024, 131072, 32, 32, True, False, True): (6, 512, 3, 4),
        (1024, 1024, 131072, 64, 64, False, True, True): (1, 512, 2, 4),
        (1024, 1024, 131072, 64, 64, True, False, True): (4, 1024, 3, 4),
        (1024, 1024, 131072, 128, 128, False, True, True): (12, 1024, 1, 4),
        (1024, 1024, 131072, 128, 128, True, False, True): (4, 1024, 1, 4),
        (2048, 2048, 256, 16, 16, False, True, True): (4, 4, 6, 2),
        (2048, 2048, 256, 16, 16, True, False, True): (2, 8, 4, 1),
        (2048, 2048, 256, 32, 32, False, True, True): (3, 4, 4, 2),
        (2048, 2048, 256, 32, 32, True, False, True): (1, 4, 5, 2),
        (2048, 2048, 256, 64, 64, False, True, True): (2, 4, 4, 4),
        (2048, 2048, 256, 64, 64, True, False, True): (2, 4, 4, 4),
        (2048, 2048, 256, 128, 128, False, True, True): (3, 2, 2, 8),
        (2048, 2048, 256, 128, 128, True, False, True): (5, 2, 2, 8),
        (2048, 2048, 512, 16, 16, False, True, True): (5, 4, 4, 4),
        (2048, 2048, 512, 16, 16, True, False, True): (2, 4, 4, 2),
        (2048, 2048, 512, 32, 32, False, True, True): (1, 4, 3, 4),
        (2048, 2048, 512, 32, 32, True, False, True): (3, 4, 4, 2),
        (2048, 2048, 512, 64, 64, False, True, True): (1, 8, 3, 4),
        (2048, 2048, 512, 64, 64, True, False, True): (1, 8, 3, 2),
        (2048, 2048, 512, 128, 128, False, True, True): (3, 4, 2, 8),
        (2048, 2048, 512, 128, 128, True, False, True): (2, 4, 2, 8),
        (2048, 2048, 1024, 16, 16, False, True, True): (3, 4, 3, 4),
        (2048, 2048, 1024, 16, 16, True, False, True): (2, 8, 3, 2),
        (2048, 2048, 1024, 32, 32, False, True, True): (3, 8, 3, 4),
        (2048, 2048, 1024, 32, 32, True, False, True): (1, 8, 3, 2),
        (2048, 2048, 1024, 64, 64, False, True, True): (1, 8, 3, 4),
        (2048, 2048, 1024, 64, 64, True, False, True): (1, 8, 3, 4),
        (2048, 2048, 1024, 128, 128, False, True, True): (4, 8, 2, 8),
        (2048, 2048, 1024, 128, 128, True, False, True): (4, 8, 1, 4),
        (2048, 2048, 2048, 16, 16, False, True, True): (4, 16, 3, 2),
        (2048, 2048, 2048, 16, 16, True, False, True): (2, 16, 3, 2),
        (2048, 2048, 2048, 32, 32, False, True, True): (1, 16, 3, 4),
        (2048, 2048, 2048, 32, 32, True, False, True): (1, 16, 3, 2),
        (2048, 2048, 2048, 64, 64, False, True, True): (1, 16, 3, 4),
        (2048, 2048, 2048, 64, 64, True, False, True): (1, 16, 3, 4),
        (2048, 2048, 2048, 128, 128, False, True, True): (6, 16, 2, 8),
        (2048, 2048, 2048, 128, 128, True, False, True): (5, 16, 1, 4),
        (2048, 2048, 4096, 16, 16, False, True, True): (4, 32, 4, 2),
        (2048, 2048, 4096, 16, 16, True, False, True): (4, 32, 3, 2),
        (2048, 2048, 4096, 32, 32, False, True, True): (4, 16, 3, 8),
        (2048, 2048, 4096, 32, 32, True, False, True): (4, 16, 3, 4),
        (2048, 2048, 4096, 64, 64, False, True, True): (4, 32, 3, 4),
        (2048, 2048, 4096, 64, 64, True, False, True): (4, 32, 3, 4),
        (2048, 2048, 4096, 128, 128, False, True, True): (4, 32, 2, 8),
        (2048, 2048, 4096, 128, 128, True, False, True): (2, 32, 1, 4),
        (2048, 2048, 8192, 16, 16, False, True, True): (4, 64, 4, 2),
        (2048, 2048, 8192, 16, 16, True, False, True): (4, 64, 4, 2),
        (2048, 2048, 8192, 32, 32, False, True, True): (4, 32, 3, 8),
        (2048, 2048, 8192, 32, 32, True, False, True): (4, 32, 4, 8),
        (2048, 2048, 8192, 64, 64, False, True, True): (2, 64, 3, 4),
        (2048, 2048, 8192, 64, 64, True, False, True): (4, 64, 3, 4),
        (2048, 2048, 8192, 128, 128, False, True, True): (3, 64, 1, 4),
        (2048, 2048, 8192, 128, 128, True, False, True): (2, 64, 1, 4),
        (2048, 2048, 16384, 16, 16, False, True, True): (4, 64, 3, 4),
        (2048, 2048, 16384, 16, 16, True, False, True): (1, 64, 3, 4),
        (2048, 2048, 16384, 32, 32, False, True, True): (4, 64, 3, 4),
        (2048, 2048, 16384, 32, 32, True, False, True): (4, 64, 3, 4),
        (2048, 2048, 16384, 64, 64, False, True, True): (4, 128, 3, 4),
        (2048, 2048, 16384, 64, 64, True, False, True): (4, 128, 3, 4),
        (2048, 2048, 16384, 128, 128, False, True, True): (3, 128, 1, 4),
        (2048, 2048, 16384, 128, 128, True, False, True): (2, 128, 1, 4),
        (2048, 2048, 32768, 16, 16, False, True, True): (8, 128, 3, 2),
        (2048, 2048, 32768, 16, 16, True, False, True): (8, 128, 3, 4),
        (2048, 2048, 32768, 32, 32, False, True, True): (8, 128, 3, 4),
        (2048, 2048, 32768, 32, 32, True, False, True): (8, 128, 3, 4),
        (2048, 2048, 32768, 64, 64, False, True, True): (8, 256, 3, 4),
        (2048, 2048, 32768, 64, 64, True, False, True): (8, 256, 3, 4),
        (2048, 2048, 32768, 128, 128, False, True, True): (3, 256, 1, 4),
        (2048, 2048, 32768, 128, 128, True, False, True): (1, 256, 1, 4),
        (2048, 2048, 65536, 16, 16, False, True, True): (9, 256, 3, 2),
        (2048, 2048, 65536, 16, 16, True, False, True): (9, 256, 4, 4),
        (2048, 2048, 65536, 32, 32, False, True, True): (7, 256, 3, 4),
        (2048, 2048, 65536, 32, 32, True, False, True): (7, 256, 3, 4),
        (2048, 2048, 65536, 64, 64, False, True, True): (2, 256, 2, 4),
        (2048, 2048, 65536, 64, 64, True, False, True): (9, 512, 3, 4),
        (2048, 2048, 65536, 128, 128, False, True, True): (5, 512, 1, 4),
        (2048, 2048, 65536, 128, 128, True, False, True): (1, 512, 1, 4),
        (2048, 2048, 131072, 16, 16, False, True, True): (9, 512, 3, 2),
        (2048, 2048, 131072, 16, 16, True, False, True): (9, 512, 4, 4),
        (2048, 2048, 131072, 32, 32, False, True, True): (7, 512, 3, 4),
        (2048, 2048, 131072, 32, 32, True, False, True): (3, 512, 3, 4),
        (2048, 2048, 131072, 64, 64, False, True, True): (1, 512, 2, 4),
        (2048, 2048, 131072, 64, 64, True, False, True): (2, 1024, 3, 4),
        (2048, 2048, 131072, 128, 128, False, True, True): (3, 1024, 1, 4),
        (2048, 2048, 131072, 128, 128, True, False, True): (1, 1024, 1, 4),
        (4096, 4096, 256, 16, 16, False, True, True): (2, 2, 6, 4),
        (4096, 4096, 256, 16, 16, True, False, True): (2, 2, 5, 4),
        (4096, 4096, 256, 32, 32, False, True, True): (7, 2, 4, 4),
        (4096, 4096, 256, 32, 32, True, False, True): (1, 2, 4, 4),
        (4096, 4096, 256, 64, 64, False, True, True): (3, 4, 3, 4),
        (4096, 4096, 256, 64, 64, True, False, True): (3, 4, 3, 4),
        (4096, 4096, 256, 128, 128, False, True, True): (1, 2, 2, 8),
        (4096, 4096, 256, 128, 128, True, False, True): (1, 2, 2, 8),
        (4096, 4096, 512, 16, 16, False, True, True): (4, 2, 3, 4),
        (4096, 4096, 512, 16, 16, True, False, True): (2, 4, 3, 2),
        (4096, 4096, 512, 32, 32, False, True, True): (3, 4, 3, 4),
        (4096, 4096, 512, 32, 32, True, False, True): (3, 4, 3, 2),
        (4096, 4096, 512, 64, 64, False, True, True): (3, 4, 3, 4),
        (4096, 4096, 512, 64, 64, True, False, True): (3, 4, 3, 4),
        (4096, 4096, 512, 128, 128, False, True, True): (2, 4, 2, 8),
        (4096, 4096, 512, 128, 128, True, False, True): (2, 4, 1, 4),
        (4096, 4096, 1024, 16, 16, False, True, True): (2, 8, 3, 2),
        (4096, 4096, 1024, 16, 16, True, False, True): (2, 8, 3, 2),
        (4096, 4096, 1024, 32, 32, False, True, True): (3, 8, 3, 4),
        (4096, 4096, 1024, 32, 32, True, False, True): (1, 8, 3, 2),
        (4096, 4096, 1024, 64, 64, False, True, True): (1, 8, 3, 4),
        (4096, 4096, 1024, 64, 64, True, False, True): (1, 8, 3, 4),
        (4096, 4096, 1024, 128, 128, False, True, True): (2, 8, 2, 8),
        (4096, 4096, 1024, 128, 128, True, False, True): (2, 8, 2, 8),
        (4096, 4096, 2048, 16, 16, False, True, True): (2, 8, 4, 4),
        (4096, 4096, 2048, 16, 16, True, False, True): (2, 8, 4, 4),
        (4096, 4096, 2048, 32, 32, False, True, True): (4, 8, 4, 8),
        (4096, 4096, 2048, 32, 32, True, False, True): (4, 8, 4, 8),
        (4096, 4096, 2048, 64, 64, False, True, True): (1, 16, 3, 4),
        (4096, 4096, 2048, 64, 64, True, False, True): (4, 16, 3, 4),
        (4096, 4096, 2048, 128, 128, False, True, True): (2, 16, 2, 8),
        (4096, 4096, 2048, 128, 128, True, False, True): (4, 16, 1, 4),
        (4096, 4096, 4096, 16, 16, False, True, True): (4, 32, 4, 4),
        (4096, 4096, 4096, 16, 16, True, False, True): (4, 32, 4, 2),
        (4096, 4096, 4096, 32, 32, False, True, True): (4, 16, 4, 8),
        (4096, 4096, 4096, 32, 32, True, False, True): (4, 16, 3, 8),
        (4096, 4096, 4096, 64, 64, False, True, True): (1, 32, 3, 4),
        (4096, 4096, 4096, 64, 64, True, False, True): (1, 32, 3, 4),
        (4096, 4096, 4096, 128, 128, False, True, True): (3, 32, 1, 4),
        (4096, 4096, 4096, 128, 128, True, False, True): (2, 32, 1, 4),
        (4096, 4096, 8192, 16, 16, False, True, True): (4, 64, 4, 2),
        (4096, 4096, 8192, 16, 16, True, False, True): (4, 64, 4, 2),
        (4096, 4096, 8192, 32, 32, False, True, True): (4, 32, 4, 8),
        (4096, 4096, 8192, 32, 32, True, False, True): (4, 32, 4, 8),
        (4096, 4096, 8192, 64, 64, False, True, True): (2, 64, 3, 4),
        (4096, 4096, 8192, 64, 64, True, False, True): (2, 64, 3, 4),
        (4096, 4096, 8192, 128, 128, False, True, True): (3, 64, 1, 4),
        (4096, 4096, 8192, 128, 128, True, False, True): (1, 64, 1, 4),
        (4096, 4096, 16384, 16, 16, False, True, True): (4, 64, 3, 4),
        (4096, 4096, 16384, 16, 16, True, False, True): (4, 64, 4, 4),
        (4096, 4096, 16384, 32, 32, False, True, True): (4, 64, 4, 8),
        (4096, 4096, 16384, 32, 32, True, False, True): (4, 64, 4, 8),
        (4096, 4096, 16384, 64, 64, False, True, True): (1, 64, 2, 4),
        (4096, 4096, 16384, 64, 64, True, False, True): (1, 64, 3, 8),
        (4096, 4096, 16384, 128, 128, False, True, True): (3, 128, 1, 4),
        (4096, 4096, 16384, 128, 128, True, False, True): (1, 128, 1, 4),
        (4096, 4096, 32768, 16, 16, False, True, True): (8, 128, 3, 2),
        (4096, 4096, 32768, 16, 16, True, False, True): (5, 128, 4, 4),
        (4096, 4096, 32768, 32, 32, False, True, True): (3, 128, 4, 4),
        (4096, 4096, 32768, 32, 32, True, False, True): (3, 128, 4, 8),
        (4096, 4096, 32768, 64, 64, False, True, True): (1, 128, 2, 4),
        (4096, 4096, 32768, 64, 64, True, False, True): (3, 256, 3, 4),
        (4096, 4096, 32768, 128, 128, False, True, True): (3, 256, 1, 4),
        (4096, 4096, 32768, 128, 128, True, False, True): (1, 256, 1, 4),
        (4096, 4096, 65536, 16, 16, False, True, True): (5, 256, 4, 4),
        (4096, 4096, 65536, 16, 16, True, False, True): (5, 256, 4, 4),
        (4096, 4096, 65536, 32, 32, False, True, True): (4, 256, 4, 8),
        (4096, 4096, 65536, 32, 32, True, False, True): (4, 256, 3, 8),
        (4096, 4096, 65536, 64, 64, False, True, True): (1, 256, 2, 4),
        (4096, 4096, 65536, 64, 64, True, False, True): (1, 512, 3, 4),
        (4096, 4096, 65536, 128, 128, False, True, True): (3, 512, 1, 4),
        (4096, 4096, 65536, 128, 128, True, False, True): (1, 512, 1, 4),
        (4096, 4096, 131072, 16, 16, False, True, True): (4, 512, 3, 4),
        (4096, 4096, 131072, 16, 16, True, False, True): (5, 512, 4, 4),
        (4096, 4096, 131072, 32, 32, False, True, True): (1, 512, 4, 8),
        (4096, 4096, 131072, 32, 32, True, False, True): (4, 512, 4, 8),
        (4096, 4096, 131072, 64, 64, False, True, True): (1, 512, 2, 4),
        (4096, 4096, 131072, 64, 64, True, False, True): (1, 512, 2, 4),
        (4096, 4096, 131072, 128, 128, False, True, True): (3, 1024, 1, 4),
        (4096, 4096, 131072, 128, 128, True, False, True): (1, 1024, 1, 4),
        (8192, 8192, 256, 16, 16, False, True, True): (2, 2, 6, 4),
        (8192, 8192, 256, 16, 16, True, False, True): (2, 4, 2, 2),
        (8192, 8192, 256, 32, 32, False, True, True): (4, 2, 3, 4),
        (8192, 8192, 256, 32, 32, True, False, True): (4, 2, 3, 4),
        (8192, 8192, 256, 64, 64, False, True, True): (2, 2, 3, 8),
        (8192, 8192, 256, 64, 64, True, False, True): (6, 2, 3, 8),
        (8192, 8192, 256, 128, 128, False, True, True): (3, 2, 1, 4),
        (8192, 8192, 256, 128, 128, True, False, True): (1, 2, 1, 4),
        (8192, 8192, 512, 16, 16, False, True, True): (4, 4, 3, 2),
        (8192, 8192, 512, 16, 16, True, False, True): (4, 4, 3, 4),
        (8192, 8192, 512, 32, 32, False, True, True): (1, 4, 3, 4),
        (8192, 8192, 512, 32, 32, True, False, True): (5, 4, 3, 2),
        (8192, 8192, 512, 64, 64, False, True, True): (1, 4, 3, 4),
        (8192, 8192, 512, 64, 64, True, False, True): (2, 2, 3, 8),
        (8192, 8192, 512, 128, 128, False, True, True): (4, 4, 2, 8),
        (8192, 8192, 512, 128, 128, True, False, True): (4, 4, 2, 8),
        (8192, 8192, 1024, 16, 16, False, True, True): (4, 8, 4, 4),
        (8192, 8192, 1024, 16, 16, True, False, True): (4, 8, 4, 4),
        (8192, 8192, 1024, 32, 32, False, True, True): (2, 4, 4, 8),
        (8192, 8192, 1024, 32, 32, True, False, True): (1, 4, 3, 4),
        (8192, 8192, 1024, 64, 64, False, True, True): (4, 8, 3, 4),
        (8192, 8192, 1024, 64, 64, True, False, True): (2, 8, 3, 4),
        (8192, 8192, 1024, 128, 128, False, True, True): (4, 8, 2, 8),
        (8192, 8192, 1024, 128, 128, True, False, True): (4, 8, 1, 4),
        (8192, 8192, 2048, 16, 16, False, True, True): (2, 8, 4, 4),
        (8192, 8192, 2048, 16, 16, True, False, True): (2, 8, 4, 4),
        (8192, 8192, 2048, 32, 32, False, True, True): (2, 8, 4, 8),
        (8192, 8192, 2048, 32, 32, True, False, True): (2, 8, 4, 8),
        (8192, 8192, 2048, 64, 64, False, True, True): (4, 8, 2, 4),
        (8192, 8192, 2048, 64, 64, True, False, True): (4, 16, 3, 4),
        (8192, 8192, 2048, 128, 128, False, True, True): (6, 16, 1, 4),
        (8192, 8192, 2048, 128, 128, True, False, True): (4, 16, 1, 4),
        (8192, 8192, 4096, 16, 16, False, True, True): (4, 32, 4, 2),
        (8192, 8192, 4096, 16, 16, True, False, True): (4, 32, 4, 2),
        (8192, 8192, 4096, 32, 32, False, True, True): (2, 16, 4, 8),
        (8192, 8192, 4096, 32, 32, True, False, True): (4, 16, 4, 8),
        (8192, 8192, 4096, 64, 64, False, True, True): (4, 16, 2, 4),
        (8192, 8192, 4096, 64, 64, True, False, True): (4, 16, 2, 4),
        (8192, 8192, 4096, 128, 128, False, True, True): (6, 32, 1, 4),
        (8192, 8192, 4096, 128, 128, True, False, True): (4, 32, 1, 4),
        (8192, 8192, 8192, 16, 16, False, True, True): (4, 64, 4, 2),
        (8192, 8192, 8192, 16, 16, True, False, True): (4, 64, 4, 2),
        (8192, 8192, 8192, 32, 32, False, True, True): (2, 32, 4, 8),
        (8192, 8192, 8192, 32, 32, True, False, True): (2, 32, 4, 8),
        (8192, 8192, 8192, 64, 64, False, True, True): (2, 32, 2, 4),
        (8192, 8192, 8192, 64, 64, True, False, True): (4, 32, 2, 4),
        (8192, 8192, 8192, 128, 128, False, True, True): (6, 64, 1, 4),
        (8192, 8192, 8192, 128, 128, True, False, True): (4, 64, 1, 4),
        (8192, 8192, 16384, 16, 16, False, True, True): (4, 64, 3, 4),
        (8192, 8192, 16384, 16, 16, True, False, True): (4, 64, 4, 4),
        (8192, 8192, 16384, 32, 32, False, True, True): (4, 64, 4, 8),
        (8192, 8192, 16384, 32, 32, True, False, True): (4, 64, 4, 8),
        (8192, 8192, 16384, 64, 64, False, True, True): (4, 64, 2, 4),
        (8192, 8192, 16384, 64, 64, True, False, True): (4, 64, 3, 8),
        (8192, 8192, 16384, 128, 128, False, True, True): (6, 128, 1, 4),
        (8192, 8192, 16384, 128, 128, True, False, True): (4, 128, 1, 4),
        (8192, 8192, 32768, 16, 16, False, True, True): (3, 128, 4, 4),
        (8192, 8192, 32768, 16, 16, True, False, True): (3, 128, 4, 4),
        (8192, 8192, 32768, 32, 32, False, True, True): (2, 128, 4, 8),
        (8192, 8192, 32768, 32, 32, True, False, True): (2, 128, 4, 8),
        (8192, 8192, 32768, 64, 64, False, True, True): (2, 128, 2, 4),
        (8192, 8192, 32768, 64, 64, True, False, True): (2, 128, 3, 8),
        (8192, 8192, 32768, 128, 128, False, True, True): (6, 256, 1, 4),
        (8192, 8192, 32768, 128, 128, True, False, True): (4, 256, 1, 4),
        (8192, 8192, 65536, 16, 16, False, True, True): (3, 256, 4, 4),
        (8192, 8192, 65536, 16, 16, True, False, True): (4, 256, 4, 4),
        (8192, 8192, 65536, 32, 32, False, True, True): (2, 256, 4, 8),
        (8192, 8192, 65536, 32, 32, True, False, True): (2, 256, 3, 8),
        (8192, 8192, 65536, 64, 64, False, True, True): (2, 256, 2, 4),
        (8192, 8192, 65536, 64, 64, True, False, True): (4, 256, 3, 8),
        (8192, 8192, 65536, 128, 128, False, True, True): (6, 512, 1, 4),
        (8192, 8192, 65536, 128, 128, True, False, True): (4, 512, 1, 4),
        (8192, 8192, 131072, 16, 16, False, True, True): (4, 512, 4, 4),
        (8192, 8192, 131072, 16, 16, True, False, True): (3, 512, 4, 4),
        (8192, 8192, 131072, 32, 32, False, True, True): (2, 512, 4, 8),
        (8192, 8192, 131072, 32, 32, True, False, True): (2, 512, 4, 8),
        (8192, 8192, 131072, 64, 64, False, True, True): (2, 512, 2, 4),
        (8192, 8192, 131072, 64, 64, True, False, True): (2, 512, 2, 4),
        (8192, 8192, 131072, 128, 128, False, True, True): (4, 1024, 1, 4),
        (8192, 8192, 131072, 128, 128, True, False, True): (4, 1024, 1, 4),
        (16384, 16384, 256, 16, 16, False, True, True): (2, 2, 3, 2),
        (16384, 16384, 256, 16, 16, True, False, True): (2, 2, 6, 4),
        (16384, 16384, 256, 32, 32, False, True, True): (4, 2, 3, 4),
        (16384, 16384, 256, 32, 32, True, False, True): (4, 2, 3, 2),
        (16384, 16384, 256, 64, 64, False, True, True): (2, 2, 5, 4),
        (16384, 16384, 256, 64, 64, True, False, True): (2, 2, 3, 8),
        (16384, 16384, 256, 128, 128, False, True, True): (4, 2, 2, 8),
        (16384, 16384, 256, 128, 128, True, False, True): (2, 2, 1, 4),
        (16384, 16384, 512, 16, 16, False, True, True): (1, 2, 4, 4),
        (16384, 16384, 512, 16, 16, True, False, True): (1, 2, 4, 4),
        (16384, 16384, 512, 32, 32, False, True, True): (2, 2, 3, 8),
        (16384, 16384, 512, 32, 32, True, False, True): (2, 2, 4, 8),
        (16384, 16384, 512, 64, 64, False, True, True): (4, 4, 3, 4),
        (16384, 16384, 512, 64, 64, True, False, True): (2, 4, 3, 4),
        (16384, 16384, 512, 128, 128, False, True, True): (4, 4, 2, 8),
        (16384, 16384, 512, 128, 128, True, False, True): (4, 4, 2, 8),
        (16384, 16384, 1024, 16, 16, False, True, True): (4, 8, 4, 4),
        (16384, 16384, 1024, 16, 16, True, False, True): (2, 4, 4, 4),
        (16384, 16384, 1024, 32, 32, False, True, True): (2, 4, 4, 8),
        (16384, 16384, 1024, 32, 32, True, False, True): (2, 4, 4, 8),
        (16384, 16384, 1024, 64, 64, False, True, True): (4, 4, 2, 4),
        (16384, 16384, 1024, 64, 64, True, False, True): (2, 4, 2, 4),
        (16384, 16384, 1024, 128, 128, False, True, True): (6, 8, 1, 4),
        (16384, 16384, 1024, 128, 128, True, False, True): (4, 8, 1, 4),
        (16384, 16384, 2048, 16, 16, False, True, True): (2, 8, 4, 4),
        (16384, 16384, 2048, 16, 16, True, False, True): (2, 8, 4, 4),
        (16384, 16384, 2048, 32, 32, False, True, True): (2, 8, 4, 8),
        (16384, 16384, 2048, 32, 32, True, False, True): (2, 8, 4, 8),
        (16384, 16384, 2048, 64, 64, False, True, True): (2, 8, 2, 4),
        (16384, 16384, 2048, 64, 64, True, False, True): (2, 8, 2, 4),
        (16384, 16384, 2048, 128, 128, False, True, True): (4, 16, 2, 8),
        (16384, 16384, 2048, 128, 128, True, False, True): (4, 16, 1, 4),
        (16384, 16384, 4096, 16, 16, False, True, True): (2, 16, 4, 4),
        (16384, 16384, 4096, 16, 16, True, False, True): (2, 16, 4, 4),
        (16384, 16384, 4096, 32, 32, False, True, True): (1, 16, 4, 8),
        (16384, 16384, 4096, 32, 32, True, False, True): (2, 16, 3, 4),
        (16384, 16384, 4096, 64, 64, False, True, True): (1, 16, 2, 4),
        (16384, 16384, 4096, 64, 64, True, False, True): (2, 16, 2, 4),
        (16384, 16384, 4096, 128, 128, False, True, True): (4, 32, 2, 8),
        (16384, 16384, 4096, 128, 128, True, False, True): (4, 32, 1, 4),
        (16384, 16384, 8192, 16, 16, False, True, True): (2, 64, 4, 2),
        (16384, 16384, 8192, 16, 16, True, False, True): (2, 64, 4, 2),
        (16384, 16384, 8192, 32, 32, False, True, True): (2, 32, 4, 8),
        (16384, 16384, 8192, 32, 32, True, False, True): (2, 32, 4, 8),
        (16384, 16384, 8192, 64, 64, False, True, True): (2, 32, 2, 4),
        (16384, 16384, 8192, 64, 64, True, False, True): (2, 32, 4, 8),
        (16384, 16384, 8192, 128, 128, False, True, True): (4, 64, 2, 8),
        (16384, 16384, 8192, 128, 128, True, False, True): (4, 64, 1, 4),
        (16384, 16384, 16384, 16, 16, False, True, True): (1, 64, 4, 4),
        (16384, 16384, 16384, 16, 16, True, False, True): (1, 64, 4, 4),
        (16384, 16384, 16384, 32, 32, False, True, True): (1, 64, 4, 8),
        (16384, 16384, 16384, 32, 32, True, False, True): (1, 64, 4, 8),
        (16384, 16384, 16384, 64, 64, False, True, True): (1, 64, 2, 4),
        (16384, 16384, 16384, 64, 64, True, False, True): (1, 64, 3, 8),
        (16384, 16384, 16384, 128, 128, False, True, True): (4, 128, 1, 4),
        (16384, 16384, 16384, 128, 128, True, False, True): (4, 128, 1, 4),
        (16384, 16384, 32768, 16, 16, False, True, True): (1, 128, 4, 4),
        (16384, 16384, 32768, 16, 16, True, False, True): (1, 128, 4, 4),
        (16384, 16384, 32768, 32, 32, False, True, True): (1, 128, 3, 4),
        (16384, 16384, 32768, 32, 32, True, False, True): (1, 128, 3, 8),
        (16384, 16384, 32768, 64, 64, False, True, True): (2, 128, 2, 4),
        (16384, 16384, 32768, 64, 64, True, False, True): (1, 128, 4, 8),
        (16384, 16384, 32768, 128, 128, False, True, True): (4, 256, 2, 8),
        (16384, 16384, 32768, 128, 128, True, False, True): (4, 256, 1, 4),
        (16384, 16384, 65536, 16, 16, False, True, True): (1, 256, 3, 4),
        (16384, 16384, 65536, 16, 16, True, False, True): (1, 256, 4, 4),
        (16384, 16384, 65536, 32, 32, False, True, True): (1, 256, 4, 8),
        (16384, 16384, 65536, 32, 32, True, False, True): (1, 256, 3, 4),
        (16384, 16384, 65536, 64, 64, False, True, True): (2, 256, 2, 4),
        (16384, 16384, 65536, 64, 64, True, False, True): (1, 256, 3, 8),
        (16384, 16384, 65536, 128, 128, False, True, True): (4, 512, 2, 8),
        (16384, 16384, 65536, 128, 128, True, False, True): (4, 512, 1, 4),
        (16384, 16384, 131072, 16, 16, False, True, True): (1, 512, 4, 4),
        (16384, 16384, 131072, 16, 16, True, False, True): (1, 512, 3, 2),
        (16384, 16384, 131072, 32, 32, False, True, True): (1, 512, 4, 8),
        (16384, 16384, 131072, 32, 32, True, False, True): (1, 512, 3, 2),
        (16384, 16384, 131072, 64, 64, False, True, True): (1, 512, 2, 4),
        (16384, 16384, 131072, 64, 64, True, False, True): (1, 512, 2, 4),
        (16384, 16384, 131072, 128, 128, False, True, True): (4, 1024, 1, 4),
        (16384, 16384, 131072, 128, 128, True, False, True): (4, 1024, 1, 4),
    },
    ("bsr_dense_addmm", "NVIDIA A100-SXM4-80GB", (0, torch.float32, 0.5)): {
        (16, 16, 16, 16, 16, False, False, False): (2, 1, 1, 16),
        (16, 16, 16, 16, 16, False, False, True): (1, 1, 2, 4),
        (16, 16, 16, 16, 16, False, True, False): (1, 1, 2, 16),
        (16, 16, 16, 16, 16, False, True, True): (2, 1, 2, 8),
        (16, 16, 16, 16, 16, True, False, False): (1, 1, 1, 2),
        (16, 16, 16, 16, 16, True, False, True): (2, 1, 1, 4),
        (16, 16, 32, 16, 16, False, False, False): (1, 1, 1, 2),
        (16, 16, 32, 16, 16, False, False, True): (1, 1, 2, 8),
        (16, 16, 32, 16, 16, False, True, False): (1, 2, 1, 4),
        (16, 16, 32, 16, 16, False, True, True): (1, 2, 2, 4),
        (16, 16, 32, 16, 16, True, False, False): (1, 1, 2, 4),
        (16, 16, 32, 16, 16, True, False, True): (1, 2, 2, 4),
        (16, 16, 64, 16, 16, False, False, False): (1, 4, 1, 4),
        (16, 16, 64, 16, 16, False, False, True): (2, 2, 1, 4),
        (16, 16, 64, 16, 16, False, True, False): (1, 4, 1, 4),
        (16, 16, 64, 16, 16, False, True, True): (1, 4, 1, 8),
        (16, 16, 64, 16, 16, True, False, False): (1, 2, 1, 4),
        (16, 16, 64, 16, 16, True, False, True): (1, 4, 2, 8),
        (16, 32, 16, 16, 16, False, False, False): (1, 1, 2, 8),
        (16, 32, 16, 16, 16, False, False, True): (2, 1, 1, 4),
        (16, 32, 16, 16, 16, False, True, False): (1, 1, 1, 4),
        (16, 32, 16, 16, 16, False, True, True): (1, 1, 1, 4),
        (16, 32, 16, 16, 16, True, False, False): (1, 1, 1, 4),
        (16, 32, 16, 16, 16, True, False, True): (1, 1, 2, 8),
        (16, 32, 16, 16, 32, False, False, False): (1, 1, 2, 4),
        (16, 32, 16, 16, 32, False, False, True): (2, 1, 2, 2),
        (16, 32, 16, 16, 32, False, True, False): (1, 1, 1, 8),
        (16, 32, 16, 16, 32, False, True, True): (1, 1, 1, 2),
        (16, 32, 16, 16, 32, True, False, False): (3, 1, 1, 4),
        (16, 32, 16, 16, 32, True, False, True): (1, 1, 1, 4),
        (16, 32, 32, 16, 16, False, False, False): (1, 2, 1, 4),
        (16, 32, 32, 16, 16, False, False, True): (2, 2, 1, 4),
        (16, 32, 32, 16, 16, False, True, False): (1, 2, 1, 2),
        (16, 32, 32, 16, 16, False, True, True): (1, 2, 1, 4),
        (16, 32, 32, 16, 16, True, False, False): (1, 2, 1, 4),
        (16, 32, 32, 16, 16, True, False, True): (1, 2, 1, 4),
        (16, 32, 32, 16, 32, False, False, False): (1, 1, 2, 4),
        (16, 32, 32, 16, 32, False, False, True): (1, 2, 1, 4),
        (16, 32, 32, 16, 32, False, True, False): (1, 2, 2, 8),
        (16, 32, 32, 16, 32, False, True, True): (1, 2, 1, 1),
        (16, 32, 32, 16, 32, True, False, False): (1, 2, 1, 2),
        (16, 32, 32, 16, 32, True, False, True): (1, 2, 1, 4),
        (16, 32, 64, 16, 16, False, False, False): (1, 2, 1, 4),
        (16, 32, 64, 16, 16, False, False, True): (2, 4, 1, 4),
        (16, 32, 64, 16, 16, False, True, False): (1, 4, 2, 4),
        (16, 32, 64, 16, 16, False, True, True): (1, 4, 1, 4),
        (16, 32, 64, 16, 16, True, False, False): (1, 2, 2, 8),
        (16, 32, 64, 16, 16, True, False, True): (1, 4, 1, 2),
        (16, 32, 64, 16, 32, False, False, False): (1, 4, 1, 4),
        (16, 32, 64, 16, 32, False, False, True): (1, 4, 3, 4),
        (16, 32, 64, 16, 32, False, True, False): (1, 2, 1, 4),
        (16, 32, 64, 16, 32, False, True, True): (1, 4, 1, 4),
        (16, 32, 64, 16, 32, True, False, False): (1, 2, 1, 8),
        (16, 32, 64, 16, 32, True, False, True): (1, 2, 1, 4),
        (16, 64, 16, 16, 32, False, False, False): (1, 1, 1, 2),
        (16, 64, 16, 16, 32, False, False, True): (1, 1, 1, 8),
        (16, 64, 16, 16, 32, False, True, False): (1, 1, 1, 8),
        (16, 64, 16, 16, 32, False, True, True): (1, 1, 1, 4),
        (16, 64, 16, 16, 32, True, False, False): (1, 1, 1, 8),
        (16, 64, 16, 16, 32, True, False, True): (1, 1, 1, 4),
        (16, 64, 32, 16, 32, False, False, False): (1, 2, 1, 4),
        (16, 64, 32, 16, 32, False, False, True): (1, 1, 1, 4),
        (16, 64, 32, 16, 32, False, True, False): (1, 2, 1, 1),
        (16, 64, 32, 16, 32, False, True, True): (1, 2, 1, 8),
        (16, 64, 32, 16, 32, True, False, False): (2, 2, 1, 4),
        (16, 64, 32, 16, 32, True, False, True): (2, 2, 1, 4),
        (16, 64, 64, 16, 32, False, False, False): (1, 2, 1, 4),
        (16, 64, 64, 16, 32, False, False, True): (1, 4, 1, 4),
        (16, 64, 64, 16, 32, False, True, False): (1, 4, 1, 4),
        (16, 64, 64, 16, 32, False, True, True): (1, 4, 1, 4),
        (16, 64, 64, 16, 32, True, False, False): (1, 4, 1, 2),
        (16, 64, 64, 16, 32, True, False, True): (3, 4, 1, 4),
        (32, 16, 16, 16, 16, False, False, False): (1, 1, 2, 4),
        (32, 16, 16, 16, 16, False, False, True): (1, 1, 1, 2),
        (32, 16, 16, 16, 16, False, True, False): (1, 1, 2, 4),
        (32, 16, 16, 16, 16, False, True, True): (1, 1, 2, 4),
        (32, 16, 16, 16, 16, True, False, False): (1, 1, 3, 8),
        (32, 16, 16, 16, 16, True, False, True): (1, 1, 2, 4),
        (32, 16, 32, 16, 16, False, False, False): (1, 2, 1, 4),
        (32, 16, 32, 16, 16, False, False, True): (1, 2, 3, 4),
        (32, 16, 32, 16, 16, False, True, False): (1, 1, 1, 8),
        (32, 16, 32, 16, 16, False, True, True): (1, 2, 1, 4),
        (32, 16, 32, 16, 16, True, False, False): (1, 1, 1, 2),
        (32, 16, 32, 16, 16, True, False, True): (1, 1, 1, 4),
        (32, 16, 64, 16, 16, False, False, False): (1, 4, 1, 4),
        (32, 16, 64, 16, 16, False, False, True): (3, 4, 1, 4),
        (32, 16, 64, 16, 16, False, True, False): (1, 4, 1, 1),
        (32, 16, 64, 16, 16, False, True, True): (1, 4, 1, 4),
        (32, 16, 64, 16, 16, True, False, False): (1, 4, 1, 4),
        (32, 16, 64, 16, 16, True, False, True): (1, 4, 1, 4),
        (32, 32, 16, 16, 16, False, False, False): (1, 1, 1, 2),
        (32, 32, 16, 16, 16, False, False, True): (2, 1, 1, 4),
        (32, 32, 16, 16, 16, False, True, False): (1, 1, 1, 2),
        (32, 32, 16, 16, 16, False, True, True): (2, 1, 1, 4),
        (32, 32, 16, 16, 16, True, False, False): (3, 1, 2, 4),
        (32, 32, 16, 16, 16, True, False, True): (1, 1, 2, 4),
        (32, 32, 16, 16, 32, False, False, False): (2, 1, 1, 2),
        (32, 32, 16, 16, 32, False, False, True): (1, 1, 1, 4),
        (32, 32, 16, 16, 32, False, True, False): (1, 1, 1, 4),
        (32, 32, 16, 16, 32, False, True, True): (1, 1, 1, 8),
        (32, 32, 16, 16, 32, True, False, False): (1, 1, 1, 8),
        (32, 32, 16, 16, 32, True, False, True): (1, 1, 1, 4),
        (32, 32, 16, 32, 32, False, False, False): (2, 1, 1, 4),
        (32, 32, 16, 32, 32, False, False, True): (1, 1, 2, 4),
        (32, 32, 16, 32, 32, False, True, False): (2, 1, 1, 1),
        (32, 32, 16, 32, 32, False, True, True): (2, 1, 2, 4),
        (32, 32, 16, 32, 32, True, False, False): (1, 1, 1, 8),
        (32, 32, 16, 32, 32, True, False, True): (1, 1, 1, 4),
        (32, 32, 32, 16, 16, False, False, False): (1, 1, 1, 4),
        (32, 32, 32, 16, 16, False, False, True): (1, 2, 1, 2),
        (32, 32, 32, 16, 16, False, True, False): (2, 2, 1, 4),
        (32, 32, 32, 16, 16, False, True, True): (1, 2, 2, 4),
        (32, 32, 32, 16, 16, True, False, False): (1, 2, 1, 4),
        (32, 32, 32, 16, 16, True, False, True): (2, 2, 1, 4),
        (32, 32, 32, 16, 32, False, False, False): (1, 2, 1, 4),
        (32, 32, 32, 16, 32, False, False, True): (1, 2, 1, 4),
        (32, 32, 32, 16, 32, False, True, False): (1, 2, 1, 4),
        (32, 32, 32, 16, 32, False, True, True): (1, 2, 1, 4),
        (32, 32, 32, 16, 32, True, False, False): (2, 1, 1, 2),
        (32, 32, 32, 16, 32, True, False, True): (2, 2, 2, 4),
        (32, 32, 32, 32, 32, False, False, False): (1, 1, 1, 4),
        (32, 32, 32, 32, 32, False, False, True): (1, 1, 1, 2),
        (32, 32, 32, 32, 32, False, True, False): (1, 1, 1, 4),
        (32, 32, 32, 32, 32, False, True, True): (1, 1, 2, 2),
        (32, 32, 32, 32, 32, True, False, False): (1, 1, 1, 2),
        (32, 32, 32, 32, 32, True, False, True): (1, 1, 2, 1),
        (32, 32, 64, 16, 16, False, False, False): (2, 4, 1, 4),
        (32, 32, 64, 16, 16, False, False, True): (1, 4, 2, 4),
        (32, 32, 64, 16, 16, False, True, False): (1, 4, 1, 4),
        (32, 32, 64, 16, 16, False, True, True): (1, 4, 1, 4),
        (32, 32, 64, 16, 16, True, False, False): (1, 2, 1, 4),
        (32, 32, 64, 16, 16, True, False, True): (2, 4, 1, 4),
        (32, 32, 64, 16, 32, False, False, False): (1, 4, 1, 8),
        (32, 32, 64, 16, 32, False, False, True): (1, 4, 1, 4),
        (32, 32, 64, 16, 32, False, True, False): (1, 4, 1, 4),
        (32, 32, 64, 16, 32, False, True, True): (2, 4, 1, 4),
        (32, 32, 64, 16, 32, True, False, False): (1, 2, 2, 4),
        (32, 32, 64, 16, 32, True, False, True): (2, 4, 1, 4),
        (32, 32, 64, 32, 32, False, False, False): (2, 2, 1, 4),
        (32, 32, 64, 32, 32, False, False, True): (1, 1, 1, 4),
        (32, 32, 64, 32, 32, False, True, False): (1, 1, 1, 8),
        (32, 32, 64, 32, 32, False, True, True): (2, 1, 1, 4),
        (32, 32, 64, 32, 32, True, False, False): (1, 1, 1, 4),
        (32, 32, 64, 32, 32, True, False, True): (1, 2, 1, 1),
        (32, 64, 16, 16, 32, False, False, False): (1, 1, 2, 2),
        (32, 64, 16, 16, 32, False, False, True): (2, 1, 1, 4),
        (32, 64, 16, 16, 32, False, True, False): (1, 1, 1, 8),
        (32, 64, 16, 16, 32, False, True, True): (1, 1, 3, 4),
        (32, 64, 16, 16, 32, True, False, False): (1, 1, 1, 2),
        (32, 64, 16, 16, 32, True, False, True): (1, 1, 2, 4),
        (32, 64, 16, 32, 32, False, False, False): (1, 1, 1, 2),
        (32, 64, 16, 32, 32, False, False, True): (1, 1, 3, 4),
        (32, 64, 16, 32, 32, False, True, False): (1, 1, 2, 4),
        (32, 64, 16, 32, 32, False, True, True): (1, 1, 1, 8),
        (32, 64, 16, 32, 32, True, False, False): (1, 1, 2, 4),
        (32, 64, 16, 32, 32, True, False, True): (1, 1, 1, 8),
        (32, 64, 32, 16, 32, False, False, False): (1, 2, 1, 4),
        (32, 64, 32, 16, 32, False, False, True): (1, 2, 3, 4),
        (32, 64, 32, 16, 32, False, True, False): (1, 2, 1, 8),
        (32, 64, 32, 16, 32, False, True, True): (3, 2, 1, 4),
        (32, 64, 32, 16, 32, True, False, False): (1, 1, 1, 8),
        (32, 64, 32, 16, 32, True, False, True): (1, 2, 1, 4),
        (32, 64, 32, 32, 32, False, False, False): (1, 1, 1, 1),
        (32, 64, 32, 32, 32, False, False, True): (1, 1, 1, 4),
        (32, 64, 32, 32, 32, False, True, False): (1, 1, 1, 4),
        (32, 64, 32, 32, 32, False, True, True): (1, 1, 1, 4),
        (32, 64, 32, 32, 32, True, False, False): (1, 1, 1, 4),
        (32, 64, 32, 32, 32, True, False, True): (1, 1, 2, 8),
        (32, 64, 64, 16, 32, False, False, False): (2, 4, 1, 4),
        (32, 64, 64, 16, 32, False, False, True): (1, 4, 1, 4),
        (32, 64, 64, 16, 32, False, True, False): (1, 4, 1, 4),
        (32, 64, 64, 16, 32, False, True, True): (2, 4, 1, 4),
        (32, 64, 64, 16, 32, True, False, False): (1, 4, 1, 4),
        (32, 64, 64, 16, 32, True, False, True): (1, 4, 1, 4),
        (32, 64, 64, 32, 32, False, False, False): (2, 2, 1, 4),
        (32, 64, 64, 32, 32, False, False, True): (1, 2, 1, 8),
        (32, 64, 64, 32, 32, False, True, False): (1, 2, 1, 4),
        (32, 64, 64, 32, 32, False, True, True): (1, 2, 1, 4),
        (32, 64, 64, 32, 32, True, False, False): (2, 2, 1, 4),
        (32, 64, 64, 32, 32, True, False, True): (1, 2, 3, 8),
        (64, 32, 16, 32, 32, False, False, False): (1, 1, 1, 4),
        (64, 32, 16, 32, 32, False, False, True): (3, 1, 2, 4),
        (64, 32, 16, 32, 32, False, True, False): (2, 1, 1, 2),
        (64, 32, 16, 32, 32, False, True, True): (1, 1, 1, 8),
        (64, 32, 16, 32, 32, True, False, False): (1, 1, 1, 2),
        (64, 32, 16, 32, 32, True, False, True): (1, 1, 1, 4),
        (64, 32, 32, 32, 32, False, False, False): (1, 1, 1, 4),
        (64, 32, 32, 32, 32, False, False, True): (1, 1, 2, 8),
        (64, 32, 32, 32, 32, False, True, False): (1, 1, 1, 8),
        (64, 32, 32, 32, 32, False, True, True): (1, 1, 1, 4),
        (64, 32, 32, 32, 32, True, False, False): (1, 1, 2, 4),
        (64, 32, 32, 32, 32, True, False, True): (1, 1, 3, 8),
        (64, 32, 64, 32, 32, False, False, False): (1, 2, 1, 4),
        (64, 32, 64, 32, 32, False, False, True): (2, 2, 1, 4),
        (64, 32, 64, 32, 32, False, True, False): (1, 1, 1, 4),
        (64, 32, 64, 32, 32, False, True, True): (1, 2, 1, 8),
        (64, 32, 64, 32, 32, True, False, False): (2, 2, 1, 4),
        (64, 32, 64, 32, 32, True, False, True): (1, 2, 1, 8),
        (64, 64, 16, 32, 32, False, False, False): (1, 1, 2, 8),
        (64, 64, 16, 32, 32, False, False, True): (2, 1, 2, 4),
        (64, 64, 16, 32, 32, False, True, False): (1, 1, 1, 2),
        (64, 64, 16, 32, 32, False, True, True): (1, 1, 2, 4),
        (64, 64, 16, 32, 32, True, False, False): (1, 1, 1, 2),
        (64, 64, 16, 32, 32, True, False, True): (1, 1, 2, 4),
        (64, 64, 32, 32, 32, False, False, False): (1, 1, 1, 4),
        (64, 64, 32, 32, 32, False, False, True): (2, 1, 1, 4),
        (64, 64, 32, 32, 32, False, True, False): (1, 1, 1, 8),
        (64, 64, 32, 32, 32, False, True, True): (2, 1, 1, 4),
        (64, 64, 32, 32, 32, True, False, False): (1, 1, 1, 4),
        (64, 64, 32, 32, 32, True, False, True): (1, 1, 1, 8),
        (64, 64, 64, 32, 32, False, False, False): (2, 2, 1, 4),
        (64, 64, 64, 32, 32, False, False, True): (1, 2, 1, 4),
        (64, 64, 64, 32, 32, False, True, False): (1, 2, 1, 4),
        (64, 64, 64, 32, 32, False, True, True): (2, 2, 1, 4),
        (64, 64, 64, 32, 32, True, False, False): (1, 1, 1, 8),
        (64, 64, 64, 32, 32, True, False, True): (1, 2, 2, 4),
        (256, 256, 256, 16, 16, False, True, True): (1, 16, 3, 4),
        (256, 256, 256, 16, 16, True, False, True): (2, 16, 1, 4),
        (256, 256, 256, 32, 32, False, True, True): (1, 8, 4, 8),
        (256, 256, 256, 32, 32, True, False, True): (4, 8, 4, 4),
        (256, 256, 256, 64, 64, False, True, True): (1, 4, 4, 8),
        (256, 256, 256, 64, 64, True, False, True): (1, 4, 3, 8),
        (256, 256, 256, 128, 128, False, True, True): (7, 2, 1, 32),
        (256, 256, 256, 128, 128, True, False, True): (3, 2, 1, 32),
        (256, 256, 512, 16, 16, False, True, True): (1, 16, 5, 4),
        (256, 256, 512, 16, 16, True, False, True): (1, 16, 3, 2),
        (256, 256, 512, 32, 32, False, True, True): (4, 16, 4, 4),
        (256, 256, 512, 32, 32, True, False, True): (4, 16, 3, 4),
        (256, 256, 512, 64, 64, False, True, True): (1, 8, 3, 8),
        (256, 256, 512, 64, 64, True, False, True): (1, 8, 3, 8),
        (256, 256, 512, 128, 128, False, True, True): (1, 4, 1, 32),
        (256, 256, 512, 128, 128, True, False, True): (3, 4, 1, 32),
        (256, 256, 1024, 16, 16, False, True, True): (3, 32, 5, 2),
        (256, 256, 1024, 16, 16, True, False, True): (2, 32, 5, 2),
        (256, 256, 1024, 32, 32, False, True, True): (1, 32, 4, 4),
        (256, 256, 1024, 32, 32, True, False, True): (1, 32, 5, 4),
        (256, 256, 1024, 64, 64, False, True, True): (4, 16, 3, 8),
        (256, 256, 1024, 64, 64, True, False, True): (1, 16, 3, 8),
        (256, 256, 1024, 128, 128, False, True, True): (1, 8, 1, 32),
        (256, 256, 1024, 128, 128, True, False, True): (3, 8, 1, 32),
        (256, 256, 2048, 16, 16, False, True, True): (3, 32, 3, 4),
        (256, 256, 2048, 16, 16, True, False, True): (1, 64, 3, 2),
        (256, 256, 2048, 32, 32, False, True, True): (1, 64, 3, 4),
        (256, 256, 2048, 32, 32, True, False, True): (1, 64, 3, 4),
        (256, 256, 2048, 64, 64, False, True, True): (2, 32, 1, 8),
        (256, 256, 2048, 64, 64, True, False, True): (2, 32, 1, 8),
        (256, 256, 2048, 128, 128, False, True, True): (4, 16, 1, 32),
        (256, 256, 2048, 128, 128, True, False, True): (4, 16, 1, 32),
        (256, 256, 4096, 16, 16, False, True, True): (1, 32, 2, 4),
        (256, 256, 4096, 16, 16, True, False, True): (1, 32, 3, 4),
        (256, 256, 4096, 32, 32, False, True, True): (1, 128, 2, 4),
        (256, 256, 4096, 32, 32, True, False, True): (1, 128, 2, 4),
        (256, 256, 4096, 64, 64, False, True, True): (2, 64, 4, 8),
        (256, 256, 4096, 64, 64, True, False, True): (3, 64, 2, 8),
        (256, 256, 4096, 128, 128, False, True, True): (3, 32, 1, 32),
        (256, 256, 4096, 128, 128, True, False, True): (2, 32, 1, 32),
        (256, 256, 8192, 16, 16, False, True, True): (1, 64, 3, 4),
        (256, 256, 8192, 16, 16, True, False, True): (2, 128, 3, 2),
        (256, 256, 8192, 32, 32, False, True, True): (3, 128, 3, 4),
        (256, 256, 8192, 32, 32, True, False, True): (1, 128, 3, 4),
        (256, 256, 8192, 64, 64, False, True, True): (3, 128, 1, 4),
        (256, 256, 8192, 64, 64, True, False, True): (4, 128, 2, 8),
        (256, 256, 8192, 128, 128, False, True, True): (6, 64, 1, 32),
        (256, 256, 8192, 128, 128, True, False, True): (2, 64, 1, 32),
        (256, 256, 16384, 16, 16, False, True, True): (4, 128, 3, 4),
        (256, 256, 16384, 16, 16, True, False, True): (3, 128, 3, 4),
        (256, 256, 16384, 32, 32, False, True, True): (4, 256, 3, 4),
        (256, 256, 16384, 32, 32, True, False, True): (2, 256, 3, 4),
        (256, 256, 16384, 64, 64, False, True, True): (3, 256, 1, 4),
        (256, 256, 16384, 64, 64, True, False, True): (2, 256, 2, 4),
        (256, 256, 16384, 128, 128, False, True, True): (1, 128, 1, 32),
        (256, 256, 16384, 128, 128, True, False, True): (3, 128, 1, 32),
        (256, 256, 32768, 16, 16, False, True, True): (1, 256, 3, 4),
        (256, 256, 32768, 16, 16, True, False, True): (2, 128, 3, 4),
        (256, 256, 32768, 32, 32, False, True, True): (2, 512, 3, 4),
        (256, 256, 32768, 32, 32, True, False, True): (4, 512, 3, 4),
        (256, 256, 32768, 64, 64, False, True, True): (1, 512, 1, 8),
        (256, 256, 32768, 64, 64, True, False, True): (1, 512, 2, 4),
        (256, 256, 32768, 128, 128, False, True, True): (1, 256, 1, 32),
        (256, 256, 32768, 128, 128, True, False, True): (1, 256, 1, 32),
        (256, 256, 65536, 16, 16, False, True, True): (2, 512, 3, 4),
        (256, 256, 65536, 16, 16, True, False, True): (1, 256, 3, 4),
        (256, 256, 65536, 32, 32, False, True, True): (1, 1024, 3, 4),
        (256, 256, 65536, 32, 32, True, False, True): (2, 1024, 3, 4),
        (256, 256, 65536, 64, 64, False, True, True): (1, 1024, 2, 4),
        (256, 256, 65536, 64, 64, True, False, True): (1, 1024, 2, 4),
        (256, 256, 65536, 128, 128, False, True, True): (1, 512, 1, 32),
        (256, 256, 65536, 128, 128, True, False, True): (2, 512, 1, 32),
        (256, 256, 131072, 16, 16, False, True, True): (1, 1024, 3, 4),
        (256, 256, 131072, 16, 16, True, False, True): (1, 512, 3, 4),
        (256, 256, 131072, 32, 32, False, True, True): (1, 2048, 3, 4),
        (256, 256, 131072, 32, 32, True, False, True): (1, 2048, 3, 4),
        (256, 256, 131072, 64, 64, False, True, True): (1, 2048, 1, 8),
        (256, 256, 131072, 64, 64, True, False, True): (1, 2048, 2, 4),
        (256, 256, 131072, 128, 128, False, True, True): (1, 1024, 1, 32),
        (256, 256, 131072, 128, 128, True, False, True): (4, 1024, 1, 32),
        (512, 512, 256, 16, 16, False, True, True): (1, 8, 4, 4),
        (512, 512, 256, 16, 16, True, False, True): (1, 8, 3, 2),
        (512, 512, 256, 32, 32, False, True, True): (4, 8, 3, 4),
        (512, 512, 256, 32, 32, True, False, True): (4, 8, 3, 4),
        (512, 512, 256, 64, 64, False, True, True): (3, 4, 3, 8),
        (512, 512, 256, 64, 64, True, False, True): (5, 4, 3, 8),
        (512, 512, 256, 128, 128, False, True, True): (1, 2, 1, 32),
        (512, 512, 256, 128, 128, True, False, True): (3, 2, 1, 32),
        (512, 512, 512, 16, 16, False, True, True): (2, 16, 3, 2),
        (512, 512, 512, 16, 16, True, False, True): (1, 8, 4, 4),
        (512, 512, 512, 32, 32, False, True, True): (3, 16, 3, 4),
        (512, 512, 512, 32, 32, True, False, True): (5, 16, 2, 4),
        (512, 512, 512, 64, 64, False, True, True): (1, 8, 3, 8),
        (512, 512, 512, 64, 64, True, False, True): (3, 8, 3, 8),
        (512, 512, 512, 128, 128, False, True, True): (1, 4, 1, 32),
        (512, 512, 512, 128, 128, True, False, True): (3, 4, 1, 16),
        (512, 512, 1024, 16, 16, False, True, True): (1, 16, 3, 4),
        (512, 512, 1024, 16, 16, True, False, True): (3, 16, 3, 4),
        (512, 512, 1024, 32, 32, False, True, True): (3, 32, 3, 4),
        (512, 512, 1024, 32, 32, True, False, True): (3, 32, 2, 4),
        (512, 512, 1024, 64, 64, False, True, True): (1, 16, 3, 8),
        (512, 512, 1024, 64, 64, True, False, True): (4, 16, 3, 8),
        (512, 512, 1024, 128, 128, False, True, True): (4, 8, 1, 32),
        (512, 512, 1024, 128, 128, True, False, True): (4, 8, 1, 32),
        (512, 512, 2048, 16, 16, False, True, True): (5, 16, 3, 4),
        (512, 512, 2048, 16, 16, True, False, True): (5, 16, 3, 4),
        (512, 512, 2048, 32, 32, False, True, True): (1, 32, 3, 4),
        (512, 512, 2048, 32, 32, True, False, True): (1, 32, 4, 4),
        (512, 512, 2048, 64, 64, False, True, True): (4, 32, 3, 8),
        (512, 512, 2048, 64, 64, True, False, True): (4, 32, 3, 8),
        (512, 512, 2048, 128, 128, False, True, True): (3, 16, 1, 32),
        (512, 512, 2048, 128, 128, True, False, True): (3, 16, 1, 32),
        (512, 512, 4096, 16, 16, False, True, True): (4, 32, 3, 4),
        (512, 512, 4096, 16, 16, True, False, True): (4, 64, 3, 2),
        (512, 512, 4096, 32, 32, False, True, True): (3, 64, 3, 4),
        (512, 512, 4096, 32, 32, True, False, True): (3, 64, 3, 4),
        (512, 512, 4096, 64, 64, False, True, True): (4, 64, 2, 4),
        (512, 512, 4096, 64, 64, True, False, True): (1, 64, 2, 4),
        (512, 512, 4096, 128, 128, False, True, True): (1, 32, 1, 32),
        (512, 512, 4096, 128, 128, True, False, True): (1, 32, 1, 32),
        (512, 512, 8192, 16, 16, False, True, True): (1, 64, 3, 4),
        (512, 512, 8192, 16, 16, True, False, True): (4, 64, 3, 4),
        (512, 512, 8192, 32, 32, False, True, True): (2, 128, 3, 4),
        (512, 512, 8192, 32, 32, True, False, True): (3, 128, 3, 4),
        (512, 512, 8192, 64, 64, False, True, True): (1, 128, 2, 4),
        (512, 512, 8192, 64, 64, True, False, True): (1, 128, 2, 4),
        (512, 512, 8192, 128, 128, False, True, True): (6, 64, 1, 32),
        (512, 512, 8192, 128, 128, True, False, True): (4, 64, 1, 32),
        (512, 512, 16384, 16, 16, False, True, True): (1, 128, 3, 4),
        (512, 512, 16384, 16, 16, True, False, True): (1, 64, 3, 4),
        (512, 512, 16384, 32, 32, False, True, True): (1, 256, 3, 4),
        (512, 512, 16384, 32, 32, True, False, True): (4, 256, 3, 4),
        (512, 512, 16384, 64, 64, False, True, True): (1, 256, 2, 4),
        (512, 512, 16384, 64, 64, True, False, True): (1, 256, 2, 4),
        (512, 512, 16384, 128, 128, False, True, True): (1, 128, 1, 32),
        (512, 512, 16384, 128, 128, True, False, True): (2, 128, 1, 32),
        (512, 512, 32768, 16, 16, False, True, True): (1, 256, 3, 4),
        (512, 512, 32768, 16, 16, True, False, True): (1, 128, 3, 4),
        (512, 512, 32768, 32, 32, False, True, True): (1, 512, 3, 4),
        (512, 512, 32768, 32, 32, True, False, True): (1, 512, 3, 4),
        (512, 512, 32768, 64, 64, False, True, True): (1, 512, 2, 4),
        (512, 512, 32768, 64, 64, True, False, True): (2, 512, 2, 4),
        (512, 512, 32768, 128, 128, False, True, True): (1, 256, 1, 32),
        (512, 512, 32768, 128, 128, True, False, True): (2, 256, 1, 32),
        (512, 512, 65536, 16, 16, False, True, True): (1, 512, 3, 4),
        (512, 512, 65536, 16, 16, True, False, True): (1, 256, 3, 4),
        (512, 512, 65536, 32, 32, False, True, True): (1, 1024, 3, 4),
        (512, 512, 65536, 32, 32, True, False, True): (1, 1024, 3, 4),
        (512, 512, 65536, 64, 64, False, True, True): (1, 1024, 2, 4),
        (512, 512, 65536, 64, 64, True, False, True): (1, 1024, 2, 4),
        (512, 512, 65536, 128, 128, False, True, True): (1, 512, 1, 32),
        (512, 512, 65536, 128, 128, True, False, True): (4, 512, 1, 32),
        (512, 512, 131072, 16, 16, False, True, True): (1, 512, 3, 4),
        (512, 512, 131072, 16, 16, True, False, True): (1, 512, 3, 4),
        (512, 512, 131072, 32, 32, False, True, True): (1, 2048, 3, 4),
        (512, 512, 131072, 32, 32, True, False, True): (1, 2048, 3, 4),
        (512, 512, 131072, 64, 64, False, True, True): (1, 2048, 2, 4),
        (512, 512, 131072, 64, 64, True, False, True): (1, 2048, 2, 4),
        (512, 512, 131072, 128, 128, False, True, True): (1, 1024, 1, 32),
        (512, 512, 131072, 128, 128, True, False, True): (2, 1024, 1, 32),
        (1024, 1024, 256, 16, 16, False, True, True): (4, 8, 3, 2),
        (1024, 1024, 256, 16, 16, True, False, True): (2, 8, 3, 2),
        (1024, 1024, 256, 32, 32, False, True, True): (1, 8, 3, 4),
        (1024, 1024, 256, 32, 32, True, False, True): (1, 8, 3, 4),
        (1024, 1024, 256, 64, 64, False, True, True): (1, 4, 3, 8),
        (1024, 1024, 256, 64, 64, True, False, True): (2, 4, 3, 8),
        (1024, 1024, 256, 128, 128, False, True, True): (3, 2, 1, 32),
        (1024, 1024, 256, 128, 128, True, False, True): (5, 2, 1, 32),
        (1024, 1024, 512, 16, 16, False, True, True): (3, 8, 3, 4),
        (1024, 1024, 512, 16, 16, True, False, True): (3, 8, 3, 4),
        (1024, 1024, 512, 32, 32, False, True, True): (1, 16, 3, 4),
        (1024, 1024, 512, 32, 32, True, False, True): (3, 16, 3, 4),
        (1024, 1024, 512, 64, 64, False, True, True): (6, 8, 3, 8),
        (1024, 1024, 512, 64, 64, True, False, True): (8, 8, 3, 8),
        (1024, 1024, 512, 128, 128, False, True, True): (1, 4, 1, 32),
        (1024, 1024, 512, 128, 128, True, False, True): (1, 4, 1, 32),
        (1024, 1024, 1024, 16, 16, False, True, True): (4, 8, 3, 4),
        (1024, 1024, 1024, 16, 16, True, False, True): (1, 8, 3, 4),
        (1024, 1024, 1024, 32, 32, False, True, True): (4, 16, 4, 4),
        (1024, 1024, 1024, 32, 32, True, False, True): (5, 16, 3, 4),
        (1024, 1024, 1024, 64, 64, False, True, True): (6, 16, 3, 8),
        (1024, 1024, 1024, 64, 64, True, False, True): (3, 16, 2, 4),
        (1024, 1024, 1024, 128, 128, False, True, True): (1, 8, 1, 32),
        (1024, 1024, 1024, 128, 128, True, False, True): (2, 8, 1, 32),
        (1024, 1024, 2048, 16, 16, False, True, True): (4, 16, 3, 4),
        (1024, 1024, 2048, 16, 16, True, False, True): (1, 16, 3, 4),
        (1024, 1024, 2048, 32, 32, False, True, True): (1, 32, 3, 4),
        (1024, 1024, 2048, 32, 32, True, False, True): (2, 32, 3, 4),
        (1024, 1024, 2048, 64, 64, False, True, True): (4, 32, 2, 4),
        (1024, 1024, 2048, 64, 64, True, False, True): (8, 32, 2, 4),
        (1024, 1024, 2048, 128, 128, False, True, True): (1, 16, 1, 32),
        (1024, 1024, 2048, 128, 128, True, False, True): (1, 16, 1, 32),
        (1024, 1024, 4096, 16, 16, False, True, True): (4, 32, 3, 4),
        (1024, 1024, 4096, 16, 16, True, False, True): (1, 64, 3, 2),
        (1024, 1024, 4096, 32, 32, False, True, True): (1, 64, 3, 4),
        (1024, 1024, 4096, 32, 32, True, False, True): (1, 64, 3, 4),
        (1024, 1024, 4096, 64, 64, False, True, True): (2, 64, 2, 4),
        (1024, 1024, 4096, 64, 64, True, False, True): (2, 64, 2, 4),
        (1024, 1024, 4096, 128, 128, False, True, True): (1, 32, 1, 32),
        (1024, 1024, 4096, 128, 128, True, False, True): (4, 32, 1, 32),
        (1024, 1024, 8192, 16, 16, False, True, True): (1, 128, 3, 1),
        (1024, 1024, 8192, 16, 16, True, False, True): (1, 128, 3, 1),
        (1024, 1024, 8192, 32, 32, False, True, True): (1, 128, 3, 4),
        (1024, 1024, 8192, 32, 32, True, False, True): (1, 128, 3, 4),
        (1024, 1024, 8192, 64, 64, False, True, True): (2, 128, 2, 4),
        (1024, 1024, 8192, 64, 64, True, False, True): (2, 128, 2, 4),
        (1024, 1024, 8192, 128, 128, False, True, True): (1, 64, 1, 32),
        (1024, 1024, 8192, 128, 128, True, False, True): (4, 64, 1, 32),
        (1024, 1024, 16384, 16, 16, False, True, True): (1, 128, 2, 4),
        (1024, 1024, 16384, 16, 16, True, False, True): (4, 256, 3, 1),
        (1024, 1024, 16384, 32, 32, False, True, True): (1, 256, 3, 4),
        (1024, 1024, 16384, 32, 32, True, False, True): (1, 256, 3, 4),
        (1024, 1024, 16384, 64, 64, False, True, True): (1, 256, 2, 4),
        (1024, 1024, 16384, 64, 64, True, False, True): (1, 256, 2, 4),
        (1024, 1024, 16384, 128, 128, False, True, True): (1, 128, 1, 32),
        (1024, 1024, 16384, 128, 128, True, False, True): (4, 128, 1, 32),
        (1024, 1024, 32768, 16, 16, False, True, True): (1, 256, 2, 4),
        (1024, 1024, 32768, 16, 16, True, False, True): (4, 512, 3, 1),
        (1024, 1024, 32768, 32, 32, False, True, True): (1, 512, 3, 4),
        (1024, 1024, 32768, 32, 32, True, False, True): (1, 512, 3, 4),
        (1024, 1024, 32768, 64, 64, False, True, True): (1, 512, 2, 4),
        (1024, 1024, 32768, 64, 64, True, False, True): (1, 512, 2, 4),
        (1024, 1024, 32768, 128, 128, False, True, True): (1, 256, 1, 32),
        (1024, 1024, 32768, 128, 128, True, False, True): (1, 256, 1, 32),
        (1024, 1024, 65536, 16, 16, False, True, True): (1, 512, 2, 4),
        (1024, 1024, 65536, 16, 16, True, False, True): (1, 1024, 3, 1),
        (1024, 1024, 65536, 32, 32, False, True, True): (1, 1024, 3, 4),
        (1024, 1024, 65536, 32, 32, True, False, True): (1, 512, 3, 4),
        (1024, 1024, 65536, 64, 64, False, True, True): (1, 1024, 2, 4),
        (1024, 1024, 65536, 64, 64, True, False, True): (1, 1024, 2, 4),
        (1024, 1024, 65536, 128, 128, False, True, True): (1, 512, 1, 32),
        (1024, 1024, 65536, 128, 128, True, False, True): (1, 512, 1, 32),
        (1024, 1024, 131072, 16, 16, False, True, True): (4, 2048, 3, 1),
        (1024, 1024, 131072, 16, 16, True, False, True): (4, 2048, 3, 1),
        (1024, 1024, 131072, 32, 32, False, True, True): (1, 2048, 3, 4),
        (1024, 1024, 131072, 32, 32, True, False, True): (1, 1024, 3, 4),
        (1024, 1024, 131072, 64, 64, False, True, True): (1, 2048, 2, 4),
        (1024, 1024, 131072, 64, 64, True, False, True): (1, 2048, 2, 4),
        (1024, 1024, 131072, 128, 128, False, True, True): (1, 1024, 1, 32),
        (1024, 1024, 131072, 128, 128, True, False, True): (1, 1024, 1, 32),
        (2048, 2048, 256, 16, 16, False, True, True): (1, 4, 3, 4),
        (2048, 2048, 256, 16, 16, True, False, True): (1, 4, 3, 4),
        (2048, 2048, 256, 32, 32, False, True, True): (3, 8, 3, 4),
        (2048, 2048, 256, 32, 32, True, False, True): (3, 8, 3, 4),
        (2048, 2048, 256, 64, 64, False, True, True): (4, 4, 4, 8),
        (2048, 2048, 256, 64, 64, True, False, True): (8, 4, 4, 8),
        (2048, 2048, 256, 128, 128, False, True, True): (3, 2, 1, 32),
        (2048, 2048, 256, 128, 128, True, False, True): (3, 2, 1, 32),
        (2048, 2048, 512, 16, 16, False, True, True): (4, 8, 3, 2),
        (2048, 2048, 512, 16, 16, True, False, True): (4, 8, 3, 2),
        (2048, 2048, 512, 32, 32, False, True, True): (3, 8, 3, 4),
        (2048, 2048, 512, 32, 32, True, False, True): (1, 16, 2, 4),
        (2048, 2048, 512, 64, 64, False, True, True): (4, 8, 2, 4),
        (2048, 2048, 512, 64, 64, True, False, True): (4, 8, 2, 4),
        (2048, 2048, 512, 128, 128, False, True, True): (1, 4, 1, 32),
        (2048, 2048, 512, 128, 128, True, False, True): (4, 4, 1, 32),
        (2048, 2048, 1024, 16, 16, False, True, True): (4, 8, 3, 4),
        (2048, 2048, 1024, 16, 16, True, False, True): (4, 8, 3, 4),
        (2048, 2048, 1024, 32, 32, False, True, True): (4, 16, 3, 4),
        (2048, 2048, 1024, 32, 32, True, False, True): (1, 16, 3, 4),
        (2048, 2048, 1024, 64, 64, False, True, True): (2, 16, 2, 4),
        (2048, 2048, 1024, 64, 64, True, False, True): (2, 16, 2, 4),
        (2048, 2048, 1024, 128, 128, False, True, True): (8, 8, 1, 32),
        (2048, 2048, 1024, 128, 128, True, False, True): (4, 8, 1, 32),
        (2048, 2048, 2048, 16, 16, False, True, True): (4, 32, 3, 1),
        (2048, 2048, 2048, 16, 16, True, False, True): (3, 32, 3, 2),
        (2048, 2048, 2048, 32, 32, False, True, True): (1, 32, 3, 4),
        (2048, 2048, 2048, 32, 32, True, False, True): (1, 32, 3, 4),
        (2048, 2048, 2048, 64, 64, False, True, True): (2, 32, 2, 4),
        (2048, 2048, 2048, 64, 64, True, False, True): (2, 32, 2, 4),
        (2048, 2048, 2048, 128, 128, False, True, True): (6, 16, 1, 32),
        (2048, 2048, 2048, 128, 128, True, False, True): (4, 16, 1, 32),
        (2048, 2048, 4096, 16, 16, False, True, True): (4, 64, 3, 1),
        (2048, 2048, 4096, 16, 16, True, False, True): (1, 64, 3, 1),
        (2048, 2048, 4096, 32, 32, False, True, True): (1, 64, 3, 4),
        (2048, 2048, 4096, 32, 32, True, False, True): (4, 64, 3, 4),
        (2048, 2048, 4096, 64, 64, False, True, True): (2, 64, 2, 4),
        (2048, 2048, 4096, 64, 64, True, False, True): (2, 64, 2, 4),
        (2048, 2048, 4096, 128, 128, False, True, True): (4, 32, 1, 32),
        (2048, 2048, 4096, 128, 128, True, False, True): (4, 32, 1, 32),
        (2048, 2048, 8192, 16, 16, False, True, True): (4, 128, 3, 1),
        (2048, 2048, 8192, 16, 16, True, False, True): (1, 128, 3, 1),
        (2048, 2048, 8192, 32, 32, False, True, True): (4, 128, 3, 4),
        (2048, 2048, 8192, 32, 32, True, False, True): (4, 64, 3, 4),
        (2048, 2048, 8192, 64, 64, False, True, True): (1, 128, 2, 4),
        (2048, 2048, 8192, 64, 64, True, False, True): (2, 128, 2, 4),
        (2048, 2048, 8192, 128, 128, False, True, True): (1, 64, 1, 32),
        (2048, 2048, 8192, 128, 128, True, False, True): (4, 64, 1, 32),
        (2048, 2048, 16384, 16, 16, False, True, True): (4, 256, 3, 1),
        (2048, 2048, 16384, 16, 16, True, False, True): (1, 256, 3, 1),
        (2048, 2048, 16384, 32, 32, False, True, True): (1, 256, 3, 4),
        (2048, 2048, 16384, 32, 32, True, False, True): (1, 128, 3, 4),
        (2048, 2048, 16384, 64, 64, False, True, True): (1, 256, 2, 4),
        (2048, 2048, 16384, 64, 64, True, False, True): (1, 256, 2, 4),
        (2048, 2048, 16384, 128, 128, False, True, True): (1, 128, 1, 32),
        (2048, 2048, 16384, 128, 128, True, False, True): (4, 128, 1, 32),
        (2048, 2048, 32768, 16, 16, False, True, True): (8, 512, 3, 1),
        (2048, 2048, 32768, 16, 16, True, False, True): (1, 512, 3, 1),
        (2048, 2048, 32768, 32, 32, False, True, True): (1, 512, 3, 4),
        (2048, 2048, 32768, 32, 32, True, False, True): (1, 256, 3, 4),
        (2048, 2048, 32768, 64, 64, False, True, True): (1, 512, 2, 4),
        (2048, 2048, 32768, 64, 64, True, False, True): (1, 512, 2, 4),
        (2048, 2048, 32768, 128, 128, False, True, True): (1, 256, 1, 32),
        (2048, 2048, 32768, 128, 128, True, False, True): (4, 256, 1, 32),
        (2048, 2048, 65536, 16, 16, False, True, True): (4, 1024, 3, 1),
        (2048, 2048, 65536, 16, 16, True, False, True): (1, 1024, 3, 1),
        (2048, 2048, 65536, 32, 32, False, True, True): (1, 1024, 3, 4),
        (2048, 2048, 65536, 32, 32, True, False, True): (1, 512, 3, 4),
        (2048, 2048, 65536, 64, 64, False, True, True): (1, 1024, 2, 4),
        (2048, 2048, 65536, 64, 64, True, False, True): (1, 1024, 2, 4),
        (2048, 2048, 65536, 128, 128, False, True, True): (1, 512, 1, 32),
        (2048, 2048, 65536, 128, 128, True, False, True): (4, 512, 1, 32),
        (2048, 2048, 131072, 16, 16, False, True, True): (4, 2048, 3, 1),
        (2048, 2048, 131072, 16, 16, True, False, True): (1, 2048, 3, 1),
        (2048, 2048, 131072, 32, 32, False, True, True): (1, 2048, 3, 4),
        (2048, 2048, 131072, 32, 32, True, False, True): (1, 1024, 3, 4),
        (2048, 2048, 131072, 64, 64, False, True, True): (1, 2048, 2, 4),
        (2048, 2048, 131072, 64, 64, True, False, True): (1, 2048, 2, 4),
        (2048, 2048, 131072, 128, 128, False, True, True): (1, 1024, 1, 32),
        (2048, 2048, 131072, 128, 128, True, False, True): (4, 1024, 1, 32),
        (4096, 4096, 256, 16, 16, False, True, True): (1, 4, 3, 2),
        (4096, 4096, 256, 16, 16, True, False, True): (1, 2, 3, 4),
        (4096, 4096, 256, 32, 32, False, True, True): (4, 4, 4, 4),
        (4096, 4096, 256, 32, 32, True, False, True): (4, 4, 4, 4),
        (4096, 4096, 256, 64, 64, False, True, True): (1, 4, 3, 8),
        (4096, 4096, 256, 64, 64, True, False, True): (4, 4, 2, 4),
        (4096, 4096, 256, 128, 128, False, True, True): (1, 2, 1, 32),
        (4096, 4096, 256, 128, 128, True, False, True): (3, 2, 1, 32),
        (4096, 4096, 512, 16, 16, False, True, True): (1, 4, 3, 4),
        (4096, 4096, 512, 16, 16, True, False, True): (5, 8, 3, 2),
        (4096, 4096, 512, 32, 32, False, True, True): (4, 8, 3, 4),
        (4096, 4096, 512, 32, 32, True, False, True): (4, 8, 3, 4),
        (4096, 4096, 512, 64, 64, False, True, True): (1, 8, 2, 4),
        (4096, 4096, 512, 64, 64, True, False, True): (1, 8, 2, 4),
        (4096, 4096, 512, 128, 128, False, True, True): (4, 4, 1, 32),
        (4096, 4096, 512, 128, 128, True, False, True): (4, 4, 1, 32),
        (4096, 4096, 1024, 16, 16, False, True, True): (1, 8, 3, 4),
        (4096, 4096, 1024, 16, 16, True, False, True): (1, 8, 3, 4),
        (4096, 4096, 1024, 32, 32, False, True, True): (1, 16, 3, 4),
        (4096, 4096, 1024, 32, 32, True, False, True): (1, 16, 3, 4),
        (4096, 4096, 1024, 64, 64, False, True, True): (4, 16, 2, 4),
        (4096, 4096, 1024, 64, 64, True, False, True): (4, 16, 2, 4),
        (4096, 4096, 1024, 128, 128, False, True, True): (4, 8, 1, 32),
        (4096, 4096, 1024, 128, 128, True, False, True): (4, 8, 1, 32),
        (4096, 4096, 2048, 16, 16, False, True, True): (1, 32, 3, 1),
        (4096, 4096, 2048, 16, 16, True, False, True): (6, 8, 3, 4),
        (4096, 4096, 2048, 32, 32, False, True, True): (1, 32, 3, 4),
        (4096, 4096, 2048, 32, 32, True, False, True): (1, 32, 3, 4),
        (4096, 4096, 2048, 64, 64, False, True, True): (4, 32, 2, 4),
        (4096, 4096, 2048, 64, 64, True, False, True): (4, 32, 2, 4),
        (4096, 4096, 2048, 128, 128, False, True, True): (4, 16, 1, 32),
        (4096, 4096, 2048, 128, 128, True, False, True): (4, 16, 1, 32),
        (4096, 4096, 4096, 16, 16, False, True, True): (1, 16, 3, 4),
        (4096, 4096, 4096, 16, 16, True, False, True): (1, 64, 3, 1),
        (4096, 4096, 4096, 32, 32, False, True, True): (1, 64, 3, 4),
        (4096, 4096, 4096, 32, 32, True, False, True): (1, 32, 3, 4),
        (4096, 4096, 4096, 64, 64, False, True, True): (4, 64, 2, 4),
        (4096, 4096, 4096, 64, 64, True, False, True): (4, 64, 2, 4),
        (4096, 4096, 4096, 128, 128, False, True, True): (4, 32, 1, 32),
        (4096, 4096, 4096, 128, 128, True, False, True): (4, 32, 1, 32),
        (4096, 4096, 8192, 16, 16, False, True, True): (4, 128, 3, 1),
        (4096, 4096, 8192, 16, 16, True, False, True): (1, 128, 3, 1),
        (4096, 4096, 8192, 32, 32, False, True, True): (1, 128, 3, 4),
        (4096, 4096, 8192, 32, 32, True, False, True): (1, 64, 3, 4),
        (4096, 4096, 8192, 64, 64, False, True, True): (4, 128, 2, 4),
        (4096, 4096, 8192, 64, 64, True, False, True): (4, 128, 2, 4),
        (4096, 4096, 8192, 128, 128, False, True, True): (4, 64, 1, 32),
        (4096, 4096, 8192, 128, 128, True, False, True): (4, 64, 1, 32),
        (4096, 4096, 16384, 16, 16, False, True, True): (1, 64, 3, 4),
        (4096, 4096, 16384, 16, 16, True, False, True): (1, 256, 3, 1),
        (4096, 4096, 16384, 32, 32, False, True, True): (1, 256, 3, 4),
        (4096, 4096, 16384, 32, 32, True, False, True): (1, 128, 3, 4),
        (4096, 4096, 16384, 64, 64, False, True, True): (4, 256, 2, 4),
        (4096, 4096, 16384, 64, 64, True, False, True): (4, 256, 2, 4),
        (4096, 4096, 16384, 128, 128, False, True, True): (4, 128, 1, 32),
        (4096, 4096, 16384, 128, 128, True, False, True): (4, 128, 1, 32),
        (4096, 4096, 32768, 16, 16, False, True, True): (1, 128, 3, 4),
        (4096, 4096, 32768, 16, 16, True, False, True): (1, 512, 3, 1),
        (4096, 4096, 32768, 32, 32, False, True, True): (1, 512, 3, 4),
        (4096, 4096, 32768, 32, 32, True, False, True): (1, 256, 3, 4),
        (4096, 4096, 32768, 64, 64, False, True, True): (4, 512, 2, 4),
        (4096, 4096, 32768, 64, 64, True, False, True): (4, 512, 2, 4),
        (4096, 4096, 32768, 128, 128, False, True, True): (4, 256, 1, 32),
        (4096, 4096, 32768, 128, 128, True, False, True): (4, 256, 1, 32),
        (4096, 4096, 65536, 16, 16, False, True, True): (1, 256, 3, 4),
        (4096, 4096, 65536, 16, 16, True, False, True): (1, 1024, 3, 1),
        (4096, 4096, 65536, 32, 32, False, True, True): (1, 1024, 3, 4),
        (4096, 4096, 65536, 32, 32, True, False, True): (1, 512, 3, 4),
        (4096, 4096, 65536, 64, 64, False, True, True): (4, 1024, 2, 4),
        (4096, 4096, 65536, 64, 64, True, False, True): (2, 1024, 2, 4),
        (4096, 4096, 65536, 128, 128, False, True, True): (4, 512, 1, 32),
        (4096, 4096, 65536, 128, 128, True, False, True): (4, 512, 1, 32),
        (4096, 4096, 131072, 16, 16, False, True, True): (2, 2048, 3, 1),
        (4096, 4096, 131072, 16, 16, True, False, True): (1, 2048, 3, 1),
        (4096, 4096, 131072, 32, 32, False, True, True): (2, 2048, 3, 4),
        (4096, 4096, 131072, 32, 32, True, False, True): (1, 1024, 3, 4),
        (4096, 4096, 131072, 64, 64, False, True, True): (2, 2048, 2, 4),
        (4096, 4096, 131072, 64, 64, True, False, True): (2, 2048, 2, 4),
        (4096, 4096, 131072, 128, 128, False, True, True): (4, 1024, 1, 32),
        (4096, 4096, 131072, 128, 128, True, False, True): (4, 1024, 1, 32),
        (8192, 8192, 256, 16, 16, False, True, True): (2, 2, 4, 4),
        (8192, 8192, 256, 16, 16, True, False, True): (1, 1, 3, 4),
        (8192, 8192, 256, 32, 32, False, True, True): (2, 4, 3, 4),
        (8192, 8192, 256, 32, 32, True, False, True): (2, 4, 3, 4),
        (8192, 8192, 256, 64, 64, False, True, True): (4, 4, 2, 4),
        (8192, 8192, 256, 64, 64, True, False, True): (4, 4, 2, 4),
        (8192, 8192, 256, 128, 128, False, True, True): (1, 2, 1, 32),
        (8192, 8192, 256, 128, 128, True, False, True): (4, 2, 1, 32),
        (8192, 8192, 512, 16, 16, False, True, True): (1, 4, 3, 4),
        (8192, 8192, 512, 16, 16, True, False, True): (3, 4, 3, 4),
        (8192, 8192, 512, 32, 32, False, True, True): (1, 8, 3, 4),
        (8192, 8192, 512, 32, 32, True, False, True): (6, 8, 3, 4),
        (8192, 8192, 512, 64, 64, False, True, True): (4, 8, 2, 4),
        (8192, 8192, 512, 64, 64, True, False, True): (4, 8, 2, 4),
        (8192, 8192, 512, 128, 128, False, True, True): (4, 4, 1, 32),
        (8192, 8192, 512, 128, 128, True, False, True): (4, 4, 1, 32),
        (8192, 8192, 1024, 16, 16, False, True, True): (1, 4, 3, 4),
        (8192, 8192, 1024, 16, 16, True, False, True): (1, 32, 3, 1),
        (8192, 8192, 1024, 32, 32, False, True, True): (1, 16, 3, 4),
        (8192, 8192, 1024, 32, 32, True, False, True): (1, 16, 3, 4),
        (8192, 8192, 1024, 64, 64, False, True, True): (4, 16, 2, 4),
        (8192, 8192, 1024, 64, 64, True, False, True): (4, 16, 2, 4),
        (8192, 8192, 1024, 128, 128, False, True, True): (4, 8, 1, 32),
        (8192, 8192, 1024, 128, 128, True, False, True): (4, 8, 1, 32),
        (8192, 8192, 2048, 16, 16, False, True, True): (4, 8, 3, 4),
        (8192, 8192, 2048, 16, 16, True, False, True): (1, 32, 3, 1),
        (8192, 8192, 2048, 32, 32, False, True, True): (1, 32, 3, 4),
        (8192, 8192, 2048, 32, 32, True, False, True): (1, 16, 4, 4),
        (8192, 8192, 2048, 64, 64, False, True, True): (4, 32, 2, 4),
        (8192, 8192, 2048, 64, 64, True, False, True): (4, 32, 2, 4),
        (8192, 8192, 2048, 128, 128, False, True, True): (4, 16, 1, 32),
        (8192, 8192, 2048, 128, 128, True, False, True): (4, 16, 1, 32),
        (8192, 8192, 4096, 16, 16, False, True, True): (3, 16, 3, 4),
        (8192, 8192, 4096, 16, 16, True, False, True): (2, 64, 3, 1),
        (8192, 8192, 4096, 32, 32, False, True, True): (1, 64, 3, 4),
        (8192, 8192, 4096, 32, 32, True, False, True): (1, 32, 3, 4),
        (8192, 8192, 4096, 64, 64, False, True, True): (4, 64, 2, 4),
        (8192, 8192, 4096, 64, 64, True, False, True): (2, 64, 2, 4),
        (8192, 8192, 4096, 128, 128, False, True, True): (4, 32, 1, 32),
        (8192, 8192, 4096, 128, 128, True, False, True): (4, 32, 1, 32),
        (8192, 8192, 8192, 16, 16, False, True, True): (2, 128, 3, 1),
        (8192, 8192, 8192, 16, 16, True, False, True): (2, 128, 3, 1),
        (8192, 8192, 8192, 32, 32, False, True, True): (1, 128, 3, 4),
        (8192, 8192, 8192, 32, 32, True, False, True): (1, 64, 3, 4),
        (8192, 8192, 8192, 64, 64, False, True, True): (4, 128, 2, 4),
        (8192, 8192, 8192, 64, 64, True, False, True): (2, 128, 2, 4),
        (8192, 8192, 8192, 128, 128, False, True, True): (4, 64, 1, 32),
        (8192, 8192, 8192, 128, 128, True, False, True): (4, 64, 1, 32),
        (8192, 8192, 16384, 16, 16, False, True, True): (1, 64, 3, 4),
        (8192, 8192, 16384, 16, 16, True, False, True): (1, 256, 3, 1),
        (8192, 8192, 16384, 32, 32, False, True, True): (1, 256, 3, 4),
        (8192, 8192, 16384, 32, 32, True, False, True): (1, 128, 3, 4),
        (8192, 8192, 16384, 64, 64, False, True, True): (2, 256, 2, 4),
        (8192, 8192, 16384, 64, 64, True, False, True): (2, 256, 2, 4),
        (8192, 8192, 16384, 128, 128, False, True, True): (4, 128, 1, 32),
        (8192, 8192, 16384, 128, 128, True, False, True): (4, 128, 1, 32),
        (8192, 8192, 32768, 16, 16, False, True, True): (1, 512, 3, 1),
        (8192, 8192, 32768, 16, 16, True, False, True): (1, 512, 3, 1),
        (8192, 8192, 32768, 32, 32, False, True, True): (1, 512, 3, 4),
        (8192, 8192, 32768, 32, 32, True, False, True): (1, 256, 3, 4),
        (8192, 8192, 32768, 64, 64, False, True, True): (2, 512, 2, 4),
        (8192, 8192, 32768, 64, 64, True, False, True): (2, 512, 2, 4),
        (8192, 8192, 32768, 128, 128, False, True, True): (4, 256, 1, 32),
        (8192, 8192, 32768, 128, 128, True, False, True): (4, 256, 1, 32),
        (8192, 8192, 65536, 16, 16, False, True, True): (1, 256, 3, 4),
        (8192, 8192, 65536, 16, 16, True, False, True): (1, 1024, 3, 1),
        (8192, 8192, 65536, 32, 32, False, True, True): (1, 1024, 3, 4),
        (8192, 8192, 65536, 32, 32, True, False, True): (1, 512, 3, 4),
        (8192, 8192, 65536, 64, 64, False, True, True): (4, 1024, 2, 4),
        (8192, 8192, 65536, 64, 64, True, False, True): (2, 1024, 2, 4),
        (8192, 8192, 65536, 128, 128, False, True, True): (4, 512, 1, 32),
        (8192, 8192, 65536, 128, 128, True, False, True): (4, 512, 1, 32),
        (8192, 8192, 131072, 16, 16, False, True, True): (1, 2048, 3, 1),
        (8192, 8192, 131072, 16, 16, True, False, True): (2, 2048, 3, 1),
        (8192, 8192, 131072, 32, 32, False, True, True): (4, 2048, 3, 4),
        (8192, 8192, 131072, 32, 32, True, False, True): (1, 1024, 3, 4),
        (8192, 8192, 131072, 64, 64, False, True, True): (2, 2048, 2, 4),
        (8192, 8192, 131072, 64, 64, True, False, True): (2, 2048, 2, 4),
        (8192, 8192, 131072, 128, 128, False, True, True): (4, 1024, 1, 32),
        (8192, 8192, 131072, 128, 128, True, False, True): (4, 1024, 1, 32),
        (16384, 16384, 256, 16, 16, False, True, True): (1, 2, 3, 4),
        (16384, 16384, 256, 16, 16, True, False, True): (1, 2, 3, 4),
        (16384, 16384, 256, 32, 32, False, True, True): (1, 4, 3, 4),
        (16384, 16384, 256, 32, 32, True, False, True): (1, 4, 3, 4),
        (16384, 16384, 256, 64, 64, False, True, True): (2, 4, 2, 4),
        (16384, 16384, 256, 64, 64, True, False, True): (2, 4, 2, 4),
        (16384, 16384, 256, 128, 128, False, True, True): (2, 2, 1, 32),
        (16384, 16384, 256, 128, 128, True, False, True): (2, 2, 1, 32),
        (16384, 16384, 512, 16, 16, False, True, True): (1, 2, 3, 4),
        (16384, 16384, 512, 16, 16, True, False, True): (5, 2, 3, 4),
        (16384, 16384, 512, 32, 32, False, True, True): (1, 8, 3, 4),
        (16384, 16384, 512, 32, 32, True, False, True): (1, 4, 3, 4),
        (16384, 16384, 512, 64, 64, False, True, True): (4, 8, 2, 4),
        (16384, 16384, 512, 64, 64, True, False, True): (4, 8, 2, 4),
        (16384, 16384, 512, 128, 128, False, True, True): (4, 4, 1, 32),
        (16384, 16384, 512, 128, 128, True, False, True): (4, 4, 1, 32),
        (16384, 16384, 1024, 16, 16, False, True, True): (1, 4, 3, 4),
        (16384, 16384, 1024, 16, 16, True, False, True): (2, 16, 3, 1),
        (16384, 16384, 1024, 32, 32, False, True, True): (1, 16, 3, 4),
        (16384, 16384, 1024, 32, 32, True, False, True): (1, 8, 3, 4),
        (16384, 16384, 1024, 64, 64, False, True, True): (4, 16, 2, 4),
        (16384, 16384, 1024, 64, 64, True, False, True): (4, 16, 2, 4),
        (16384, 16384, 1024, 128, 128, False, True, True): (4, 8, 1, 32),
        (16384, 16384, 1024, 128, 128, True, False, True): (4, 8, 1, 32),
        (16384, 16384, 2048, 16, 16, False, True, True): (1, 8, 3, 4),
        (16384, 16384, 2048, 16, 16, True, False, True): (2, 32, 3, 1),
        (16384, 16384, 2048, 32, 32, False, True, True): (1, 32, 3, 4),
        (16384, 16384, 2048, 32, 32, True, False, True): (1, 16, 3, 4),
        (16384, 16384, 2048, 64, 64, False, True, True): (4, 32, 2, 4),
        (16384, 16384, 2048, 64, 64, True, False, True): (2, 32, 2, 4),
        (16384, 16384, 2048, 128, 128, False, True, True): (4, 16, 1, 32),
        (16384, 16384, 2048, 128, 128, True, False, True): (4, 16, 1, 32),
        (16384, 16384, 4096, 16, 16, False, True, True): (1, 16, 3, 4),
        (16384, 16384, 4096, 16, 16, True, False, True): (2, 64, 3, 1),
        (16384, 16384, 4096, 32, 32, False, True, True): (1, 64, 3, 4),
        (16384, 16384, 4096, 32, 32, True, False, True): (1, 32, 3, 4),
        (16384, 16384, 4096, 64, 64, False, True, True): (4, 64, 2, 4),
        (16384, 16384, 4096, 64, 64, True, False, True): (2, 64, 2, 4),
        (16384, 16384, 4096, 128, 128, False, True, True): (4, 32, 1, 32),
        (16384, 16384, 4096, 128, 128, True, False, True): (4, 32, 1, 32),
        (16384, 16384, 8192, 16, 16, False, True, True): (1, 128, 3, 1),
        (16384, 16384, 8192, 16, 16, True, False, True): (2, 128, 3, 1),
        (16384, 16384, 8192, 32, 32, False, True, True): (1, 128, 3, 4),
        (16384, 16384, 8192, 32, 32, True, False, True): (1, 64, 3, 4),
        (16384, 16384, 8192, 64, 64, False, True, True): (2, 128, 2, 4),
        (16384, 16384, 8192, 64, 64, True, False, True): (2, 128, 2, 4),
        (16384, 16384, 8192, 128, 128, False, True, True): (4, 64, 1, 32),
        (16384, 16384, 8192, 128, 128, True, False, True): (4, 64, 1, 32),
        (16384, 16384, 16384, 16, 16, False, True, True): (1, 64, 3, 4),
        (16384, 16384, 16384, 16, 16, True, False, True): (2, 256, 3, 1),
        (16384, 16384, 16384, 32, 32, False, True, True): (1, 256, 3, 4),
        (16384, 16384, 16384, 32, 32, True, False, True): (1, 128, 3, 4),
        (16384, 16384, 16384, 64, 64, False, True, True): (2, 256, 2, 4),
        (16384, 16384, 16384, 64, 64, True, False, True): (2, 256, 2, 4),
        (16384, 16384, 16384, 128, 128, False, True, True): (4, 128, 1, 32),
        (16384, 16384, 16384, 128, 128, True, False, True): (4, 128, 1, 32),
        (16384, 16384, 32768, 16, 16, False, True, True): (1, 512, 3, 1),
        (16384, 16384, 32768, 16, 16, True, False, True): (1, 128, 3, 4),
        (16384, 16384, 32768, 32, 32, False, True, True): (2, 512, 3, 4),
        (16384, 16384, 32768, 32, 32, True, False, True): (1, 256, 4, 4),
        (16384, 16384, 32768, 64, 64, False, True, True): (2, 512, 2, 4),
        (16384, 16384, 32768, 64, 64, True, False, True): (2, 512, 2, 4),
        (16384, 16384, 32768, 128, 128, False, True, True): (4, 256, 1, 32),
        (16384, 16384, 32768, 128, 128, True, False, True): (4, 256, 1, 32),
        (16384, 16384, 65536, 16, 16, False, True, True): (1, 256, 3, 4),
        (16384, 16384, 65536, 16, 16, True, False, True): (1, 1024, 3, 1),
        (16384, 16384, 65536, 32, 32, False, True, True): (1, 1024, 3, 4),
        (16384, 16384, 65536, 32, 32, True, False, True): (1, 512, 4, 4),
        (16384, 16384, 65536, 64, 64, False, True, True): (2, 1024, 2, 4),
        (16384, 16384, 65536, 64, 64, True, False, True): (2, 1024, 2, 4),
        (16384, 16384, 65536, 128, 128, False, True, True): (4, 512, 1, 32),
        (16384, 16384, 65536, 128, 128, True, False, True): (4, 512, 1, 32),
        (16384, 16384, 131072, 16, 16, False, True, True): (1, 1024, 4, 4),
        (16384, 16384, 131072, 16, 16, True, False, True): (2, 2048, 3, 1),
        (16384, 16384, 131072, 32, 32, False, True, True): (1, 1024, 2, 4),
        (16384, 16384, 131072, 32, 32, True, False, True): (1, 1024, 2, 4),
        (16384, 16384, 131072, 64, 64, False, True, True): (4, 2048, 2, 4),
        (16384, 16384, 131072, 64, 64, True, False, True): (2, 2048, 2, 4),
        (16384, 16384, 131072, 128, 128, False, True, True): (4, 1024, 1, 32),
        (16384, 16384, 131072, 128, 128, True, False, True): (4, 1024, 1, 32),
    },
    ("scatter_mm", "NVIDIA A100-SXM4-80GB", (0, torch.bfloat16, 0.5)): {
        (256, 256, 256, 16, 16): (1, 1, 16, 16, 1, 2),
        (256, 256, 256, 32, 32): (1, 1, 16, 16, 1, 4),
        (256, 256, 256, 64, 64): (1, 1, 16, 16, 1, 1),
        (256, 256, 256, 128, 128): (2, 4, 16, 64, 1, 4),
        (256, 256, 512, 16, 16): (1, 1, 16, 16, 1, 4),
        (256, 256, 512, 32, 32): (1, 1, 16, 32, 1, 4),
        (256, 256, 512, 64, 64): (1, 1, 16, 32, 1, 1),
        (256, 256, 512, 128, 128): (1, 1, 32, 32, 1, 4),
        (256, 256, 1024, 16, 16): (1, 1, 16, 16, 1, 4),
        (256, 256, 1024, 32, 32): (1, 2, 16, 32, 1, 1),
        (256, 256, 1024, 64, 64): (1, 1, 32, 32, 1, 2),
        (256, 256, 1024, 128, 128): (1, 1, 32, 64, 1, 4),
        (256, 256, 2048, 16, 16): (1, 1, 16, 64, 1, 8),
        (256, 256, 2048, 32, 32): (2, 1, 32, 64, 1, 2),
        (256, 256, 2048, 64, 64): (1, 1, 32, 32, 1, 1),
        (256, 256, 2048, 128, 128): (1, 1, 64, 64, 1, 4),
        (256, 256, 4096, 16, 16): (1, 1, 16, 64, 1, 1),
        (256, 256, 4096, 32, 32): (2, 2, 32, 64, 1, 2),
        (256, 256, 4096, 64, 64): (1, 1, 32, 128, 1, 4),
        (256, 256, 4096, 128, 128): (1, 1, 64, 64, 1, 4),
        (256, 256, 8192, 16, 16): (1, 2, 16, 64, 1, 2),
        (256, 256, 8192, 32, 32): (1, 1, 32, 64, 1, 2),
        (256, 256, 8192, 64, 64): (1, 1, 32, 64, 1, 2),
        (256, 256, 8192, 128, 128): (1, 1, 64, 64, 1, 4),
        (256, 256, 16384, 16, 16): (1, 1, 16, 64, 1, 2),
        (256, 256, 16384, 32, 32): (1, 1, 32, 64, 1, 2),
        (256, 256, 16384, 64, 64): (1, 1, 64, 64, 1, 2),
        (256, 256, 16384, 128, 128): (2, 16, 64, 64, 1, 4),
        (256, 256, 32768, 16, 16): (1, 1, 16, 128, 1, 2),
        (256, 256, 32768, 32, 32): (1, 1, 32, 64, 1, 2),
        (256, 256, 32768, 64, 64): (1, 1, 64, 64, 1, 2),
        (256, 256, 32768, 128, 128): (2, 32, 64, 64, 1, 4),
        (256, 256, 65536, 16, 16): (1, 1, 16, 64, 1, 1),
        (256, 256, 65536, 32, 32): (1, 1, 32, 64, 1, 2),
        (256, 256, 65536, 64, 64): (1, 1, 64, 32, 1, 1),
        (256, 256, 65536, 128, 128): (2, 32, 64, 64, 1, 4),
        (256, 256, 131072, 16, 16): (1, 1, 16, 64, 1, 1),
        (256, 256, 131072, 32, 32): (1, 1, 32, 64, 1, 2),
        (256, 256, 131072, 64, 64): (4, 1, 64, 32, 1, 1),
        (256, 256, 131072, 128, 128): (2, 64, 64, 64, 1, 4),
        (512, 512, 256, 16, 16): (1, 1, 16, 16, 1, 2),
        (512, 512, 256, 32, 32): (1, 1, 16, 32, 1, 1),
        (512, 512, 256, 64, 64): (1, 2, 16, 32, 1, 1),
        (512, 512, 256, 128, 128): (2, 16, 64, 16, 2, 4),
        (512, 512, 512, 16, 16): (1, 1, 16, 16, 1, 4),
        (512, 512, 512, 32, 32): (1, 1, 16, 32, 1, 1),
        (512, 512, 512, 64, 64): (1, 1, 32, 32, 1, 2),
        (512, 512, 512, 128, 128): (2, 8, 32, 64, 1, 4),
        (512, 512, 1024, 16, 16): (1, 1, 16, 64, 1, 8),
        (512, 512, 1024, 32, 32): (1, 1, 32, 32, 3, 1),
        (512, 512, 1024, 64, 64): (1, 4, 32, 64, 1, 2),
        (512, 512, 1024, 128, 128): (1, 4, 64, 64, 1, 4),
        (512, 512, 2048, 16, 16): (1, 1, 16, 64, 1, 2),
        (512, 512, 2048, 32, 32): (1, 1, 32, 64, 1, 2),
        (512, 512, 2048, 64, 64): (1, 1, 64, 64, 3, 4),
        (512, 512, 2048, 128, 128): (1, 1, 64, 64, 1, 4),
        (512, 512, 4096, 16, 16): (1, 1, 16, 64, 1, 2),
        (512, 512, 4096, 32, 32): (2, 64, 32, 64, 1, 2),
        (512, 512, 4096, 64, 64): (1, 1, 64, 64, 3, 4),
        (512, 512, 4096, 128, 128): (1, 1, 64, 64, 1, 4),
        (512, 512, 8192, 16, 16): (1, 2, 16, 128, 1, 2),
        (512, 512, 8192, 32, 32): (1, 1, 32, 64, 1, 2),
        (512, 512, 8192, 64, 64): (1, 1, 64, 64, 1, 2),
        (512, 512, 8192, 128, 128): (1, 1, 64, 64, 1, 4),
        (512, 512, 16384, 16, 16): (1, 2, 16, 128, 1, 2),
        (512, 512, 16384, 32, 32): (1, 1, 32, 64, 1, 2),
        (512, 512, 16384, 64, 64): (1, 1, 64, 64, 3, 2),
        (512, 512, 16384, 128, 128): (2, 1, 64, 64, 1, 4),
        (512, 512, 32768, 16, 16): (1, 2, 16, 128, 1, 2),
        (512, 512, 32768, 32, 32): (1, 1, 32, 64, 1, 2),
        (512, 512, 32768, 64, 64): (1, 1, 64, 64, 3, 4),
        (512, 512, 32768, 128, 128): (2, 1, 64, 64, 1, 4),
        (512, 512, 65536, 16, 16): (1, 2, 16, 128, 1, 2),
        (512, 512, 65536, 32, 32): (1, 1, 32, 64, 1, 2),
        (512, 512, 65536, 64, 64): (1, 1, 64, 64, 3, 4),
        (512, 512, 65536, 128, 128): (2, 1, 64, 64, 1, 4),
        (512, 512, 131072, 16, 16): (1, 1, 16, 64, 1, 1),
        (512, 512, 131072, 32, 32): (1, 1, 32, 64, 1, 2),
        (512, 512, 131072, 64, 64): (1, 1, 64, 64, 3, 4),
        (512, 512, 131072, 128, 128): (2, 4, 64, 64, 1, 4),
        (1024, 1024, 256, 16, 16): (1, 1, 16, 16, 1, 4),
        (1024, 1024, 256, 32, 32): (2, 16, 32, 16, 3, 4),
        (1024, 1024, 256, 64, 64): (1, 4, 32, 32, 1, 2),
        (1024, 1024, 256, 128, 128): (1, 4, 128, 16, 3, 16),
        (1024, 1024, 512, 16, 16): (1, 1, 16, 64, 1, 2),
        (1024, 1024, 512, 32, 32): (2, 2, 32, 64, 1, 2),
        (1024, 1024, 512, 64, 64): (2, 8, 64, 64, 3, 4),
        (1024, 1024, 512, 128, 128): (1, 4, 64, 64, 1, 8),
        (1024, 1024, 1024, 16, 16): (1, 1, 16, 64, 1, 2),
        (1024, 1024, 1024, 32, 32): (1, 1, 32, 64, 1, 2),
        (1024, 1024, 1024, 64, 64): (1, 8, 64, 64, 3, 4),
        (1024, 1024, 1024, 128, 128): (1, 8, 64, 64, 1, 4),
        (1024, 1024, 2048, 16, 16): (1, 2, 16, 64, 1, 2),
        (1024, 1024, 2048, 32, 32): (1, 1, 32, 64, 1, 2),
        (1024, 1024, 2048, 64, 64): (2, 16, 64, 64, 2, 2),
        (1024, 1024, 2048, 128, 128): (2, 32, 64, 64, 1, 4),
        (1024, 1024, 4096, 16, 16): (2, 16, 16, 128, 1, 2),
        (1024, 1024, 4096, 32, 32): (1, 16, 32, 64, 3, 2),
        (1024, 1024, 4096, 64, 64): (1, 1, 64, 64, 3, 4),
        (1024, 1024, 4096, 128, 128): (2, 64, 128, 64, 1, 4),
        (1024, 1024, 8192, 16, 16): (2, 16, 16, 128, 1, 2),
        (1024, 1024, 8192, 32, 32): (1, 16, 32, 64, 3, 2),
        (1024, 1024, 8192, 64, 64): (1, 1, 64, 64, 3, 4),
        (1024, 1024, 8192, 128, 128): (2, 1, 64, 64, 1, 4),
        (1024, 1024, 16384, 16, 16): (1, 2, 16, 128, 1, 2),
        (1024, 1024, 16384, 32, 32): (1, 16, 32, 64, 3, 2),
        (1024, 1024, 16384, 64, 64): (1, 1, 64, 64, 3, 4),
        (1024, 1024, 16384, 128, 128): (2, 16, 128, 64, 1, 4),
        (1024, 1024, 32768, 16, 16): (1, 1, 16, 128, 1, 2),
        (1024, 1024, 32768, 32, 32): (1, 1, 32, 128, 1, 2),
        (1024, 1024, 32768, 64, 64): (1, 32, 64, 32, 2, 1),
        (1024, 1024, 32768, 128, 128): (2, 8, 128, 64, 1, 4),
        (1024, 1024, 65536, 16, 16): (3, 2, 16, 128, 1, 2),
        (1024, 1024, 65536, 32, 32): (1, 1, 32, 128, 1, 2),
        (1024, 1024, 65536, 64, 64): (2, 4, 64, 32, 2, 1),
        (1024, 1024, 65536, 128, 128): (2, 8, 128, 64, 1, 4),
        (1024, 1024, 131072, 16, 16): (2, 1, 16, 128, 1, 2),
        (1024, 1024, 131072, 32, 32): (1, 1, 32, 128, 1, 2),
        (1024, 1024, 131072, 64, 64): (1, 4, 64, 32, 2, 1),
        (1024, 1024, 131072, 128, 128): (4, 1, 128, 64, 1, 4),
        (2048, 2048, 256, 16, 16): (1, 1, 16, 64, 1, 8),
        (2048, 2048, 256, 32, 32): (1, 1, 32, 32, 3, 1),
        (2048, 2048, 256, 64, 64): (1, 1, 32, 32, 2, 1),
        (2048, 2048, 256, 128, 128): (1, 4, 64, 64, 1, 8),
        (2048, 2048, 512, 16, 16): (1, 2, 16, 64, 1, 2),
        (2048, 2048, 512, 32, 32): (1, 2, 32, 64, 1, 4),
        (2048, 2048, 512, 64, 64): (1, 4, 64, 64, 1, 8),
        (2048, 2048, 512, 128, 128): (1, 4, 64, 64, 1, 4),
        (2048, 2048, 1024, 16, 16): (1, 2, 16, 128, 1, 2),
        (2048, 2048, 1024, 32, 32): (1, 1, 32, 64, 1, 2),
        (2048, 2048, 1024, 64, 64): (1, 8, 64, 64, 1, 4),
        (2048, 2048, 1024, 128, 128): (1, 8, 128, 64, 1, 4),
        (2048, 2048, 2048, 16, 16): (3, 4, 16, 128, 1, 2),
        (2048, 2048, 2048, 32, 32): (1, 16, 32, 64, 5, 2),
        (2048, 2048, 2048, 64, 64): (1, 1, 64, 64, 3, 4),
        (2048, 2048, 2048, 128, 128): (1, 8, 128, 64, 1, 4),
        (2048, 2048, 4096, 16, 16): (1, 2, 16, 128, 1, 2),
        (2048, 2048, 4096, 32, 32): (1, 8, 32, 64, 3, 2),
        (2048, 2048, 4096, 64, 64): (1, 1, 64, 64, 3, 4),
        (2048, 2048, 4096, 128, 128): (1, 8, 128, 64, 1, 4),
        (2048, 2048, 8192, 16, 16): (2, 4, 16, 128, 1, 2),
        (2048, 2048, 8192, 32, 32): (1, 4, 32, 128, 3, 2),
        (2048, 2048, 8192, 64, 64): (1, 8, 64, 64, 3, 2),
        (2048, 2048, 8192, 128, 128): (1, 8, 128, 64, 1, 4),
        (2048, 2048, 16384, 16, 16): (1, 2, 16, 128, 1, 2),
        (2048, 2048, 16384, 32, 32): (1, 4, 32, 128, 3, 2),
        (2048, 2048, 16384, 64, 64): (1, 8, 64, 64, 3, 2),
        (2048, 2048, 16384, 128, 128): (1, 4, 128, 64, 1, 4),
        (2048, 2048, 32768, 16, 16): (3, 2, 16, 128, 1, 2),
        (2048, 2048, 32768, 32, 32): (1, 1, 32, 128, 3, 2),
        (2048, 2048, 32768, 64, 64): (1, 1, 64, 64, 3, 2),
        (2048, 2048, 32768, 128, 128): (1, 4, 128, 64, 1, 4),
        (2048, 2048, 65536, 16, 16): (1, 2, 16, 128, 1, 2),
        (2048, 2048, 65536, 32, 32): (1, 4, 32, 128, 1, 2),
        (2048, 2048, 65536, 64, 64): (1, 1, 64, 64, 3, 2),
        (2048, 2048, 65536, 128, 128): (1, 2, 128, 64, 1, 4),
        (2048, 2048, 131072, 16, 16): (4, 2, 16, 128, 1, 2),
        (2048, 2048, 131072, 32, 32): (1, 1, 32, 128, 3, 2),
        (2048, 2048, 131072, 64, 64): (1, 1, 64, 64, 3, 2),
        (2048, 2048, 131072, 128, 128): (1, 2, 128, 64, 1, 4),
        (4096, 4096, 256, 16, 16): (1, 1, 16, 64, 1, 2),
        (4096, 4096, 256, 32, 32): (1, 1, 32, 64, 3, 4),
        (4096, 4096, 256, 64, 64): (1, 1, 64, 64, 3, 4),
        (4096, 4096, 256, 128, 128): (3, 4, 128, 32, 1, 4),
        (4096, 4096, 512, 16, 16): (1, 2, 16, 128, 1, 2),
        (4096, 4096, 512, 32, 32): (1, 2, 32, 64, 3, 2),
        (4096, 4096, 512, 64, 64): (1, 4, 64, 64, 1, 4),
        (4096, 4096, 512, 128, 128): (1, 4, 128, 64, 1, 4),
        (4096, 4096, 1024, 16, 16): (1, 2, 16, 128, 1, 2),
        (4096, 4096, 1024, 32, 32): (1, 8, 32, 64, 3, 2),
        (4096, 4096, 1024, 64, 64): (1, 4, 64, 64, 1, 4),
        (4096, 4096, 1024, 128, 128): (2, 4, 128, 64, 1, 4),
        (4096, 4096, 2048, 16, 16): (1, 1, 16, 128, 1, 2),
        (4096, 4096, 2048, 32, 32): (1, 4, 32, 128, 1, 4),
        (4096, 4096, 2048, 64, 64): (1, 1, 64, 64, 3, 4),
        (4096, 4096, 2048, 128, 128): (1, 16, 128, 64, 1, 4),
        (4096, 4096, 4096, 16, 16): (1, 1, 16, 64, 3, 1),
        (4096, 4096, 4096, 32, 32): (1, 4, 32, 64, 3, 2),
        (4096, 4096, 4096, 64, 64): (1, 1, 64, 64, 3, 4),
        (4096, 4096, 4096, 128, 128): (5, 1, 128, 64, 1, 4),
        (4096, 4096, 8192, 16, 16): (1, 1, 16, 128, 1, 2),
        (4096, 4096, 8192, 32, 32): (1, 1, 32, 128, 3, 2),
        (4096, 4096, 8192, 64, 64): (1, 1, 64, 64, 3, 4),
        (4096, 4096, 8192, 128, 128): (2, 1, 128, 64, 1, 4),
        (4096, 4096, 16384, 16, 16): (1, 1, 16, 128, 1, 2),
        (4096, 4096, 16384, 32, 32): (1, 1, 32, 128, 3, 2),
        (4096, 4096, 16384, 64, 64): (1, 1, 64, 64, 4, 4),
        (4096, 4096, 16384, 128, 128): (2, 1, 128, 64, 1, 4),
        (4096, 4096, 32768, 16, 16): (3, 1, 16, 128, 1, 2),
        (4096, 4096, 32768, 32, 32): (1, 1, 32, 128, 3, 2),
        (4096, 4096, 32768, 64, 64): (1, 1, 64, 64, 3, 4),
        (4096, 4096, 32768, 128, 128): (2, 1, 128, 64, 1, 4),
        (4096, 4096, 65536, 16, 16): (2, 2, 16, 128, 1, 2),
        (4096, 4096, 65536, 32, 32): (1, 1, 32, 128, 4, 2),
        (4096, 4096, 65536, 64, 64): (1, 1, 64, 64, 4, 4),
        (4096, 4096, 65536, 128, 128): (2, 1, 128, 64, 1, 4),
        (4096, 4096, 131072, 16, 16): (2, 1, 16, 128, 1, 2),
        (4096, 4096, 131072, 32, 32): (1, 1, 32, 128, 3, 2),
        (4096, 4096, 131072, 64, 64): (1, 1, 64, 64, 3, 4),
        (4096, 4096, 131072, 128, 128): (2, 1, 128, 64, 1, 4),
        (8192, 8192, 256, 16, 16): (1, 2, 16, 64, 1, 2),
        (8192, 8192, 256, 32, 32): (1, 1, 32, 64, 1, 2),
        (8192, 8192, 256, 64, 64): (1, 2, 64, 64, 1, 4),
        (8192, 8192, 256, 128, 128): (3, 16, 128, 16, 1, 2),
        (8192, 8192, 512, 16, 16): (1, 2, 16, 128, 1, 2),
        (8192, 8192, 512, 32, 32): (1, 4, 32, 64, 3, 2),
        (8192, 8192, 512, 64, 64): (2, 8, 64, 64, 4, 4),
        (8192, 8192, 512, 128, 128): (1, 8, 128, 64, 1, 4),
        (8192, 8192, 1024, 16, 16): (4, 2, 16, 128, 1, 2),
        (8192, 8192, 1024, 32, 32): (1, 8, 32, 128, 1, 2),
        (8192, 8192, 1024, 64, 64): (1, 16, 64, 64, 3, 2),
        (8192, 8192, 1024, 128, 128): (2, 16, 128, 64, 2, 4),
        (8192, 8192, 2048, 16, 16): (2, 1, 16, 64, 4, 1),
        (8192, 8192, 2048, 32, 32): (1, 16, 32, 64, 5, 2),
        (8192, 8192, 2048, 64, 64): (1, 16, 64, 64, 3, 2),
        (8192, 8192, 2048, 128, 128): (2, 16, 128, 64, 2, 4),
        (8192, 8192, 4096, 16, 16): (1, 1, 16, 64, 4, 1),
        (8192, 8192, 4096, 32, 32): (1, 16, 32, 64, 5, 2),
        (8192, 8192, 4096, 64, 64): (1, 16, 64, 64, 3, 2),
        (8192, 8192, 4096, 128, 128): (2, 64, 128, 64, 2, 4),
        (8192, 8192, 8192, 16, 16): (1, 1, 16, 64, 4, 1),
        (8192, 8192, 8192, 32, 32): (1, 8, 32, 128, 5, 4),
        (8192, 8192, 8192, 64, 64): (1, 8, 64, 64, 3, 2),
        (8192, 8192, 8192, 128, 128): (2, 8, 128, 64, 1, 4),
        (8192, 8192, 16384, 16, 16): (1, 1, 16, 64, 4, 1),
        (8192, 8192, 16384, 32, 32): (1, 8, 32, 64, 5, 2),
        (8192, 8192, 16384, 64, 64): (1, 8, 64, 64, 3, 2),
        (8192, 8192, 16384, 128, 128): (1, 8, 128, 64, 1, 4),
        (8192, 8192, 32768, 16, 16): (1, 1, 16, 64, 4, 1),
        (8192, 8192, 32768, 32, 32): (1, 8, 32, 64, 5, 2),
        (8192, 8192, 32768, 64, 64): (3, 8, 64, 64, 3, 2),
        (8192, 8192, 32768, 128, 128): (2, 8, 128, 64, 1, 4),
        (8192, 8192, 65536, 16, 16): (1, 1, 16, 64, 4, 1),
        (8192, 8192, 65536, 32, 32): (5, 4, 32, 64, 3, 2),
        (8192, 8192, 65536, 64, 64): (1, 8, 64, 64, 3, 2),
        (8192, 8192, 65536, 128, 128): (2, 8, 128, 64, 1, 4),
        (8192, 8192, 131072, 16, 16): (2, 1, 16, 64, 4, 1),
        (8192, 8192, 131072, 32, 32): (1, 4, 32, 64, 5, 2),
        (8192, 8192, 131072, 64, 64): (1, 4, 64, 128, 3, 4),
        (8192, 8192, 131072, 128, 128): (2, 8, 128, 64, 1, 4),
        (16384, 16384, 256, 16, 16): (1, 2, 16, 128, 1, 2),
        (16384, 16384, 256, 32, 32): (1, 4, 32, 64, 3, 2),
        (16384, 16384, 256, 64, 64): (2, 4, 64, 64, 4, 4),
        (16384, 16384, 256, 128, 128): (1, 4, 128, 64, 1, 16),
        (16384, 16384, 512, 16, 16): (1, 2, 16, 128, 3, 2),
        (16384, 16384, 512, 32, 32): (1, 4, 32, 128, 5, 4),
        (16384, 16384, 512, 64, 64): (1, 8, 64, 64, 3, 2),
        (16384, 16384, 512, 128, 128): (2, 8, 128, 64, 1, 4),
        (16384, 16384, 1024, 16, 16): (1, 2, 16, 128, 1, 2),
        (16384, 16384, 1024, 32, 32): (1, 8, 32, 64, 5, 2),
        (16384, 16384, 1024, 64, 64): (1, 16, 64, 64, 3, 2),
        (16384, 16384, 1024, 128, 128): (5, 16, 128, 64, 2, 4),
        (16384, 16384, 2048, 16, 16): (1, 2, 16, 128, 1, 2),
        (16384, 16384, 2048, 32, 32): (1, 8, 32, 64, 5, 2),
        (16384, 16384, 2048, 64, 64): (1, 16, 64, 64, 3, 2),
        (16384, 16384, 2048, 128, 128): (4, 32, 128, 64, 2, 4),
        (16384, 16384, 4096, 16, 16): (3, 2, 16, 128, 1, 2),
        (16384, 16384, 4096, 32, 32): (1, 4, 32, 64, 5, 2),
        (16384, 16384, 4096, 64, 64): (2, 16, 64, 64, 3, 2),
        (16384, 16384, 4096, 128, 128): (3, 32, 128, 64, 2, 4),
        (16384, 16384, 8192, 16, 16): (1, 2, 16, 128, 1, 2),
        (16384, 16384, 8192, 32, 32): (1, 4, 32, 64, 5, 2),
        (16384, 16384, 8192, 64, 64): (4, 8, 64, 64, 3, 2),
        (16384, 16384, 8192, 128, 128): (5, 8, 128, 64, 1, 4),
        (16384, 16384, 16384, 16, 16): (1, 2, 16, 128, 1, 2),
        (16384, 16384, 16384, 32, 32): (1, 4, 32, 64, 5, 2),
        (16384, 16384, 16384, 64, 64): (2, 4, 64, 128, 3, 4),
        (16384, 16384, 16384, 128, 128): (4, 8, 128, 64, 1, 4),
        (16384, 16384, 32768, 16, 16): (4, 2, 16, 128, 1, 2),
        (16384, 16384, 32768, 32, 32): (1, 4, 32, 64, 5, 2),
        (16384, 16384, 32768, 64, 64): (1, 8, 64, 64, 3, 2),
        (16384, 16384, 32768, 128, 128): (2, 512, 128, 64, 2, 4),
        (16384, 16384, 65536, 16, 16): (3, 2, 16, 128, 1, 2),
        (16384, 16384, 65536, 32, 32): (1, 4, 32, 64, 5, 2),
        (16384, 16384, 65536, 64, 64): (1, 4, 64, 128, 3, 4),
        (16384, 16384, 65536, 128, 128): (2, 1024, 128, 64, 2, 4),
        (16384, 16384, 131072, 16, 16): (1, 2, 16, 128, 1, 2),
        (16384, 16384, 131072, 32, 32): (1, 4, 32, 64, 5, 2),
        (16384, 16384, 131072, 64, 64): (3, 4, 64, 128, 3, 4),
        (16384, 16384, 131072, 128, 128): (4, 2048, 128, 64, 2, 4),
    },
    ("scatter_mm", "NVIDIA A100-SXM4-80GB", (0, torch.float16, 0.5)): {
        (256, 256, 256, 16, 16): (5, 4, 16, 16, 1, 4),
        (256, 256, 256, 32, 32): (5, 2, 32, 16, 1, 4),
        (256, 256, 256, 64, 64): (4, 1, 32, 32, 1, 8),
        (256, 256, 256, 128, 128): (2, 1, 32, 32, 1, 4),
        (256, 256, 512, 16, 16): (2, 2, 16, 32, 1, 4),
        (256, 256, 512, 32, 32): (4, 8, 32, 32, 1, 8),
        (256, 256, 512, 64, 64): (4, 8, 32, 64, 1, 4),
        (256, 256, 512, 128, 128): (4, 8, 32, 64, 1, 4),
        (256, 256, 1024, 16, 16): (4, 2, 16, 64, 1, 2),
        (256, 256, 1024, 32, 32): (4, 16, 32, 64, 1, 2),
        (256, 256, 1024, 64, 64): (4, 16, 32, 64, 1, 4),
        (256, 256, 1024, 128, 128): (4, 16, 64, 64, 1, 8),
        (256, 256, 2048, 16, 16): (2, 16, 16, 64, 1, 8),
        (256, 256, 2048, 32, 32): (4, 16, 32, 64, 1, 2),
        (256, 256, 2048, 64, 64): (4, 16, 32, 64, 1, 4),
        (256, 256, 2048, 128, 128): (4, 16, 64, 64, 1, 4),
        (256, 256, 4096, 16, 16): (4, 32, 16, 64, 1, 1),
        (256, 256, 4096, 32, 32): (2, 64, 32, 64, 1, 2),
        (256, 256, 4096, 64, 64): (4, 64, 64, 64, 1, 4),
        (256, 256, 4096, 128, 128): (4, 32, 64, 64, 1, 4),
        (256, 256, 8192, 16, 16): (4, 64, 16, 64, 1, 1),
        (256, 256, 8192, 32, 32): (4, 128, 32, 64, 1, 2),
        (256, 256, 8192, 64, 64): (4, 64, 64, 64, 1, 4),
        (256, 256, 8192, 128, 128): (4, 64, 64, 64, 1, 4),
        (256, 256, 16384, 16, 16): (4, 128, 16, 64, 1, 1),
        (256, 256, 16384, 32, 32): (2, 128, 32, 64, 1, 2),
        (256, 256, 16384, 64, 64): (4, 32, 32, 128, 1, 4),
        (256, 256, 16384, 128, 128): (4, 16, 64, 64, 1, 4),
        (256, 256, 32768, 16, 16): (4, 64, 16, 64, 1, 1),
        (256, 256, 32768, 32, 32): (2, 256, 32, 64, 1, 2),
        (256, 256, 32768, 64, 64): (4, 32, 32, 128, 1, 4),
        (256, 256, 32768, 128, 128): (4, 32, 64, 64, 1, 4),
        (256, 256, 65536, 16, 16): (4, 128, 16, 64, 1, 1),
        (256, 256, 65536, 32, 32): (4, 1, 32, 64, 1, 2),
        (256, 256, 65536, 64, 64): (2, 1, 64, 64, 1, 2),
        (256, 256, 65536, 128, 128): (4, 32, 64, 64, 1, 4),
        (256, 256, 131072, 16, 16): (4, 64, 16, 64, 1, 1),
        (256, 256, 131072, 32, 32): (2, 1, 32, 64, 1, 2),
        (256, 256, 131072, 64, 64): (4, 32, 32, 128, 1, 4),
        (256, 256, 131072, 128, 128): (4, 32, 64, 64, 1, 4),
        (512, 512, 256, 16, 16): (4, 16, 16, 16, 1, 4),
        (512, 512, 256, 32, 32): (2, 4, 32, 16, 1, 4),
        (512, 512, 256, 64, 64): (2, 16, 64, 16, 3, 8),
        (512, 512, 256, 128, 128): (4, 16, 64, 16, 1, 4),
        (512, 512, 512, 16, 16): (1, 1, 16, 64, 1, 8),
        (512, 512, 512, 32, 32): (2, 4, 16, 32, 1, 1),
        (512, 512, 512, 64, 64): (2, 1, 32, 32, 1, 2),
        (512, 512, 512, 128, 128): (4, 8, 32, 64, 1, 4),
        (512, 512, 1024, 16, 16): (2, 8, 16, 64, 1, 8),
        (512, 512, 1024, 32, 32): (4, 16, 32, 64, 1, 2),
        (512, 512, 1024, 64, 64): (4, 16, 64, 64, 1, 4),
        (512, 512, 1024, 128, 128): (2, 8, 64, 64, 1, 4),
        (512, 512, 2048, 16, 16): (4, 16, 16, 64, 1, 4),
        (512, 512, 2048, 32, 32): (4, 16, 32, 64, 1, 2),
        (512, 512, 2048, 64, 64): (4, 16, 64, 64, 1, 8),
        (512, 512, 2048, 128, 128): (4, 16, 64, 64, 1, 4),
        (512, 512, 4096, 16, 16): (4, 32, 16, 128, 1, 2),
        (512, 512, 4096, 32, 32): (4, 32, 32, 64, 1, 2),
        (512, 512, 4096, 64, 64): (4, 32, 64, 64, 1, 4),
        (512, 512, 4096, 128, 128): (4, 32, 64, 64, 1, 4),
        (512, 512, 8192, 16, 16): (2, 32, 16, 128, 1, 2),
        (512, 512, 8192, 32, 32): (4, 64, 32, 64, 1, 2),
        (512, 512, 8192, 64, 64): (4, 128, 64, 64, 1, 2),
        (512, 512, 8192, 128, 128): (4, 64, 64, 64, 1, 4),
        (512, 512, 16384, 16, 16): (4, 32, 16, 64, 1, 1),
        (512, 512, 16384, 32, 32): (4, 64, 32, 64, 1, 2),
        (512, 512, 16384, 64, 64): (4, 16, 64, 64, 1, 4),
        (512, 512, 16384, 128, 128): (4, 32, 64, 64, 1, 4),
        (512, 512, 32768, 16, 16): (7, 16, 16, 128, 1, 2),
        (512, 512, 32768, 32, 32): (4, 64, 32, 64, 1, 2),
        (512, 512, 32768, 64, 64): (2, 32, 64, 64, 3, 2),
        (512, 512, 32768, 128, 128): (2, 32, 64, 64, 1, 4),
        (512, 512, 65536, 16, 16): (2, 32, 16, 64, 1, 1),
        (512, 512, 65536, 32, 32): (4, 64, 32, 64, 1, 2),
        (512, 512, 65536, 64, 64): (3, 32, 64, 64, 3, 2),
        (512, 512, 65536, 128, 128): (4, 16, 64, 64, 1, 4),
        (512, 512, 131072, 16, 16): (3, 32, 16, 128, 1, 2),
        (512, 512, 131072, 32, 32): (4, 64, 32, 64, 1, 2),
        (512, 512, 131072, 64, 64): (2, 32, 64, 64, 3, 2),
        (512, 512, 131072, 128, 128): (3, 1, 64, 64, 1, 4),
        (1024, 1024, 256, 16, 16): (4, 16, 16, 16, 1, 4),
        (1024, 1024, 256, 32, 32): (4, 16, 32, 16, 1, 4),
        (1024, 1024, 256, 64, 64): (4, 4, 64, 32, 1, 16),
        (1024, 1024, 256, 128, 128): (4, 16, 64, 16, 1, 8),
        (1024, 1024, 512, 16, 16): (2, 8, 16, 64, 1, 8),
        (1024, 1024, 512, 32, 32): (3, 2, 32, 64, 1, 2),
        (1024, 1024, 512, 64, 64): (4, 8, 32, 64, 1, 8),
        (1024, 1024, 512, 128, 128): (4, 8, 64, 64, 1, 8),
        (1024, 1024, 1024, 16, 16): (2, 2, 16, 64, 1, 2),
        (1024, 1024, 1024, 32, 32): (2, 8, 32, 64, 1, 2),
        (1024, 1024, 1024, 64, 64): (2, 8, 32, 128, 1, 4),
        (1024, 1024, 1024, 128, 128): (2, 8, 64, 64, 1, 4),
        (1024, 1024, 2048, 16, 16): (2, 16, 16, 128, 3, 2),
        (1024, 1024, 2048, 32, 32): (4, 32, 32, 64, 1, 2),
        (1024, 1024, 2048, 64, 64): (4, 16, 64, 64, 1, 4),
        (1024, 1024, 2048, 128, 128): (4, 32, 64, 64, 1, 4),
        (1024, 1024, 4096, 16, 16): (4, 16, 16, 128, 1, 2),
        (1024, 1024, 4096, 32, 32): (3, 32, 32, 64, 1, 2),
        (1024, 1024, 4096, 64, 64): (4, 32, 64, 64, 1, 4),
        (1024, 1024, 4096, 128, 128): (4, 32, 64, 64, 1, 4),
        (1024, 1024, 8192, 16, 16): (5, 16, 16, 128, 1, 2),
        (1024, 1024, 8192, 32, 32): (2, 32, 32, 64, 3, 2),
        (1024, 1024, 8192, 64, 64): (1, 16, 64, 64, 3, 2),
        (1024, 1024, 8192, 128, 128): (4, 32, 64, 64, 1, 4),
        (1024, 1024, 16384, 16, 16): (4, 16, 16, 128, 1, 2),
        (1024, 1024, 16384, 32, 32): (1, 32, 32, 64, 3, 2),
        (1024, 1024, 16384, 64, 64): (4, 16, 64, 64, 3, 2),
        (1024, 1024, 16384, 128, 128): (4, 32, 128, 64, 1, 4),
        (1024, 1024, 32768, 16, 16): (3, 16, 16, 128, 1, 2),
        (1024, 1024, 32768, 32, 32): (1, 8, 32, 64, 3, 2),
        (1024, 1024, 32768, 64, 64): (4, 16, 64, 64, 3, 2),
        (1024, 1024, 32768, 128, 128): (4, 8, 128, 64, 2, 4),
        (1024, 1024, 65536, 16, 16): (1, 2, 16, 128, 1, 2),
        (1024, 1024, 65536, 32, 32): (2, 4, 32, 64, 3, 2),
        (1024, 1024, 65536, 64, 64): (5, 16, 64, 64, 3, 2),
        (1024, 1024, 65536, 128, 128): (5, 8, 128, 64, 2, 4),
        (1024, 1024, 131072, 16, 16): (5, 2, 16, 128, 1, 2),
        (1024, 1024, 131072, 32, 32): (1, 2, 32, 64, 3, 2),
        (1024, 1024, 131072, 64, 64): (5, 16, 64, 64, 3, 2),
        (1024, 1024, 131072, 128, 128): (2, 1, 128, 64, 2, 4),
        (2048, 2048, 256, 16, 16): (4, 4, 16, 64, 1, 8),
        (2048, 2048, 256, 32, 32): (4, 8, 32, 32, 1, 8),
        (2048, 2048, 256, 64, 64): (4, 16, 64, 16, 1, 8),
        (2048, 2048, 256, 128, 128): (4, 4, 128, 32, 3, 8),
        (2048, 2048, 512, 16, 16): (2, 2, 16, 64, 1, 2),
        (2048, 2048, 512, 32, 32): (2, 4, 32, 64, 3, 2),
        (2048, 2048, 512, 64, 64): (4, 4, 64, 64, 1, 8),
        (2048, 2048, 512, 128, 128): (4, 8, 64, 64, 1, 4),
        (2048, 2048, 1024, 16, 16): (1, 8, 16, 64, 1, 2),
        (2048, 2048, 1024, 32, 32): (2, 16, 32, 64, 3, 2),
        (2048, 2048, 1024, 64, 64): (4, 8, 64, 64, 1, 4),
        (2048, 2048, 1024, 128, 128): (4, 8, 128, 64, 1, 4),
        (2048, 2048, 2048, 16, 16): (5, 4, 16, 128, 1, 2),
        (2048, 2048, 2048, 32, 32): (1, 16, 32, 64, 3, 2),
        (2048, 2048, 2048, 64, 64): (2, 8, 64, 64, 1, 4),
        (2048, 2048, 2048, 128, 128): (2, 8, 128, 64, 1, 4),
        (2048, 2048, 4096, 16, 16): (4, 2, 16, 128, 1, 2),
        (2048, 2048, 4096, 32, 32): (2, 16, 32, 64, 3, 2),
        (2048, 2048, 4096, 64, 64): (2, 8, 64, 64, 3, 2),
        (2048, 2048, 4096, 128, 128): (4, 8, 128, 64, 1, 4),
        (2048, 2048, 8192, 16, 16): (5, 4, 16, 128, 1, 2),
        (2048, 2048, 8192, 32, 32): (2, 8, 32, 64, 3, 2),
        (2048, 2048, 8192, 64, 64): (4, 8, 64, 64, 3, 2),
        (2048, 2048, 8192, 128, 128): (4, 8, 128, 64, 1, 4),
        (2048, 2048, 16384, 16, 16): (3, 2, 16, 128, 1, 2),
        (2048, 2048, 16384, 32, 32): (2, 4, 32, 128, 3, 2),
        (2048, 2048, 16384, 64, 64): (4, 8, 64, 64, 3, 2),
        (2048, 2048, 16384, 128, 128): (4, 4, 128, 64, 1, 4),
        (2048, 2048, 32768, 16, 16): (3, 2, 16, 128, 1, 2),
        (2048, 2048, 32768, 32, 32): (3, 4, 32, 128, 3, 2),
        (2048, 2048, 32768, 64, 64): (6, 4, 64, 64, 3, 2),
        (2048, 2048, 32768, 128, 128): (3, 4, 128, 64, 1, 4),
        (2048, 2048, 65536, 16, 16): (6, 2, 16, 128, 1, 2),
        (2048, 2048, 65536, 32, 32): (1, 2, 32, 128, 1, 2),
        (2048, 2048, 65536, 64, 64): (5, 4, 64, 64, 3, 2),
        (2048, 2048, 65536, 128, 128): (5, 1, 128, 64, 2, 4),
        (2048, 2048, 131072, 16, 16): (3, 2, 16, 128, 1, 2),
        (2048, 2048, 131072, 32, 32): (2, 1, 32, 128, 3, 2),
        (2048, 2048, 131072, 64, 64): (4, 1, 64, 64, 3, 2),
        (2048, 2048, 131072, 128, 128): (3, 1, 128, 64, 2, 4),
        (4096, 4096, 256, 16, 16): (5, 8, 16, 32, 1, 4),
        (4096, 4096, 256, 32, 32): (4, 16, 32, 16, 2, 4),
        (4096, 4096, 256, 64, 64): (2, 1, 64, 64, 3, 4),
        (4096, 4096, 256, 128, 128): (4, 4, 128, 32, 1, 4),
        (4096, 4096, 512, 16, 16): (4, 2, 16, 128, 1, 2),
        (4096, 4096, 512, 32, 32): (4, 8, 32, 64, 1, 2),
        (4096, 4096, 512, 64, 64): (4, 4, 64, 64, 1, 4),
        (4096, 4096, 512, 128, 128): (4, 8, 128, 64, 2, 4),
        (4096, 4096, 1024, 16, 16): (1, 2, 16, 128, 1, 2),
        (4096, 4096, 1024, 32, 32): (6, 8, 32, 64, 3, 2),
        (4096, 4096, 1024, 64, 64): (2, 16, 64, 64, 4, 4),
        (4096, 4096, 1024, 128, 128): (2, 4, 128, 64, 2, 4),
        (4096, 4096, 2048, 16, 16): (3, 1, 16, 128, 1, 2),
        (4096, 4096, 2048, 32, 32): (1, 4, 32, 64, 5, 2),
        (4096, 4096, 2048, 64, 64): (3, 16, 64, 64, 3, 2),
        (4096, 4096, 2048, 128, 128): (4, 32, 128, 64, 2, 4),
        (4096, 4096, 4096, 16, 16): (1, 2, 16, 128, 1, 2),
        (4096, 4096, 4096, 32, 32): (1, 4, 32, 64, 3, 2),
        (4096, 4096, 4096, 64, 64): (1, 1, 64, 64, 4, 4),
        (4096, 4096, 4096, 128, 128): (2, 1, 128, 128, 1, 8),
        (4096, 4096, 8192, 16, 16): (3, 1, 16, 128, 1, 2),
        (4096, 4096, 8192, 32, 32): (2, 2, 32, 64, 5, 2),
        (4096, 4096, 8192, 64, 64): (4, 16, 64, 64, 3, 2),
        (4096, 4096, 8192, 128, 128): (4, 16, 128, 64, 2, 4),
        (4096, 4096, 16384, 16, 16): (1, 2, 16, 128, 1, 2),
        (4096, 4096, 16384, 32, 32): (4, 2, 32, 64, 5, 2),
        (4096, 4096, 16384, 64, 64): (4, 16, 64, 64, 3, 2),
        (4096, 4096, 16384, 128, 128): (4, 16, 128, 64, 2, 4),
        (4096, 4096, 32768, 16, 16): (3, 1, 16, 128, 1, 2),
        (4096, 4096, 32768, 32, 32): (3, 1, 32, 128, 1, 4),
        (4096, 4096, 32768, 64, 64): (3, 1, 64, 64, 3, 4),
        (4096, 4096, 32768, 128, 128): (5, 16, 128, 64, 2, 4),
        (4096, 4096, 65536, 16, 16): (5, 1, 16, 128, 1, 2),
        (4096, 4096, 65536, 32, 32): (5, 1, 32, 128, 1, 4),
        (4096, 4096, 65536, 64, 64): (1, 1, 64, 64, 3, 4),
        (4096, 4096, 65536, 128, 128): (3, 16, 128, 64, 2, 4),
        (4096, 4096, 131072, 16, 16): (3, 1, 16, 128, 1, 2),
        (4096, 4096, 131072, 32, 32): (3, 1, 32, 128, 3, 2),
        (4096, 4096, 131072, 64, 64): (2, 1, 64, 64, 3, 4),
        (4096, 4096, 131072, 128, 128): (1, 1, 128, 64, 1, 4),
        (8192, 8192, 256, 16, 16): (4, 16, 16, 16, 1, 4),
        (8192, 8192, 256, 32, 32): (1, 16, 32, 16, 4, 4),
        (8192, 8192, 256, 64, 64): (4, 16, 64, 16, 3, 8),
        (8192, 8192, 256, 128, 128): (4, 16, 128, 16, 1, 2),
        (8192, 8192, 512, 16, 16): (2, 8, 16, 64, 1, 4),
        (8192, 8192, 512, 32, 32): (4, 8, 32, 64, 3, 2),
        (8192, 8192, 512, 64, 64): (2, 8, 64, 64, 4, 4),
        (8192, 8192, 512, 128, 128): (4, 8, 128, 64, 2, 4),
        (8192, 8192, 1024, 16, 16): (4, 16, 16, 64, 1, 8),
        (8192, 8192, 1024, 32, 32): (2, 8, 32, 64, 5, 2),
        (8192, 8192, 1024, 64, 64): (1, 16, 64, 64, 3, 2),
        (8192, 8192, 1024, 128, 128): (5, 16, 128, 64, 2, 4),
        (8192, 8192, 2048, 16, 16): (7, 2, 16, 128, 1, 2),
        (8192, 8192, 2048, 32, 32): (1, 16, 32, 64, 5, 2),
        (8192, 8192, 2048, 64, 64): (4, 16, 64, 64, 3, 2),
        (8192, 8192, 2048, 128, 128): (6, 16, 128, 64, 2, 4),
        (8192, 8192, 4096, 16, 16): (4, 2, 16, 128, 1, 2),
        (8192, 8192, 4096, 32, 32): (2, 8, 32, 64, 5, 2),
        (8192, 8192, 4096, 64, 64): (3, 16, 64, 64, 3, 2),
        (8192, 8192, 4096, 128, 128): (3, 64, 128, 64, 2, 4),
        (8192, 8192, 8192, 16, 16): (4, 2, 16, 128, 1, 2),
        (8192, 8192, 8192, 32, 32): (1, 4, 32, 128, 5, 4),
        (8192, 8192, 8192, 64, 64): (4, 4, 64, 64, 1, 4),
        (8192, 8192, 8192, 128, 128): (2, 2, 128, 128, 3, 8),
        (8192, 8192, 16384, 16, 16): (1, 2, 16, 128, 1, 2),
        (8192, 8192, 16384, 32, 32): (4, 8, 32, 64, 5, 2),
        (8192, 8192, 16384, 64, 64): (5, 8, 64, 64, 3, 2),
        (8192, 8192, 16384, 128, 128): (3, 16, 128, 64, 2, 4),
        (8192, 8192, 32768, 16, 16): (7, 2, 16, 128, 1, 2),
        (8192, 8192, 32768, 32, 32): (3, 4, 32, 64, 3, 2),
        (8192, 8192, 32768, 64, 64): (2, 8, 64, 64, 3, 2),
        (8192, 8192, 32768, 128, 128): (6, 16, 128, 64, 2, 4),
        (8192, 8192, 65536, 16, 16): (9, 2, 16, 128, 1, 2),
        (8192, 8192, 65536, 32, 32): (7, 4, 32, 64, 5, 2),
        (8192, 8192, 65536, 64, 64): (4, 8, 64, 64, 3, 2),
        (8192, 8192, 65536, 128, 128): (3, 16, 128, 64, 2, 4),
        (8192, 8192, 131072, 16, 16): (9, 2, 16, 128, 1, 2),
        (8192, 8192, 131072, 32, 32): (1, 8, 32, 64, 5, 2),
        (8192, 8192, 131072, 64, 64): (1, 8, 64, 64, 3, 2),
        (8192, 8192, 131072, 128, 128): (4, 16, 128, 64, 2, 4),
        (16384, 16384, 256, 16, 16): (5, 16, 16, 16, 1, 4),
        (16384, 16384, 256, 32, 32): (4, 16, 32, 16, 4, 4),
        (16384, 16384, 256, 64, 64): (4, 16, 64, 16, 3, 8),
        (16384, 16384, 256, 128, 128): (4, 16, 128, 16, 1, 2),
        (16384, 16384, 512, 16, 16): (2, 8, 16, 64, 1, 4),
        (16384, 16384, 512, 32, 32): (1, 4, 32, 64, 5, 2),
        (16384, 16384, 512, 64, 64): (4, 8, 64, 64, 1, 4),
        (16384, 16384, 512, 128, 128): (3, 8, 128, 64, 2, 4),
        (16384, 16384, 1024, 16, 16): (4, 2, 16, 128, 1, 2),
        (16384, 16384, 1024, 32, 32): (4, 8, 32, 64, 5, 2),
        (16384, 16384, 1024, 64, 64): (6, 16, 64, 64, 3, 2),
        (16384, 16384, 1024, 128, 128): (3, 16, 128, 64, 2, 4),
        (16384, 16384, 2048, 16, 16): (3, 2, 16, 128, 1, 2),
        (16384, 16384, 2048, 32, 32): (1, 8, 32, 64, 5, 2),
        (16384, 16384, 2048, 64, 64): (5, 16, 64, 64, 3, 2),
        (16384, 16384, 2048, 128, 128): (2, 32, 128, 64, 2, 4),
        (16384, 16384, 4096, 16, 16): (2, 2, 16, 128, 1, 2),
        (16384, 16384, 4096, 32, 32): (1, 4, 32, 64, 3, 2),
        (16384, 16384, 4096, 64, 64): (2, 8, 64, 64, 3, 2),
        (16384, 16384, 4096, 128, 128): (3, 16, 128, 64, 2, 4),
        (16384, 16384, 8192, 16, 16): (3, 2, 16, 128, 1, 2),
        (16384, 16384, 8192, 32, 32): (2, 4, 32, 64, 5, 2),
        (16384, 16384, 8192, 64, 64): (4, 8, 64, 64, 3, 2),
        (16384, 16384, 8192, 128, 128): (8, 32, 128, 64, 2, 4),
        (16384, 16384, 16384, 16, 16): (1, 2, 16, 256, 1, 4),
        (16384, 16384, 16384, 32, 32): (1, 4, 32, 128, 3, 4),
        (16384, 16384, 16384, 64, 64): (5, 4, 64, 64, 1, 4),
        (16384, 16384, 16384, 128, 128): (4, 8, 128, 64, 2, 4),
        (16384, 16384, 32768, 16, 16): (2, 2, 16, 128, 1, 2),
        (16384, 16384, 32768, 32, 32): (1, 4, 32, 64, 3, 2),
        (16384, 16384, 32768, 64, 64): (5, 4, 64, 64, 1, 4),
        (16384, 16384, 32768, 128, 128): (5, 8, 128, 64, 2, 4),
        (16384, 16384, 65536, 16, 16): (8, 2, 16, 128, 1, 2),
        (16384, 16384, 65536, 32, 32): (6, 4, 32, 64, 5, 2),
        (16384, 16384, 65536, 64, 64): (2, 4, 64, 64, 1, 4),
        (16384, 16384, 65536, 128, 128): (4, 8, 128, 64, 2, 4),
        (16384, 16384, 131072, 16, 16): (3, 1, 16, 128, 1, 2),
        (16384, 16384, 131072, 32, 32): (1, 4, 32, 64, 3, 2),
        (16384, 16384, 131072, 64, 64): (4, 4, 64, 64, 1, 4),
        (16384, 16384, 131072, 128, 128): (1, 8, 128, 64, 2, 4),
        (32768, 32768, 256, 16, 16): (4, 16, 16, 16, 1, 4),
        (32768, 32768, 512, 16, 16): (4, 2, 16, 128, 1, 2),
        (32768, 32768, 1024, 16, 16): (3, 2, 16, 128, 1, 2),
        (32768, 32768, 2048, 16, 16): (4, 2, 16, 128, 1, 2),
        (32768, 32768, 4096, 16, 16): (5, 4, 16, 64, 1, 1),
        (32768, 32768, 8192, 16, 16): (4, 4, 16, 64, 1, 1),
        (32768, 32768, 16384, 16, 16): (4, 4, 16, 64, 1, 1),
        (32768, 32768, 32768, 16, 16): (5, 4, 16, 64, 1, 1),
    },
    ("scatter_mm", "NVIDIA A100-SXM4-80GB", (0, torch.float32, 0.5)): {
        (256, 256, 256, 16, 16): (1, 1, 16, 16, 1, 8),
        (256, 256, 256, 32, 32): (1, 1, 16, 16, 1, 4),
        (256, 256, 256, 64, 64): (1, 1, 16, 16, 1, 4),
        (256, 256, 256, 128, 128): (1, 1, 16, 16, 1, 1),
        (256, 256, 512, 16, 16): (1, 1, 16, 16, 1, 4),
        (256, 256, 512, 32, 32): (1, 16, 16, 16, 1, 1),
        (256, 256, 512, 64, 64): (1, 1, 16, 16, 1, 1),
        (256, 256, 512, 128, 128): (1, 1, 32, 32, 1, 4),
        (256, 256, 1024, 16, 16): (1, 1, 16, 32, 1, 2),
        (256, 256, 1024, 32, 32): (1, 4, 16, 16, 1, 1),
        (256, 256, 1024, 64, 64): (1, 1, 32, 32, 1, 4),
        (256, 256, 1024, 128, 128): (1, 1, 32, 32, 1, 4),
        (256, 256, 2048, 16, 16): (1, 2, 16, 32, 1, 2),
        (256, 256, 2048, 32, 32): (1, 1, 16, 32, 1, 2),
        (256, 256, 2048, 64, 64): (2, 1, 16, 32, 1, 2),
        (256, 256, 2048, 128, 128): (1, 1, 16, 16, 1, 1),
        (256, 256, 4096, 16, 16): (1, 1, 16, 32, 1, 2),
        (256, 256, 4096, 32, 32): (1, 1, 16, 32, 1, 2),
        (256, 256, 4096, 64, 64): (1, 1, 32, 32, 1, 4),
        (256, 256, 4096, 128, 128): (3, 1, 32, 64, 1, 4),
        (256, 256, 8192, 16, 16): (1, 32, 16, 64, 1, 2),
        (256, 256, 8192, 32, 32): (1, 1, 32, 64, 1, 4),
        (256, 256, 8192, 64, 64): (1, 1, 32, 64, 1, 4),
        (256, 256, 8192, 128, 128): (2, 1, 64, 32, 1, 4),
        (256, 256, 16384, 16, 16): (1, 1, 16, 64, 1, 2),
        (256, 256, 16384, 32, 32): (1, 1, 32, 64, 1, 4),
        (256, 256, 16384, 64, 64): (1, 128, 64, 64, 1, 4),
        (256, 256, 16384, 128, 128): (2, 1, 64, 32, 1, 4),
        (256, 256, 32768, 16, 16): (2, 128, 16, 64, 1, 1),
        (256, 256, 32768, 32, 32): (1, 1, 32, 64, 1, 4),
        (256, 256, 32768, 64, 64): (1, 128, 64, 64, 1, 4),
        (256, 256, 32768, 128, 128): (2, 1, 64, 64, 1, 4),
        (256, 256, 65536, 16, 16): (1, 1, 16, 64, 1, 2),
        (256, 256, 65536, 32, 32): (1, 1, 32, 64, 1, 4),
        (256, 256, 65536, 64, 64): (2, 1, 64, 64, 1, 4),
        (256, 256, 65536, 128, 128): (1, 1, 128, 32, 1, 4),
        (256, 256, 131072, 16, 16): (3, 128, 16, 64, 1, 1),
        (256, 256, 131072, 32, 32): (1, 1, 32, 64, 1, 4),
        (256, 256, 131072, 64, 64): (2, 1, 64, 64, 1, 4),
        (256, 256, 131072, 128, 128): (1, 8192, 64, 16, 1, 4),
        (512, 512, 256, 16, 16): (1, 2, 16, 16, 1, 1),
        (512, 512, 256, 32, 32): (1, 4, 16, 16, 1, 1),
        (512, 512, 256, 64, 64): (1, 16, 16, 16, 1, 1),
        (512, 512, 256, 128, 128): (1, 1, 16, 32, 1, 4),
        (512, 512, 512, 16, 16): (1, 8, 16, 32, 1, 2),
        (512, 512, 512, 32, 32): (1, 8, 16, 32, 1, 2),
        (512, 512, 512, 64, 64): (1, 2, 16, 32, 1, 2),
        (512, 512, 512, 128, 128): (1, 1, 32, 32, 1, 4),
        (512, 512, 1024, 16, 16): (1, 1, 16, 32, 1, 2),
        (512, 512, 1024, 32, 32): (1, 1, 16, 32, 1, 2),
        (512, 512, 1024, 64, 64): (1, 1, 16, 32, 1, 2),
        (512, 512, 1024, 128, 128): (1, 1, 64, 32, 1, 4),
        (512, 512, 2048, 16, 16): (1, 16, 16, 64, 1, 2),
        (512, 512, 2048, 32, 32): (1, 1, 32, 32, 1, 4),
        (512, 512, 2048, 64, 64): (1, 1, 32, 32, 1, 4),
        (512, 512, 2048, 128, 128): (2, 1, 32, 32, 1, 4),
        (512, 512, 4096, 16, 16): (2, 64, 16, 64, 1, 1),
        (512, 512, 4096, 32, 32): (1, 64, 32, 64, 1, 4),
        (512, 512, 4096, 64, 64): (1, 1, 32, 32, 1, 4),
        (512, 512, 4096, 128, 128): (1, 1, 64, 32, 1, 4),
        (512, 512, 8192, 16, 16): (2, 64, 16, 64, 1, 1),
        (512, 512, 8192, 32, 32): (1, 256, 32, 32, 1, 1),
        (512, 512, 8192, 64, 64): (1, 64, 64, 64, 1, 4),
        (512, 512, 8192, 128, 128): (2, 1, 64, 32, 1, 8),
        (512, 512, 16384, 16, 16): (2, 64, 16, 64, 1, 1),
        (512, 512, 16384, 32, 32): (1, 128, 32, 32, 1, 1),
        (512, 512, 16384, 64, 64): (1, 64, 64, 64, 1, 4),
        (512, 512, 16384, 128, 128): (3, 1, 64, 32, 1, 8),
        (512, 512, 32768, 16, 16): (2, 64, 16, 64, 1, 1),
        (512, 512, 32768, 32, 32): (1, 128, 32, 32, 1, 1),
        (512, 512, 32768, 64, 64): (1, 64, 64, 64, 1, 4),
        (512, 512, 32768, 128, 128): (2, 1, 64, 32, 1, 8),
        (512, 512, 65536, 16, 16): (2, 32, 16, 64, 1, 1),
        (512, 512, 65536, 32, 32): (1, 128, 32, 32, 1, 1),
        (512, 512, 65536, 64, 64): (1, 64, 64, 64, 1, 4),
        (512, 512, 65536, 128, 128): (2, 1, 64, 32, 1, 8),
        (512, 512, 131072, 16, 16): (2, 32, 16, 64, 1, 1),
        (512, 512, 131072, 32, 32): (1, 128, 32, 32, 1, 1),
        (512, 512, 131072, 64, 64): (3, 64, 64, 64, 1, 4),
        (512, 512, 131072, 128, 128): (1, 8192, 64, 16, 1, 4),
        (1024, 1024, 256, 16, 16): (1, 4, 16, 32, 1, 2),
        (1024, 1024, 256, 32, 32): (1, 4, 16, 32, 1, 2),
        (1024, 1024, 256, 64, 64): (1, 1, 16, 32, 1, 2),
        (1024, 1024, 256, 128, 128): (1, 1, 16, 16, 1, 1),
        (1024, 1024, 512, 16, 16): (1, 8, 16, 32, 1, 2),
        (1024, 1024, 512, 32, 32): (1, 8, 16, 32, 1, 1),
        (1024, 1024, 512, 64, 64): (1, 8, 32, 32, 1, 4),
        (1024, 1024, 512, 128, 128): (2, 1, 32, 32, 1, 4),
        (1024, 1024, 1024, 16, 16): (1, 16, 16, 32, 1, 2),
        (1024, 1024, 1024, 32, 32): (1, 16, 32, 64, 1, 4),
        (1024, 1024, 1024, 64, 64): (1, 16, 32, 64, 1, 4),
        (1024, 1024, 1024, 128, 128): (1, 1, 32, 32, 1, 4),
        (1024, 1024, 2048, 16, 16): (2, 32, 16, 64, 1, 1),
        (1024, 1024, 2048, 32, 32): (1, 32, 32, 64, 1, 4),
        (1024, 1024, 2048, 64, 64): (1, 32, 64, 64, 1, 4),
        (1024, 1024, 2048, 128, 128): (1, 1, 32, 64, 1, 4),
        (1024, 1024, 4096, 16, 16): (2, 16, 16, 64, 1, 1),
        (1024, 1024, 4096, 32, 32): (1, 64, 32, 32, 1, 1),
        (1024, 1024, 4096, 64, 64): (1, 64, 64, 64, 1, 4),
        (1024, 1024, 4096, 128, 128): (2, 64, 64, 32, 1, 8),
        (1024, 1024, 8192, 16, 16): (2, 16, 16, 64, 1, 1),
        (1024, 1024, 8192, 32, 32): (1, 64, 32, 32, 1, 1),
        (1024, 1024, 8192, 64, 64): (1, 64, 64, 64, 1, 4),
        (1024, 1024, 8192, 128, 128): (4, 1, 32, 64, 1, 4),
        (1024, 1024, 16384, 16, 16): (2, 16, 16, 64, 1, 1),
        (1024, 1024, 16384, 32, 32): (1, 64, 32, 32, 1, 1),
        (1024, 1024, 16384, 64, 64): (1, 32, 64, 64, 1, 4),
        (1024, 1024, 16384, 128, 128): (2, 64, 64, 32, 1, 4),
        (1024, 1024, 32768, 16, 16): (2, 16, 16, 64, 1, 1),
        (1024, 1024, 32768, 32, 32): (1, 64, 32, 32, 1, 1),
        (1024, 1024, 32768, 64, 64): (1, 32, 64, 64, 1, 4),
        (1024, 1024, 32768, 128, 128): (4, 1, 32, 64, 1, 4),
        (1024, 1024, 65536, 16, 16): (2, 16, 16, 64, 1, 1),
        (1024, 1024, 65536, 32, 32): (1, 32, 32, 32, 1, 1),
        (1024, 1024, 65536, 64, 64): (2, 32, 64, 64, 1, 4),
        (1024, 1024, 65536, 128, 128): (4, 1, 64, 32, 1, 4),
        (1024, 1024, 131072, 16, 16): (2, 16, 16, 64, 1, 1),
        (1024, 1024, 131072, 32, 32): (1, 32, 32, 32, 1, 1),
        (1024, 1024, 131072, 64, 64): (1, 16, 64, 64, 1, 4),
        (1024, 1024, 131072, 128, 128): (1, 8192, 64, 16, 1, 4),
        (2048, 2048, 256, 16, 16): (1, 4, 16, 32, 1, 2),
        (2048, 2048, 256, 32, 32): (1, 8, 16, 32, 1, 1),
        (2048, 2048, 256, 64, 64): (1, 8, 32, 32, 1, 4),
        (2048, 2048, 256, 128, 128): (1, 4, 64, 64, 1, 8),
        (2048, 2048, 512, 16, 16): (2, 8, 16, 32, 1, 2),
        (2048, 2048, 512, 32, 32): (2, 8, 32, 64, 1, 4),
        (2048, 2048, 512, 64, 64): (2, 4, 64, 64, 1, 4),
        (2048, 2048, 512, 128, 128): (1, 8, 32, 64, 1, 4),
        (2048, 2048, 1024, 16, 16): (2, 16, 16, 64, 3, 1),
        (2048, 2048, 1024, 32, 32): (1, 32, 32, 32, 1, 1),
        (2048, 2048, 1024, 64, 64): (1, 16, 64, 64, 1, 4),
        (2048, 2048, 1024, 128, 128): (2, 4, 64, 64, 1, 8),
        (2048, 2048, 2048, 16, 16): (2, 16, 16, 64, 1, 1),
        (2048, 2048, 2048, 32, 32): (1, 32, 32, 32, 1, 1),
        (2048, 2048, 2048, 64, 64): (1, 16, 64, 64, 1, 4),
        (2048, 2048, 2048, 128, 128): (2, 32, 32, 64, 1, 4),
        (2048, 2048, 4096, 16, 16): (3, 2, 16, 64, 1, 1),
        (2048, 2048, 4096, 32, 32): (3, 4, 32, 32, 1, 1),
        (2048, 2048, 4096, 64, 64): (1, 16, 64, 64, 1, 4),
        (2048, 2048, 4096, 128, 128): (2, 32, 64, 32, 1, 4),
        (2048, 2048, 8192, 16, 16): (3, 4, 16, 64, 1, 1),
        (2048, 2048, 8192, 32, 32): (2, 4, 32, 32, 1, 1),
        (2048, 2048, 8192, 64, 64): (2, 32, 64, 32, 1, 2),
        (2048, 2048, 8192, 128, 128): (4, 1, 32, 64, 1, 4),
        (2048, 2048, 16384, 16, 16): (3, 4, 16, 64, 1, 1),
        (2048, 2048, 16384, 32, 32): (1, 4, 32, 32, 1, 1),
        (2048, 2048, 16384, 64, 64): (2, 8, 64, 32, 1, 2),
        (2048, 2048, 16384, 128, 128): (2, 8, 64, 32, 1, 4),
        (2048, 2048, 32768, 16, 16): (2, 4, 16, 64, 1, 1),
        (2048, 2048, 32768, 32, 32): (2, 8, 32, 32, 1, 1),
        (2048, 2048, 32768, 64, 64): (1, 16, 64, 32, 1, 2),
        (2048, 2048, 32768, 128, 128): (4, 1, 32, 64, 1, 4),
        (2048, 2048, 65536, 16, 16): (3, 4, 16, 64, 1, 1),
        (2048, 2048, 65536, 32, 32): (1, 8, 32, 32, 1, 1),
        (2048, 2048, 65536, 64, 64): (1, 8, 64, 32, 1, 2),
        (2048, 2048, 65536, 128, 128): (4, 1, 64, 32, 1, 4),
        (2048, 2048, 131072, 16, 16): (2, 4, 16, 64, 1, 1),
        (2048, 2048, 131072, 32, 32): (1, 8, 32, 32, 1, 1),
        (2048, 2048, 131072, 64, 64): (3, 1, 64, 32, 1, 2),
        (2048, 2048, 131072, 128, 128): (1, 8192, 128, 16, 1, 8),
        (4096, 4096, 256, 16, 16): (2, 4, 16, 32, 1, 2),
        (4096, 4096, 256, 32, 32): (1, 4, 32, 64, 1, 4),
        (4096, 4096, 256, 64, 64): (1, 4, 64, 64, 1, 4),
        (4096, 4096, 256, 128, 128): (1, 4, 32, 64, 1, 4),
        (4096, 4096, 512, 16, 16): (2, 8, 16, 64, 3, 1),
        (4096, 4096, 512, 32, 32): (2, 16, 32, 32, 1, 1),
        (4096, 4096, 512, 64, 64): (1, 8, 64, 64, 1, 4),
        (4096, 4096, 512, 128, 128): (1, 8, 32, 64, 1, 4),
        (4096, 4096, 1024, 16, 16): (1, 8, 16, 64, 3, 1),
        (4096, 4096, 1024, 32, 32): (1, 16, 32, 32, 1, 1),
        (4096, 4096, 1024, 64, 64): (1, 16, 64, 32, 1, 2),
        (4096, 4096, 1024, 128, 128): (1, 16, 32, 64, 1, 4),
        (4096, 4096, 2048, 16, 16): (1, 16, 16, 64, 3, 1),
        (4096, 4096, 2048, 32, 32): (1, 16, 32, 32, 1, 1),
        (4096, 4096, 2048, 64, 64): (3, 16, 64, 32, 1, 2),
        (4096, 4096, 2048, 128, 128): (4, 8, 32, 64, 1, 4),
        (4096, 4096, 4096, 16, 16): (1, 8, 16, 64, 3, 1),
        (4096, 4096, 4096, 32, 32): (1, 1, 32, 32, 1, 1),
        (4096, 4096, 4096, 64, 64): (2, 16, 64, 32, 1, 2),
        (4096, 4096, 4096, 128, 128): (4, 8, 32, 64, 1, 4),
        (4096, 4096, 8192, 16, 16): (1, 8, 16, 64, 3, 1),
        (4096, 4096, 8192, 32, 32): (2, 1, 32, 32, 1, 1),
        (4096, 4096, 8192, 64, 64): (1, 16, 64, 32, 1, 2),
        (4096, 4096, 8192, 128, 128): (2, 1, 32, 64, 1, 4),
        (4096, 4096, 16384, 16, 16): (1, 8, 16, 64, 3, 1),
        (4096, 4096, 16384, 32, 32): (1, 1, 32, 32, 1, 1),
        (4096, 4096, 16384, 64, 64): (2, 8, 64, 32, 1, 2),
        (4096, 4096, 16384, 128, 128): (2, 1, 32, 64, 1, 4),
        (4096, 4096, 32768, 16, 16): (1, 8, 16, 64, 3, 1),
        (4096, 4096, 32768, 32, 32): (1, 1, 32, 32, 1, 1),
        (4096, 4096, 32768, 64, 64): (1, 8, 64, 32, 1, 2),
        (4096, 4096, 32768, 128, 128): (2, 1, 32, 64, 1, 4),
        (4096, 4096, 65536, 16, 16): (1, 8, 16, 64, 3, 1),
        (4096, 4096, 65536, 32, 32): (3, 1, 32, 32, 1, 1),
        (4096, 4096, 65536, 64, 64): (3, 4, 64, 32, 1, 2),
        (4096, 4096, 65536, 128, 128): (2, 1, 32, 64, 1, 4),
        (4096, 4096, 131072, 16, 16): (1, 8, 16, 64, 3, 1),
        (4096, 4096, 131072, 32, 32): (1, 1, 32, 32, 1, 1),
        (4096, 4096, 131072, 64, 64): (2, 8, 64, 32, 1, 2),
        (4096, 4096, 131072, 128, 128): (1, 8192, 128, 16, 1, 8),
        (8192, 8192, 256, 16, 16): (2, 4, 16, 64, 3, 1),
        (8192, 8192, 256, 32, 32): (1, 8, 32, 32, 1, 1),
        (8192, 8192, 256, 64, 64): (1, 4, 64, 64, 1, 4),
        (8192, 8192, 256, 128, 128): (1, 4, 32, 64, 1, 4),
        (8192, 8192, 512, 16, 16): (1, 4, 16, 64, 3, 1),
        (8192, 8192, 512, 32, 32): (1, 16, 32, 32, 1, 1),
        (8192, 8192, 512, 64, 64): (2, 4, 64, 64, 1, 4),
        (8192, 8192, 512, 128, 128): (2, 1, 32, 64, 1, 4),
        (8192, 8192, 1024, 16, 16): (3, 8, 16, 64, 3, 1),
        (8192, 8192, 1024, 32, 32): (1, 16, 32, 32, 1, 1),
        (8192, 8192, 1024, 64, 64): (1, 8, 64, 32, 1, 2),
        (8192, 8192, 1024, 128, 128): (2, 4, 32, 64, 1, 4),
        (8192, 8192, 2048, 16, 16): (1, 8, 16, 64, 3, 1),
        (8192, 8192, 2048, 32, 32): (1, 16, 32, 32, 1, 1),
        (8192, 8192, 2048, 64, 64): (2, 8, 64, 32, 1, 2),
        (8192, 8192, 2048, 128, 128): (4, 1, 32, 64, 1, 4),
        (8192, 8192, 4096, 16, 16): (1, 8, 16, 64, 3, 1),
        (8192, 8192, 4096, 32, 32): (1, 16, 32, 32, 1, 1),
        (8192, 8192, 4096, 64, 64): (1, 4, 64, 32, 1, 2),
        (8192, 8192, 4096, 128, 128): (3, 1, 32, 64, 1, 4),
        (8192, 8192, 8192, 16, 16): (1, 8, 16, 64, 3, 1),
        (8192, 8192, 8192, 32, 32): (1, 8, 32, 32, 1, 1),
        (8192, 8192, 8192, 64, 64): (1, 8, 64, 32, 1, 2),
        (8192, 8192, 8192, 128, 128): (4, 1, 32, 64, 1, 4),
        (8192, 8192, 16384, 16, 16): (3, 4, 16, 64, 3, 1),
        (8192, 8192, 16384, 32, 32): (1, 8, 32, 32, 1, 1),
        (8192, 8192, 16384, 64, 64): (2, 2, 64, 32, 1, 2),
        (8192, 8192, 16384, 128, 128): (7, 1, 32, 64, 1, 4),
        (8192, 8192, 32768, 16, 16): (1, 4, 16, 64, 3, 1),
        (8192, 8192, 32768, 32, 32): (1, 8, 32, 32, 1, 1),
        (8192, 8192, 32768, 64, 64): (3, 2, 64, 32, 1, 2),
        (8192, 8192, 32768, 128, 128): (6, 1, 32, 64, 1, 4),
        (8192, 8192, 65536, 16, 16): (1, 4, 16, 64, 3, 1),
        (8192, 8192, 65536, 32, 32): (4, 8, 32, 32, 1, 1),
        (8192, 8192, 65536, 64, 64): (1, 2, 64, 32, 1, 2),
        (8192, 8192, 65536, 128, 128): (4, 1, 32, 64, 1, 4),
        (8192, 8192, 131072, 16, 16): (1, 4, 16, 64, 3, 1),
        (8192, 8192, 131072, 32, 32): (1, 8, 32, 32, 1, 1),
        (8192, 8192, 131072, 64, 64): (5, 4, 64, 32, 1, 2),
        (8192, 8192, 131072, 128, 128): (1, 4096, 128, 16, 1, 8),
        (16384, 16384, 256, 16, 16): (1, 4, 16, 64, 3, 1),
        (16384, 16384, 256, 32, 32): (1, 8, 32, 32, 1, 1),
        (16384, 16384, 256, 64, 64): (1, 4, 64, 32, 1, 2),
        (16384, 16384, 256, 128, 128): (1, 4, 32, 64, 1, 4),
        (16384, 16384, 512, 16, 16): (1, 8, 16, 64, 3, 1),
        (16384, 16384, 512, 32, 32): (1, 16, 32, 32, 1, 1),
        (16384, 16384, 512, 64, 64): (1, 4, 64, 32, 1, 2),
        (16384, 16384, 512, 128, 128): (3, 1, 32, 64, 1, 4),
        (16384, 16384, 1024, 16, 16): (1, 8, 16, 64, 3, 1),
        (16384, 16384, 1024, 32, 32): (1, 16, 32, 32, 1, 1),
        (16384, 16384, 1024, 64, 64): (2, 4, 64, 32, 1, 2),
        (16384, 16384, 1024, 128, 128): (1, 2, 32, 64, 1, 4),
        (16384, 16384, 2048, 16, 16): (1, 4, 16, 64, 3, 1),
        (16384, 16384, 2048, 32, 32): (1, 16, 32, 32, 1, 1),
        (16384, 16384, 2048, 64, 64): (3, 4, 64, 32, 1, 2),
        (16384, 16384, 2048, 128, 128): (2, 1, 32, 64, 1, 4),
        (16384, 16384, 4096, 16, 16): (4, 8, 16, 64, 3, 1),
        (16384, 16384, 4096, 32, 32): (5, 16, 32, 32, 1, 1),
        (16384, 16384, 4096, 64, 64): (3, 2, 64, 32, 1, 2),
        (16384, 16384, 4096, 128, 128): (2, 1, 32, 64, 1, 4),
        (16384, 16384, 8192, 16, 16): (1, 4, 16, 64, 3, 1),
        (16384, 16384, 8192, 32, 32): (1, 4, 32, 32, 1, 1),
        (16384, 16384, 8192, 64, 64): (1, 2, 64, 32, 1, 2),
        (16384, 16384, 8192, 128, 128): (2, 1, 32, 64, 1, 4),
        (16384, 16384, 16384, 16, 16): (1, 8, 16, 64, 3, 1),
        (16384, 16384, 16384, 32, 32): (1, 4, 32, 32, 1, 1),
        (16384, 16384, 16384, 64, 64): (1, 2, 64, 32, 1, 2),
        (16384, 16384, 16384, 128, 128): (3, 1, 32, 64, 1, 4),
        (16384, 16384, 32768, 16, 16): (1, 4, 16, 64, 3, 1),
        (16384, 16384, 32768, 32, 32): (1, 2, 32, 32, 1, 1),
        (16384, 16384, 32768, 64, 64): (3, 2, 64, 32, 1, 2),
        (16384, 16384, 32768, 128, 128): (3, 1, 32, 64, 1, 4),
        (16384, 16384, 65536, 16, 16): (1, 8, 16, 64, 3, 1),
        (16384, 16384, 65536, 32, 32): (1, 4, 32, 32, 1, 1),
        (16384, 16384, 65536, 64, 64): (4, 4, 64, 32, 1, 2),
        (16384, 16384, 65536, 128, 128): (5, 1, 32, 64, 1, 4),
        (16384, 16384, 131072, 16, 16): (1, 2, 16, 64, 3, 1),
        (16384, 16384, 131072, 32, 32): (1, 4, 32, 32, 1, 1),
        (16384, 16384, 131072, 64, 64): (1, 2, 64, 32, 1, 2),
        (16384, 16384, 131072, 128, 128): (1, 4096, 128, 16, 1, 8),
    },
}

if __name__ == "__main__":
    for dtype in [torch.float16, torch.bfloat16, torch.float32]:
        for op in ["bsr_dense_addmm"]:
            main(op=op, force=False, dtype=dtype)

<END>

<START>
import torch

from torch._export.db.case import export_case, ExportArgs, SupportLevel


@export_case(
    example_inputs=ExportArgs(
        torch.randn(4),
        (torch.randn(4), torch.randn(4)),
        *[torch.randn(4), torch.randn(4)],
        mykw0=torch.randn(4),
        input0=torch.randn(4), input1=torch.randn(4)
    ),
    tags={"python.data-structure"},
    support_level=SupportLevel.SUPPORTED,
)
def fn_with_kwargs(pos0, tuple0, *myargs, mykw0, **mykwargs):
    out = pos0
    for arg in tuple0:
        out = out * arg
    for arg in myargs:
        out = out * arg
    out = out * mykw0
    out = out * mykwargs["input0"] * mykwargs["input1"]
    return out

<END>

<START>
from functools import wraps, partial
from itertools import product, chain, islice
import itertools
import functools
import copy
import operator
import random
import unittest
import math
import enum

import torch
import numpy as np
from torch import inf, nan

from typing import Any, Dict, List, Tuple, Union, Sequence
from torch.testing import make_tensor
from torch.testing._internal.common_dtype import (
    _dispatch_dtypes, floating_types, floating_types_and, complex_types, floating_and_complex_types,
    floating_and_complex_types_and, all_types_and_complex_and, all_types_and, all_types_and_complex, integral_types_and,
    all_types, empty_types, complex_types_and, integral_types, custom_types
)
from torch.testing._internal.common_device_type import \
    (onlyCPU, onlyCUDA, onlyNativeDeviceTypes, disablecuDNN, skipCUDAIfNoMagma, skipCUDAIfNoMagmaAndNoCusolver,
     skipCUDAIfNoCusolver, skipCPUIfNoLapack, skipCPUIfNoFFT, skipCUDAIf, precisionOverride,
     skipCPUIfNoMklSparse,
     toleranceOverride, tol)
from torch.testing._internal.common_cuda import (
    PLATFORM_SUPPORTS_FLASH_ATTENTION, SM53OrLater, SM80OrLater, SM90OrLater, with_tf32_off, TEST_CUDNN,
    _get_torch_cuda_version, _get_torch_rocm_version,
)
from torch.testing._internal.common_utils import (
    make_fullrank_matrices_with_distinct_singular_values,
    TEST_WITH_ROCM, IS_WINDOWS, IS_MACOS, TEST_SCIPY,
    torch_to_numpy_dtype_dict, TEST_WITH_ASAN,
    GRADCHECK_NONDET_TOL, freeze_rng_state, slowTest, TEST_WITH_SLOW,
    TEST_WITH_TORCHINDUCTOR
)

import torch._refs as refs  # noqa: F401
import torch._refs.nn.functional
import torch._refs.special
import torch._refs.linalg
import torch._prims as prims  # noqa: F401
from torch.utils import _pytree as pytree


from packaging import version

from torch.testing._internal.opinfo.core import (  # noqa: F401
    L,
    M,
    S,
    XS,
    _NOTHING,
    _getattr_qual,
    DecorateInfo,
    SampleInput,
    ErrorInput,
    AliasInfo,
    NumericsFilter,
    OpInfo,
    _generate_reduction_inputs,
    _generate_reduction_kwargs,
    sample_inputs_reduction,
    ReductionOpInfo,
    reference_inputs_elementwise_binary,
    make_error_inputs_elementwise_binary,
    generate_elementwise_binary_tensors,
    generate_elementwise_binary_arbitrarily_strided_tensors,
    generate_elementwise_binary_small_value_tensors,
    generate_elementwise_binary_large_value_tensors,
    generate_elementwise_binary_extremal_value_tensors,
    generate_elementwise_binary_broadcasting_tensors,
    generate_elementwise_binary_with_scalar_samples,
    generate_elementwise_binary_with_scalar_and_type_promotion_samples,
    generate_elementwise_binary_noncontiguous_tensors,
    sample_inputs_elementwise_binary,
    BinaryUfuncInfo,
    sample_inputs_elementwise_unary,
    generate_elementwise_unary_tensors,
    generate_elementwise_unary_small_value_tensors,
    generate_elementwise_unary_large_value_tensors,
    generate_elementwise_unary_extremal_value_tensors,
    reference_inputs_elementwise_unary,
    UnaryUfuncInfo,
    sample_inputs_spectral_ops,
    SpectralFuncType,
    SpectralFuncInfo,
    ShapeFuncInfo,
    sample_inputs_foreach,
    ForeachFuncInfo,
    gradcheck_wrapper_hermitian_input,
    gradcheck_wrapper_triangular_input,
    gradcheck_wrapper_triangular_input_real_positive_diagonal,
    gradcheck_wrapper_masked_operation,
    gradcheck_wrapper_masked_pointwise_operation,
    clone_sample,
)
from torch.testing._internal.opinfo.refs import (  # NOQA: F401
    _find_referenced_opinfo,
    _inherit_constructor_args,
    PythonRefInfo,
    ReductionPythonRefInfo,
    ElementwiseUnaryPythonRefInfo,
    ElementwiseBinaryPythonRefInfo,
)
from torch.testing._internal.opinfo.utils import (
    np_unary_ufunc_integer_promotion_wrapper,
    reference_reduction_numpy,
    prod_numpy
)
from torch.testing._internal import opinfo
from torch.testing._internal.opinfo.definitions.linalg import (
    sample_inputs_linalg_cholesky,
    sample_inputs_linalg_cholesky_inverse,
    sample_inputs_cross,
    sample_inputs_linalg_qr_geqrf,
    sample_inputs_linalg_invertible,
    sample_inputs_lu_solve,
    sample_inputs_legacy_solve,
    sample_inputs_svd,
    sample_inputs_linalg_det_logdet_slogdet,
    sample_inputs_linalg_lu,
    sample_inputs_diagonal_diag_embed,
    error_inputs_diagonal_diag_embed,
)
from torch.testing._internal.opinfo.definitions.special import (
    sample_inputs_i0_i1,
    sample_inputs_polygamma,
    reference_polygamma,
)
from torch.testing._internal.opinfo.definitions._masked import (
    sample_inputs_softmax_variant,
)
from torch.testing._internal.opinfo.definitions.sparse import (
    error_inputs_sparse_like_fns,
    sample_inputs_sparse_like_fns,
    error_inputs_sparse_mul,
    sample_inputs_sparse_mul,
    error_inputs_sparse_reduction_sum,
    sample_inputs_sparse_reduction_sum
)

if TEST_SCIPY:
    from scipy import stats
    import scipy.spatial
    import scipy.special


def close_to_int(x, eps=0.1):
    if x.is_complex():
        y = torch.abs(torch.view_as_complex(torch.frac(torch.view_as_real(x))))
    else:
        y = torch.abs(torch.frac(x))
    return (y < eps) | (y > (1 - eps))


def sample_inputs_slice(op_info, device, dtype, requires_grad, **kwargs):

    make_input = partial(make_tensor, device=device, dtype=dtype,
                         low=None, high=None, requires_grad=requires_grad)

    yield SampleInput(make_input(3), 0)

    yield SampleInput(make_input(20, 30, 40), dim=1, start=1, end=-2)

    yield SampleInput(make_input(20, 30, 40), dim=1, start=1, end=-2, step=3)

    yield SampleInput(make_input(20, 30, 40), dim=0, start=-10, end=-2, step=2)


def sample_inputs_tensor_split(op_info, device, dtype, requires_grad, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=dtype,
                         low=None, high=None, requires_grad=requires_grad)

    args_cases = (
        (torch.tensor([1, 2, 3]),),
        (torch.tensor(1),),
        (torch.tensor([1, 2, 3]), 1),
        (torch.tensor([1, 4, 2, 5, 3, 6])[::2], 1),
        ((2, 4),),
        ((2, 4), 1),
        ((2, 4), -1),
        (3,),
        (3, 1),
        (3, -1),
    )

    for args in args_cases:
        yield SampleInput(make_input((S, S, S)), args=args)


def sample_inputs_hsplit(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device,
                       low=None, high=None, requires_grad=requires_grad)
    yield SampleInput(make_arg(6), 2)
    yield SampleInput(make_arg(S, S, S), [1, 2, 3])

def sample_inputs_vsplit(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device,
                       low=None, high=None, requires_grad=requires_grad)
    yield SampleInput(make_arg(6, S), 2)
    yield SampleInput(make_arg(S, S, S), [1, 2, 3])

def sample_inputs_dsplit(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device,
                       low=None, high=None, requires_grad=requires_grad)
    yield SampleInput(make_arg(S, S, S), [1, 2, 3])
    yield SampleInput(make_arg(S, S, 6), 2)

def error_inputs_hsplit(op_info, device, **kwargs):
    make_arg = partial(make_tensor, dtype=torch.float32, device=device)
    err_msg1 = ("torch.hsplit requires a tensor with at least 1 dimension, "
                "but got a tensor with 0 dimensions!")
    yield ErrorInput(SampleInput(make_arg(()), 0), error_regex=err_msg1)

    err_msg2 = (f"torch.hsplit attempted to split along dimension 1, "
                f"but the size of the dimension {S} "
                f"is not divisible by the split_size 0!")
    yield ErrorInput(SampleInput(make_arg((S, S, S)), 0), error_regex=err_msg2)

    err_msg3 = ("received an invalid combination of arguments.")
    yield ErrorInput(
        SampleInput(make_arg((S, S, S)), "abc"),
        error_type=TypeError, error_regex=err_msg3)

def error_inputs_vsplit(op_info, device, **kwargs):
    make_arg = partial(make_tensor, dtype=torch.float32, device=device)
    err_msg1 = ("torch.vsplit requires a tensor with at least 2 dimension, "
                "but got a tensor with 1 dimensions!")
    yield ErrorInput(SampleInput(make_arg(S), 0), error_regex=err_msg1)

    err_msg2 = (f"torch.vsplit attempted to split along dimension 0, "
                f"but the size of the dimension {S} "
                f"is not divisible by the split_size 0!")
    yield ErrorInput(SampleInput(make_arg(S, S, S), 0),
                     error_regex=err_msg2)

    err_msg3 = ("received an invalid combination of arguments.")
    yield ErrorInput(SampleInput(make_arg(S, S, S), "abc"),
                     error_type=TypeError, error_regex=err_msg3)

def error_inputs_dsplit(op_info, device, **kwargs):
    make_arg = partial(make_tensor, dtype=torch.float32, device=device)
    err_msg1 = ("torch.dsplit requires a tensor with at least 3 dimension, "
                "but got a tensor with 1 dimensions!")
    yield ErrorInput(SampleInput(make_arg(S), 0), error_regex=err_msg1)

    err_msg2 = (f"torch.dsplit attempted to split along dimension 2, "
                f"but the size of the dimension {S} "
                f"is not divisible by the split_size 0!")
    yield ErrorInput(SampleInput(make_arg(S, S, S), 0), error_regex=err_msg2)


def sample_inputs_as_strided(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    test_cases = (
        ((1,), (1,), (1,), 0),
        ((3, 3), (2, 2), (1, 2), 0),
        ((3, 3), (2, 2), (1, 2), 1),
        ((16,), (2, 2, 2, 2), (1, 1, 1, 1), 0),
        ((16,), (2, 1, 1, 2), (1, 7, 7, 1), 0),
    )

    for input_shape, output_shape, stride, storage_offset in test_cases:
        input_t = make_arg(input_shape)
        kwargs = dict(storage_offset=storage_offset)
        yield SampleInput(input_t, args=(output_shape, stride), kwargs=kwargs)

def sample_inputs_as_strided_partial_views(op_info, device, dtype, requires_grad, **kwargs):
    def make_arg():
        base = make_tensor((20,), device=device, dtype=dtype)
        return base[5:15].requires_grad_(requires_grad)

    yield SampleInput(make_arg(), (2, 2), (1, 2))
    yield SampleInput(make_arg(), (2, 2), (1, 2), storage_offset=0)
    yield SampleInput(make_arg(), (2, 2), (1, 2), storage_offset=10)

def sample_inputs_as_strided_scatter(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    test_cases = [
        ((1,), (), (), 0),
        ((1,), (1,), (1,), 0),
        ((3, 3), (2, 2), (1, 2), 0),
        ((3, 3), (2, 2), (1, 2), 1),
        ((3, 3), (2, 2), (2, 1), 0),
        ((16,), (2, 2, 2, 2), (8, 4, 2, 1), 0),
        ((16,), (2, 1, 1, 2), (1, 2, 4, 8), 0),
    ]

    for input_shape, output_shape, stride, storage_offset in test_cases:
        input_t = make_arg(input_shape)
        input_src = make_arg(output_shape)
        yield SampleInput(input_t, input_src, output_shape, stride, storage_offset=storage_offset)


def error_inputs_as_strided_scatter(op_info, device, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=torch.float32, requires_grad=False)

    input_t = make_arg([4, 4])
    input_src = make_arg([2, 2])
    yield ErrorInput(
        SampleInput(input_t, input_src, [2, 2], [200, 200], storage_offset=0),
        error_regex="itemsize 4 requiring a storage size of 1604 are out of bounds for storage of size 64"
    )


def sample_inputs_combinations(op_info, device, dtype, requires_grad, **kwargs):
    inputs = (
        (0,),
        (0, 1),
        (0, 1, 2, 3),
    )

    rvals = [1, 2, 4]

    products = product(inputs, rvals, [False, True])

    for input_data, r, with_replacement in products:
        input_t = torch.tensor(input_data, device=device, dtype=dtype, requires_grad=requires_grad)
        yield SampleInput(input_t, r=r, with_replacement=with_replacement)

def sample_inputs_cartesian_prod(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(torch.tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    a = make_arg((0,))
    b = make_arg((0, 1))
    c = make_arg((0, 1, 2, 3))

    yield SampleInput(a)

    yield SampleInput(a, b)

    yield SampleInput(a, b, c)

def sample_inputs_cosine_similarity(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases: Tuple[tuple, dict] = (  # type: ignore[assignment]
        ((S, S), {'dim': 1}),
        ((S, 2), {'dim': -1}),
        ((S,), {'dim': 0, 'eps': 0.5}),
        ((), {'dim': 0}),
        ((S, S, M), {'dim': 2}),
        ((S, S), {})
    )

    for input_shape, kwargs in cases:
        yield SampleInput(make_arg(input_shape), args=(make_arg(input_shape),), kwargs=kwargs)
    yield SampleInput(make_arg((1, 2, 3)), args=(make_arg((2, 1, 3)),), kwargs={'dim': -1})
    yield SampleInput(make_arg((1, 2, 3)), args=(make_arg((2, 1, 3)),), kwargs={'dim': -2})
    yield SampleInput(make_arg((2, 3)), args=(make_arg((2, 1, 3)),), kwargs={'dim': -1})


def sample_inputs_item(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=False)

    cases = (
        (),
        (()),
        (1),
        ((1,)),
    )

    for shape in cases:
        yield SampleInput(make_arg(shape))

def error_inputs_item(op, device, **kwargs):
    make_arg = partial(make_tensor, dtype=torch.float32, device=device, requires_grad=False)

    cases = (
        (M),
        ((S,)),
        (S, S),
        (S, M, L),
    )

    for shape in cases:
        yield ErrorInput(
            SampleInput(make_arg(shape)), error_type=RuntimeError,
            error_regex="elements cannot be converted to Scalar")


def sample_inputs_batch_norm(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    make_arg_without_requires_grad = partial(make_tensor, device=device, dtype=dtype, requires_grad=False)

    cases: Tuple[Tuple[int], dict] = (  # type: ignore[assignment]
        ((S, S, S), {'training': True, 'momentum': 0.5, 'eps': 0.6}),
        ((3, 2, 4), {'training': False, 'momentum': -1.2}),
        ((3, 1), {'training': True, 'momentum': 0.0}),
        ((0,), {'training': True}),
        ((0,), {'training': False}),
        ((3, 2, 3, 4), {'training': True, 'momentum': -1.0, 'eps': 0.5}),
        ((3, 2, 3, 4), {'training': False, 'momentum': -1.0, 'eps': 0.5}),
        ((2, 1), {}),
    )

    for input_shape, kwargs in cases:
        channels = input_shape[1] if len(input_shape) > 1 else 0
        weight = make_arg(channels) if channels > 0 else None
        bias = make_arg(channels) if channels > 0 else None
        running_mean = make_arg_without_requires_grad(channels, low=0)
        running_var = make_arg_without_requires_grad(channels, low=0)

        yield SampleInput(
            make_arg(input_shape),
            args=(
                running_mean,
                running_var,
                weight,
                bias
            ),
            kwargs=kwargs
        )

    weights = [channels, None, None]
    biases = [None, channels, None]
    is_training = [True, False, False]

    for weight, bias, training in zip(weights, biases, is_training):
        yield SampleInput(
            make_arg(input_shape),
            args=(
                running_mean,
                running_var,
                make_arg(channels),
                make_arg(channels)
            ),
            kwargs={'training': training}
        )

    yield SampleInput(make_arg((1, 2, 3)), args=(None, None, None, None), kwargs={'training': True})

def sample_inputs_softmax_backward_data(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(
        make_tensor, device=device, dtype=dtype, requires_grad=requires_grad
    )
    cases = [
        ((S,), 0),
        ((S, S), 0),
        ((S, M, S), -1),
    ]
    input_dtypes = [dtype]
    if dtype == torch.float and device == 'cuda':
        input_dtypes += [torch.float16]

    for (shape, dim), input_dtype in product(cases, input_dtypes):
        input = make_arg(shape)
        output = torch.nn.functional.softmax(input, dim=dim, dtype=input_dtype)
        yield SampleInput(make_arg(shape), output, dim, input_dtype)

def sample_inputs_native_batch_norm(op_info, device, dtype, requires_grad, **kwargs):
    samples = sample_inputs_batch_norm(op_info, device, dtype, requires_grad, **kwargs)
    for sample in samples:
        if sample.input.numel() == 0:
            continue
        args = sample.args
        training = sample.kwargs.get('training', True)
        momentum = sample.kwargs.get('momentum', 0.5)
        eps = sample.kwargs.get('eps', 1e-5)
        yield SampleInput(sample.input, args=(args[2], args[3], args[0], args[1], training, momentum, eps))


def sample_inputs__native_batch_norm_legit(op_info, device, dtype, requires_grad, **kwargs):
    samples = sample_inputs_batch_norm(op_info, device, dtype, requires_grad, **kwargs)
    for sample in samples:
        if sample.input.numel() == 0:
            continue
        args = sample.args
        training = sample.kwargs.get('training', True)
        momentum = sample.kwargs.get('momentum', 0.5)
        eps = sample.kwargs.get('eps', 1e-5)
        if args[0] is not None and args[1] is not None:
            yield SampleInput(sample.input, args=(args[2], args[3], args[0], args[1], training, momentum, eps))
        else:
            yield SampleInput(sample.input, args=(args[2], args[3], training, momentum, eps))


def sample_inputs_nn_activation_relu(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases = (
        (()),
        ((S, )),
        ((S, S)),
        ((S, M, S))
    )

    for shape in cases:
        yield SampleInput(make_arg(shape))

def sample_inputs_prelu(op_info, device, dtype, requires_grad, **kwargs):
    op_kwargs = op_info.sample_kwargs(device, dtype, None)[0]
    yield from sample_inputs_elementwise_unary(op_info, device, dtype, requires_grad,
                                               op_kwargs=op_kwargs)

    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases = (
        (()),
        ((S, )),
        ((S, S)),
        ((S, M, S))
    )

    for shape in cases:
        for weight in [-1., 0., 0.8, 1.]:
            weight_tensor = torch.tensor(weight, device=device, dtype=dtype, requires_grad=requires_grad)
            yield SampleInput(make_arg(shape), args=(weight_tensor,))

        channel_size = shape[1] if len(shape) >= 2 else 1
        yield SampleInput(make_arg(shape), args=(make_arg((channel_size,)),))

    weight_tensor = torch.tensor(1., device=device, dtype=dtype, requires_grad=requires_grad)

    yield SampleInput(make_arg((S, S)), kwargs=dict(weight=weight_tensor,))
    yield SampleInput(make_arg((S, S)), kwargs=dict(weight=make_arg((S,)),))

def reference_inputs_prelu(op, device, dtype, requires_grad, **kwargs):
    yield from sample_inputs_prelu(op, device, dtype, requires_grad, **kwargs)
    yield from reference_inputs_elementwise_unary(op, device, dtype, requires_grad, **kwargs)

def sample_kwargs_prelu_scalar_weight(device, dtype, input):
    weight = torch.rand(tuple(), device=device, dtype=dtype)
    if dtype == torch.bfloat16:
        weight_cpu = weight.to(dtype=torch.float32, device="cpu")
    else:
        weight_cpu = weight.cpu()
    np_weight = weight_cpu.numpy()
    return ({'weight': weight}, {'weight': np_weight})

def error_inputs_prelu(op, device):
    inp = make_tensor(tuple(), device=device, dtype=torch.float32)
    weight = make_tensor((2,), device=device, dtype=torch.float32)
    yield ErrorInput(SampleInput(inp, kwargs={'weight': weight}),
                     error_regex="Not allow zero-dim input tensor.")

    inp = make_tensor((2, 8, 3), device=device, dtype=torch.float32)
    weight = make_tensor((9,), device=device, dtype=torch.float32)
    yield ErrorInput(SampleInput(inp, kwargs={'weight': weight}),
                     error_regex="Mismatch of parameter numbers and input channel size.")

    inp = make_tensor((2, 8, 3), device=device, dtype=torch.float32)
    weight = make_tensor((2, 4), device=device, dtype=torch.float32)
    yield ErrorInput(SampleInput(inp, kwargs={'weight': weight}),
                     error_regex="prelu: Expected `weight` to be a scalar or 1D tensor, but got: ndim = 2")

def sample_inputs_norm(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases = [
        ((S, S), (2,), '2'),
        ((S, S), (0,), '0'),
        ((S, S), (0.5,), '0_5'),
        ((S, S), (1,), '1'),
        ((S, S), (3,), '3'),
        ((S, S), (-1,), 'neg_1'),
        ((S, S), (-2,), 'neg_2'),
        ((S, S), (-0.5,), 'neg_0_5'),
        ((S, S), (-1.5,), 'neg_1_5'),
    ]

    cases_nonzero_input = (
        ((S, S, S), (1.5,), '1_5_default'),
        ((S, S, S), (1.5, 1), '1_5_dim'),
        ((S, S, S), (1.5, -1), '1_5_neg_dim'),
        ((S, S, S), (1.5, 1, True), 'keepdim_1_5_dim'),
        ((S, S, S), (1.5, -1, True), 'keepdim_1_5_neg_dim'),
    )

    cases_posdim = (
        ((S, S), (-2, 1,), 'neg_2_dim'),
        ((S, S), (-1, 1,), 'neg_1_dim'),
        ((S, S), (0, 1,), '0_dim'),
        ((S, S), (1, 1,), '1_dim'),
        ((S, S), (2, 1,), '2_dim'),
        ((S, S), (3, 1,), '3_dim'),
        ((S, S, S), (2, 1), '2_dim'),
        ((S, S, S), (3, 1), '3_dim'),
        ((S, S, S), (2, 1, True), 'keepdim_2_dim'),
        ((S, S, S), (3, 1, True), 'keepdim_3_dim'),
        ((), (2, 0), '2_dim_scalar'),
        ((), (3, 0), '3_dim_scalar'),
        ((), (2, 0, True), 'keepdim_2_dim_scalar'),
        ((), (3, 0, True), 'keepdim_3_dim_scalar'),
    )

    cases_negdim = ((shape, args[:1] + (-args[1],) + args[2:], name.replace("_dim", "_neg_dim"))
                    for shape, args, name in cases_posdim)

    for shape, args, name in itertools.chain(cases, cases_posdim, cases_negdim):
        yield SampleInput(make_arg(shape), args=args, name=name)

    for shape, args, name in cases_nonzero_input:
        yield SampleInput(make_arg(shape, exclude_zero=True), args=args, name=name)


def sample_inputs_norm_fro(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases = (
        ((S, S), (), 'default'),
        ((S, S), ('fro',), 'fro_default'),
        ((S, S), ('fro', [0, 1],), 'fro'),
    )

    for shape, args, name in cases:
        yield SampleInput(make_arg(shape), args=args, name=name)


def sample_inputs_norm_nuc(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases = (
        ((S, S), ('nuc',), 'nuc'),
        ((S, S, S), ('nuc', [1, 2]), 'nuc_batched'),
    )

    for shape, args, name in cases:
        yield SampleInput(make_arg(shape), args=args, name=name)


def sample_inputs_norm_inf(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases = (
        ((S, S), (-inf,), '-inf'),
        ((S, S), (inf,), 'inf'),
        ((S, S), (inf, 1,), 'inf_2_dim'),
        ((S, S), (inf, -1,), 'inf_2_neg_dim'),
    )

    for shape, args, name in cases:
        yield SampleInput(make_arg(shape), args=args, name=name)


def sample_inputs_equal(op, device, dtype, requires_grad, **kwargs):
    make_arg = partial(
        make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    shapes = (
        ((), ()),
        ((S,), ()),
        ((), (S,)),
        ((S, 1), (S,)),
        ((M, S), ()),
        ((S, S), (S, S))
    )

    for shape_lhs, shape_rhs in shapes:
        lhs = make_arg(shape_lhs)
        rhs = make_arg(shape_rhs)
        broadcasts_input = shape_lhs != torch.broadcast_shapes(shape_lhs, shape_rhs)

        yield SampleInput(lhs, args=(rhs,), broadcasts_input=broadcasts_input)
        if shape_lhs == shape_rhs:
            yield SampleInput(lhs, args=(lhs.clone().detach_(),))



def sample_inputs_jiterator(op, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    shapes = (
        ((), ()),
        ((S,), ()),
        ((S, 1), (S,)),
        ((M, S), ()),
        ((S, M, S), (M, S)),
        ((S, M, S), (S, M, S)),
        ((M, 1, S), (M, S)),
        ((M, 1, S), (1, M, S)),
        ((0, 1, 3), (0, 10, 3))
    )

    num_inputs = kwargs.get('num_inputs')
    sample_kwargs = kwargs.get('sample_kwargs', {})

    for shape_lhs, shape_rhs in shapes:
        lhs = make_arg(shape_lhs)

        args = []
        for i in range(num_inputs - 1):
            args.append(make_arg(shape_rhs))
        broadcasts_input = (shape_lhs != torch.broadcast_shapes(shape_lhs, shape_rhs))

        yield SampleInput(lhs, args=tuple(args), kwargs=sample_kwargs, broadcasts_input=broadcasts_input)

def sample_inputs_broadcast_shapes(op, device, dtype, requires_grad, **kwargs):
    shapes = (
        ((), ()),
        ((S,), ()),
        ((S, 1), (S,)),
        ((S, 1), S),
        ((M, S), ()),
        ((S, M, S), (M, S)),
        ((S, M, S), (S, M, S)),
        ((M, 1, S), (M, S)),
        ((M, 1, S), (1, M, S)),
        ((0, 1, 3), (0, 10, 3))
    )

    for shape in shapes:
        inp, *arg0 = shape
        yield SampleInput(inp, args=tuple(arg0))

def sample_inputs_add_sub(op, device, dtype, requires_grad, **kwargs):
    yield from sample_inputs_elementwise_binary(op, device, dtype, requires_grad, **kwargs)

    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    lhs = make_arg((S, S), **op.lhs_make_tensor_kwargs)
    rhs = make_arg((S, S), **op.rhs_make_tensor_kwargs)
    if dtype is not torch.bool:
        yield SampleInput(lhs, args=(rhs,), kwargs={'alpha': 2})
    else:
        yield SampleInput(lhs, args=(rhs,), kwargs={'alpha': True})
    neg_alpha = -3.125 if (dtype.is_floating_point or dtype.is_complex) else -3
    lhs = make_arg((S, S), **op.lhs_make_tensor_kwargs)
    rhs = make_arg((S, S), **op.rhs_make_tensor_kwargs)
    if dtype is not torch.bool:
        yield SampleInput(lhs, args=(rhs,), kwargs={'alpha': neg_alpha})
    else:
        yield SampleInput(lhs, args=(rhs,), kwargs={'alpha': False})

def error_inputs_arange(op, device, **kwargs):
    yield ErrorInput(SampleInput(0, args=(3, 0)), error_type=RuntimeError, error_regex='step must be nonzer')
    yield ErrorInput(SampleInput(0, args=(-3, 2)), error_type=RuntimeError, error_regex='bound inconsistent with step sign')
    yield ErrorInput(SampleInput(0, args=(3, -2)), error_type=RuntimeError, error_regex='bound inconsistent with step sign')
    yield ErrorInput(SampleInput(0, args=(float('inf'), 2)), error_type=RuntimeError, error_regex='unsupported range')
    yield ErrorInput(SampleInput(float('-inf'), args=(1, 2)), error_type=RuntimeError, error_regex='unsupported range')

def sample_inputs_arange(op, device, dtype, requires_grad, **kwargs):
    int_samples = (
        (-1, 2, 2),
        (2, -3, -1),
        (1, 1, 1),
        (1, 1, -1),
        (0, -8, -4),
        (1, 5, 2),
        (False, True, True),
        (0, 1, None),
        (None, 3, None),
    )

    def to_float(start, end, step):
        start = start + 0.1 if start is not None else None
        end = end + 0.1
        step = float(step) if step is not None else None
        return start, end, step

    float_samples = (
        (0., -8. - 1e-6, -4.),
        (1., 5. + 1e-6, 2.),
        (0., -8., -4.),
        (1., 5., 2.),
        *(to_float(start, end, step) for (start, end, step) in int_samples),
    )

    large_samples = (
        (0, 10000, None),
    )

    samples = int_samples + float_samples
    if dtype not in (torch.int8, torch.uint8):
        samples += large_samples

    for start, end, step in samples:
        if start is None:
            assert step is None
            yield SampleInput(end, kwargs={"dtype": dtype, "device": device})
            yield SampleInput(0, kwargs={"end": end, "dtype": dtype, "device": device})
        elif step is None:
            yield SampleInput(start, args=(end,), kwargs={"dtype": dtype, "device": device})
        else:
            yield SampleInput(start, args=(end, step), kwargs={"dtype": dtype, "device": device})

    yield SampleInput(2)
    yield SampleInput(1, args=(3, 1))

def sample_inputs_randn(op, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=False)

    shapes = (
        (M,),
        (S, S)
    )

    for shape in shapes:
        yield SampleInput(input=shape, kwargs=dict(dtype=dtype, device=device, requires_grad=requires_grad))

def sample_inputs_normal(op, device, dtype, requires_grad, **kwargs):

    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=False)
    samples = (
        ((S, S), 0, 5),
        ((S, S, S), -2, 0.5),
    )
    for shape, mean, std in samples:
        yield SampleInput(make_arg(shape), args=(mean, std))

def error_inputs_normal(op, device, **kwargs):
    t = torch.zeros([10], device=device)
    invalid_std = -1
    yield ErrorInput(
        SampleInput(t, args=(0, invalid_std)),
        error_type=RuntimeError,
        error_regex=fr"normal expects std >= 0.0, but found std {invalid_std}",
    )

def sample_inputs_cauchy(op, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=False)
    samples = (
        ((M,), 0, 0.5),
        ((S, S), 0, 1),
        ((S, S, S), -2, 1),
    )
    for shape, median, gamma in samples:
        yield SampleInput(make_arg(shape), args=(median, gamma))


def error_inputs_cauchy(op, device, **kwargs):
    t = torch.zeros([10], device=device)
    invalid_scale = 0
    yield ErrorInput(
        SampleInput(t, args=(0, invalid_scale,)),
        error_type=RuntimeError,
        error_regex=fr"cauchy_ expects sigma > 0.0, but found sigma={invalid_scale}",
    )


def sample_inputs_exponential(op, device, dtype, requires_grad, **kwargs):

    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=False)
    samples = (
        ((M,), 0.5),
        ((S, S), 1),
        ((S, S, S), 1.5),
    )
    for shape, rate in samples:
        yield SampleInput(make_arg(shape), args=(rate,))


def error_inputs_exponential(op, device, **kwargs):
    t = torch.zeros([10], device=device)
    invalid_rate = 0
    yield ErrorInput(
        SampleInput(t, args=(invalid_rate,)),
        error_type=RuntimeError,
        error_regex=fr"exponential_ expects lambda > 0.0, but found lambda={invalid_rate}",
    )


def sample_inputs_geometric(op, device, dtype, requires_grad, **kwargs):

    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=False)
    samples = (
        ((M,), 0.2),
        ((S, S), 0.5),
        ((S, S, S), 0.8),
    )
    for shape, rate in samples:
        yield SampleInput(make_arg(shape), args=(rate,))


def error_inputs_geometric(op, device, **kwargs):
    t = torch.zeros([10], device=device)
    neg_prob = -1
    yield ErrorInput(
        SampleInput(t, args=(neg_prob,)),
        error_type=RuntimeError,
        error_regex=fr"geometric_ expects p to be in \(0, 1\), but got p={neg_prob}",
    )


def sample_inputs_log_normal(op, device, dtype, requires_grad, **kwargs):

    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=False)
    samples = (
        ((M,), 0, 0.25),
        ((S, S), 0.5, 1),
        ((S, S, S), 0, 0.5),
    )
    for shape, mean, std in samples:
        yield SampleInput(make_arg(shape), args=(mean, std))


def error_inputs_log_normal(op, device, **kwargs):
    t = torch.zeros([10], device=device)
    invalid_std = 0
    yield ErrorInput(
        SampleInput(t, args=(0, invalid_std)),
        error_type=RuntimeError,
        error_regex=fr"log_normal_ expects std > 0.0, but found std={invalid_std}",
    )


def sample_inputs_uniform(op, device, dtype, requires_grad, **kwargs):

    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=False)
    samples = (
        ((M,), -100, 100),
        ((S, S), 0, 1),
        ((S, S, S), 1, 2),
    )
    for shape, hi, lo in samples:
        yield SampleInput(make_arg(shape), args=(hi, lo))

def sample_inputs_ones_zeros(op, device, dtype, requires_grad, **kwargs):
    sizes = (
        (M,),
        (S, S),
    )
    for size in sizes:
        yield SampleInput(size, kwargs={'dtype': dtype, 'device': device})

def sample_inputs_full(op, device, dtype, requires_grad, **kwargs):
    def get_val(dtype):
        return make_tensor([], dtype=dtype, device="cpu").item()

    sizes = (
        (M,),
        (S, S),
    )
    fill_values = [get_val(dtype), get_val(torch.int)]

    for size, fill_value in product(sizes, fill_values):
        yield SampleInput(size, fill_value, dtype=dtype, device=device)


def error_inputs_uniform(op, device, **kwargs):
    t = torch.zeros([10], device=device)
    yield ErrorInput(
        SampleInput(t, args=(3, -1)),
        error_type=RuntimeError,
        error_regex=r"uniform_ expects to return a \[from, to\) range, but found from=3 > to=-1",
    )


def error_inputs_linspace(op, device, **kwargs):
    yield ErrorInput(SampleInput(0, args=(3, -1)), error_type=RuntimeError, error_regex='number of steps must be non-negative')
    yield ErrorInput(
        SampleInput(0, args=(3, 1.)),
        error_type=TypeError,
        error_regex="received an invalid combination of arguments - got \\(int, int, float",
    )
    yield ErrorInput(
        SampleInput(torch.tensor([1, 1], device=device), args=(torch.tensor([3, 3], device=device), 1)),
        error_type=RuntimeError,
        error_regex="only supports 0-dimensional start and end tensors"
    )


def sample_inputs_linspace(op, device, dtype, requires_grad, **kwargs):
    ends = (-3, 0, 1, 4, 50)
    starts = (-2., 0, 4.3, 50)
    nsteps = (0, 1, 50)
    cases = list(product(starts, ends, nsteps)) + [(0, 7, 50)]
    for start, end, nstep in cases:
        if dtype == torch.uint8 and (end < 0 or start < 0):
            continue
        yield SampleInput(start, args=(end, nstep), kwargs={"dtype": dtype, "device": device})

    yield SampleInput(1, args=(3, 1))


def sample_inputs_linspace_tensor_overload(op, device, dtype, requires_grad, **kwargs):
    ends = (-3, 0, 1, 4, 50)
    starts = (-2., 0, 4.3, 50)
    nsteps = (0, 1, 50)
    is_start_end_tensors = ((True, True), (True, False), (False, True))
    make_arg = partial(torch.tensor, device=device, requires_grad=False)

    cases = list(product(starts, ends, nsteps, is_start_end_tensors)) + [(0, 7, 50, (True, True))]
    for start, end, nstep, (is_start_tensor, is_end_tensor) in cases:
        if dtype == torch.uint8 and (end < 0 or start < 0):
            continue

        tensor_options = {"dtype": dtype, "device": device}
        if is_start_tensor:
            start = make_arg(start, dtype=torch.float32 if isinstance(start, float) else torch.int64)
        if is_end_tensor:
            end = make_arg(end, dtype=torch.float32 if isinstance(end, float) else torch.int64)

        yield SampleInput(start, args=(end, nstep), kwargs=tensor_options)

    yield SampleInput(1, args=(3, 1))


def sample_inputs_logspace(op, device, dtype, requires_grad, **kwargs):
    ends = (-3, 0, 1.2, 2, 4)
    starts = (-2., 0, 1, 2, 4.3)
    nsteps = (0, 1, 2, 4)
    bases = (2., 1.1) if dtype in (torch.int8, torch.uint8) else (None, 2., 3., 1.1, 5.)
    for start, end, nstep, base in product(starts, ends, nsteps, bases):
        if dtype == torch.uint8 and end < 0 or start < 0:
            continue
        if nstep == 1 and isinstance(start, float) and not (dtype.is_complex or dtype.is_floating_point):
            continue
        if base is None:
            yield SampleInput(start, args=(end, nstep), kwargs={"dtype": dtype, "device": device})
        else:
            yield SampleInput(start, args=(end, nstep, base), kwargs={"dtype": dtype, "device": device})

    yield SampleInput(1, args=(3, 1, 2.))


def sample_inputs_logspace_tensor_overload(op, device, dtype, requires_grad, **kwargs):
    ends = (-3, 0, 1.2, 2, 4)
    starts = (-2., 0, 1, 2, 4.3)
    nsteps = (0, 1, 2, 4)
    bases = (2., 1.1) if dtype in (torch.int8, torch.uint8) else (None, 2., 3., 1.1, 5.)
    is_start_end_tensors = ((True, True), (True, False), (False, True))
    make_arg = partial(torch.tensor, device=device)
    for start, end, nstep, base, (is_start_tensor, is_end_tensor) in product(starts, ends, nsteps, bases, is_start_end_tensors):
        if dtype == torch.uint8 and end < 0 or start < 0:
            continue
        if nstep == 1 and isinstance(start, float) and not (dtype.is_complex or dtype.is_floating_point):
            continue

        tensor_options = {"dtype": dtype, "device": device}

        if (is_start_tensor):
            start = make_arg(start, dtype=torch.float32 if isinstance(start, float) else torch.int64)
        if (is_end_tensor):
            end = make_arg(end, dtype=torch.float32 if isinstance(end, float) else torch.int64)

        if base is None:
            yield SampleInput(start, args=(end, nstep), kwargs=tensor_options)
        else:
            yield SampleInput(start, args=(end, nstep, base), kwargs=tensor_options)

    yield SampleInput(1, args=(3, 1, 2.))


def sample_inputs_isclose(op, device, dtype, requires_grad, **kwargs):
    yield from sample_inputs_elementwise_binary(op, device, dtype, requires_grad, **kwargs)

    rtols = [0., 1e-7]
    atols = [0., 1e-7]
    equal_nans = [False, True]

    products = product(rtols, atols, equal_nans)

    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    for rtol, atol, equal_nan in products:
        lhs = make_arg((S, S), **op.lhs_make_tensor_kwargs)
        rhs = make_arg((S, S), **op.rhs_make_tensor_kwargs)

        yield SampleInput(lhs, args=(rhs,),
                          kwargs=dict(rtol=rtol, atol=atol, equal_nan=equal_nan))


def error_inputs_isclose(op, device, **kwargs):
    make_float_arg = partial(make_tensor, device=device, dtype=torch.float, requires_grad=False)

    yield ErrorInput(SampleInput(make_float_arg(()), args=(make_float_arg(()),), kwargs={'rtol': -0.4}),
                     error_type=RuntimeError,
                     error_regex='rtol must be greater than or equal to zero')

    yield ErrorInput(SampleInput(make_float_arg(()), args=(make_float_arg(()),), kwargs={'atol': -0.4}),
                     error_type=RuntimeError,
                     error_regex='atol must be greater than or equal to zero')


def sample_inputs_t(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    yield SampleInput(make_arg((1, 2)))
    yield SampleInput(make_arg((2,)))
    yield SampleInput(make_arg(()))


def sample_inputs_mm(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    def make_arg_conj(size):
        return make_arg(size).conj().requires_grad_(requires_grad)

    first_shape, second_shape = (S, M), (M, S)

    yield SampleInput(make_arg(first_shape), args=(make_arg(second_shape),))

    if dtype.is_complex:
        yield SampleInput(make_arg(first_shape), args=(make_arg_conj(second_shape),))


def sample_inputs_addmm(op_info, device, dtype, requires_grad, **kwargs):
    alpha_val = kwargs.get('alpha', 2 + 3j if dtype.is_complex else 0.6)
    beta_val = kwargs.get('beta', 1 + 2j if dtype.is_complex else 0.2)
    tests_list = [
        ((2, 3), (2, 2), (2, 3), False),
        ((3, 3), (3, 3), (3, 3), False),
    ]
    tests_with_lhs_broadcasting = [
        ((1,), (2, 2), (2, 3), True),
        ((), (2, 2), (2, 3), True),
    ]
    test_cases = tests_list + tests_with_lhs_broadcasting  # type: ignore[operator]

    kwargs = dict(alpha=alpha_val, beta=beta_val)
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    for shape_a, shape_b, shape_c, broadcasts_input in test_cases:
        yield SampleInput(
            make_arg(shape_a),
            make_arg(shape_b),
            make_arg(shape_c),
            **kwargs,
        ).with_metadata(broadcasts_input=broadcasts_input)

    if dtype.is_complex:
        shape = (3, 3)
        yield SampleInput(
            make_arg(shape),
            make_arg(shape, requires_grad=False).mH.requires_grad_(requires_grad),
            make_arg(shape),
            **kwargs,
        )
        yield SampleInput(
            make_arg(shape),
            make_arg(shape),
            make_arg(shape, requires_grad=False).mH.requires_grad_(requires_grad),
            **kwargs,
        )

def sample_inputs_sparse_sampled_addmm(op_info, device, dtype, requires_grad, **kwargs):
    alpha = 2 + 3j if dtype.is_complex else 0.6
    beta = 1 + 2j if dtype.is_complex else 0.2
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    for m, n, k in itertools.product([0, 5], repeat=3):
        yield SampleInput(
            torch.eye(m, n, device=device, dtype=dtype)
            .to_sparse_csr()
            .requires_grad_(requires_grad),
            make_arg((m, k)),
            make_arg((k, n)),
            alpha=alpha,
            beta=beta,
        )

def sample_inputs_sparse_mm_reduce(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    reductions = ["sum", "mean", "amax", "amin"]
    for m, k, reduce in product([5, 7], [3, 11], reductions):
        yield SampleInput(
            torch.eye(m, m)
            .to(device=device, dtype=dtype)
            .to_sparse_csr()
            .requires_grad_(requires_grad),
            make_arg((m, k)),
            reduce,
        )


def sample_inputs_mv(self, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, low=None, high=None, requires_grad=requires_grad)
    yield SampleInput(make_arg(S, M), make_arg(M))

def sample_inputs_bmm(self, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, low=None, high=None, requires_grad=requires_grad)
    yield SampleInput(make_arg(M, S, M), make_arg(M, M, S))

def sample_inputs_dot_vdot(self, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    def make_arg_conj(size):
        return make_arg(size).conj().requires_grad_(requires_grad)

    yield SampleInput(make_arg((S, )), make_arg((S, )))
    if dtype.is_complex:
        yield SampleInput(make_arg((S, )), make_arg_conj((S, )))


def error_inputs_dot_vdot(op_info, device, is_ref=False, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=torch.float32)

    if not is_ref:
        yield ErrorInput(SampleInput(make_input(1), args=(make_input(3, dtype=torch.float16),)),
                         error_regex='dot : expected both vectors to have same dtype')
    yield ErrorInput(SampleInput(make_input(1, 1), args=(make_input(3),)),
                     error_regex='1D tensors expected')
    yield ErrorInput(SampleInput(make_input(9), args=(make_input(3),)),
                     error_regex='inconsistent tensor size')
    if device != "cpu" and not is_ref:
        yield ErrorInput(SampleInput(make_input(3), args=(make_input(3, device="cpu"),)),
                         error_regex='Expected all tensors to be on the same device')


def sample_inputs_addmv(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    test_cases = (((S,), (S, M), (M,), 1, 1, False),
                  ((S,), (S, M), (M,), 0.2, 0.6, False),
                  )

    test_cases_with_broadcast = (((1,), (S, M), (M,), 1, 1, True),
                                 ((1,), (S, M), (M,), 0.2, 0.6, True),
                                 ((), (S, M), (M,), 1, 1, True),
                                 ((), (S, M), (M,), 0.2, 0.6, True),
                                 )

    cases = test_cases + test_cases_with_broadcast

    for size, mat, vec, beta, alpha, broadcasts_input in cases:
        yield SampleInput(make_arg(size), args=(make_arg(mat), make_arg(vec)),
                          kwargs=dict(beta=beta, alpha=alpha), broadcasts_input=broadcasts_input)

def sample_inputs_addbmm(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    test_cases = [((S, M), (S, S, S), (S, S, M), 1, 1, False),
                  ((1,), (S, S, S), (S, S, M), 1, 1, True),
                  ((S, M), (S, S, S), (S, S, M), 0.6, 0.2, False),
                  ((1,), (S, S, S), (S, S, M), 0.6, 0.2, True),
                  ((), (S, S, S), (S, S, M), 1, 1, True),
                  ((), (S, S, S), (S, S, M), 0.6, 0.2, True),
                  ]

    for input_shape, batch1_shape, batch2_shape, beta, alpha, is_broadcasting in test_cases:
        if dtype.is_complex:
            beta_complex, alpha_complex = beta * (1 + 2j), alpha * (2 + 3j)
            yield SampleInput(make_arg(input_shape), args=(make_arg(batch1_shape), make_arg(batch2_shape)),
                              kwargs=dict(beta=beta_complex, alpha=alpha_complex), broadcasts_input=is_broadcasting)
        yield SampleInput(make_arg(input_shape), args=(make_arg(batch1_shape), make_arg(batch2_shape)),
                          kwargs=dict(beta=beta, alpha=alpha), broadcasts_input=is_broadcasting)

def sample_inputs_addcmul_addcdiv(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    test_cases = [(((S, S), (S, S), (S, S)), False),
                  (((S, S), (S, 1), (1, S)), False),
                  (((1,), (S, S, 1), (1, S)), True),
                  (((), (), ()), False),
                  (((S, S), (), ()), True),
                  (((), (S, S, 1), (1, S)), True)
                  ]

    for input_args, broadcasts_input in test_cases:
        args = tuple(make_arg(arg, exclude_zero=True) if isinstance(arg, tuple) else arg
                     for arg in input_args)
        yield SampleInput(*args).with_metadata(broadcasts_input=broadcasts_input)

        args = tuple(make_arg(arg, exclude_zero=True) if isinstance(arg, tuple) else arg
                     for arg in input_args)
        yield SampleInput(
            *args, value=3.14 if dtype.is_floating_point or dtype.is_complex else 3
        ).with_metadata(broadcasts_input=broadcasts_input)

def reference_inputs_addcmul_addcdiv(op_info, device, dtype, requires_grad, **kwargs):
    yield from sample_inputs_addcmul_addcdiv(
        op_info, device, dtype, requires_grad, **kwargs)

    supported_dtypes = op_info.supported_dtypes(device)
    make_arg = partial(make_tensor, device=device, requires_grad=requires_grad)

    types = (
        (torch.float64, torch.complex128),
        (torch.bfloat16, torch.float32),
    )

    values = (
        None,
        True, False,
        3.14, 3,
        1.0, 1,
        0.0, 0,
        -3.14, -3,
        3.14 + 2.71j,
    )

    for (type2, type3), value in product(types, values):
        if (type2 not in supported_dtypes or
                type3 not in supported_dtypes):
            continue

        if (type(value) is complex and
                type2 is not torch.complex128):
            continue

        arg1 = make_arg([5, 5], dtype=dtype)
        arg2 = make_arg([5, 5], dtype=type2)
        arg3 = make_arg([1, 5], dtype=type3)

        if value is not None:
            yield SampleInput(arg1, args=(arg2, arg3), kwargs=dict(value=value))
        else:
            yield SampleInput(arg1, args=(arg2, arg3))

def sample_inputs_baddbmm(op_info, device, dtype, requires_grad, **kwargs):
    test_cases = [((S, S, M), (S, S, S), (S, S, M), 1, 1, False),
                  ((1,), (S, S, S), (S, S, M), 1, 1, True),
                  ((S, S, M), (S, S, S), (S, S, M), 0.6, 0.2, False),
                  ((1,), (S, S, S), (S, S, M), 0.6, 0.2, True),
                  ((), (S, S, S), (S, S, M), 1, 1, True),
                  ((), (S, S, S), (S, S, M), 0.6, 0.2, True),
                  ]
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad, low=None, high=None)
    for (input_shape, batch1_shape, batch2_shape, alpha, beta, broadcasts_input) in test_cases:
        yield SampleInput(
            make_arg(input_shape),
            make_arg(batch1_shape),
            make_arg(batch2_shape),
            beta=beta,
            alpha=alpha
        ).with_metadata(broadcasts_input=broadcasts_input)

        if dtype.is_complex:
            yield SampleInput(
                make_arg(input_shape),
                make_arg(batch1_shape),
                make_arg(batch2_shape),
                beta=beta * (1 + 2j),
                alpha=alpha * (2 + 3j),
            ).with_metadata(broadcasts_input=broadcasts_input)

    if dtype.is_complex:
        shapes = [(S, S, S), (S, M, S), (S, S, M)]
        args = tuple(make_arg(s) for s in shapes)
        yield SampleInput(
            args[0].transpose_(-1, 1),
            args[1].transpose(-1, 1).conj().requires_grad_(requires_grad),
            args[2].transpose(-1, 1).conj().requires_grad_(requires_grad),
            beta=beta * (1 + 2j),
            alpha=alpha * (2 + 3j),
        )

def sample_inputs_multilabel_soft_margin_loss(op_info, device, dtype, requires_grad, **kwargs):
    _make_tensor = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    shapes = (
        (S,),
        (S, S),
    )

    for shape in shapes:
        yield SampleInput(_make_tensor(shape), args=(_make_tensor(shape, requires_grad=False),), kwargs={})
        yield SampleInput(_make_tensor(shape), args=(_make_tensor(shape, requires_grad=False),),
                          kwargs={'weight': _make_tensor(shape, requires_grad=False)})

def sample_inputs_addr(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(
        make_tensor, device=device, dtype=dtype, requires_grad=requires_grad, low=None, high=None
    )
    yield SampleInput(make_arg(S, M), make_arg(S), make_arg(M))

    yield SampleInput(make_arg(), make_arg(S), make_arg(M)).with_metadata(broadcasts_input=True)

    if dtype.is_complex:
        alpha, beta = 0.1 + 0.3j, 0.4 + 0.6j
    elif dtype.is_floating_point:
        alpha, beta = 0.2, 0.6
    else:
        alpha, beta = 2, 3

    yield SampleInput(make_arg(S, M), make_arg(S), make_arg(M), beta=beta, alpha=alpha)

    yield SampleInput(
        make_arg(),
        make_arg(S),
        make_arg(M),
        beta=beta,
        alpha=alpha,
    ).with_metadata(broadcasts_input=True)

    if dtype.is_floating_point and not requires_grad:
        tensor_options = dict(device=device, dtype=dtype, requires_grad=requires_grad)
        yield SampleInput(
            torch.tensor([[math.nan]], **tensor_options),
            torch.tensor([0.0], **tensor_options),
            torch.tensor([0.0], **tensor_options),
            beta=0.0,
            alpha=0.0,
        ).with_metadata(broadcasts_input=True)

        yield SampleInput(
            torch.tensor([[0.0]], **tensor_options),
            torch.tensor([math.nan], **tensor_options),
            torch.tensor([math.nan], **tensor_options),
            beta=0.0,
            alpha=0.0,
        ).with_metadata(broadcasts_input=True)

def sample_inputs_zero_(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases = ((), (S, S, S), (S,))

    for shape in cases:
        yield SampleInput(make_arg(shape))

def sample_inputs_multi_margin_loss(op_info, device, dtype, requires_grad, **kwargs):
    _make_tensor = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    make_target = partial(_make_tensor, dtype=torch.long, requires_grad=False)
    make_weight = partial(_make_tensor, requires_grad=False)

    inputs = (
        ((), make_target([], low=0, high=1), {}),
        ((S,), make_target([], low=0, high=S), {"p": 1}),
        ((S,), make_target([1], low=0, high=S), {"p": 2}),
        ((S, M), make_target([S], low=0, high=M), {"margin": 1.0}),
        ((S, M), make_target([S], low=0, high=M), {"margin": -3.14}),
        ((M, S), make_target([M], low=0, high=S), {"weight": None}),
        ((M, S), make_target([M], low=0, high=S), {"weight": make_weight([S], low=-10., high=10.)}),
        ((M, S), make_target([M], low=0, high=S), {"reduction": "none"}),
        ((M, S), make_target([M], low=0, high=S), {"reduction": "mean"}),
        ((M, S), make_target([M], low=0, high=S), {"reduction": "sum"}),
    )

    for input_shape, target, kwargs in inputs:
        yield SampleInput(_make_tensor(input_shape), args=(target,), kwargs=kwargs)


def reference_inputs_multi_margin_loss(op_info, device, dtype, requires_grad, **kwargs):
    yield from sample_inputs_multi_margin_loss(op_info, device, dtype, requires_grad, **kwargs)
    _make_tensor = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    make_target = partial(_make_tensor, dtype=torch.long, requires_grad=False)
    make_weight = partial(_make_tensor, requires_grad=False)

    inputs = (
        ((), make_target([], low=0, high=1)),
        ((S,), make_target([], low=0, high=S)),
        ((S,), make_target([1], low=0, high=S)),
        ((M, S), make_target([M], low=0, high=S)),
    )
    ps = (1, 2)
    margins = (0, 7, -3.14)
    weights = (False, True)
    reductions = (None, "none", "mean", "sum")

    for (input_shape, target), p, margin, weight, reduction in product(inputs, ps, margins, weights, reductions):
        input = _make_tensor(input_shape)
        weight_shape = [input.size(-1)] if input.ndim > 0 else [1]
        weight = make_weight(weight_shape, low=-10., high=10.) if weight else None
        kwargs = {"p": p, "margin": margin, "weight": weight}
        if reduction is not None:
            kwargs["reduction"] = reduction
        yield SampleInput(input, args=(target,), kwargs=kwargs)


def error_inputs_multi_margin_loss(op, device, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=torch.float32)
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input(5,),), kwargs={'reduction': 'abc'}),
                     error_type=ValueError, error_regex='abc is not a valid value for reduction')
    yield ErrorInput(SampleInput(make_input(5, 0), args=(make_input(5,),), kwargs={}),
                     error_type=RuntimeError,
                     error_regex=r'Expected non-empty vector or matrix with optional 0-dim batch size, but got: \[5, 0\]')
    yield ErrorInput(SampleInput(make_input(0,), args=(make_input(5,),), kwargs={}),
                     error_type=RuntimeError,
                     error_regex=r'Expected non-empty vector or matrix with optional 0-dim batch size, but got: \[0\]')
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input(5, 4),), kwargs={}),
                     error_type=RuntimeError, error_regex=r'inconsistent target size, expected 5 but got \[5, 4\]')
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input(5,),), kwargs={}),
                     error_type=RuntimeError, error_regex='expected scalar type Long but found Float')
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input(5,),), kwargs={'weight': make_input(())}),
                     error_type=ValueError, error_regex='weight must be one-dimensional')
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input(5,),), kwargs={'weight': make_input(5, 4)}),
                     error_type=ValueError, error_regex='weight must be one-dimensional')
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input(5,),), kwargs={'weight': make_input(5,)}),
                     error_type=RuntimeError, error_regex=r'inconsistent weight size, expected 4 but got \[5\]')
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input(5,),), kwargs={'p': 3}),
                     error_type=ValueError, error_regex='only p == 1 and p == 2 supported')


def sample_inputs_logsumexp(self, device, dtype, requires_grad, **kwargs):
    inputs = (
        ((), (0,), True),
        ((S, S), (1,), True),
        ((S, S), (1,), False),
        ((S, S), (-2,), False),
        ((S, S), (0, 1), False),
    )
    lows = (None, 1e3, 1e6) if dtype in (torch.float32, torch.float64) else (None,)
    for low in lows:
        high = low * 2 if low is not None else None
        for shape, dim, keepdim in inputs:
            t = make_tensor(shape, dtype=dtype, device=device,
                            low=low, high=high,
                            requires_grad=requires_grad)
            yield SampleInput(t, dim, keepdim)

def reference_inputs_logsumexp(op, device, dtype, requires_grad, **kwargs):
    yield from sample_inputs_logsumexp(op, device, dtype, requires_grad, **kwargs)

    t = torch.tensor([20, 30, 100], dtype=dtype, device=device, requires_grad=requires_grad)
    yield SampleInput(t, 0, False)

    t = torch.tensor((), dtype=dtype, device=device, requires_grad=requires_grad)
    yield SampleInput(t, 0, False)

    t = torch.tensor(float("inf"))
    yield SampleInput(t, 0, True)

def sample_inputs_like_fns(self, device, dtype, requires_grad, **kwargs):
    inputs = [
        ((), {}),
        ((S, S), {}),
        ((0, S, 0), {}),
        ((S,), {'dtype': dtype, 'device': device}),
        ((S,), {'dtype': torch.double}),
        ((S,), {'device': 'cpu'}),
        ((S,), {'dtype': torch.double, 'device': 'cpu'}),
    ]
    if torch.cuda.is_available():
        inputs.append(((S,), {'device': 'cuda'}))

    for shape, kwargs in inputs:
        t = make_tensor(shape, dtype=dtype, device=device,
                        low=None, high=None,
                        requires_grad=requires_grad)
        yield SampleInput(t, **kwargs)

def reference_inputs_like_fns(op, device, dtype, requires_grad, **kwargs):
    yield from sample_inputs_like_fns(op, device, dtype, requires_grad, **kwargs)

    cases = (
        (), (0,), (1, 0), (1, 1, 4, 5), (5, 3, 0, 1), (1, 4, 3, 1, 1)
    )

    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    for shape in cases:
        yield SampleInput(make_arg(shape))
        yield SampleInput(make_arg(shape).transpose(0, -1))
        yield SampleInput(make_arg(shape, noncontiguous=True))
        yield SampleInput(make_arg(shape, noncontiguous=True).transpose(0, -1))

def sample_inputs_multilabel_margin_loss(op_info, device, dtype, requires_grad, **kwargs):
    _make_tensor = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    make_target = partial(_make_tensor, dtype=torch.long, requires_grad=False)

    inputs = (
        ([], make_target([], low=0, high=1), {}),
        ([S], make_target([S], low=0, high=S), {}),
        ([M, S], make_target([M, S], low=0, high=S), {}),
        ([M, S], make_target([M, S], low=0, high=S), {"reduction": "none"}),
        ([M, S], make_target([M, S], low=0, high=S), {"reduction": "mean"}),
        ([M, S], make_target([M, S], low=0, high=S), {"reduction": "sum"}),
    )

    for shape, target, kwargs in inputs:
        yield SampleInput(_make_tensor(shape), args=(target,), kwargs=kwargs)


def reference_inputs_multilabel_margin_loss(op_info, device, dtype, requires_grad, **kwargs):
    yield from sample_inputs_multilabel_margin_loss(op_info, device, dtype, requires_grad, **kwargs)
    _make_tensor = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    make_target = partial(_make_tensor, dtype=torch.long, requires_grad=False)
    make_target_tensor = partial(torch.tensor, device=device, dtype=torch.long, requires_grad=False)

    inputs = (
        ([], make_target([], low=-1, high=1)),
        ([S], make_target([S], low=-1, high=S)),
        ([M, S], make_target([M, S], low=-1, high=S)),
        ([], make_target_tensor(-1)),
        ([7], make_target_tensor([2, 0, 6, -1, 4, -1, 6])),
        ([4, 5], make_target_tensor([[4, -1, 0, -1, 2], [0, 0, 4, 1, 4], [-1, 3, -1, 1, 0], [4, 3, 2, 1, 0]])),
    )
    reductions = (None, "none", "mean", "sum")

    for (shape, target), reduction in product(inputs, reductions):
        kwargs = {}
        if reduction is not None:
            kwargs["reduction"] = reduction
        yield SampleInput(_make_tensor(shape), args=(target,), kwargs=kwargs)


def error_inputs_multilabel_margin_loss(op, device, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=torch.float32)
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input(5, 4),), kwargs={'reduction': 'abc'}),
                     error_type=ValueError, error_regex='abc is not a valid value for reduction')
    yield ErrorInput(SampleInput(make_input(5, 0), args=(make_input(5, 4),), kwargs={}),
                     error_type=RuntimeError,
                     error_regex=r'Expected non-empty vector or matrix with optional 0-dim batch size, but got: \[5, 0\]')
    yield ErrorInput(SampleInput(make_input(0,), args=(make_input(0,),), kwargs={}),
                     error_type=RuntimeError,
                     error_regex=r'Expected non-empty vector or matrix with optional 0-dim batch size, but got: \[0\]')
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input(4,),), kwargs={}),
                     error_type=RuntimeError,
                     error_regex=r'inconsistent target size: \[4\] for input of size: \[5, 4\]')
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input((),),), kwargs={}),
                     error_type=RuntimeError,
                     error_regex=r'inconsistent target size: \[\] for input of size: \[5, 4\]')


def get_independent_tensor(tensor):
    return tensor.clone().requires_grad_(tensor.requires_grad)

def sample_inputs_randint(self, device, dtype, requires_grad, **kwargs):
    low = 2
    high = 10

    for sample in sample_inputs_like_fns(self, device, dtype, requires_grad, **kwargs):
        sample.kwargs.setdefault('device', device)
        yield SampleInput(high, sample.input.shape, *sample.args, **sample.kwargs)
        yield SampleInput(low, high, sample.input.shape, *sample.args, **sample.kwargs)

def sample_inputs_randint_like(self, device, dtype, requires_grad, **kwargs):
    low = 2
    high = 10

    for sample in sample_inputs_like_fns(self, device, dtype, requires_grad, **kwargs):
        yield SampleInput(
            sample.input,
            high,
            *sample.args,
            **sample.kwargs)
        yield SampleInput(
            get_independent_tensor(sample.input),
            low,
            high,
            *sample.args,
            **sample.kwargs)

def sample_inputs_margin_ranking_loss(op_info, device, dtype, requires_grad, **kwargs):
    _make_tensor = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    shapes = (
        (),
        (S,),
        (S, S),
        (S, S, S),
    )

    margins = (0., 1.)
    reductions = ('sum', 'mean', 'none')

    for shape in shapes:
        for margin, reduction in product(margins, reductions):
            kwargs = {'margin': margin, 'reduction': reduction}
            yield SampleInput(_make_tensor(shape),
                              args=(_make_tensor(shape, requires_grad=False),
                                    _make_tensor(shape, requires_grad=False)),
                              kwargs=kwargs)

def reference_inputs_margin_ranking_loss(op, device, dtype, requires_grad, **kwargs):
    yield from sample_inputs_margin_ranking_loss(op, device, dtype, requires_grad, **kwargs)
    make_input = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    for reduction in ('sum', 'mean', 'none'):
        if dtype.is_floating_point:  # only supports ints and floats
            inp1 = make_input((10, ))
            inp1[2] = float('nan')
            inp2 = make_input((10, ))
            inp2[4] = float('nan')
            target = make_input((10, ))
            inp2[9] = float('nan')
            yield SampleInput(inp1, args=(inp2, target), kwargs={'reduction': reduction})

            inp1 = make_input((10, ))
            inp2[1] = float('inf')
            inp2 = make_input((10, ))
            inp2[4] = float('inf')
            target = make_input((10, ))
            inp2[7] = float('inf')
            yield SampleInput(inp1, args=(inp2, target), kwargs={'reduction': reduction})

        inp1 = make_input((5, 2))
        inp2 = make_input((5, 1))
        target = make_input((1, 2))
        yield SampleInput(inp1, args=(inp2, target), kwargs={'reduction': reduction})

def error_inputs_margin_ranking_loss(op, device, **kwargs):
    make_input = partial(make_tensor, device=device, dtype=torch.float32)
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input(5, 4), make_input(5, 4),), kwargs={'reduction': 'abc'}),
                     error_type=ValueError, error_regex='is not a valid value')
    yield ErrorInput(SampleInput(make_input(5, 4), args=(make_input(5, 4), make_input(5,),)),
                     error_regex='margin_ranking_loss : All input tensors should')

def sample_inputs_new_fns(self, device, dtype, requires_grad, *, is_strided=False, **kwargs):
    inputs = [
        ((), (), (), {}),
        ((S, S), (2, 0), (3, 4), {}),
        ((0, S, 0), (3, 2, 2), (1, 2, 3), {}),
        ((S,), (2, 3), (7, 8), {'dtype': dtype, 'device': device}),
        ((S,), (10,), (S,), {'dtype': torch.double}),
        ((S,), (1, 1, 12), (S, L, M), {'device': 'cpu'}),
        ((S,), (2, 2, 2), (L, M, S), {'dtype': torch.double, 'device': 'cpu'}),
    ]
    if torch.cuda.is_available():
        inputs.append(((S,), (7, 2), (3, 4), {'device': 'cuda'}))

    for input_shape, output_shape, strides, kwargs in inputs:
        t = make_tensor(input_shape, dtype=dtype, device=device,
                        low=None, high=None,
                        requires_grad=requires_grad)
        if is_strided:
            yield SampleInput(t, output_shape, strides, **kwargs)
        else:
            yield SampleInput(t, output_shape, **kwargs)

def sample_inputs_empty_strided(op, device, dtype, requires_grad=False, **kwargs):

    inputs = [
        ((), (), {'dtype': dtype, 'device': device}),
        ((S,), (4,), {'dtype': dtype, 'device': device}),
        ((S, S), (2, 1), {'dtype': dtype, 'device': device}),
        ((S, S, S), (2, 0, 1), {'dtype': dtype, 'device': device}),
    ]

    for shape, strides, kwargs in inputs:
        yield SampleInput(shape, strides, requires_grad=requires_grad, **kwargs)

def sample_inputs_empty(op, device, dtype, requires_grad, **kwargs):
    cases = (
        (), (0,), (1,), (1, 3, 5), (5, 3, 1), (1, 0, 5, 1),
    )

    for case in cases:
        yield SampleInput(case, device=device, dtype=dtype, requires_grad=requires_grad)

def sample_inputs_empty_permuted(op, device, dtype, requires_grad, **kwargs):
    cases = (
        (), (0,), (1,), (1, 3, 5), (5, 3, 1), (1, 0, 5, 1),
    )

    for case in cases:
        for layout in itertools.permutations(range(len(case))):
            yield SampleInput(case, layout, device=device, dtype=dtype, requires_grad=requires_grad)

def error_inputs_empty_permuted(op_info, device, **kwargs):
    yield ErrorInput(
        SampleInput((2,), args=((0, 1),)),
        error_type=RuntimeError,
        error_regex="Number of dimensions in size does not match the length of the physical_layout"
    )
    yield ErrorInput(
        SampleInput((2,), args=((3,),)),
        error_type=RuntimeError,
        error_regex="Dimension out of range"
    )
    yield ErrorInput(
        SampleInput((2, 3), args=((0, 0),)),
        error_type=RuntimeError,
        error_regex="Duplicate dim not allowed"
    )

def sample_inputs_scalar_tensor(op, device, dtype, requires_grad, **kwargs):
    vals = (-5, 0, 1)

    for item in vals:
        yield SampleInput(item, device=device, dtype=dtype, requires_grad=requires_grad)

def sample_inputs_eye(op, device, dtype, requires_grad, **kwargs):
    sizes = (None, 0, 1, 2, 3, 4, 7, L, M, S)

    for n, m in product(sizes, sizes):
        if n is None:
            continue

        _kwargs = {'device': device, 'dtype': dtype, 'requires_grad': requires_grad}
        if m is None:
            yield SampleInput(n, args=(), kwargs=_kwargs)
        else:
            yield SampleInput(n, args=(m,), kwargs=_kwargs)

def error_inputs_eye(op_info, device, **kwargs):
    _kwargs = {'device': device, 'dtype': torch.float32}

    yield ErrorInput(
        SampleInput(-1, args=(), kwargs=_kwargs),
        error_regex="n must be greater or equal to 0, got -1"
    )

    yield ErrorInput(
        SampleInput(-7, args=(42,), kwargs=_kwargs),
        error_regex="n must be greater or equal to 0, got -7"
    )

    yield ErrorInput(
        SampleInput(0, args=(-3,), kwargs=_kwargs),
        error_regex="m must be greater or equal to 0, got -3"
    )


def sample_inputs_new_full(self, device, dtype, requires_grad, **kwargs):
    def get_val(dtype):
        return make_tensor([], dtype=dtype, device="cpu").item()

    for sample in sample_inputs_new_fns(self, device, dtype, requires_grad, **kwargs):
        use_dtype = sample.kwargs['dtype'] if 'dtype' in sample.kwargs else dtype
        yield SampleInput(
            sample.input, *sample.args, get_val(use_dtype), **sample.kwargs)

def sample_inputs_full_like(self, device, dtype, requires_grad, **kwargs):
    def get_val(dtype):
        return make_tensor([], dtype=dtype, device="cpu").item()

    inputs = [
        ((), get_val(dtype), {}),
        ((S, S), get_val(dtype), {}),
        ((0, S, 0), get_val(dtype), {}),
        ((S,), get_val(dtype), {'dtype': dtype, 'device': device}),
        ((S,), get_val(torch.double), {'dtype': torch.double}),
        ((S,), get_val(dtype), {'device': 'cpu'}),
        ((S,), get_val(torch.double), {'dtype': torch.double, 'device': 'cpu'}),
    ]
    if torch.cuda.is_available():
        inputs.append(((S,), get_val(dtype), {'device': 'cuda'}))

    for shape, fill_value, kwargs in inputs:
        t = make_tensor(shape, dtype=dtype, device=device,
                        low=None, high=None,
                        requires_grad=requires_grad)
        yield SampleInput(t, fill_value, **kwargs)

def sample_inputs_multinomial(self, device, dtype, requires_grad, **kwargs):
    cases = [
        ([3], 3, {}),
        ([10], 3, {}),
        ([3, 10], 3, {}),
        ([3], 3, dict(replacement=False)),
        ([3], 3, dict(replacement=True)),
        ([3, 4], 4, dict(replacement=True)),
        ([3, 4], 4, dict(replacement=False)),
    ]

    for shape, num_samples, kwargs in cases:
        t = make_tensor(shape, dtype=dtype, device=device,
                        low=0, high=None,
                        requires_grad=requires_grad)
        yield SampleInput(t, num_samples, **kwargs)

def sample_inputs_normal_common(self, device, dtype, requires_grad, cases, **kwargs):
    def get_value_or_make_tensor(value_or_shape):
        if isinstance(value_or_shape, list):
            return make_tensor(value_or_shape, dtype=dtype, device=device,
                               low=0, high=None,
                               requires_grad=requires_grad)
        return value_or_shape

    for value_or_mean_shape, value_or_std_shape, kwargs in cases:
        mean = get_value_or_make_tensor(value_or_mean_shape)
        std = get_value_or_make_tensor(value_or_std_shape)
        yield SampleInput(mean, std, **kwargs)

def sample_inputs_normal_tensor_first(self, device, dtype, requires_grad, **kwargs):
    cases = [
        ([], [], {}),
        ([3], [3], {}),
        ([3, 4, 2], [3, 4, 2], {}),
        ([2, 3], 1.1, {}),
        ([1, 2, 3], [5, 2, 3], {}),  # broadcasting
    ]

    return sample_inputs_normal_common(self, device, dtype, requires_grad, cases, **kwargs)

def sample_inputs_normal_tensor_second(self, device, dtype, requires_grad, **kwargs):
    yield SampleInput(1.6, 0.3, [2, 3], dtype=dtype, device=device)
    yield SampleInput(1.6, 0.3, [2, 2, 2], dtype=dtype, layout=torch.strided, device=device)
    yield SampleInput(2.7, make_tensor([4, 3], dtype=dtype, device=device, low=0, high=None, requires_grad=requires_grad))

def sample_inputs_bernoulli(self, device, dtype, requires_grad, **kwargs):
    shapes = [
        [3],
        [],
        [0, 3],
        [2, 3, 4],
    ]

    for shape in shapes:
        t = make_tensor(shape, dtype=dtype, device=device,
                        low=0, high=1,
                        requires_grad=requires_grad)
        yield SampleInput(t)

def error_inputs_bernoulli(op_info, device, **kwargs):
    x = torch.rand((1,), device=device).expand((6,))
    err_msg = 'unsupported operation'
    yield ErrorInput(SampleInput(torch.rand_like(x), kwargs={'out': x}),
                     error_regex=err_msg)

def sample_inputs_logcumsumexp(self, device, dtype, requires_grad, **kwargs):
    inputs = (
        ((S, S, S), 0),
        ((S, S, S), 1),
        ((), 0),
    )

    for large_number in (True, False):
        for shape, dim in inputs:
            t = make_tensor(shape, dtype=dtype, device=device,
                            low=None, high=None,
                            requires_grad=requires_grad)

            if large_number and t.dim() > 0:
                t[0] = 10000
            yield SampleInput(t, dim)

def sample_inputs_trace(self, device, dtype, requires_grad, **kwargs):
    yield SampleInput(
        make_tensor((S, S), dtype=dtype, device=device,
                    low=None, high=None,
                    requires_grad=requires_grad))


def error_inputs_trace(op, device):
    yield ErrorInput(SampleInput(make_tensor((3, 4, 5), dtype=torch.float32, device=device)), error_regex="expected a matrix")


def sample_inputs_renorm(self, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    cases = (((S, S, S), (2, 1, 0.5)),
             ((S, S, S), (2, -1, 0.5)),
             ((S, S, S), (1, 2, 3)),
             ((S, S, S), (float('inf'), 2, 0.5)),
             )

    for shape, args in cases:
        yield SampleInput(make_arg(shape), args=args)


def sample_inputs_transpose_swapdims(self, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    cases = (((1, 2, 3), (-1, -2)),
             ((1, 2, 3), (-1, 2)),
             ((1, 2, 3), (1, -2)),
             ((1, 2, 3), (1, 2)),
             ((), (0, 0)),
             ((1, ), (0, 0)),
             ((M, M), (0, 1)),
             ((S, S, S), (2, 0)), )

    for shape, args in cases:
        yield SampleInput(make_arg(shape), args=args)

def _numpy_ref_transpose(a, dim0, dim1):
    if a.ndim <= 1:
        return a

    return np.swapaxes(a, dim0, dim1)

def sample_inputs_adjoint(self, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    shapes = ((1, 2, 3), (M, M), (S, S, S), (S, M, S), (M, S, M, S))
    return (SampleInput(make_arg(shape)) for shape in shapes)

def sample_inputs_T(self, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    shapes = ((M, M), (M, L))
    return (SampleInput(make_arg(shape)) for shape in shapes)

def error_inputs_T(self, device, has_ndims_error=False):
    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    if has_ndims_error:
        yield ErrorInput(SampleInput(make_arg(M)),
                         error_regex=(r'The use of `x\.T` on tensors of dimension other than 0 or 2 '
                                      r'to reverse their shape is not supported\.'))

        yield ErrorInput(SampleInput(make_arg(M, S, L)),
                         error_regex=(r'The use of `x\.T` on tensors of dimension other than 0 or 2 '
                                      r'to reverse their shape is not supported\.'))


def sample_inputs_singular_matrix_factors(op_info, device, dtype, requires_grad=False, **kwargs):

    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    batches = [(), (0, ), (2, ), (1, 1)]
    size = [1, 5, 10]

    for batch, m, n in product(batches, size, size):
        for k in range(min(3, m, n)):
            a = make_arg((*batch, m, k))
            b = make_arg((*batch, n, k))
            yield SampleInput(a, b, **kwargs)


def sample_inputs_svd_lowrank(op_info, device, dtype, requires_grad=False, **kwargs):
    for sample in sample_inputs_singular_matrix_factors(op_info, device, dtype, requires_grad, **kwargs):
        *batch, m, k = sample.input.shape
        *_, n, _ = sample.args[0].shape

        op_kwargs = {
            'q': k,
            'M': None
        }

        yield clone_sample(sample, **op_kwargs)

        op_kwargs['M'] = make_tensor((*batch, m, n), dtype=dtype, device=device, requires_grad=requires_grad)
        yield clone_sample(sample, **op_kwargs)

def chunk_iter(iterable, size):
    it = iter(iterable)
    while True:
        chunk = tuple(islice(it, size))
        if not chunk:
            break
        yield chunk

def sample_inputs_pca_lowrank(op_info, device, dtype, requires_grad=False, **kwargs):
    samples = sample_inputs_svd_lowrank(op_info, device, dtype, requires_grad, **kwargs)
    for s1, s2 in chunk_iter(samples, 2):
        del s1.kwargs['M']
        del s2.kwargs['M']
        s1.kwargs['center'] = False
        s2.kwargs['center'] = True
        yield s1
        yield s2

def np_sinc_with_fp16_as_fp32(x):
    if x.dtype == np.float16:
        return np.sinc(x.astype(np.float32))
    else:
        return np.sinc(x)

def sample_inputs_broadcast_to(op_info, device, dtype, requires_grad, **kwargs):
    test_cases = (
        ((S, 1, 1), (S, S, S)),
        ((S, 1, S), (S, S, S)),
        ((S, 1), (S, S, S)),
        ((1,), (S, S, S)),
        ((1, S), (1, 1, S)),
        ((), ()),
        ((), (1, 3, 2)),
    )

    return (
        SampleInput(
            make_tensor(size, dtype=dtype, device=device, low=None, high=None, requires_grad=requires_grad),
            shape,
        ) for size, shape in test_cases)

def sample_inputs_broadcast_tensors(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    test_cases: Tuple[tuple] = (((3,), (1, 2, 1), (1, 1), (5, 1, 1),),)

    for shape, *other_shapes in test_cases:
        yield SampleInput(make_arg(shape), args=tuple(make_arg(s) for s in other_shapes))

def reference_inputs_broadcast_tensors(op, device, dtype, requires_grad, **kwargs):
    yield from sample_inputs_broadcast_tensors(op, device, dtype, requires_grad, **kwargs)

    m = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    n = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad, noncontiguous=True)

    cases = (
        ((), (1, 1), (1, 1, 7, 1), (3, 1, 1)),
        ((3, 5, 6), (1, 3, 5, 6), (1, 1, 1, 1, 6), (8, 3, 5, 6))
    )

    for a, b, c, d in cases:
        yield SampleInput(m(a), args=(m(b), m(c), m(d)))
        yield SampleInput(n(a), args=(n(b), n(c), n(d)))

def sample_inputs_block_diag(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    test_cases: Tuple[tuple] = (
        ((1, S), (2, S), (3, S),),
        ((S, 1), (S, 2), (S, 3),),
        ((1,), (2,), (3,),),
        ((2, S), (S,))
    )

    for shape, *other_shapes in test_cases:
        yield SampleInput(make_arg(shape), args=tuple(make_arg(s) for s in other_shapes))
        if dtype == torch.complex32 or dtype == torch.complex64:
            non_complex_dtype = torch.float32 if dtype == torch.complex32 else torch.float64
            make_arg_non_complex = partial(make_tensor, dtype=non_complex_dtype, device=device, requires_grad=requires_grad)
            yield SampleInput(make_arg_non_complex(shape), args=tuple(make_arg(s) for s in other_shapes))

def sample_inputs_cdist(op_info, device, dtype, requires_grad, **kwargs):
    small_S = 2
    test_cases = (
        ((S, S, 2), (S, S + 1, 2)),
        ((S, S), (S, S)),
        ((S, S, S), (S, S, S)),
        ((3, 5), (3, 5)),
        ((2, 3, 5), (2, 3, 5)),
        ((1, 2, 3), (1, 2, 3)),
        ((1, 1), (S, 1)),
        ((0, 5), (4, 5)),
        ((4, 5), (0, 5)),
        ((0, 4, 5), (3, 5)),
        ((4, 5), (0, 3, 5)),
        ((0, 4, 5), (1, 3, 5)),
        ((1, 4, 5), (0, 3, 5)),
        ((small_S, small_S, small_S + 1, 2), (small_S, small_S, small_S + 2, 2)),
        ((small_S, 1, 1, small_S), (1, small_S, small_S)),
        ((1, 1, small_S), (small_S, 1, small_S, small_S)),
    )

    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    for cm in ['use_mm_for_euclid_dist', 'donot_use_mm_for_euclid_dist']:
        for p in [0., 1., 2., 3., 0.5, 1.5, 2.5, float("inf")]:
            for t1_size, t2_size in test_cases:
                yield SampleInput(make_arg(t1_size), make_arg(t2_size), p, cm)

def _fill_np(a, value):
    a = a.copy()
    a.fill(value)
    return a

def _fill_sample_kwargs(device, dtype, input):
    if dtype is torch.bool:
        value = True
    else:
        value = 3

    return ({'value': value}, {'value': value})

def sample_inputs_comparison_ops(op, device, dtype, requires_grad, **kwargs):
    yield from sample_inputs_elementwise_binary(op, device, dtype, requires_grad, **kwargs)

    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    lhs = make_arg((S, S))
    yield SampleInput(lhs, args=(lhs.clone(),))

def sample_inputs_stack(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases = (
        ((3, 4), 1),
        ((1, 2, 1, 4), 3),
        ((0, 1, 0), 2),)

    for shape, num_tensors in cases:
        tensors = []
        for _ in range(num_tensors):
            tensors.append(make_arg(shape))
        for dim in range(-1, len(shape) - 1):
            yield SampleInput(tensors, args=(dim,))

def sample_inputs_cat_concat(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases: Tuple[tuple, tuple, dict] = (  # type: ignore[assignment]
        ((S, S), (S, S), {'dim': -1}),
        ((S, S), (S, S), {'dim': 1}),
        ((M, S), (S, S), {'dim': 0}),  # different shapes
        ((1, 2, 3), (1, 2, 3), {'dim': -2}),
        ((0,), (0,), {'dim': 0}),  # empty tensor
        ((0,), (S, S), {'dim': 1}),  # empty tensor with unempty and dim=1 (special case for legacy_cat_wrap_dim)
        ((0, S), (S, S), {'dim': 0}),
        ((1,), (1,), {})  # dim not passed, fallback to default
    )

    for input_shape1, input_shape2, kwargs in cases:
        yield SampleInput([make_arg(input_shape1), make_arg(input_shape2)], kwargs=kwargs)

    yield SampleInput([make_arg((2, 2, 2, 2), memory_format=torch.channels_last)], args=(1,),)

def error_inputs_cat(op_info, device, **kwargs):

    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    yield ErrorInput(SampleInput([make_arg((S, S)), make_arg((S, S))],
                                 kwargs={'out': make_arg((1, S)).expand((2 * S, S))}),
                     error_regex='unsupported operation')

    yield ErrorInput(SampleInput([], kwargs={'dim': 1}),
                     error_regex='non-empty list of Tensors')

    yield ErrorInput(SampleInput([make_arg((S, S, L, L)), make_arg((S, 0, L - 1, L))], kwargs={'dim': 1}),
                     error_regex='Sizes of tensors must match except in dimension')
    yield ErrorInput(SampleInput([make_arg((S, 0, L - 1, L)), make_arg((S, S, L, L))], kwargs={'dim': 1}),
                     error_regex='Sizes of tensors must match except in dimension')

    yield ErrorInput(SampleInput([make_arg((S - 1, 0)), make_arg((S, 0, L - 1, L))], kwargs={'dim': 1}),
                     error_regex='Tensors must have same number of dimensions')
    yield ErrorInput(SampleInput([make_arg((S, 0, L - 1, L)), make_arg((S - 1, 0))], kwargs={'dim': 1}),
                     error_regex='Tensors must have same number of dimensions')

    x = torch.zeros((0), device=device)
    y = torch.randn((4, 6), device=device)

    err_msg = "the written-to tensor refer to a single memory location"

    yield ErrorInput(SampleInput((x, y), kwargs={'dim': 0, 'out': x}),
                     error_regex=err_msg)
    yield ErrorInput(SampleInput((x, y), kwargs={'dim': 0, 'out': y}),
                     error_regex=err_msg)

    z = torch.zeros((4, 6), device=device)
    yield ErrorInput(SampleInput((y, z), kwargs={'out': z[:2, :]}),
                     error_regex=err_msg)

    if torch.device(device).type == 'cuda':
        x_cuda = make_tensor((3, 3), device=device, dtype=torch.float32)
        y_cpu = make_tensor((3, 3), device='cpu', dtype=torch.float32)
        yield ErrorInput(SampleInput((x_cuda, y_cpu)),
                         error_regex='Expected all tensors to be on the same device')

    yield ErrorInput(SampleInput([make_arg((L, 1)), make_arg((L, 1, 1)), make_arg((L, 1, 1))]),
                     error_regex='Tensors must have same number of dimensions')

    yield ErrorInput(SampleInput([make_arg((S, 1, M)), make_arg((S, 1, 1)), make_arg((S, M, 1))],
                                 kwargs={'dim': 1}),
                     error_regex='Sizes of tensors must match')

    yield ErrorInput(SampleInput((make_arg((S, 1, 1)), None)), error_type=TypeError,
                     error_regex='got None')

    yield ErrorInput(SampleInput([make_arg(()), make_arg(())]),
                     error_regex='zero-dimensional.*cannot be concatenated')

    d = make_tensor((2, 3), device=device, dtype=torch.double)
    x = make_tensor((2, 3), device=device, dtype=torch.float32)
    yield ErrorInput(SampleInput(x, kwargs={'out': d}), error_type=TypeError,
                     error_regex='invalid combination of arguments')

def reference_inputs_cat(op, device, dtype, requires_grad, **kwargs):
    yield from sample_inputs_cat_concat(op, device, dtype, requires_grad, **kwargs)

    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    a = make_arg((3, 4, 2))
    b = make_arg((3, 2, 2), noncontiguous=True, dtype=torch.double)
    c = make_arg((3, 3, 2), dtype=torch.float16).permute(1, 0, 2)

    yield SampleInput((a, b, c), kwargs={'dim': 1})

    a = make_arg((0,))
    b = make_arg((3, 2, 2))

    yield SampleInput((a, b, a))
    yield SampleInput((a, a, a))

def _elementwise_type_promo_np(*args, type_promotion_kind):
    def _maybe_torch(x):
        if isinstance(x, np.ndarray):
            return torch.from_numpy(x)
        return x

    flattened = pytree.arg_tree_leaves(*args)
    transformed = tuple(_maybe_torch(a) for a in flattened)
    result_dtype, _ = prims.utils.elementwise_dtypes(
        *transformed,
        type_promotion_kind=type_promotion_kind)
    return torch_to_numpy_dtype_dict[result_dtype]

def _cat_np(input_seq, dim=0):
    inputs = tuple(a for a in input_seq if not (a.ndim == 1 and a.size == 0))

    if len(inputs) == 0:
        np_dtype = _elementwise_type_promo_np(
            input_seq,
            type_promotion_kind=prims.utils.ELEMENTWISE_TYPE_PROMOTION_KIND.NO_OPMATH)
        return np.empty(0, dtype=np_dtype)

    return np.concatenate(inputs, axis=dim)

def _floor_divide_np(a, b):
    dtype = _elementwise_type_promo_np(
        a,
        b,
        type_promotion_kind=prims.utils.ELEMENTWISE_TYPE_PROMOTION_KIND.DEFAULT)
    if isinstance(a, np.ndarray):
        a = a.astype(dtype)
    if isinstance(b, np.ndarray):
        b = b.astype(dtype)
    return np.floor_divide(a, b)

def sample_inputs_hstack_dstack_vstack(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    tensor_shapes = (
        ((S,), (S,), (S,)),
        ((S, S), (S, S), (S, S)),
    )
    for s1, s2, s3 in tensor_shapes:
        tensors = (make_arg(s1,), make_arg(s2,), make_arg(s3))
        yield SampleInput(tensors)

def error_inputs_hstack_dstack_vstack(op, device):
    make_arg = partial(make_tensor, dtype=torch.int32, device=device, requires_grad=False)
    tensor_shapes = (
        ((S,), (S, S, S, S), (S,)),
    )
    for s1, s2, s3 in tensor_shapes:
        tensors = (make_arg(s1,), make_arg(s2,), make_arg(s3))
        yield ErrorInput(SampleInput(tensors), error_regex="Tensors must have same number of dimensions")

    yield ErrorInput(SampleInput(()), error_regex="expects a non-empty TensorList")

def sample_inputs_unbind(op_info, device, dtype, requires_grad, **kwargs):
    shape_dims = (((S,), 0),
                  ((S, S), 0),
                  ((S, S), 1),
                  ((S, S), -1),
                  ((S, 0, S), 0),
                  ((S, S, S), 1),
                  )
    for shape, dim in shape_dims:
        yield SampleInput(make_tensor(shape, dtype=dtype, device=device,
                                      requires_grad=requires_grad),
                          args=(dim,))

def error_inputs_unbind(op_info, device):
    make_arg = partial(make_tensor, dtype=torch.int32, device=device, requires_grad=False)
    yield ErrorInput(SampleInput(make_arg(()), args=(0,)), error_type=IndexError,
                     error_regex="Dimension specified as 0 but tensor has no dimensions")
    yield ErrorInput(SampleInput(make_arg((2,)), args=(2,)), error_type=IndexError,
                     error_regex="Dimension out of range")

def reference_unbind(t, dim):

        t = torch.tensor([[1], [2], [3]])
        yield ErrorInput(SampleInput(t, kwargs=dict(edge_order=1)),
                         error_type=RuntimeError,
                         error_regex='torch.gradient expected each dimension size to be at least')

        t = torch.tensor([[1, 2], [3, 4]])
        yield ErrorInput(SampleInput(t, kwargs=dict(edge_order=2)),
                         error_type=RuntimeError,
                         error_regex='torch.gradient expected each dimension size to be at least')

def error_inputs_rrelu(op_info, device, **kwargs):
    input = make_tensor((S, S), device=device, dtype=torch.float32)
    yield ErrorInput(SampleInput(input, kwargs={'lower': 0.3, 'upper': 0.1}),
                     error_regex='Lower bound should be less than or equal to the upper bound')

def error_inputs_masked_select(op_info, device, **kwargs):
    x = torch.rand((1,), device=device).expand((3,))
    y = torch.rand((6,), device=device)
    mask = torch.tensor([True, False, True, True, False, False], device=device)

    yield ErrorInput(SampleInput(y, args=(mask,), kwargs=dict(out=x)),
                     error_type=RuntimeError,
                     error_regex='unsupported operation')

    yield ErrorInput(SampleInput(y, args=(mask,), kwargs=dict(out=y)),
                     error_type=RuntimeError,
                     error_regex='unsupported operation')

    yield ErrorInput(SampleInput(mask.clone(), args=(mask,), kwargs=dict(out=mask)),
                     error_type=RuntimeError,
                     error_regex='unsupported operation')

def error_inputs_median(op_info, device, **kwargs):
    x = torch.tensor([[[[[[[[[[[[[[[[[[[[[[[[[nan],
                               [nan]]]]]]]]]]]]]]]]]]]]]]]]], device=device)
    if device == 'cuda':
        yield ErrorInput(SampleInput(x, kwargs=dict(dim=(-1))),
                         error_type=RuntimeError,
                         error_regex='CUDA Tensors cannot have more than 25 dimensions')
    else:
        return


def error_inputs_index_select(op_info, device, **kwargs):
    x = torch.rand((1, 6), device=device).expand((2, 6))
    y = torch.rand((3, 6), device=device)
    ind = torch.tensor([0, 1], dtype=torch.int64, device=device)

    yield ErrorInput(SampleInput(y, args=(1, ind,), kwargs=dict(out=x)),
                     error_type=RuntimeError,
                     error_regex='unsupported operation')

def error_inputs_index_add(op_info, device, **kwargs):
    result = torch.tensor([[1., 2.], [4., 5.], [7., 8.]])
    source = torch.tensor([2., 4.])

    yield ErrorInput(SampleInput(result, args=(0, torch.tensor([0, 2]), source)),
                     error_type=RuntimeError,
                     error_regex=r'source tensor shape must match self tensor shape, '
                     r'excluding the specified dimension. Got self.shape = \[3, 2\] source.shape = \[2\]')

def error_inputs_logcumsumexp(op_info, device, **kwargs):
    dim = 3
    srcs = [torch.randn(5, 2, device=device), torch.randn(0, 2, device=device)]
    for src in srcs:
        yield ErrorInput(SampleInput(src, args=(dim,)),
                         error_type=IndexError,
                         error_regex='Dimension out of range')

def sample_inputs_take_along_dim(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad, low=None, high=None)
    yield SampleInput(
        make_arg((S, S)), gather_variable((S, S), 1, S, True, device=device), 0)

    yield SampleInput(
        make_arg((S, S)), gather_variable((1, S // 2), 0, S, True, device=device), 1)

    yield SampleInput(
        make_arg((1, S)), gather_variable((S, S // 2), 0, S, True, device=device), 1)

    yield SampleInput(
        make_arg((S, S)), gather_variable((S, S // 2), 0, S, True, device=device))


def error_inputs_aminmax_amax_amin(op_info, device, is_ref=False, **kwargs):

    shape = (S, 0, S)
    err_msg_amax_amin = "reduction"
    err_msg_aminmax = "cannot compute aminmax over an empty dimension as the operation has no identity"
    if op_info.name in ['amax', 'amin', '_refs.amax', '_refs.amin']:
        yield ErrorInput(SampleInput(torch.rand(shape, device=device)), error_regex=err_msg_amax_amin)
    elif op_info.name in ['aminmax']:
        yield ErrorInput(SampleInput(torch.rand(shape, device=device)), error_regex=err_msg_aminmax)

    sizes = [1] * 65
    err_msg1 = "only tensors with up to 64 dims are supported"
    yield ErrorInput(SampleInput(torch.randn(sizes, device=device), kwargs={'dim': -1}),
                     error_regex=err_msg1)
    yield ErrorInput(SampleInput(torch.randn(sizes, device=device), kwargs={'dim': 64}),
                     error_regex=err_msg1)

    if op_info.name in ['amax', 'amin', '_refs.amax', '_refs.amin']:
        dims = [(0, 0), (0, -4)]
        err_msg2 = "in the list of dims"
        x = torch.randn(S, S, S, S, device=device)
        for dim in dims:
            yield ErrorInput(SampleInput(x, kwargs={'dim': dim}), error_regex=err_msg2)

    input5 = torch.randn(L, L, dtype=torch.float32, device=device)
    max_values = torch.empty(L, dtype=torch.float32, device=device)
    min_values = torch.empty(L, dtype=torch.double, device=device)
    illegal_values = torch.empty(L, dtype=torch.int, device=device)

    if is_ref:
        err_msg_amax_amin2 = ("Attempting to cast from torch.float32 to out tensor with dtype "
                              "torch.int32, but this can't be cast because it is not safe!")
    else:
        err_msg_amax_amin2 = ("Expected the dtype for input and out to match, but got Float "
                              "for input's dtype and Int for out's dtype.")
    err_msg_aminmax2 = "Expected out tensor to have dtype float, but got double instead"

    if op_info.name in ['amax', 'amin', '_refs.amax', '_refs.amin']:
        yield ErrorInput(SampleInput(input5, kwargs={'dim': 0, 'out': illegal_values}),
                         error_regex=err_msg_amax_amin2)
    elif op_info.name in ['aminmax']:
        yield ErrorInput(SampleInput(input5, kwargs={'dim': 0, 'out': (max_values, min_values)}),
                         error_regex=err_msg_aminmax2)

    err_msg3 = "reduction"
    error_type = IndexError if 'refs' not in op_info.name else RuntimeError
    yield ErrorInput(SampleInput(torch.rand(shape, device=device), kwargs={'dim': 1}),
                     error_type=error_type, error_regex=err_msg3)

def sample_inputs_aminmax(op_info, device, dtype, requires_grad, **kwargs):
    test_cases: Tuple[tuple, dict] = (  # type: ignore[assignment]
        ((S, S, S), {}),
        ((S, S, S), {'dim': 1}),
        ((S, S, S), {'dim': 1, 'keepdim': True}),
        ((), {'dim': 0}),
        ((), {}),
        ((), {'dim': 0, 'keepdim': True}),
        ((S, 0, S), {'dim': 0}),
    )

    for shape, kwargs in test_cases:
        yield SampleInput(
            make_tensor(shape, dtype=dtype, device=device, requires_grad=requires_grad),
            **kwargs)

def error_inputs_diff(op_info, device, **kwargs):
    t = torch.rand((1, 3), device=device)
    n = -1
    yield ErrorInput(SampleInput(t, args=(n, ), kwargs=kwargs),
                     error_type=RuntimeError,
                     error_regex=f'order must be non-negative but got {n}')

def sample_inputs_diff(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    test_cases = (
        ((1,), 0, None, None),
        ((S,), 0, None, None),
        ((S, 1), 0, None, None),
        ((S, 1), 1, None, None),
        ((S, S), 0, None, None),
        ((S, S), 1, None, None),
        ((S, S), 0, (1, S), (2, S)),
        ((S, S), 0, None, (2, S)),
        ((XS, XS, XS), 1, None, None),
        ((XS, XS, XS), 2, None, None),
        ((XS, XS, XS), 1, (XS, 1, XS), (XS, 1, XS)),
        ((XS, XS, XS), 2, (XS, XS, 1), (XS, XS, 1)),
        ((XS, XS, XS), 2, (XS, XS, XS), (XS, XS, XS)),)

    sample_inputs = []
    for size, dim, size_prepend, size_append in test_cases:
        prepend_size = 0 if (size_prepend is None) else size_prepend[dim]
        append_size = 0 if (size_append is None) else size_append[dim]
        dim_size = size[dim] + prepend_size + append_size
        for n in range(dim_size):
            input_tensor = make_arg(size)
            prepend = make_arg(size_prepend) if size_prepend else None
            append = make_arg(size_append) if size_append else None
            yield SampleInput(input_tensor, n, dim, prepend, append)

    yield SampleInput(make_arg((XS, XS, XS)), S + 1, 1)
    yield SampleInput(make_arg((XS, XS, XS)), S * 3 + 2, 2, make_arg((XS, XS, XS)), make_arg((XS, XS, XS)))

def sample_inputs_histogram(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    sizes = ((), (S,), (S, S), (S, S, S), (S, 1, S), (S, 0, S))

    for size, bin_ct, weighted, density in product(sizes, range(1, 5), [False, True], [False, True]):
        input_tensor = make_arg(size)
        weight_tensor = make_arg(size) if weighted else None

        yield SampleInput(input_tensor, bin_ct,
                          weight=weight_tensor, density=density)

        bins_tensor = make_arg((bin_ct + 1,))
        yield SampleInput(input_tensor, bins_tensor,
                          weight=weight_tensor, density=density)

def sample_inputs_histogramdd(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    sizes = ((S, S), (S, S, S), (S, 1, S), (S, 0, S))
    bin_ct_patterns = ((1, 1, 1, 1, 1), (2, 3, 2, 3, 2), (3, 2, 3, 2, 3))

    for size, bin_ct_pattern, weighted, density in product(sizes, bin_ct_patterns, [False, True], [False, True]):
        input_tensor = make_arg(size)
        bin_ct = bin_ct_pattern[:size[-1]]
        weight_tensor = make_arg(size[:-1]) if weighted else None

        yield SampleInput(input_tensor, bin_ct,
                          weight=weight_tensor, density=density)

        bins_tensor = [make_arg(ct + 1) for ct in bin_ct]
        yield SampleInput(input_tensor, bins_tensor,
                          weight=weight_tensor, density=density)

def error_inputs_histogramdd(opinfo, device, **kwargs):
    invalid_bins = [1, 1, 1, 1, 1]
    make_arg = partial(make_tensor, dtype=torch.float, device=device, requires_grad=False)
    msg = "histogramdd: The size of bins must be equal to the innermost dimension of the input."
    yield ErrorInput(SampleInput(make_arg(5, 6), invalid_bins), error_regex=msg)

def sample_inputs_histc(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    sizes = ((), (S,), (S, S), (S, S, S), (S, 1, S), (S, 0, S))

    for size, min, max in product(sizes, [0, -10], [0, 10]):
        yield SampleInput(make_arg(size), min=min, max=max)

        for bins in [1, 3, 10]:
            yield SampleInput(make_arg(size), bins=bins, min=min, max=max)

def sample_inputs_bincount(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    for size, weighted in product((S, M), [False, True]):
        input_tensor = torch.randint(0, size, (size,), dtype=dtype, device=device)
        weight_tensor = make_arg((size,)) if weighted else None

        max_val = int(input_tensor.max().item())

        for minlength in [0, max_val // 2, max_val, 2 * max_val]:
            yield SampleInput(
                input_tensor, weights=weight_tensor, minlength=minlength)

def sample_inputs_bucketize(op_info, device, dtype, requires_grad, reference_inputs_mode=False, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    sizes = (((), S), ((S,), S), ((S, S), S), ((S, S, S), S), ((S, 1, S), S), ((S, 0, S), S))

    if reference_inputs_mode:
        sizes += (((256,), 128), ((128,), 256), ((32, 32), 11), ((32, 4, 32), 33))

    for (input_shape, nb), out_int32, right in product(sizes, [False, True], [False, True]):
        input_tensor = make_arg(input_shape)
        boundaries = make_arg(nb).msort()

        yield SampleInput(input_tensor, boundaries,
                          out_int32=out_int32, right=right)

reference_inputs_bucketize = partial(sample_inputs_bucketize, reference_inputs_mode=True)

def error_inputs_bucketize(opinfo, device, **kwargs):
    make_arg = partial(make_tensor, dtype=torch.float, device=device, requires_grad=False)
    yield ErrorInput(SampleInput(make_arg((S, S, S)), make_arg((S, S))),
                     error_regex="boundaries tensor must be 1 dimension")

def sample_inputs_searchsorted(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    sizes = (
        ((0,), ((0,),), False),
        ((M,), ((), (M,), (M, M)), False),
        ((0, 0), ((0, 0),), False),
        ((M, M), ((M, M),), False),
        ((0, 0, 0), ((0, 0, 0),), False),
        ((M, M, M), ((M, M, M),), False),
        ((L,), ((),), True),
    )

    for (size, input_sizes, is_scalar), noncontiguous, out_int32, right in product(
        sizes, [False, True], [False, True], [False, True]
    ):
        unsorted_tensor = make_arg(size, noncontiguous=noncontiguous)
        for input_size in input_sizes:
            input = make_arg(input_size, noncontiguous=noncontiguous)
            if is_scalar:
                input = input.item()
            if np.prod(size) == 0:
                boundary_tensor = unsorted_tensor
                sorter = make_tensor(size, dtype=torch.int64, device=device, noncontiguous=noncontiguous)
            else:
                boundary_tensor, sorter = torch.sort(unsorted_tensor)
            side = "right" if right else "left"

            yield SampleInput(boundary_tensor, input, out_int32=out_int32, right=right)
            yield SampleInput(boundary_tensor, input, out_int32=out_int32, side=side)

            yield SampleInput(unsorted_tensor, input, out_int32=out_int32, right=right, sorter=sorter)
            yield SampleInput(unsorted_tensor, input, out_int32=out_int32, side=side, sorter=sorter)

def sample_inputs_gradient(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad, low=None, high=None)
    test_cases_float = (
        ((S,), None, None, 1),
        ((S,), 2., None, 1),
        ((S, S), None, None, 2),
        ((S, S), [2.0, 2.1], None, 1),
        ((S, S), [2.0, 2.1], (0, 1), 1),
        ((4, 4, 4), [2., 1.], (0, 1), 2),
    )
    for size, spacing, dim, edge_order in test_cases_float:
        t = make_arg(size)
        yield SampleInput(t, dim=dim, spacing=spacing, edge_order=edge_order)

    test_cases_tensor = (
        ((3, 3, 3), ((1.1, 2.0, 3.5), (4.0, 2, 6.0)), (0, -1), 1),
        ((3, 3, 3), ((1.0, 3.0, 2.0), (8.0, 6.0, 1.0)), (0, 1), 2),
    )
    for size, coordinates, dim, edge_order in test_cases_tensor:
        t = make_arg(size)
        coordinates_tensor_list = []
        for coords in coordinates:
            a = torch.tensor(coords, device=device)
            coordinates_tensor_list.append(a.to(dtype))
        yield SampleInput(t, dim=dim, spacing=coordinates_tensor_list, edge_order=edge_order)

def sample_inputs_getitem(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    test_args = [
        ([1, 2],),
        (slice(0, 3),),
        ([slice(0, 3), 1],),
        ([[0, 2, 3], [1, 3, 3], [0, 0, 2]],),
        ([[0, 0, 3], [1, 1, 3], [0, 0, 2]],),
        ([slice(None), slice(None), [0, 3]],),
        ([slice(None), [0, 3], slice(None)],),
        ([[0, 3], slice(None), slice(None)],),
        ([[0, 3], [1, 2], slice(None)],),
        ([[0, 3], ],),
        ([[0, 3], slice(None)],),
        ([[0, 3], Ellipsis],),
        ([[0, 2, 3], [1, 3, 3], torch.LongTensor([0, 0, 2])],),
        (index_variable(2, S, device=device),),
        (mask_not_all_zeros((S,)),),
    ]

    for args in test_args:
        yield SampleInput(make_arg((S, S, S)), args=args)

    yield SampleInput(make_arg((S, S, S, S)), args=([slice(None), [0, 1], slice(None), [0, 1]],))

def sample_inputs_index_put(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)

    for accumulate in [False, True]:
        yield SampleInput(
            make_arg((S, S,)),
            (index_variable(2, S, device=device),),
            make_arg((2, S)),
            accumulate=accumulate)

        mask = torch.zeros(S, dtype=torch.bool) if accumulate else mask_not_all_zeros((S,))
        yield SampleInput(
            make_arg((S, S)), (mask, ), make_arg((S,)), accumulate=accumulate)

def sample_inputs_sort(op_info, device, dtype, requires_grad, **kwargs):
    def small_3d_unique():
        res = torch.randperm(S * S * S, dtype=torch.int64, device=device).view(S, S, S)
        res = res.to(dtype).requires_grad_(requires_grad)
        return res

    def large_1d_unique():
        res = torch.randperm(L * L * L, dtype=torch.int64, device=device)
        res = res.to(dtype).requires_grad_(requires_grad)
        return res

    yield SampleInput(large_1d_unique())

    dims = range(-3, 3)
    flag = [True, False]
    for dim, descending, stable in product(dims, flag, flag):
        yield SampleInput(small_3d_unique(), dim, descending)
        if torch.device(device).type == 'cpu':
            yield SampleInput(
                small_3d_unique(), dim=dim, descending=descending, stable=stable)

    tensor_opt = dict(dtype=dtype, device=device, requires_grad=requires_grad)
    yield SampleInput(torch.tensor(1, **tensor_opt))
    yield SampleInput(torch.tensor(1, **tensor_opt), 0)
    yield SampleInput(torch.tensor(1, **tensor_opt), 0, True)

    yield SampleInput(torch.tensor((), **tensor_opt))
    yield SampleInput(torch.tensor((), **tensor_opt), 0)
    yield SampleInput(torch.tensor((), **tensor_opt), 0, True)

    yield SampleInput(small_3d_unique(), stable=True)
    yield SampleInput(small_3d_unique(), dim=0, stable=True)
    yield SampleInput(small_3d_unique(), dim=0, descending=True, stable=True)

def sample_inputs_threshold(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, dtype=dtype, device=device, requires_grad=requires_grad)
    sizes = ((), (S,), (S, S), (S, S, S))
    for x_size in sizes:
        yield SampleInput(make_arg(x_size), make_arg(()).item(), make_arg(()).item())

def sample_inputs_unique(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    sizes = ((), (S,), (S, S), (S, S, S), (S, 1, S), (S, 0, S))

    for shape, sorted, return_inverse, return_counts, dim in \
            product(sizes, [False, True], [False, True], [False, True], [None, -2, -1, 0, 1, 2]):
        if 0 in shape and shape.index(0) is not dim:
            continue

        if dim is not None and (dim < -len(shape) or dim >= len(shape)):
            continue

        kwargs = dict(sorted=sorted, return_inverse=return_inverse, return_counts=return_counts, dim=dim)

        input_t = torch.zeros(shape, dtype=dtype, device=device, requires_grad=requires_grad)
        yield SampleInput(input_t, **kwargs)

        input_t = make_arg(shape, dtype=torch.bool, requires_grad=False)\
            .to(dtype).requires_grad_(requires_grad)
        yield SampleInput(input_t, **kwargs)

        yield SampleInput(make_arg(shape), **kwargs)

def sample_inputs_unique_consecutive(*args, **kwargs):
    for sample_input in sample_inputs_unique(*args, **kwargs):
        if not sample_input.kwargs["sorted"]:
            sample_input.kwargs.pop("sorted")
            yield sample_input

def sample_inputs_adaptive_avg_pool1d(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases = (
        ((0, 8, 8), (5,)),
        ((3, 8, 8), 5),
        ((3, 8, 8), 1)
    )

    for input_shape, output_size in cases:
        yield SampleInput(make_arg(input_shape), args=(output_size,))
        yield SampleInput(make_arg(input_shape[1:]), args=(output_size,))


def error_inputs_adaptive_avg_pool1d(opinfo, device, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    yield ErrorInput(SampleInput(make_arg((1, 2, 3)), output_size=()),
                     error_regex="'output_size' should contain one int")

    yield ErrorInput(SampleInput(make_arg((1, 1, 1)), output_size=(-1,)),
                     error_regex="elements of output_size must be greater than or equal to 0")


def sample_inputs_adaptive_avg_pool2d(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases = (
        ((1, 8, 8, 8), (5, 7)),
        ((2, 8, 8, 8), (None, 7)),
        ((1, 8, 4, 3), (5, None)),
        ((1, 8, 4, 3), (None, None)),
        ((1, 8, 4, 3), (5)),
    )

    for input_shape, output_size in cases:
        yield SampleInput(make_arg(input_shape), args=(output_size,))
        yield SampleInput(make_arg(input_shape[1:]), args=(output_size,))


def error_inputs_adaptive_avg_pool2d(opinfo, device, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    yield ErrorInput(SampleInput(make_arg((2, 2)), output_size=(2, 2)),
                     error_type=ValueError, error_regex="Input dimension should be at least 3")

    yield ErrorInput(SampleInput(make_arg((1, 2, 3, 4)), output_size=()),
                     error_regex="output_size must be 2")

    yield ErrorInput(SampleInput(make_arg((1, 1, 1, 1)), output_size=(-1, 0)),
                     error_regex="elements of output_size must be greater than or equal to 0")


def sample_inputs_adaptive_avg_pool3d(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases = (
        ((0, 8, 8, 8, 8), (5, 7, 4)),
        ((1, 8, 4, 3, 7), (None, None, None)),
        ((1, 8, 4, 3, 7), (1, 1, 1)),
        ((3, 3, 8, 8, 6), (5, 7, None)),
        ((1, 3, 8, 8, 6), (5, None, 2)),
        ((3, 3, 8, 8, 6), (None, 3, 2)),
    )

    for input_shape, output_size in cases:
        yield SampleInput(make_arg(input_shape), args=(output_size,))
        yield SampleInput(make_arg(input_shape[1:]), args=(output_size,))


def error_inputs_adaptive_avg_pool3d(opinfo, device, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    yield ErrorInput(SampleInput(make_arg((2, 2, 2)), output_size=(2, 2, 2)),
                     error_type=ValueError, error_regex="Input dimension should be at least 4")

    yield ErrorInput(SampleInput(make_arg((1, 2, 3, 4)), output_size=()),
                     error_regex="output_size must be 3")

    yield ErrorInput(SampleInput(make_arg((1, 1, 1, 1, 1)), output_size=(-1, 0, 2)),
                     error_regex="elements of output_size must be greater than or equal to 0")


def sample_inputs_adaptive_max_pool1d(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases = (
        ((3, 4, 4), 3),
        ((3, 4, 4), 1)
    )

    for shapes, return_idx in product(cases, (True, False)):
        yield SampleInput(make_arg(shapes[0]), args=(shapes[1], return_idx))
        yield SampleInput(make_arg(shapes[0][1:]), args=(shapes[1], return_idx))


def error_inputs_adaptive_max_pool1d(opinfo, device, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    yield ErrorInput(SampleInput(make_arg((1, 2, 3)), output_size=()),
                     error_regex="'output_size' should contain one int")

    yield ErrorInput(SampleInput(make_arg((1, 1, 1)), output_size=(-1,)),
                     error_regex="Trying to create tensor with negative dimension")

def sample_inputs_adaptive_max_pool2d(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases = (
        ((1, 4, 4, 4), (2, 3)),
        ((2, 4, 4, 4), (None, 3)),
        ((2, 4, 4, 4), (1, 1)),
        ((1, 4, 4, 3), (3, None)),
        ((1, 4, 4, 3), (None, None)),
        ((1, 4, 4, 3), (3)),
    )

    for shapes, return_idx in product(cases, (True, False)):
        yield SampleInput(make_arg(shapes[0]), args=(shapes[1], return_idx))
        yield SampleInput(make_arg(shapes[0][1:]), args=(shapes[1], return_idx))

def error_inputs_adaptive_max_pool2d(opinfo, device, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    yield ErrorInput(SampleInput(make_arg((2, 2)), output_size=(2, 2)),
                     error_type=ValueError, error_regex="Input dimension should be at least 3")

    yield ErrorInput(SampleInput(make_arg((1, 2, 3, 4)), output_size=()),
                     error_regex="internal error")

    yield ErrorInput(SampleInput(make_arg((1, 1, 1, 1)), output_size=(-1, 0)),
                     error_regex="Trying to create tensor with negative dimension")


def sample_inputs_adaptive_max_pool3d(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases = (
        ((1, 4, 4, 3, 5), (None, None, None)),
        ((1, 4, 4, 3, 5), (1, 1, 1)),
        ((3, 3, 4, 4, 6), (2, 3, None)),
        ((1, 3, 4, 4, 6), (3, None, 2)),
        ((3, 3, 4, 4, 6), (None, 3, 2)),
    )

    for shapes, return_idx in product(cases, (True, False)):
        yield SampleInput(make_arg(shapes[0]), args=(shapes[1], return_idx))
        yield SampleInput(make_arg(shapes[0][1:]), args=(shapes[1], return_idx))

def error_inputs_adaptive_max_pool3d(opinfo, device, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=torch.float32)

    yield ErrorInput(SampleInput(make_arg((2, 2, 2)), output_size=(2, 2, 2)),
                     error_type=ValueError, error_regex="Input dimension should be at least 4")

    yield ErrorInput(SampleInput(make_arg((1, 2, 3, 4)), output_size=()),
                     error_regex="internal error")

    yield ErrorInput(SampleInput(make_arg((1, 1, 1, 1, 1)), output_size=(-1, 0, 2)),
                     error_regex="Trying to create tensor with negative dimension")


class _TestParamsMaxPoolBase:

    def __init__(self):
        self.kwargs = {
            'kernel_size': [3],
            'stride': [2, None],
            'ceil_mode': [True, False],
            'padding': [0, 1],
            'dilation': [1],
            'return_indices': [True, False]
        }

        self.shapes = [
            [1, 2, None],  # batch
            [2],  # channels
            [3, 6]  # signal
        ]

    def _gen_shape(self):
        for shape in product(*self.shapes):
            if shape[0] is None:
                shape = shape[1:]

            yield shape, torch.contiguous_format
            if len(self.shapes) == 4 and len(shape) == 4:
                yield shape, torch.channels_last

    def _gen_kwargs(self):
        keys = self.kwargs.keys()
        for values in product(*self.kwargs.values()):
            yield dict(zip(keys, values))

    def gen_input_params(self):
        yield from product(self._gen_shape(), self._gen_kwargs())

class _TestParamsMaxPool1d(_TestParamsMaxPoolBase):

    def __init__(self):
        super().__init__()
        self.kwargs['kernel_size'] += [(3,)]
        self.kwargs['stride'] += [(2,)]
        self.kwargs['padding'] += [(1,)]
        self.kwargs['dilation'] += [(1,)]

class _TestParamsMaxPool2d(_TestParamsMaxPoolBase):

    def __init__(self):
        super().__init__()
        self.kwargs['kernel_size'] += [(3, 2)]
        self.kwargs['stride'] += [(2, 1)]
        self.kwargs['padding'] += [(1, 1)]
        self.kwargs['dilation'] += [(1, 2)]

        self.shapes.append([6])

class _TestParamsMaxPool3d(_TestParamsMaxPoolBase):

    def __init__(self):
        super().__init__()
        self.kwargs['kernel_size'] += [(3, 2, 3)]
        self.kwargs['stride'] += [(2, 1, 2)]
        self.kwargs['dilation'] += [(1, 2, 1)]

        self.shapes.append([6])
        self.shapes.append([5])

def sample_inputs_max_pool(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=False)

    params_generator_type_dict = {
        'nn.functional.max_pool1d': _TestParamsMaxPool1d,
        'nn.functional.max_pool2d': _TestParamsMaxPool2d,
        'nn.functional.max_pool3d': _TestParamsMaxPool3d,
        'max_pool2d_with_indices_backward': _TestParamsMaxPool2d,
    }

    params_generator = params_generator_type_dict[op_info.name]()
    for (shape, memory_format), kwargs in params_generator.gen_input_params():
        arg = make_arg(shape).to(memory_format=memory_format).requires_grad_(requires_grad)
        yield SampleInput(arg, kwargs=kwargs)

def max_pool2d_backward(*args, kernel_size=(), stride=(), padding=(0,), dilation=(1,), ceil_mode=False, **kwargs):
    out, indices = torch.nn.functional.max_pool2d_with_indices(
        *args, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, ceil_mode=ceil_mode, return_indices=True)
    grad_out = torch.ones_like(out)
    if stride is None:
        stride = kernel_size
    out_b = torch.ops.aten.max_pool2d_with_indices_backward.default(
        grad_out, *args, kernel_size, stride, padding, dilation, ceil_mode, indices)
    return out_b

def error_inputs_max_pool1d(op_info, device, **kwargs):
    for requires_grad in (True, False):
        make_arg = partial(make_tensor, device=device, dtype=torch.float, requires_grad=requires_grad)
        x = make_arg((0, 1, 49))
        yield ErrorInput(SampleInput(x, kwargs={'kernel_size': 2, 'stride': 50, 'padding': -1, 'return_indices': True}),
                         error_regex='pad must be non-negative')

        yield ErrorInput(SampleInput(x, kwargs={'kernel_size': 2, 'stride': 50, 'padding': 4, 'return_indices': True}),
                         error_regex='pad should be at most half of kernel size')

        error_msg = r'Expected 2D or 3D \(batch mode\) tensor with optional 0 dim batch size for input'
        yield ErrorInput(SampleInput(make_arg((), requires_grad=requires_grad), kwargs={'kernel_size': 1}),
                         error_regex=error_msg)

        yield ErrorInput(SampleInput(torch.tensor([], device=device, requires_grad=requires_grad),
                                     kwargs={'kernel_size': 1}),
                         error_regex=error_msg)

        yield ErrorInput(SampleInput(make_arg((0, 10), requires_grad=requires_grad),
                                     kwargs={'kernel_size': 1}),
                         error_regex=error_msg)

        yield ErrorInput(SampleInput(make_arg((1, 10, 0), requires_grad=requires_grad),
                                     kwargs={'kernel_size': 1}),
                         error_regex=error_msg)

        error_msg = 'stride must be greater than zero, but got 0'
        yield ErrorInput(SampleInput(make_arg((3, 3, 3)), kwargs={'kernel_size': 1, 'stride': 0}),
                         error_regex=error_msg)

        error_msg = 'dilation must be greater than zero, but got 0'
        yield ErrorInput(SampleInput(make_arg((3, 3, 3)),
                                     kwargs={'kernel_size': 1, 'stride': 1, 'padding': 0, 'dilation': 0}),
                         error_regex=error_msg)

        error_msg = 'Invalid computed output size: -2'
        yield ErrorInput(SampleInput(make_arg((2, 2, 2)),
                                     kwargs={'kernel_size': 5, 'stride': 1, 'padding': 0, 'dilation': 1}),
                         error_regex=error_msg)

        error_msg = 'kernel_size must be greater than zero'
        yield ErrorInput(SampleInput(x, kwargs={'kernel_size': 0}),
                         error_regex=error_msg)

        error_msg = 'stride must be greater than zero'
        yield ErrorInput(SampleInput(x, kwargs={'kernel_size': 2, 'stride': 0}),
                         error_regex=error_msg)


def error_inputs_max_pool2d(op_info, device, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=torch.float, requires_grad=False)
    x = make_arg((0, 1, 49))
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': 2, 'stride': 50, 'padding': -1, 'return_indices': True}),
                     error_regex='pad must be non-negative')
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': (3, 2), 'stride': 50, 'padding': -1, 'return_indices': True}),
                     error_regex='pad must be non-negative')

    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': 2, 'stride': 50, 'padding': 4, 'return_indices': True}),
                     error_regex='pad should be at most half of kernel size')

    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': (3, 2), 'stride': 50, 'padding': 4, 'return_indices': True}),
                     error_regex='pad should be at most half of kernel size')

    err_msg = r'Expected 3D or 4D \(batch mode\) tensor with optional 0 dim batch size for input'
    yield ErrorInput(SampleInput(make_arg((1, 0, 10)),
                                 kwargs={'kernel_size': 1}),
                     error_regex=err_msg)

    yield ErrorInput(SampleInput(make_arg((2, 1, 10, 0)),
                                 kwargs={'kernel_size': 1}),
                     error_regex=err_msg)


def error_inputs_max_pool3d(op_info, device, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=torch.float, requires_grad=False)
    x = make_arg((0, 1, 49, 50))
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': 2, 'stride': 50, 'padding': -1, 'return_indices': True}),
                     error_regex='pad must be non-negative')
    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': (3, 2, 2), 'stride': 50,
                                            'padding': -1, 'return_indices': True}),
                     error_regex='pad must be non-negative')

    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': 2, 'stride': 50, 'padding': 4, 'return_indices': True}),
                     error_regex='pad should be at most half of kernel size')

    yield ErrorInput(SampleInput(x, kwargs={'kernel_size': (3, 2, 2), 'stride': 50,
                                            'padding': 4, 'return_indices': True}),
                     error_regex='pad should be at most half of kernel size')

    err_msg = r'Expected input\'s non-batch dimensions to have positive length'
    yield ErrorInput(SampleInput(make_arg((0, 1, 2, 10)),
                                 kwargs={'kernel_size': 1}),
                     error_regex=err_msg)

    yield ErrorInput(SampleInput(make_arg((2, 1, 0, 1, 2)),
                                 kwargs={'kernel_size': 1}),
                     error_regex=err_msg)


def sample_inputs_normalize(self, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, low=-1, high=1, device=device, dtype=dtype, requires_grad=requires_grad)

    cases: Tuple[Tuple[int], dict] = (  # type: ignore[assignment]
                                     ((2, 1, 4, 5), {'p': 1., 'dim': 2}),
                                     ((2, 3, 4, 5), {'p': 2., 'dim': 1}),
                                     ((1, 2, 4, 5), {'p': 0.5, 'dim': 0}),
                                     ((1, 3, 4, 5), {'p': -1., 'dim': 1}),
                                     ((1, 3, 4, 5), {'p': 0., 'dim': -1}),
                                     ((), {'p': 1.2, 'dim': 0}),
                                     ((2, 3, 4, 5), {}),
                                     ((2, 3, 4, 5), {'eps': 1e-4}))

    for input_shape, kwargs in cases:
        yield SampleInput(make_arg(input_shape), kwargs=kwargs)


def complex_conv(fn, input_size, weight, grad_output, stride, padding, dilation, groups):

    grad_output_ = torch.view_as_real(grad_output)
    grad_output_r = grad_output_[..., 0]
    grad_output_i = grad_output_[..., 1]

    weight_ = torch.view_as_real(weight)
    weight_r = weight_[..., 0]
    weight_i = weight_[..., 1]

    a = fn(input_size, weight_r, grad_output_r, stride, padding, dilation, groups)
    b = fn(input_size, weight_i, grad_output_i, stride, padding, dilation, groups)
    c = fn(input_size, weight_r + weight_i, grad_output_r + grad_output_i, stride, padding, dilation, groups)

    return (a - b) + 1j * (c - a - b)


def conv_transpose_ref(input, weight, bias, stride=1, padding=0,
                       output_padding=0, dilation=1, groups=1,
                       fn=None):

    assert fn is not None

    grad_fn_map = {torch.nn.functional.conv_transpose1d: torch.nn.grad.conv1d_input,
                   torch.nn.functional.conv_transpose2d: torch.nn.grad.conv2d_input,
                   torch.nn.functional.conv_transpose3d: torch.nn.grad.conv3d_input}
    batched_dim_map = {torch.nn.functional.conv_transpose1d: 3,
                       torch.nn.functional.conv_transpose2d: 4,
                       torch.nn.functional.conv_transpose3d: 5}

    input, weight = torch.from_numpy(input), torch.from_numpy(weight)

    is_batched = len(input.shape) == batched_dim_map[fn]
    if not is_batched:
        input = input.unsqueeze(0)

    if bias is not None:
        bias = torch.from_numpy(bias)
        unsqueeze_dims = input.ndim - 2
        for _ in range(unsqueeze_dims):
            bias = bias.unsqueeze(1)

    grad_output = input
    conv_transpose_output = fn(grad_output.to('meta'), weight.to('meta'), None,
                               stride=stride, padding=padding, output_padding=output_padding,
                               groups=groups, dilation=dilation)
    input_size = conv_transpose_output.shape

    grad_fn = grad_fn_map[fn]
    if weight.dtype.is_complex:
        out = complex_conv(grad_fn, input_size, weight, grad_output, stride, padding, dilation, groups)
    else:  # Floating
        out = grad_fn(input_size, weight, grad_output, stride, padding, dilation, groups)

    if bias is not None:
        out = out + bias

    return out.squeeze(0) if not is_batched else out


def sample_inputs_conv_transpose1d(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases: Tuple[Tuple[int], Tuple[int], Tuple[int], dict] = (  # type: ignore[assignment]
        ((1, 3, 4), (3, 3, 3), (3,),
         {'stride': (2,), 'padding': 2, 'output_padding': (1,), 'groups': 1}),
        ((2, 2, 4), (2, 2, 4), (4,),
         {'stride': (3,), 'padding': (1,), 'output_padding': (2,), 'groups': 2, 'dilation': (4,)}),
        ((1, 1, 4), (1, 1, 4), (1,),
         {'stride': 2, 'padding': 1, 'output_padding': 1, 'groups': 1, 'dilation': (2,)}),
        ((1, 1, 4), (1, 2, 3), None,
         {'stride': 2, 'padding': 1, 'output_padding': 1, 'groups': 1}),
        ((1, 4, 5), (4, 8, 3), None,
         {})
    )

    for input_shape, weight, bias, kwargs in cases:
        yield SampleInput(make_arg(input_shape), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)
        yield SampleInput(make_arg(input_shape[1:]), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)


def sample_inputs_conv_transpose2d(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases: Tuple[Tuple[int], Tuple[int], Tuple[int], dict] = (  # type: ignore[assignment]
        ((1, 3, 4, 4), (3, 3, 3, 3), (3,),
         {'stride': (2, 2), 'padding': 2, 'output_padding': (1, 1), 'groups': 1}),
        ((2, 2, 4, 4), (2, 2, 4, 5), (4,),
         {'stride': (3, 2), 'padding': (1, 2), 'output_padding': (2, 3), 'groups': 2, 'dilation': (4, 4)}),
        ((1, 1, 4, 5), (1, 1, 4, 3), (1,),
         {'stride': 2, 'padding': 1, 'output_padding': 1, 'groups': 1, 'dilation': (2, 3)}),
        ((1, 1, 4, 3), (1, 2, 3, 4), None,
         {'stride': 2, 'padding': 1, 'output_padding': 1, 'groups': 1}),
        ((2, 4, 4, 4), (4, 1, 3, 3), None, {'groups': 4}),
        ((1, 2, 5, 5), (2, 4, 3, 3), None, {})
    )

    for input_shape, weight, bias, kwargs in cases:
        yield SampleInput(make_arg(input_shape), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)
        yield SampleInput(make_arg(input_shape[1:]), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)

def sample_inputs_conv_transpose3d(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases: Tuple[Tuple[int], Tuple[int], Tuple[int], dict] = (  # type: ignore[assignment]
        ((1, 3, 4, 4, 4), (3, 3, 3, 3, 3), (3,),
         {'stride': (2, 2, 2), 'padding': 2, 'output_padding': (1, 1, 1), 'groups': 1}),
        ((2, 2, 4, 4, 4), (2, 2, 4, 5, 6), (4,),
         {'stride': (3, 2, 1), 'padding': (1, 2, 3), 'output_padding': (2, 3, 1), 'groups': 2, 'dilation': (4, 4, 4)}),
        ((1, 1, 4, 5, 2), (1, 1, 4, 3, 1), (1,),
         {'stride': 2, 'padding': 1, 'output_padding': 1, 'groups': 1, 'dilation': (2, 3, 2)}),
        ((1, 1, 4, 3, 4), (1, 2, 3, 4, 5), None,
         {'stride': 2, 'padding': 1, 'output_padding': 1, 'groups': 1}),
        ((1, 4, 5, 5, 5), (4, 8, 3, 3, 3), None,
         {})
    )

    for input_shape, weight, bias, kwargs in cases:
        yield SampleInput(make_arg(input_shape), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)
        yield SampleInput(make_arg(input_shape[1:]), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)


def sample_inputs_conv1d(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases: Tuple = (
        ((1, 3, 4), (3, 3, 3), (3,), {'stride': (2,), 'padding': 2, 'groups': 1}),
        ((2, 4, 8), (2, 2, 3), (2,), {'stride': 3, 'padding': 1, 'groups': 2, 'dilation': 2}),
        ((1, 4, 5), (1, 4, 3), None, {'stride': (2,), 'padding': 'valid'}),
        ((2, 2, 4), (2, 1, 4), (2,), {'stride': (1,), 'padding': 'same', 'groups': 2, 'dilation': (2,)}),
        ((1, 4, 5), (3, 4, 3), None, {}),
    )

    for input_shape, weight, bias, kwargs in cases:
        yield SampleInput(make_arg(input_shape), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)
        yield SampleInput(make_arg(input_shape[1:]), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)


def error_inputs_conv1d(opinfo, device, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=torch.float64)
    make_int_arg = partial(make_tensor, device=device, dtype=torch.int64)
    make_complex_arg = partial(make_tensor, device=device, dtype=torch.complex128)

    yield ErrorInput(
        SampleInput(make_int_arg((1, 1, 4)), args=(make_int_arg((1, 1, 2)), make_arg((1,)))),
        error_regex="should be the same")

    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4)), args=(make_arg((1, 1, 2)), make_complex_arg((1,)))),
        error_regex="should be the same")

    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4)), args=(make_arg((1, 2, 2)), make_arg((1,))),
                    kwargs={'stride': (-1,)}), error_regex="non-positive stride is not supported")

    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4)), args=(make_arg((1, 2, 2)), make_arg((1,))),
                    kwargs={'padding': (-1,)}), error_regex="negative padding is not supported")

    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4)), args=(make_arg((1, 1, 2)), make_arg((1,))),
                    kwargs={'dilation': (-1,)}), error_regex="dilation should be greater than zero")


    yield ErrorInput(SampleInput(make_arg((1, 1, 4)), args=(make_arg((1, 2)), make_arg((1,)))),
                     error_regex="weight should have at least three dimensions")

    yield ErrorInput(
        SampleInput(make_arg((2, 2, 4)), args=(make_arg((2, 2, 2)), make_arg((2,))),
                    kwargs={'padding': 'same', 'groups': 3}), error_regex="expected weight to be at least 3 at dimension 0")

    yield ErrorInput(
        SampleInput(make_arg((2, 2, 4)), args=(make_arg((2, 2, 2)), make_arg((2,))),
                    kwargs={'groups': 3}), error_regex="expected weight to be at least 3 at dimension 0")

    yield ErrorInput(
        SampleInput(make_arg((2, 2, 4)), args=(make_arg((2, 2, 2)), make_arg((2,))),
                    kwargs={'padding': 'same', 'groups': -1}), error_regex="non-positive groups is not supported")

    yield ErrorInput(
        SampleInput(make_arg((2, 2, 4)), args=(make_arg((2, 2, 2)), make_arg((2,))),
                    kwargs={'padding': 'same', 'groups': 0}), error_regex="non-positive groups is not supported")


def error_inputs_conv2d(opinfo, device, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=torch.float64)
    make_int_arg = partial(make_tensor, device=device, dtype=torch.int64)
    make_complex_arg = partial(make_tensor, device=device, dtype=torch.complex128)

    yield ErrorInput(
        SampleInput(make_int_arg((2, 4, 4)), args=(make_int_arg((3, 2, 3, 3)), make_arg((3,)))),
        error_regex="should be the same")

    yield ErrorInput(
        SampleInput(make_arg((2, 4, 4)), args=(make_arg((3, 2, 3, 3)), make_complex_arg((3,)))),
        error_regex="should be the same")

    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4, 4)), args=(make_arg((1, 2, 2, 3)), make_arg((1,))),
                    kwargs={'stride': (-1,)}), error_regex="non-positive stride is not supported")

    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4, 3)), args=(make_arg((1, 2, 2, 4)), make_arg((1,))),
                    kwargs={'padding': (-1,)}), error_regex="negative padding is not supported")

    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4, 2)), args=(make_arg((1, 1, 2, 5)), make_arg((1,))),
                    kwargs={'dilation': (-1,)}), error_regex="dilation should be greater than zero")


    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4, 3)), args=(make_arg((1, 2, 2)), make_arg((1,))),
                    kwargs={'padding': 'same'}), error_regex="Expected 3-dimensional input for 3-dimensional weight")

    yield ErrorInput(
        SampleInput(make_arg((2, 2, 4, 3)), args=(make_arg((2, 2, 1, 3)), make_arg((2,))),
                    kwargs={'groups': 3}), error_regex="expected weight to be at least 3 at dimension 0")

    yield ErrorInput(
        SampleInput(make_arg((2, 2, 4, 3)), args=(make_arg((2, 2, 1, 3)), make_arg((2,))),
                    kwargs={'padding': 'same', 'groups': 3}), error_regex="expected weight to be at least 3 at dimension 0")

    yield ErrorInput(
        SampleInput(make_arg((2, 2, 4, 5)), args=(make_arg((2, 2, 1, 4)), make_arg((2,))),
                    kwargs={'padding': 'same', 'groups': -1}), error_regex="non-positive groups is not supported")

    yield ErrorInput(
        SampleInput(make_arg((2, 2, 4, 3)), args=(make_arg((2, 2, 4, 3)), make_arg((2,))),
                    kwargs={'padding': 'same', 'groups': 0}), error_regex="non-positive groups is not supported")


def sample_inputs_conv2d(op_info, device, dtype, requires_grad, jit_fail_sample=False, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases: Tuple = (
        ((1, 3, 4, 4), (3, 3, 3, 3), (3,),
            {'stride': (2, 2), 'padding': 2, 'groups': 1}),
        ((2, 4, 8, 8), (2, 2, 3, 3), (2,),
            {'stride': (3, 2), 'padding': (2, 1), 'groups': 2, 'dilation': (4, 4)}),
        ((1, 4, 5, 5), (1, 4, 2, 3), (1,),
            {'stride': 2, 'padding': 1, 'groups': 1, 'dilation': (2, 3)}),
        ((1, 4, 5, 5), (1, 4, 2, 3), (1,),
            {'stride': 2, 'padding': 1, 'groups': 1, 'dilation': (2, 3)}),
        ((1, 2, 4, 3), (4, 2, 3, 4), None,
            {'stride': 2, 'padding': 1, 'groups': 1}),
        ((1, 4, 5, 5), (1, 4, 2, 3), (1,),
            {'stride': 2, 'padding': "valid"}),
        ((1, 4, 5, 5), (1, 4, 2, 3), (1,),
            {'stride': 1, 'padding': "same", 'dilation': 3}),
        ((2, 4, 6, 6), (4, 1, 3, 3), (4,), {'groups': 4}),
        ((2, 4, 6, 6), (8, 1, 3, 3), (8,), {'groups': 4}),
        ((2, 4, 6, 6), (8, 1, 3, 3), None, {'groups': 4}),
        ((2, 4, 6, 6), (4, 1, 3, 3), (4,), {'groups': 4, 'stride': (3, 2)}),
        ((2, 4, 6, 6), (4, 1, 3, 3), (4,), {'groups': 4, 'padding': (1, 1)}),
        ((2, 4, 5, 5), (4, 1, 2, 2), (4,), {'groups': 4, 'dilation': (2, 2)}),
        ((2, 4, 6, 5), (6, 2, 3, 2), (6,), {'groups': 2}),
        ((1, 4, 5, 5), (3, 4, 3, 3), None, {}),
    )

    for input_shape, weight, bias, kwargs in cases:
        yield SampleInput(make_arg(input_shape), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)
        yield SampleInput(make_arg(input_shape[1:]), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)


def sample_inputs_conv3d(opinfo, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases: Tuple = (
        ((1, 1, 4, 4, 4), (1, 1, 1, 1, 1), (1,), {'padding': 'same'}),
        ((1, 1, 4, 4, 4), (1, 1, 4, 4, 4), (1,), {'stride': (2, 2, 2)}),
        ((1, 1, 5, 5, 5), (1, 1, 3, 3, 3), (1,), {'dilation': 2}),
        ((1, 1, 1, 1, 10), (1, 1, 1, 1, 4), None, {'padding': 'valid'}),
        ((1, 1, 10, 11, 12), (1, 1, 1, 2, 5), None, {'padding': 'same'}),
        ((1, 1, 10, 11, 12), (1, 1, 1, 2, 5), None, {'padding': 'same', 'dilation': 2}),
        ((1, 1, 10, 11, 12), (1, 1, 4, 4, 4), None, {'padding': 'same', 'dilation': 3}),
        ((1, 1, 1, 1, 10), (1, 1, 1, 1, 4), None, {'padding': 'valid'}),
        ((3, 9, 3, 1, 9), (3, 3, 3, 1, 9), (3,), {'groups': 3}),
        ((3, 9, 3, 1, 9), (3, 3, 3, 1, 9), (3,), {'stride': (2, 2, 2), 'dilation': 1, 'groups': 3}),
    )

    for input_shape, weight, bias, kwargs in cases:
        yield SampleInput(make_arg(input_shape), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)
        yield SampleInput(make_arg(input_shape[1:]), args=(
            make_arg(weight),
            make_arg(bias) if bias is not None else bias
        ), kwargs=kwargs)


def error_inputs_conv3d(opinfo, device, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=torch.float64)
    make_int_arg = partial(make_tensor, device=device, dtype=torch.int64)
    make_complex_arg = partial(make_tensor, device=device, dtype=torch.complex128)

    yield ErrorInput(
        SampleInput(make_int_arg((1, 1, 4, 4, 4)), args=(make_int_arg((1, 1, 2, 2, 2)), make_arg((1,)))),
        error_regex="should be the same")

    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4, 4, 4)), args=(make_arg((1, 1, 2, 2, 2)), make_complex_arg((1,)))),
        error_regex="should be the same")

    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4, 4, 4)), args=(make_arg((1, 1, 2, 2, 2)), make_arg((1,))),
                    kwargs={'stride': (-1,)}), error_regex="non-positive stride is not supported")

    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4, 4, 4)), args=(make_arg((1, 1, 2, 2, 2)), make_arg((1,))),
                    kwargs={'padding': (-1,)}), error_regex="negative padding is not supported")

    yield ErrorInput(
        SampleInput(make_arg((1, 1, 4, 4, 4)), args=(make_arg((1, 1, 2, 2, 2)), make_arg((1,))),
                    kwargs={'dilation': (-1,)}), error_regex="dilation should be greater than zero")


    yield ErrorInput(
        SampleInput(make_arg((1, 1, 3, 4, 5)), args=(make_arg((1, 1, 4, 3)), make_arg((1,))),
                    kwargs={'padding': 'same'}), error_regex="Expected 4-dimensional input for 4-dimensional weight")

    yield ErrorInput(
        SampleInput(make_arg((2, 2, 3, 4, 5)), args=(make_arg((2, 2, 4, 3, 3)),
                    make_arg((2,))), kwargs={'groups': 3}),
        error_regex="expected weight to be at least 3 at dimension 0")

    yield ErrorInput(
        SampleInput(make_arg((2, 2, 3, 4, 5)), args=(make_arg((2, 2, 4, 3, 3)),
                    make_arg((2,))), kwargs={'padding': 'same', 'groups': 3}),
        error_regex="expected weight to be at least 3 at dimension 0")

    yield ErrorInput(
        SampleInput(make_arg((2, 2, 3, 4, 5)), args=(make_arg((2, 2, 4, 3, 3)),
                    make_arg((2,))), kwargs={'padding': 'same', 'groups': 0}),
        error_regex="non-positive groups is not supported")

    yield ErrorInput(
        SampleInput(make_arg((18, 27, 9, 1, 9)), args=(make_arg((9, 9, 9, 1, 9)),
                    make_arg((9,))), kwargs={'stride': 2, 'padding': 'same', 'groups': 3}),
        error_regex="padding='same' is not supported for strided convolutions")


def sample_inputs_group_norm(opinfo, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases: Tuple[Tuple[int], int, float] = (  # type: ignore[assignment]
        ((1, 6, 3), 2, {'eps' : 0.5}),
        ((2, 6, 3), 2, {'eps' : -0.5}),
        ((1, 3), 1, {'eps' : 1e-5}),
        ((0, 2), 1, {'eps' : 1e-5}),
        ((S, S, S), 1, {'eps' : 0.5}),
    )

    for input_shape, num_groups, kwargs in cases:
        channels = input_shape[1] if len(input_shape) > 1 else 0
        weight_tensor = make_arg(channels)
        bias_tensor = make_arg(channels)

        weights = [weight_tensor, None]
        biases = [bias_tensor, None]
        for weight, bias in itertools.product(weights, biases):
            kwargs = {
                'weight': weight,
                'bias': bias,
                **kwargs
            }
            yield SampleInput(make_arg(input_shape), num_groups, **kwargs)

    yield SampleInput(make_arg((1, 2)), args=(1,))

def reference_inputs_group_norm(op_info, device, dtype, requires_grad, **kwargs):
    yield from sample_inputs_group_norm(
        op_info, device, dtype, requires_grad, **kwargs)

    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases: Tuple[Tuple[int], int, float] = (  # type: ignore[assignment]
        ((20, 6, 10, 10), 3, {'eps' : 1e-5}),
        ((20, 6, 10, 10), 6, {'eps' : 1e-5}),
        ((20, 6, 10, 10), 1, {'eps' : 1e-5}),
    )

    for input_shape, num_groups, kwargs in cases:
        channels = input_shape[1] if len(input_shape) > 1 else 0
        input_tensor = make_arg(input_shape)
        weight_tensor = make_arg(channels)
        bias_tensor = make_arg(channels)

        weights = [weight_tensor, None]
        biases = [bias_tensor, None]
        for weight, bias in itertools.product(weights, biases):
            kwargs = {
                'weight': weight,
                'bias': bias,
                **kwargs
            }
            yield SampleInput(input_tensor, num_groups, **kwargs)


def sample_inputs_instance_norm(opinfo, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)
    make_arg_without_requires_grad = partial(make_tensor, device=device, dtype=dtype, requires_grad=False)

    cases: Tuple[Tuple[int], dict] = (  # type: ignore[assignment]
        ((S, S, S), {'momentum': 0.5, 'eps': 0.6}),
        ((S, S, S), {'momentum': 0.5, 'eps': 0.6, 'use_input_stats': True}),
        ((3, 2, 4), {'momentum': -1.2}),
        ((3, 2, 4), {'momentum': 0.0}),
        ((3, 2, 3, 4), {'momentum': -1.0, 'eps': 0.5}),
        ((3, 2, 3, 4), {'momentum': -1.0, 'eps': 0.5}),
    )

    for input_shape, kwargs in cases:
        channels = input_shape[1]
        weight = make_arg(channels)
        bias = make_arg(channels)
        running_mean = make_arg_without_requires_grad(channels, low=0)
        running_var = make_arg_without_requires_grad(channels, low=0)
        new_kwargs = {
            'running_mean': running_mean,
            'running_var': running_var,
            'weight': weight,
            'bias': bias,
            **kwargs
        }

        yield SampleInput(
            make_arg(input_shape),
            args=(),
            kwargs=new_kwargs
        )

    weights = [channels, None]
    biases = [None, None]

    for weight_channels, bias_channels in zip(weights, biases):
        running_mean = make_arg_without_requires_grad(channels, low=0)
        running_var = make_arg_without_requires_grad(channels, low=0)
        yield SampleInput(
            make_arg(input_shape),
            args=(),
            kwargs={
                'running_mean': running_mean,
                'running_var': running_var,
                'weight': make_arg(weight_channels) if weight_channels is not None else None,
                'bias': make_arg(bias_channels) if bias_channels is not None else None
            }
        )

    yield SampleInput(make_arg((1, 2, 3)), kwargs={})


def sample_inputs_layer_norm(opinfo, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases: Tuple[Tuple[int], Tuple[int], dict] = (  # type: ignore[assignment]
        ((1, 2, 3), (1, 2, 3), {'eps': 0.5}),
        ((2, 2, 3), (2, 3), {'eps': -0.5}),
        ((1,), (1,), {}),
        ((1, 2), (2,), {}),
        ((0, 1), (1,), {}),
    )

    for input_shape, normalized_shape, kwargs in cases:
        weight = make_arg(normalized_shape)
        bias = make_arg(normalized_shape)
        yield SampleInput(
            make_arg(input_shape),
            args=(normalized_shape, weight, bias),
            kwargs=kwargs
        )
    yield SampleInput(make_arg((1, 2)), args=((2,),))





def sample_inputs_native_layer_norm(opinfo, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases: Tuple[Tuple[int], Tuple[int], float] = (  # type: ignore[assignment]
        ((1, 2, 3), (1, 2, 3), 0.5),
        ((2, 2, 3), (2, 3), -0.5),
        ((1,), (1,), 1e-5),
        ((1, 2), (2,), 1e-5),
        ((0, 1), (1,), 1e-5),
    )

    for input_shape, normalized_shape, eps in cases:
        weight = make_arg(normalized_shape)
        bias = make_arg(normalized_shape)
        yield SampleInput(
            make_arg(input_shape),
            args=(normalized_shape, weight, bias, eps),
        )
        yield SampleInput(
            make_arg(input_shape),
            args=(normalized_shape, None, bias, eps),
        )
        yield SampleInput(
            make_arg(input_shape),
            args=(normalized_shape, weight, None, eps),
        )
        yield SampleInput(
            make_arg(input_shape),
            args=(normalized_shape, None, None, eps),
        )

def error_inputs_group_norm(opinfo, device, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=torch.float32, requires_grad=False)

    err_msg1 = "Expected at least 2 dimensions for input tensor but received"
    s1 = SampleInput(make_arg(1), args=(1,))
    yield ErrorInput(s1, error_regex=err_msg1)

    err_msg2 = "Expected number of channels in input to be divisible by num_groups, but got input of shape"
    s2 = SampleInput(make_arg((2, 7, 4)), args=(2,))
    yield ErrorInput(s2, error_regex=err_msg2)

def error_inputs_native_layer_norm(opinfo, device, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=torch.float32, requires_grad=False)
    input_shape = (1, 2, 3)

    err_msg1 = "Expected normalized_shape to be at least 1-dimensional"
    s1 = SampleInput(
        make_arg(input_shape), args=(tuple(), None, None, 1e-5)
    )
    yield ErrorInput(s1, error_regex=err_msg1)

    normalized_shape = (1, 2, 3)
    weight = make_arg((1, 2))
    err_msg2 = "Expected weight to be of same shape as normalized_shape"
    s2 = SampleInput(
        make_arg(input_shape), args=(normalized_shape, weight, None, 1e-5)
    )
    yield ErrorInput(s2, error_regex=err_msg2)

    bias = make_arg((1, 2))
    err_msg3 = "Expected bias to be of same shape as normalized_shape"
    s3 = SampleInput(
        make_arg(input_shape), args=(normalized_shape, None, bias, 1e-5)
    )
    yield ErrorInput(s3, error_regex=err_msg3)

    err_msg4 = "Given normalized_shape="
    s4 = SampleInput(
        make_arg((2, 2, 3)), args=((2, 2), None, None, 1e-5)
    )
    yield ErrorInput(s4, error_regex=err_msg4)


def sample_inputs_local_response_norm(opinfo, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    cases: Tuple[Tuple[int], Tuple[int], dict] = (  # type: ignore[assignment]
        ((1, 6, 3), 2, {'alpha': 3e-05, 'beta': 0.5, 'k': 1.25}),
        ((1, 6, 3), 2, {'beta': 0.5, 'k': 1.25}),
        ((1, 6, 3), 2, {'alpha': 3e-05, 'k': 1.25}),
        ((1, 6, 3), 2, {'alpha': 3e-05, 'beta': 0.5}),
        ((1, 6, 3), 2, {'alpha': 3e-05}),
        ((1, 6, 3), 2, {'beta': 0.5}),
        ((1, 6, 3), 2, {'k': 1.25}),
        ((1, 6, 3), 2, {}),
        ((2, 6, 3), 2, {'alpha': 3e-05, 'beta': 0.5, 'k': 1.25}),
        ((1, 1, 2), 1, {'alpha': 3e-05, 'beta': 0.5, 'k': 1.25}),
        ((0, 1, 2), 1, {'alpha': 3e-05, 'beta': 0.5, 'k': 1.25}),
    )

    for input_shape, size, kwargs in cases:
        yield SampleInput(make_arg(input_shape), args=(size,), kwargs=kwargs)

def sample_inputs_hardswish(self, device, dtype, requires_grad, **kwargs):
    N = 5
    make_arg = partial(make_tensor, device=device, dtype=dtype,
                       requires_grad=requires_grad, low=-5, high=5)
    return (SampleInput(make_arg((N * 2, N * 2))) for _ in range(1, N))

def sample_inputs_linear(self, device, dtype, requires_grad, **kwargs):
    features_options = [[3, 4], [8, 8]]
    batch_options: List[List[int]] = [
        [],  # no batch
        [0],
        [8],
        [2, 3],
    ]
    create_tensor = partial(make_tensor, device=device, dtype=dtype,
                            requires_grad=requires_grad, low=-2, high=2)

    for has_bias, (in_feat, out_feat), batch_shape in \
            itertools.product([True, False], features_options, batch_options):
        input_tensor = create_tensor(batch_shape + [in_feat])
        weight = create_tensor([out_feat, in_feat])
        if not has_bias:
            yield SampleInput(input_tensor, weight)
            continue

        bias = create_tensor([out_feat])
        yield SampleInput(input_tensor, weight, bias)

def sample_inputs_bilinear(self, device, dtype, requires_grad, **kwargs):
    features_options = [[3, 4, 5], [8, 8, 8]]
    batch_options: List[List[int]] = [
        [],  # no batch
        [0],
        [8],
        [2, 3],
    ]
    create_tensor = partial(make_tensor, device=device, dtype=dtype,
                            requires_grad=requires_grad, low=-2, high=2)

    for has_bias, (in_feat1, in_feat2, out_feat), batch_shape in \
            itertools.product([True, False], features_options, batch_options):
        input_tensor1 = create_tensor(batch_shape + [in_feat1])
        input_tensor2 = create_tensor(batch_shape + [in_feat2])
        weight = create_tensor([out_feat, in_feat1, in_feat2])
        if not has_bias:
            yield SampleInput(input_tensor1, input_tensor2, weight)
            continue
        bias = create_tensor([out_feat])
        yield SampleInput(input_tensor1, input_tensor2, weight, bias)

def sample_inputs_glu(self, device, dtype, requires_grad, **kwargs):
    features_options = [[2], [2, 4], [8, 8], [3, 6, 8], [1, 4, 6, 7]]
    batch_options: List[List[int]] = [
        [],  # no batch
        [0],
        [8],
        [2, 3],
    ]
    create_tensor = partial(make_tensor, device=device, dtype=dtype,
                            requires_grad=requires_grad, low=-2, high=2)

    for features, batch_shape in itertools.product(features_options, batch_options):
        ndim = len(features) + len(batch_shape)
        for dim in range(ndim):
            input_tensor = create_tensor(batch_shape + features)
            dim_size = input_tensor.size(dim)
            if dim_size > 0 and dim_size % 2 == 0:
                yield SampleInput(input_tensor, dim)

def sample_inputs_interpolate(mode, self, device, dtype, requires_grad, **kwargs):
    N, C = 2, 3
    D = 4
    S = 3
    L = 5

    align_corners_options: Tuple[Any, ...] = (None,)
    if mode in ('linear', 'bilinear', 'bicubic', 'trilinear'):
        align_corners_options = (True, False, None)
    ranks_for_mode = {
        'nearest': [1, 2, 3],
        'nearest-exact': [1, 2, 3],
        'linear': [1],
        'bilinear': [2],
        'bicubic': [2],
        'trilinear': [3],
        'area': [1, 2, 3]
    }

    def shape(size, rank, with_batch_channel=True):
        if with_batch_channel:
            return tuple([N, C] + ([size] * rank))
        return tuple([size] * rank)

    if mode in ('bilinear', 'bicubic') and dtype == torch.uint8:
        make_arg = partial(
            make_tensor,
            device=device,
            dtype=dtype,
            requires_grad=requires_grad,
            high=256 if dtype == torch.uint8 else None,
        )
        rank = 2
        for memory_format in [torch.contiguous_format, torch.channels_last]:
            yield SampleInput(
                make_arg(shape(270, rank), memory_format=memory_format),
                shape(130, rank, False),
                scale_factor=None,
                mode=mode,
                align_corners=False,
            )

    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    for align_corners in align_corners_options:
        for rank in ranks_for_mode[mode]:
            yield SampleInput(
                make_arg(shape(D, rank)),
                shape(S, rank, False),
                scale_factor=None,
                mode=mode,
                align_corners=align_corners,
            )
            yield SampleInput(
                make_arg(shape(D, rank)),
                shape(L, rank, False),
                scale_factor=None,
                mode=mode,
                align_corners=align_corners,
            )
            for recompute_scale_factor in [False, True]:
                for scale_factor in [1.7, 0.6]:
                    yield SampleInput(
                        make_arg(shape(D, rank)),
                        size=None,
                        scale_factor=scale_factor,
                        mode=mode,
                        align_corners=align_corners,
                        recompute_scale_factor=recompute_scale_factor,
                    )

def reference_inputs_interpolate(mode, self, device, dtype, requires_grad, **kwargs):
    yield from sample_inputs_interpolate(mode, self, device, dtype, requires_grad, **kwargs)

    if mode in ('bilinear', 'bicubic'):
        make_arg = partial(
            make_tensor,
            device=device,
            dtype=dtype,
            requires_grad=requires_grad,
            high=256 if dtype == torch.uint8 else None,
        )
        for memory_format in [torch.contiguous_format, torch.channels_last]:
            for aa in [True, False]:
                yield SampleInput(
                    make_arg((2, 3, 345, 456), memory_format=memory_format),
                    (270, 270),
                    scale_factor=None,
                    mode=mode,
                    align_corners=False,
                    antialias=aa,
                )

def sample_inputs_upsample(mode, self, device, dtype, requires_grad, **kwargs):
    N, C = 2, 3
    D = 4
    S = 3
    L = 5

    ranks_for_mode = {
        'nearest': [1, 2, 3],
        'bilinear': [2],
    }

    def shape(size, rank, with_batch_channel=True):
        if with_batch_channel:
            return torch.Size([N, C] + ([size] * rank))
        return torch.Size([size] * rank)

    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad)

    for rank in ranks_for_mode[mode]:
        yield SampleInput(make_arg(shape(D, rank)), size=shape(S, rank, False))
        yield SampleInput(make_arg(shape(D, rank)), size=shape(L, rank, False))
        yield SampleInput(make_arg(shape(D, rank)), scale_factor=1.7)
        yield SampleInput(make_arg(shape(D, rank)), scale_factor=0.6)

def reference_inputs_upsample(mode, self, device, dtype, requires_grad, **kwargs):
    yield from sample_inputs_upsample(mode, self, device, dtype, requires_grad, **kwargs)

    if mode in ('bilinear', ):
        make_arg = partial(
            make_tensor,
            device=device,
            dtype=dtype,
            requires_grad=requires_grad,
            high=256 if dtype == torch.uint8 else None,
        )
        for memory_format in [torch.contiguous_format, torch.channels_last]:
            yield SampleInput(
                make_arg((2, 3, 345, 456), memory_format=memory_format),
                (270, 270),
            )

def sample_inputs_upsample_aa(mode, self, device, dtype, requires_grad, **kwargs):
    N = 6
    C = 3
    H = 10
    W = 20
    S = 3
    L = 5

    input_tensor = make_tensor(torch.Size([N, C, H, W]), device=device, dtype=dtype, requires_grad=requires_grad)

    yield SampleInput(input_tensor, output_size=torch.Size([S, S]), align_corners=False, scale_factors=None)
    yield SampleInput(input_tensor, output_size=torch.Size([L, L]), align_corners=False, scale_factors=None)
    yield SampleInput(input_tensor, output_size=None, align_corners=False, scale_factors=[1.7, 0.9])
    yield SampleInput(input_tensor, output_size=None, align_corners=True, scale_factors=[0.8, 1.0])

    yield SampleInput(input_tensor, output_size=torch.Size([S, S]), align_corners=False, scales_h=None, scales_w=None)
    yield SampleInput(input_tensor, output_size=torch.Size([S, S]), align_corners=False, scales_h=1.7, scales_w=0.9)
    yield SampleInput(input_tensor, output_size=torch.Size([S, S]), align_corners=True, scales_h=1.7, scales_w=0.9)

def sample_inputs_gelu(self, device, dtype, requires_grad, **kwargs):
    N = 5
    for _ in range(1, N):
        for approximate in ['none', 'tanh']:
            yield SampleInput(
                make_tensor((N * 2, N * 2), device=device, dtype=dtype,
                            requires_grad=requires_grad, low=-3, high=3),
                approximate=approximate)


def error_inputs_gelu(op, device, **kwargs):
    yield ErrorInput(SampleInput(make_tensor((), dtype=torch.float, device=device), kwargs={"approximate": "asdf"}),
                     error_regex="approximate argument must be either")


def sample_inputs_max_min_reduction_with_dim(op_info, device, dtype, requires_grad, **kwargs):
    inputs = []
    args_for_reduction_with_dim = (
        ((S, S, S), (1,),),
        ((S, S, S), (1, True, ),),
        ((), (0,),),
        ((), (0, True,),),
    )
    return ((SampleInput(make_tensor(input_tensor, dtype=dtype, device=device,
                                     low=None, high=None,
                                     requires_grad=requires_grad),
                         *args))
            for input_tensor, args in args_for_reduction_with_dim)

def sample_inputs_max_min_reduction_no_dim(op_info, device, dtype, requires_grad, **kwargs):
    make_arg = partial(make_tensor, device=device, dtype=dtype, requires_grad=requires_grad, low=None, high=None)
    yield SampleInput(make_arg((S, S, S)))
    yield SampleInput(make_arg(()))

def _generate_nan_reduction_inputs(device, dtype, requires_grad, **kwargs):
    yield from _generate_reduction_inputs(device, dtype, requires_grad)
    if dtype.is_complex or dtype.is_floating_point:
        yield torch.tensor([2, torch.nan, -1], device=device, dtype=dtype, requires_grad=requires_grad)
        yield torch.tensor([[torch.nan, 2], [0, 1]], device=device, dtype=dtype, requires_grad=requires_grad)

def sample_inputs_nan_reduction(supports_multiple_dims):
    def fn(op_info, device, dtype, requires_grad, **kwargs):
        for t in _generate_nan_reduction_inputs(device, dtype, requires_grad):
            yield SampleInput(t.clone().requires_grad_(requires_grad))
            for kwargs in _generate_reduction_kwargs(t.ndim, supports_multiple_dims):
                yield SampleInput(t.clone().requires_grad_(requires_grad), **kwargs)

    return fn

def sample_inputs_reduction_quantile(op_info, device, dtype, requires_grad, **kwargs):
    test_quantiles = (0.5, make_tensor((2,), dtype=dtype, device=device, low=0, high=1, requires_grad=requires_grad))
    test_interpolations = ['linear', 'midpoint']

    for quantiles in test_quantiles:
        for t in _generate_reduction_inputs(device, dtype, requires_grad):
            input = t.clone().requires_grad_(requires_grad)
            yield SampleInput(input, quantiles)
            for kwargs in _generate_reduction_kwargs(t.ndim, supports_multiple_dims=False):
                kwargs.setdefault('dim', 0)
                kwargs.setdefault('keepdim', False)
                for interpolation in test_interpolations:
                    kwargs['interpolation'] = interpolation
                    input = t.clone().requires_grad_(requires_grad)
                    yield SampleInput(input, quantiles, **kwargs)

def sample_inputs_reduction_count_nonzero(*args, **kwargs):
    See: https://github.com/pytorch/pytorch/pull/62315#issuecomment-896143189 for more details.
    g = reference_reduction_numpy(f)

    @wraps(g)
    def wrapper(x: np.ndarray, *args, **kwargs):
        assert not ('unbiased' in kwargs and 'correction' in kwargs)

        if 'unbiased' in kwargs:
            kwargs['ddof'] = int(kwargs.pop('unbiased'))
        elif 'correction' in kwargs:
            kwargs['ddof'] = kwargs.pop('correction')

        return g(x, *args, **kwargs)

    return wrapper

def generate_std_var_kwargs(t: torch.Tensor, **kwargs):
            template <typename T>
            void binary_return_by_ref(T i0, T i1, T& out0) {
                out0 = i0 + i1;
            }
            template <typename T>
            void binary_2outputs(T i0, T i1, T& out0, T& out1) {
                out0 = i0 + i1;
                out1 = i0 - i1;
            }
    return (op_name, variant_name, device_type, dtypes, True)



<END>

<START>
import builtins

import torch
from torch.distributed._shard.sharding_spec import (
    ChunkShardingSpec,
    EnumerableShardingSpec,
    ShardMetadata,
)
from torch.distributed._shard.sharding_spec._internals import (
    get_chunked_dim_size,
    get_split_size,
)


def generate_chunk_sharding_specs_for_test(sharding_dim):
    return [
        ChunkShardingSpec(
            dim=sharding_dim,
            placements=[
                "rank:0/cuda:0",
                "rank:1/cuda:1",
                "rank:2/cuda:2",
                "rank:3/cuda:3",
            ],
        ),
        ChunkShardingSpec(
            dim=sharding_dim,
            placements=[
                "rank:2/cuda:2",
                "rank:3/cuda:3",
                "rank:0/cuda:0",
                "rank:1/cuda:1",
            ],
        ),
        ChunkShardingSpec(
            dim=sharding_dim,
            placements=[
                "rank:3/cuda:3",
                "rank:0/cuda:0",
                "rank:1/cuda:1",
                "rank:2/cuda:2",
            ],
        ),
    ]


def generate_enumerable_sharding_specs_for_test():
    return [
        EnumerableShardingSpec(
            [
                ShardMetadata(
                    shard_offsets=[0, 0],
                    shard_sizes=[5, 5],
                    placement="rank:0/cuda:0",
                ),
                ShardMetadata(
                    shard_offsets=[5, 0],
                    shard_sizes=[5, 5],
                    placement="rank:1/cuda:1",
                ),
                ShardMetadata(
                    shard_offsets=[0, 5],
                    shard_sizes=[5, 5],
                    placement="rank:2/cuda:2",
                ),
                ShardMetadata(
                    shard_offsets=[5, 5],
                    shard_sizes=[5, 5],
                    placement="rank:3/cuda:3",
                ),
            ]
        )
    ]


def generate_local_weight_sharding_params_for_test(
    local_weight, sharded_dim, gpu_num, spec, rank
):
    sharding_dim_size = local_weight.size(sharded_dim)
    split_size = get_split_size(sharding_dim_size, gpu_num)
    current_offsets = 0
    start_pos = current_offsets
    for idx, placement in enumerate(spec.placements):
        chunk_size = get_chunked_dim_size(sharding_dim_size, split_size, idx)
        if rank == placement.rank():
            start_pos = current_offsets
            break
        current_offsets += chunk_size
    return start_pos, chunk_size


def clone_module_parameter(module, param_name):
    tensor = getattr(module, param_name)
    return torch.nn.Parameter(tensor.detach().clone())

def gen_binary_op_func(python_op, inplace=False):
    src_lines = ['def f(lhs, rhs):']
    if "torch" in python_op:
        src_lines.append(f'  return {python_op}(lhs, rhs)\n')
    elif inplace:
        src_lines.append(f'  lhs {python_op}= rhs\n  return lhs\n')
    else:
        src_lines.append(f'  return lhs {python_op} rhs\n')

    code_str = '\n'.join(src_lines)
    g = {'torch': torch}
    builtins.exec(code_str, g)
    return g["f"]

<END>

<START>
import builtins
import functools
import inspect
import itertools
import logging
import sys
import textwrap
import time
from io import StringIO

from typing import Any, Callable, Dict, List, Optional, Type, Union
from unittest.mock import patch

import sympy

import torch
from torch._dynamo.testing import rand_strided
from torch._dynamo.utils import counters, identity, preserve_rng_state

from . import config, ir
from .autotune_process import TensorMeta, TritonBenchmarkRequest
from .codecache import code_hash, PersistentCache, PyCodeCache
from .codegen.common import ChoiceCaller, IndentedBuffer, KernelTemplate
from .codegen.triton import texpr, TritonKernel, TritonPrinter, TritonScheduling
from .codegen.triton_utils import config_of, signature_to_meta
from .exc import CUDACompileError
from .utils import do_bench, Placeholder, sympy_dot, sympy_product, unique
from .virtualized import V

log = logging.getLogger(__name__)

VERIFY: Dict[str, Any] = dict()
PRINT_AUTOTUNE = True
DEBUG = False


class KernelNamespace:
    pass


extern_kernels = KernelNamespace()


class PartialRender:

    def __init__(self, code, replacement_hooks):
        super().__init__()
        self.code = code
        self.replacement_hooks = replacement_hooks

    def finalize(self):
        code = self.code
        assert code is not None, "can only be called once"
        self.code = None
        for key, fn in self.replacement_hooks.items():
            code = code.replace(key, fn())
        return code


class TritonTemplateKernel(TritonKernel):
    def __init__(
        self,
        kernel_name,
        input_nodes,
        output_node,
        defines,
        num_stages,
        num_warps,
        grid_fn,
        meta,
        call_sizes,
        use_jit=True,
        prefix_args=0,
        suffix_args=0,
        epilogue_fn=identity,
        *,
        index_dtype,
    ):
        super().__init__(
            sympy_product(output_node.get_size()),
            sympy.Integer(1),
            index_dtype=index_dtype,
        )
        self.input_nodes = input_nodes
        self.output_node = output_node
        self.named_input_nodes = {}
        self.defines = defines
        self.kernel_name = kernel_name
        self.template_mask = None
        self.use_jit = use_jit
        self.num_stages = num_stages
        self.num_warps = num_warps
        self.grid_fn = grid_fn
        self.meta = meta
        self.call_sizes = call_sizes
        self.prefix_args = prefix_args
        self.suffix_args = suffix_args
        self.epilogue_fn = epilogue_fn
        self.render_hooks = dict()

    def need_numel_args(self):
        return False

    def jit_line(self):
        if self.use_jit:
            return "@triton.jit"

        argdefs, _, signature = self.args.python_argdefs()
        triton_meta = {
            "signature": signature_to_meta(signature, size_dtype=self.index_dtype),
            "device": V.graph.scheduler.current_device.index,
            "device_type": V.graph.scheduler.current_device.type,
            "constants": {},
        }
        triton_meta["configs"] = [config_of(signature)]

        inductor_meta = {"kernel_name": str(Placeholder.DESCRIPTIVE_NAME)}
        return textwrap.dedent(
        )

    def def_kernel(self, *argnames):
        assert all(isinstance(x, str) for x in argnames)
        renames = IndentedBuffer(initial_indent=1)

        named_args = self.input_nodes[
            self.prefix_args : len(self.input_nodes) - self.suffix_args
        ]

        assert len(argnames) == len(named_args), (
            len(argnames),
            len(named_args),
            self.prefix_args,
            len(self.input_nodes),
        )

        for input_node in self.input_nodes[: self.prefix_args]:
            self.args.input(input_node.get_name())

        for name, input_node in zip(argnames, named_args):
            arg_name = f"arg_{name}"
            self.named_input_nodes[name] = input_node
            self.args.input_buffers[input_node.get_name()] = arg_name

        for name in argnames:
            input_node = self.named_input_nodes[name]
            arg_name = self.args.input_buffers[input_node.get_name()]
            if input_node.get_layout().offset == 0:
                renames.writeline(f"{name} = {arg_name}")
            else:
                offset = texpr(self.rename_indexing(input_node.get_layout().offset))
                renames.writeline(f"{name} = {arg_name} + {offset}")

        for input_node in self.input_nodes[len(self.input_nodes) - self.suffix_args :]:
            self.args.input(input_node.get_name())

        def hook():
            arg_defs, *_ = self.args.python_argdefs()
            return "\n".join(
                [
                    "import triton.language as tl",
                    "import triton",
                    "from torch._inductor.triton_heuristics import template",
                    "from torch._inductor.utils import instance_descriptor",
                    "from torch._inductor import triton_helpers",
                    TritonKernel.gen_attr_descriptor_import(),
                    "",
                    self.jit_line(),
                    f"def {self.kernel_name}({', '.join(arg_defs)}):",
                    self.defines,
                    renames.getvalue(),
                ]
            )

        assert "<DEF_KERNEL>" not in self.render_hooks
        self.render_hooks["<DEF_KERNEL>"] = hook
        return "<DEF_KERNEL>"

    def size(self, name: str, index: int):
        assert isinstance(index, int)
        if name is None:
            val = self.output_node.get_size()[index]
        else:
            assert isinstance(name, str)
            val = self.named_input_nodes[name].get_size()[index]
        return texpr(self.rename_indexing(val))

    def stride(self, name, index):
        assert isinstance(index, int)
        if name is None:
            val = self.output_node.get_stride()[index]
        else:
            assert isinstance(name, str)
            val = self.named_input_nodes[name].get_stride()[index]
        return texpr(self.rename_indexing(val))

    def store_output(self, indices, val, mask):
        assert isinstance(indices, (list, tuple))
        assert isinstance(val, str)
        assert isinstance(mask, str)
        assert self.template_mask is None
        indices = list(map(TritonPrinter.paren, indices))
        index_symbols = [sympy.Symbol(x) for x in indices]
        lengths = [V.graph.sizevars.simplify(s) for s in self.output_node.get_size()]
        assert len(indices) == len(lengths)

        for name, range_tree_entry in zip(
            indices, self.range_trees[0].construct_entries(lengths)
        ):
            range_tree_entry.set_name(name)
        contiguous_index = sympy_dot(
            ir.FlexibleLayout.contiguous_strides(lengths), index_symbols
        )
        contiguous_index = self.rename_indexing(contiguous_index)
        self.body.writeline("xindex = " + texpr(contiguous_index))
        self.range_trees[0].lookup(sympy.Integer(1), sympy_product(lengths)).set_name(
            "xindex"
        )
        self.template_mask = mask
        self.template_indices = indices
        output_index = self.output_node.get_layout().make_indexer()(index_symbols)
        output_index = self.rename_indexing(output_index)
        if output_index == contiguous_index:
            output_index = sympy.Symbol("xindex")

        epilogue_args = [val]
        for input_node in itertools.chain(
            self.input_nodes[: self.prefix_args],
            self.input_nodes[len(self.input_nodes) - self.suffix_args :],
        ):
            input_node.freeze_layout()
            epilogue_args.append(input_node.make_loader()(index_symbols))

        V.ops.store(
            self.output_node.get_name(),
            output_index,
            self.epilogue_fn(*epilogue_args),
        )
        self.codegen_body()

        def hook():
            self.codegen_body()
            return textwrap.indent(self.body.getvalue(), "    ").strip()

        assert "<STORE_OUTPUT>" not in self.render_hooks
        self.render_hooks["<STORE_OUTPUT>"] = hook
        return "<STORE_OUTPUT>"

    def render(self, template, kwargs):
        return PartialRender(
            template.render(**self.template_env(), **kwargs),
            self.render_hooks,
        )

    def make_load(self, name, indices, mask):
        assert isinstance(indices, (list, tuple))
        assert isinstance(name, str)
        assert isinstance(mask, str)
        stride = self.named_input_nodes[name].get_stride()
        indices = list(map(TritonPrinter.paren, indices))
        assert len(indices) == len(stride)
        index = " + ".join(
            f"{texpr(self.rename_indexing(s))} * {i}" for s, i in zip(stride, indices)
        )
        return f"tl.load({name} + ({index}), {mask})"

    def template_env(self):
        return {
            fn.__name__: fn
            for fn in [
                self.def_kernel,
                self.size,
                self.stride,
                self.store_output,
                self.make_load,
            ]
        }

    def indexing(
        self,
        index: sympy.Expr,
        *,
        copy_shape=None,
        dense_indexing=False,
        override_mask=None,
    ):
        result, *mask = super().indexing(
            index,
            dense_indexing=False,
            copy_shape=self.template_mask,
            override_mask=self.template_mask,
        )
        return (result, *mask)

    def initialize_range_tree(self, pid_cache):
        super().initialize_range_tree(pid_cache)
        self.body.clear()
        self.indexing_code.clear()

    def call_kernel(self, name: str, node: Optional[ir.IRNode] = None):
        wrapper = V.graph.wrapper_code
        _, call_args, _ = self.args.python_argdefs()
        call_args = [str(a) for a in call_args]

        for i in range(len(call_args)):
            if V.graph.is_unspec_arg(call_args[i]):
                call_args[i] = call_args[i] + ".item()"
            if isinstance(call_args[i], sympy.Symbol):
                call_args[i] = texpr(call_args[i])

        if V.graph.cpp_wrapper:
            grid_args = [V.graph.sizevars.simplify(s) for s in self.call_sizes] + [
                self.meta
            ]
            grid = self.grid_fn(*grid_args)

            wrapper.generate_kernel_call(
                name,
                call_args,
                device_index=V.graph.scheduler.current_device.index,
                grid=grid,
            )
        else:
            stream_name = wrapper.write_get_raw_stream(
                V.graph.scheduler.current_device.index
            )

            wrapper.add_import_once(f"import {self.grid_fn.__module__}")
            meta = wrapper.add_meta_once(self.meta)

            grid_call = [
                texpr(V.graph.sizevars.simplify(s)) for s in self.call_sizes
            ] + [meta]
            grid_call = f"{self.grid_fn.__module__}.{self.grid_fn.__name__}({', '.join(grid_call)})"
            wrapper.writeline(
                f"{name}.run({', '.join(call_args)}, grid={grid_call}, stream={stream_name})"
            )


@functools.lru_cache(None)
def _jinja2_env():
    try:
        import jinja2

        return jinja2.Environment(
            undefined=jinja2.StrictUndefined,
        )
    except ImportError:
        return None


class TritonTemplate(KernelTemplate):
    index_counter = itertools.count()
    all_templates: Dict[str, "TritonTemplate"] = dict()

    def __init__(self, name: str, grid: Any, source: str, debug=False):
        super().__init__(name)
        self.grid = grid
        self.template = self._template_from_string(source)
        assert name not in self.all_templates, "duplicate template name"
        self.all_templates[name] = self
        self.debug = debug

    def generate(
        self,
        input_nodes,
        layout,
        num_stages,
        num_warps,
        prefix_args=0,
        suffix_args=0,
        epilogue_fn=identity,
        **kwargs,
    ):
        assert self.template, "requires jinja2"
        defines = StringIO()
        for name, val in kwargs.items():
            defines.write(f"    {name} : tl.constexpr = {val}\n")
        defines = defines.getvalue()

        fake_out = ir.Buffer("buf_out", layout)
        kernel_name = f"triton_{self.name}"

        numel = sympy_product(layout.size)
        buffers = itertools.chain(input_nodes, (fake_out,))
        if not TritonScheduling.can_use_32bit_indexing(numel, buffers):
            raise NotImplementedError(
                "64-bit indexing is not yet implemented for triton templates"
            )

        kernel_options = dict(
            input_nodes=input_nodes,
            defines=defines,
            num_stages=num_stages,
            num_warps=num_warps,
            grid_fn=self.grid,
            meta=kwargs,
            call_sizes=layout.size,
            prefix_args=prefix_args,
            suffix_args=suffix_args,
            epilogue_fn=epilogue_fn,
            index_dtype="tl.int32",
        )
        with patch.object(
            V.graph, "get_dtype", self._fake_get_dtype(fake_out)
        ), TritonTemplateKernel(
            kernel_name=kernel_name,
            output_node=fake_out,
            use_jit=True,
            **kernel_options,
        ) as kernel:
            try:
                code = kernel.render(self.template, kwargs).finalize()
            except ZeroDivisionError:
                return None
            if self.debug:
                print("Generated Code:\n", code)
            extra = (
                "-".join(
                    [
                        *[
                            f"{kwarg}={repr(kwargs[kwarg])}"
                            for kwarg in sorted(kwargs.keys())
                        ],
                        f"num_stages={num_stages}",
                        f"num_warps={num_warps}",
                    ]
                )
                + "-"
            )
            mod = PyCodeCache.load(code, extra)
            _, call_args, _ = kernel.args.python_argdefs()

        expected_args = list(unique(x.get_name() for x in input_nodes))
        expected_args.extend([fake_out.get_name()])
        assert list(call_args)[: len(expected_args)] == expected_args, (
            call_args,
            expected_args,
        )
        extra_args = V.graph.sizevars.size_hints(
            map(sympy.expand, call_args[len(expected_args) :]),
            fallback=config.unbacked_symint_fallback,
        )

        kernel_hash_name = f"triton_{self.name}_{next(self.index_counter)}"

        def make_kernel_render(out_node):
            kernel = TritonTemplateKernel(
                kernel_name=str(Placeholder.KERNEL_NAME),
                output_node=out_node,
                use_jit=False,
                **kernel_options,
            )
            render = functools.partial(
                kernel.render,
                self.template,
                kwargs,
            )
            return kernel, render

        assert mod.__file__ is not None
        grid = self.grid(
            *V.graph.sizevars.size_hints(
                layout.size,
                fallback=config.unbacked_symint_fallback,
            ),
            kwargs,
        )
        bmreq = TritonBenchmarkRequest(
            module_path=mod.__file__,
            module_cache_key=mod.key,
            kernel_name=kernel_name,
            grid=grid,
            extra_args=extra_args,
            num_stages=num_stages,
            num_warps=num_warps,
            input_tensor_meta=TensorMeta.from_irnodes(input_nodes),
            output_tensor_meta=TensorMeta.from_irnodes(layout),
        )

        return TritonTemplateCaller(
            kernel_hash_name,
            input_nodes,
            layout,
            make_kernel_render,
            extra.strip("-").replace("-", ", "),
            bmreq,
        )


class ExternKernelChoice:
    def __init__(
        self,
        kernel,
        cpp_kernel=None,
        *,
        name=None,
        has_out_variant=True,
    ):
        super().__init__()
        name = name or kernel.__name__
        assert callable(kernel)
        assert not hasattr(extern_kernels, name), "duplicate extern kernel"
        self.name = name
        self.cpp_kernel_name = cpp_kernel
        self.has_out_variant = has_out_variant
        setattr(extern_kernels, name, kernel)

    def to_callable(self):
        return getattr(extern_kernels, self.name)

    def call_name(self):
        return f"extern_kernels.{self.name}"

    @functools.lru_cache(None)
    def hash_key(self):
        fn = self.to_callable()
        parts = [
            self.name,
            getattr(fn, "__name__", ""),
            getattr(fn, "__module__", ""),
        ]
        try:
            parts.append(inspect.getsource(fn))
        except Exception:
            pass
        return code_hash("-".join(parts))

    def bind(self, input_nodes, layout, ordered_kwargs_for_cpp_kernel=(), **kwargs):
        self.ordered_kwargs_for_cpp_kernel = ordered_kwargs_for_cpp_kernel
        return ExternKernelCaller(
            self, input_nodes, layout, kwargs, has_out_variant=self.has_out_variant
        )


class TritonTemplateCaller(ChoiceCaller):
    def __init__(
        self, name, input_nodes, layout, make_kernel_render, debug_extra, bmreq
    ):
        super().__init__(name, input_nodes, layout)
        self.make_kernel_render = make_kernel_render
        self.debug_extra = debug_extra
        self.bmreq = bmreq

    def benchmark(self, *args, out):
        assert self.bmreq is not None
        return self.bmreq.benchmark(*args, output_tensor=out)

    def __str__(self):
        return f"TritonTemplateCaller({self.bmreq.module_path}, {self.debug_extra})"

    def call_name(self):
        return f"template_kernels.{self.name}"

    def hash_key(self):
        return "-".join(
            [
                self.name.rsplit("_", 1)[0],
                self.bmreq.module_cache_key,
            ]
        )

    def output_node(self):
        return ir.TensorBox.create(
            ir.TritonTemplateBuffer(
                layout=self.layout,
                inputs=self.input_nodes,
                make_kernel_render=self.make_kernel_render,
            )
        )


class ExternKernelCaller(ChoiceCaller):
    def __init__(
        self,
        choice: ExternKernelChoice,
        input_nodes,
        layout,
        kwargs=None,
        *,
        has_out_variant=True,
    ):
        super().__init__(choice.name, input_nodes, layout)
        self.choice = choice
        self.kwargs = kwargs or {}
        self.has_out_variant = has_out_variant

    def __str__(self):
        return f"ExternKernelCaller({self.choice.call_name()})"

    def benchmark(self, *args, out):
        if self.has_out_variant:
            return super().benchmark(*args, out=out)
        else:
            algo = self.to_callable()
            out_new = algo(*args)
            torch._C._dynamo.guards.assert_size_stride(
                out_new, tuple(out.size()), tuple(out.stride())
            )
            out.copy_(out_new)  # for correctness checking
            return do_bench(lambda: algo(*args))

    def to_callable(self):
        fn = self.choice.to_callable()
        if self.kwargs:
            return functools.partial(fn, **self.kwargs)
        else:
            return fn

    def hash_key(self):
        return "-".join(
            [
                self.choice.name,
                *[
                    f"{kwarg}={repr(self.kwargs[kwarg])}"
                    for kwarg in sorted(self.kwargs.keys())
                ],
                self.choice.hash_key(),
            ]
        )

    def output_node(self):
        cls: Union[Type[ir.ExternKernelOut], Type[ir.ExternKernelAlloc]]
        if self.has_out_variant:
            cls = ir.ExternKernelOut
        else:
            cls = ir.ExternKernelAlloc
        return ir.TensorBox.create(
            cls(
                layout=self.layout,
                inputs=self.input_nodes,
                python_kernel_name=self.choice.call_name(),
                cpp_kernel_name=self.choice.cpp_kernel_name,
                ordered_kwargs_for_cpp_kernel=self.choice.ordered_kwargs_for_cpp_kernel,
                kwargs=self.kwargs,
            )
        )


class ErrorFromChoice(RuntimeError):
    def __init__(self, msg, choice: ChoiceCaller, inputs_str):
        msg += f"\nFrom choice {choice}\n{inputs_str}"
        super().__init__(msg)
        self.choice = choice


class AlgorithmSelectorCache(PersistentCache):
    def __call__(
        self,
        name,
        choices: List[ChoiceCaller],
        input_nodes,
        layout,
        input_gen_fns: Optional[Dict[int, Callable[[ir.Buffer], torch.Tensor]]] = None,
    ):
        from .codegen.cuda.cuda_kernel import CUDATemplateCaller

        choices = [choice for choice in choices if choice is not None]
        if len(choices) == 0:
            raise RuntimeError(
                "No choices to select, please consider adding ATEN into max_autotune_gemm_backends "
                "config (defined in torch/_inductor/config.py) to allow at least one choice. "
            )
        log.debug("Max autotune selects from %s choices.", str(len(choices)))

        if len(choices) == 1:
            if not isinstance(choices[0], CUDATemplateCaller):
                return choices[0].output_node()

        @functools.lru_cache(None)
        def make_benchmark_fn():
            return self.make_benchmark_fn(choices, input_nodes, layout, input_gen_fns)

        def autotune(choices):
            return make_benchmark_fn()(choices)

        if config.autotune_in_subproc:
            from .autotune_process import tuning_pool

            tuning_pool.initialize()

        autotune_start_ts = time.time()
        timings = self.lookup(
            choices,
            name,
            repr([self.key_of(x) for x in input_nodes]),
            autotune,
        )
        autotune_elapse = time.time() - autotune_start_ts
        if timings == {} or choices[0] not in timings:
            return choices[0].output_node()

        if make_benchmark_fn.cache_info().currsize:
            counters["inductor"]["select_algorithm_autotune"] += 1
        if (
            make_benchmark_fn.cache_info().currsize
            or log.getEffectiveLevel() == logging.DEBUG
        ):
            self.log_results(name, input_nodes, timings, autotune_elapse)
        selected_choice = builtins.min(timings, key=timings.__getitem__).output_node()
        log.debug("selected choice: %s", str(selected_choice))
        return selected_choice

    @classmethod
    def make_benchmark_fn(
        cls,
        choices,
        input_nodes,
        layout,
        input_gen_fns=None,
    ):
        if input_gen_fns is None:
            input_gen_fns = {}

        unique_example_inputs = {
            x.get_name(): input_gen_fns.get(i, cls.benchmark_example_value)(x)
            for i, x in enumerate(input_nodes)
        }
        example_inputs = list(unique_example_inputs.values())
        example_inputs_extern = [
            torch.as_strided(
                unique_example_inputs[input_node.get_name()],
                V.graph.sizevars.size_hints(
                    input_node.get_size(),
                    fallback=config.unbacked_symint_fallback,
                ),
                V.graph.sizevars.size_hints(
                    input_node.get_stride(),
                    fallback=config.unbacked_symint_fallback,
                ),
                V.graph.sizevars.size_hint(
                    input_node.get_layout().offset,
                    fallback=config.unbacked_symint_fallback,
                ),
            )
            for input_node in input_nodes
        ]

        out = cls.benchmark_example_value(layout)
        out_extern = torch.as_strided(
            out, out.size(), out.stride(), V.graph.sizevars.size_hint(layout.offset)
        )
        if VERIFY:
            choices[0].benchmark(*example_inputs_extern, out=out_extern)
            expected = out_extern.clone()

        if DEBUG:
            print(f"{len(choices)} tuning requests:")

        def debug_str():
            def tensor_repr(x):
                return (
                    f"torch.empty_strided({tuple(x.size())!r}, {tuple(x.stride())!r}, "
                    f"dtype={x.dtype!r}, device={x.device.type!r})"
                )

            lines = [
                "inputs = [",
            ]
            for x in example_inputs:
                lines.append(f"    {tensor_repr(x)},")
            lines += ["]", f"out = {tensor_repr(out)}", ""]
            return "\n".join(lines)

        def benchmark_choice_in_current_process(choice):
            out.zero_()
            if isinstance(choice, ExternKernelCaller):
                result = choice.benchmark(*example_inputs_extern, out=out_extern)
            else:
                result = choice.benchmark(*example_inputs, out=out)
            if VERIFY:
                torch.testing.assert_close(out_extern, expected, **VERIFY)
            torch.cuda.synchronize()  # shake out any CUDA errors
            return result

        def benchmark_in_current_process(choices):
            timings = {}
            for choice in choices:
                try:
                    timing = benchmark_choice_in_current_process(choice)
                except CUDACompileError as e:
                    log.warning(
                        "CUDA compilation error: \n%s. \nIgnore this choice.", str(e)
                    )
                    timing = float("inf")
                except RuntimeError as e:
                    msg = str(e)
                    if "invalid argument" in msg:
                        msg += "\n\nThis may mean this GPU is too small for max_autotune mode.\n\n"
                        log.warning(msg)
                        timing = float("inf")
                    else:
                        if "illegal memory access" in msg:
                            msg += "\n\nEither error in template or triton bug.\n"
                        raise ErrorFromChoice(msg, choice, debug_str())  # noqa: TRY200
                except AssertionError as e:
                    raise AssertionError(  # noqa: TRY200
                        f"Incorrect result from choice {choice}\n\n{e}"
                    )

                timings[choice] = timing

            return timings

        def benchmark_in_sub_process(choices):
            from . import autotune_process

            extern = [c for c in choices if isinstance(c, ExternKernelCaller)]
            triton = [c for c in choices if not isinstance(c, ExternKernelCaller)]

            timings = benchmark_in_current_process(extern)
            timings.update(autotune_process.benchmark_in_sub_process(triton))
            return timings

        benchmark = (
            benchmark_in_sub_process
            if config.autotune_in_subproc
            else benchmark_in_current_process
        )

        return benchmark

    @staticmethod
    def log_results(name, input_nodes, timings, elapse):
        if not (config.max_autotune or config.max_autotune_gemm) or not PRINT_AUTOTUNE:
            return
        sizes = ", ".join(
            [
                "x".join(
                    map(
                        str,
                        V.graph.sizevars.size_hints(
                            n.get_size(), fallback=config.unbacked_symint_fallback
                        ),
                    )
                )
                for n in input_nodes
            ]
        )
        n = None if log.getEffectiveLevel() == logging.DEBUG else 10
        top_k = sorted(timings, key=timings.__getitem__)[:n]
        best = top_k[0]
        best_time = timings[best]
        sys.stderr.write(f"AUTOTUNE {name}({sizes})\n")
        for choice in top_k:
            result = timings[choice]
            if result:
                sys.stderr.write(
                    f"  {choice.name} {result:.4f} ms {best_time/result:.1%}\n"
                )
            else:
                sys.stderr.write(
                    f"  {choice.name} {result:.4f} ms <DIVIDED BY ZERO ERROR>\n"
                )

        autotune_type_str = (
            "SubProcess" if config.autotune_in_subproc else "SingleProcess"
        )
        sys.stderr.write(f"{autotune_type_str} AUTOTUNE takes {elapse:.4f} seconds\n")

    @staticmethod
    def benchmark_example_value(node):
        if isinstance(node, ir.Layout):
            node = ir.Buffer("fake", node)
        if isinstance(node, ir.BaseView):
            node = node.unwrap_view()
        with preserve_rng_state():
            return rand_strided(
                V.graph.sizevars.size_hints(
                    node.get_size(),
                    fallback=config.unbacked_symint_fallback,
                ),
                V.graph.sizevars.size_hints(
                    node.get_stride(),
                    fallback=config.unbacked_symint_fallback,
                ),
                device=node.get_device(),
                dtype=node.get_dtype(),
                extra_size=node.layout.offset,
            )

    @staticmethod
    def key_of(node):
        sizevars = V.graph.sizevars
        return (
            node.get_device().type,
            str(node.get_dtype()),
            *sizevars.size_hints(
                node.get_size(),
                fallback=config.unbacked_symint_fallback,
            ),
            *sizevars.size_hints(
                node.get_stride(),
                fallback=config.unbacked_symint_fallback,
            ),
            sizevars.size_hint(
                node.get_layout().offset,
                fallback=config.unbacked_symint_fallback,
            ),
        )


_ALGORITHM_SELECTOR_CACHE = None


def autotune_select_algorithm(*args, **kwargs):
    global _ALGORITHM_SELECTOR_CACHE
    if _ALGORITHM_SELECTOR_CACHE is None:
        _ALGORITHM_SELECTOR_CACHE = AlgorithmSelectorCache()
    return _ALGORITHM_SELECTOR_CACHE(*args, **kwargs)


def realize_inputs(*args):
    if len(args) == 1:
        return ir.ExternKernel.require_stride1(ir.ExternKernel.realize_input(args[0]))
    return [realize_inputs(x) for x in args]


from . import lowering  # noqa: F401

<END>

