import torch
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from datautils import MyTrainDataset

import torch.multiprocessing as mp
from torch.utils.data.distributed import DistributedSampler
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.distributed import init_process_group, destroy_process_group
import os


def ddp_setup():
	init_process_group(backend="nccl")
	torch.cuda.set_device(int(os.environ["LOCAL_RANK"]))

class Trainer:
	def __init__(
		self,
		model: torch.nn.Module,
		train_data: DataLoader,
		optimizer: torch.optim.Optimizer,
		save_every: int,
		snapshot_path: str,
	) -> None:
		self.gpu_id = int(os.environ["LOCAL_RANK"])
		self.model = model.to(self.gpu_id)
		self.train_data = train_data
		self.optimizer = optimizer
		self.save_every = save_every
		self.epochs_run = 0
		self.snapshot_path = snapshot_path
		if os.path.exists(snapshot_path):
			print("Loading snapshot")
			self._load_snapshot(snapshot_path)

		self.model = DDP(self.model, device_ids=[self.gpu_id])

	def _load_snapshot(self, snapshot_path):
		loc = f"cuda:{self.gpu_id}"
		snapshot = torch.load(snapshot_path, map_location=loc)
		self.model.load_state_dict(snapshot["MODEL_STATE"])
		self.epochs_run = snapshot["EPOCHS_RUN"]
		print(f"Resuming training from snapshot at Epoch {self.epochs_run}")

	def _run_batch(self, source, targets):
		self.optimizer.zero_grad()
		output = self.model(source)
		loss = F.cross_entropy(output, targets)
		loss.backward()
		self.optimizer.step()

	def _run_epoch(self, epoch):
		b_sz = len(next(iter(self.train_data))[0])
		print(f"[GPU{self.gpu_id}] Epoch {epoch} | Batchsize: {b_sz} | Steps: {len(self.train_data)}")
		self.train_data.sampler.set_epoch(epoch)
		for source, targets in self.train_data:
			source = source.to(self.gpu_id)
			targets = targets.to(self.gpu_id)
			self._run_batch(source, targets)

	def _save_snapshot(self, epoch):
		snapshot = {
			"MODEL_STATE": self.model.module.state_dict(),
			"EPOCHS_RUN": epoch,
		}
		torch.save(snapshot, self.snapshot_path)
		print(f"Epoch {epoch} | Training snapshot saved at {self.snapshot_path}")

	def train(self, max_epochs: int):
		for epoch in range(self.epochs_run, max_epochs):
			self._run_epoch(epoch)
			if self.gpu_id == 0 and epoch % self.save_every == 0:
				self._save_snapshot(epoch)


def load_train_objs():
	train_set = MyTrainDataset(2048)  # load your dataset
	model = torch.nn.Linear(20, 1)  # load your model
	optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)
	return train_set, model, optimizer


def prepare_dataloader(dataset: Dataset, batch_size: int):
	return DataLoader(
		dataset,
		batch_size=batch_size,
		pin_memory=True,
		shuffle=False,
		sampler=DistributedSampler(dataset)
	)


def main(save_every: int, total_epochs: int, batch_size: int, snapshot_path: str = "snapshot.pt"):
	ddp_setup()
	dataset, model, optimizer = load_train_objs()
	train_data = prepare_dataloader(dataset, batch_size)
	trainer = Trainer(model, train_data, optimizer, save_every, snapshot_path)
	trainer.train(total_epochs)
	destroy_process_group()


if __name__ == "__main__":
	import argparse
	parser = argparse.ArgumentParser(description='simple distributed training job')
	parser.add_argument('total_epochs', type=int, help='Total epochs to train the model')
	parser.add_argument('save_every', type=int, help='How often to save a snapshot')
	parser.add_argument('--batch_size', default=32, type=int, help='Input batch size on each device (default: 32)')
	args = parser.parse_args()
	
	main(args.save_every, args.total_epochs, args.batch_size)

import argparse
import os
import sys
import time
import re

import numpy as np
import torch
from torch.optim import Adam
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision import transforms
import torch.onnx

import utils
from transformer_net import TransformerNet
from vgg import Vgg16


def check_paths(args):
	try:
		if not os.path.exists(args.save_model_dir):
			os.makedirs(args.save_model_dir)
		if args.checkpoint_model_dir is not None and not (os.path.exists(args.checkpoint_model_dir)):
			os.makedirs(args.checkpoint_model_dir)
	except OSError as e:
		print(e)
		sys.exit(1)


def train(args):
	if args.cuda:
		device = torch.device("cuda")
	elif args.mps:
		device = torch.device("mps")
	else:
		device = torch.device("cpu")

	np.random.seed(args.seed)
	torch.manual_seed(args.seed)

	transform = transforms.Compose([
		transforms.Resize(args.image_size),
		transforms.CenterCrop(args.image_size),
		transforms.ToTensor(),
		transforms.Lambda(lambda x: x.mul(255))
	])
	train_dataset = datasets.ImageFolder(args.dataset, transform)
	train_loader = DataLoader(train_dataset, batch_size=args.batch_size)

	transformer = TransformerNet().to(device)
	optimizer = Adam(transformer.parameters(), args.lr)
	mse_loss = torch.nn.MSELoss()

	vgg = Vgg16(requires_grad=False).to(device)
	style_transform = transforms.Compose([
		transforms.ToTensor(),
		transforms.Lambda(lambda x: x.mul(255))
	])
	style = utils.load_image(args.style_image, size=args.style_size)
	style = style_transform(style)
	style = style.repeat(args.batch_size, 1, 1, 1).to(device)

	features_style = vgg(utils.normalize_batch(style))
	gram_style = [utils.gram_matrix(y) for y in features_style]

	for e in range(args.epochs):
		transformer.train()
		agg_content_loss = 0.
		agg_style_loss = 0.
		count = 0
		for batch_id, (x, _) in enumerate(train_loader):
			n_batch = len(x)
			count += n_batch
			optimizer.zero_grad()

			x = x.to(device)
			y = transformer(x)

			y = utils.normalize_batch(y)
			x = utils.normalize_batch(x)

			features_y = vgg(y)
			features_x = vgg(x)

			content_loss = args.content_weight * mse_loss(features_y.relu2_2, features_x.relu2_2)

			style_loss = 0.
			for ft_y, gm_s in zip(features_y, gram_style):
				gm_y = utils.gram_matrix(ft_y)
				style_loss += mse_loss(gm_y, gm_s[:n_batch, :, :])
			style_loss *= args.style_weight

			total_loss = content_loss + style_loss
			total_loss.backward()
			optimizer.step()

			agg_content_loss += content_loss.item()
			agg_style_loss += style_loss.item()

			if (batch_id + 1) % args.log_interval == 0:
				mesg = "{}\tEpoch {}:\t[{}/{}]\tcontent: {:.6f}\tstyle: {:.6f}\ttotal: {:.6f}".format(
					time.ctime(), e + 1, count, len(train_dataset),
								  agg_content_loss / (batch_id + 1),
								  agg_style_loss / (batch_id + 1),
								  (agg_content_loss + agg_style_loss) / (batch_id + 1)
				)
				print(mesg)

			if args.checkpoint_model_dir is not None and (batch_id + 1) % args.checkpoint_interval == 0:
				transformer.eval().cpu()
				ckpt_model_filename = "ckpt_epoch_" + str(e) + "_batch_id_" + str(batch_id + 1) + ".pth"
				ckpt_model_path = os.path.join(args.checkpoint_model_dir, ckpt_model_filename)
				torch.save(transformer.state_dict(), ckpt_model_path)
				transformer.to(device).train()

	transformer.eval().cpu()
	save_model_filename = "epoch_" + str(args.epochs) + "_" + str(time.ctime()).replace(' ', '_') + "_" + str(
		args.content_weight) + "_" + str(args.style_weight) + ".model"
	save_model_path = os.path.join(args.save_model_dir, save_model_filename)
	torch.save(transformer.state_dict(), save_model_path)

	print("\nDone, trained model saved at", save_model_path)


def stylize(args):
	device = torch.device("cuda" if args.cuda else "cpu")

	content_image = utils.load_image(args.content_image, scale=args.content_scale)
	content_transform = transforms.Compose([
		transforms.ToTensor(),
		transforms.Lambda(lambda x: x.mul(255))
	])
	content_image = content_transform(content_image)
	content_image = content_image.unsqueeze(0).to(device)

	if args.model.endswith(".onnx"):
		output = stylize_onnx(content_image, args)
	else:
		with torch.no_grad():
			style_model = TransformerNet()
			state_dict = torch.load(args.model)
			for k in list(state_dict.keys()):
				if re.search(r'in\d+\.running_(mean|var)$', k):
					del state_dict[k]
			style_model.load_state_dict(state_dict)
			style_model.to(device)
			style_model.eval()
			if args.export_onnx:
				assert args.export_onnx.endswith(".onnx"), "Export model file should end with .onnx"
				output = torch.onnx._export(
					style_model, content_image, args.export_onnx, opset_version=11,
				).cpu()			
			else:
				output = style_model(content_image).cpu()
	utils.save_image(args.output_image, output[0])


def stylize_onnx(content_image, args):

	assert not args.export_onnx

	import onnxruntime

	ort_session = onnxruntime.InferenceSession(args.model)

	def to_numpy(tensor):
		return (
			tensor.detach().cpu().numpy()
			if tensor.requires_grad
			else tensor.cpu().numpy()
		)

	ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(content_image)}
	ort_outs = ort_session.run(None, ort_inputs)
	img_out_y = ort_outs[0]

	return torch.from_numpy(img_out_y)


def main():
	main_arg_parser = argparse.ArgumentParser(description="parser for fast-neural-style")
	subparsers = main_arg_parser.add_subparsers(title="subcommands", dest="subcommand")

	train_arg_parser = subparsers.add_parser("train", help="parser for training arguments")
	train_arg_parser.add_argument("--epochs", type=int, default=2,
								  help="number of training epochs, default is 2")
	train_arg_parser.add_argument("--batch-size", type=int, default=4,
								  help="batch size for training, default is 4")
	train_arg_parser.add_argument("--dataset", type=str, required=True,
								  help="path to training dataset, the path should point to a folder "
									   "containing another folder with all the training images")
	train_arg_parser.add_argument("--style-image", type=str, default="images/style-images/mosaic.jpg",
								  help="path to style-image")
	train_arg_parser.add_argument("--save-model-dir", type=str, required=True,
								  help="path to folder where trained model will be saved.")
	train_arg_parser.add_argument("--checkpoint-model-dir", type=str, default=None,
								  help="path to folder where checkpoints of trained models will be saved")
	train_arg_parser.add_argument("--image-size", type=int, default=256,
								  help="size of training images, default is 256 X 256")
	train_arg_parser.add_argument("--style-size", type=int, default=None,
								  help="size of style-image, default is the original size of style image")
	train_arg_parser.add_argument("--cuda", type=int, required=True,
								  help="set it to 1 for running on GPU, 0 for CPU")
	train_arg_parser.add_argument("--seed", type=int, default=42,
								  help="random seed for training")
	train_arg_parser.add_argument("--content-weight", type=float, default=1e5,
								  help="weight for content-loss, default is 1e5")
	train_arg_parser.add_argument("--style-weight", type=float, default=1e10,
								  help="weight for style-loss, default is 1e10")
	train_arg_parser.add_argument("--lr", type=float, default=1e-3,
								  help="learning rate, default is 1e-3")
	train_arg_parser.add_argument("--log-interval", type=int, default=500,
								  help="number of images after which the training loss is logged, default is 500")
	train_arg_parser.add_argument("--checkpoint-interval", type=int, default=2000,
								  help="number of batches after which a checkpoint of the trained model will be created")

	eval_arg_parser = subparsers.add_parser("eval", help="parser for evaluation/stylizing arguments")
	eval_arg_parser.add_argument("--content-image", type=str, required=True,
								 help="path to content image you want to stylize")
	eval_arg_parser.add_argument("--content-scale", type=float, default=None,
								 help="factor for scaling down the content image")
	eval_arg_parser.add_argument("--output-image", type=str, required=True,
								 help="path for saving the output image")
	eval_arg_parser.add_argument("--model", type=str, required=True,
								 help="saved model to be used for stylizing the image. If file ends in .pth - PyTorch path is used, if in .onnx - Caffe2 path")
	eval_arg_parser.add_argument("--cuda", type=int, default=False,
								 help="set it to 1 for running on cuda, 0 for CPU")
	eval_arg_parser.add_argument("--export_onnx", type=str,
								 help="export ONNX model to a given file")
	eval_arg_parser.add_argument('--mps', action='store_true', default=False, help='enable macOS GPU training')

	args = main_arg_parser.parse_args()

	if args.subcommand is None:
		print("ERROR: specify either train or eval")
		sys.exit(1)
	if args.cuda and not torch.cuda.is_available():
		print("ERROR: cuda is not available, try running on CPU")
		sys.exit(1)
	if not args.mps and torch.backends.mps.is_available():
		print("WARNING: mps is available, run with --mps to enable macOS GPU")

	if args.subcommand == "train":
		check_paths(args)
		train(args)
	else:
		stylize(args)


if __name__ == "__main__":
	main()

import torch
import torch.fx
import operator

torch.classes.load_library('build/libinterpreter.so')

def lower_to_elementwise_interpreter(orig_mod : torch.nn.Module) -> torch.nn.Module:
	mod = torch.fx.symbolic_trace(orig_mod)

	instructions = []
	constant_idx = 0
	constants = {}
	fn_input_names = []

	target_to_name = {
		operator.add : "add",
		operator.mul : "mul"
	}

	output_node : Optional[torch.fx.Node] = None
	for n in mod.graph.nodes:
		target, args, out_name = n.target, n.args, n.name
		assert len(n.kwargs) == 0, "kwargs currently not supported"

		if n.op == 'placeholder':
			fn_input_names.append(target)
		elif n.op == 'call_function':
			assert target in target_to_name, "Unsupported call target " + target
			arg_names = []
			for arg in args:
				if not isinstance(arg, torch.fx.Node):
					arg_name = f'constant_{constant_idx}'
					constants[arg_name] = torch.Tensor(
						[arg] if isinstance(arg, numbers.Number) else arg)
					arg_names.append(arg_name)
					constant_idx += 1
				else:
					arg_names.append(arg.name)
			instructions.append((target_to_name[target], arg_names, out_name))
		elif n.op == 'output':
			if output_node is not None:
				raise RuntimeError('Multiple output nodes!')
			output_node = n
		else:
			raise RuntimeError('Unsupported opcode ' + n.op)

	interpreter = torch.classes.NativeInterpretation.ElementwiseInterpreter()
	for k, v in constants.items():
		interpreter.add_constant(k, v)
	interpreter.set_input_names(fn_input_names)
	interpreter.set_instructions(instructions)
	assert isinstance(output_node.args[0], torch.fx.Node)
	interpreter.set_output_name(output_node.args[0].name)

	class WrapperModule(torch.nn.Module):
		def __init__(self, interpreter):
			super().__init__()
			self.interpreter = interpreter

	wrapper = WrapperModule(interpreter)


	graph = torch.fx.Graph()
	placeholder_nodes = []
	for name in fn_input_names:
		placeholder_nodes.append(graph.create_node('placeholder', name))

	interpreter_node = graph.create_node('get_attr', 'interpreter')

	output_node = graph.create_node(
		op='call_method', target='__call__', args=(interpreter_node, placeholder_nodes))

	graph.output(output_node)

	graph.lint(wrapper)

	return torch.fx.GraphModule(wrapper, graph)

class MyElementwiseModule(torch.nn.Module):
	def forward(self, x, y):
		return x * y + y

mem = MyElementwiseModule()
lowered = lower_to_elementwise_interpreter(mem)
print(lowered.code)
scripted = torch.jit.script(lowered)
print(scripted.graph)

for _ in range(50):
	x, y = torch.randn(10, 20, 30), torch.randn(10, 20, 30)
	torch.testing.assert_allclose(lowered(x, y), mem(x, y))
	torch.testing.assert_allclose(scripted(x, y), mem(x, y))

import argparse
import os
import sys
import tempfile
from urllib.parse import urlparse

import torch
import torch.distributed as dist
import torch.nn as nn
import torch.optim as optim

from torch.nn.parallel import DistributedDataParallel as DDP

class ToyModel(nn.Module):
	def __init__(self):
		super(ToyModel, self).__init__()
		self.net1 = nn.Linear(10, 10)
		self.relu = nn.ReLU()
		self.net2 = nn.Linear(10, 5)

	def forward(self, x):
		return self.net2(self.relu(self.net1(x)))


def demo_basic(local_world_size, local_rank):

	n = torch.cuda.device_count() // local_world_size
	device_ids = list(range(local_rank * n, (local_rank + 1) * n))

	print(
		f"[{os.getpid()}] rank = {dist.get_rank()}, "
		+ f"world_size = {dist.get_world_size()}, n = {n}, device_ids = {device_ids} \n", end=''
	)

	model = ToyModel().cuda(device_ids[0])
	ddp_model = DDP(model, device_ids)

	loss_fn = nn.MSELoss()
	optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)

	optimizer.zero_grad()
	outputs = ddp_model(torch.randn(20, 10))
	labels = torch.randn(20, 5).to(device_ids[0])
	loss_fn(outputs, labels).backward()
	optimizer.step()


def spmd_main(local_world_size, local_rank):
	env_dict = {
		key: os.environ[key]
		for key in ("MASTER_ADDR", "MASTER_PORT", "RANK", "WORLD_SIZE")
	}
	
	if sys.platform == "win32":
		if "INIT_METHOD" in os.environ.keys():
			print(f"init_method is {os.environ['INIT_METHOD']}")
			url_obj = urlparse(os.environ["INIT_METHOD"])
			if url_obj.scheme.lower() != "file":
				raise ValueError("Windows only supports FileStore")
			else:
				init_method = os.environ["INIT_METHOD"]
		else:
			temp_dir = tempfile.gettempdir()
			init_method = f"file:///{os.path.join(temp_dir, 'ddp_example')}"
		dist.init_process_group(backend="gloo", init_method=init_method, rank=int(env_dict["RANK"]), world_size=int(env_dict["WORLD_SIZE"]))
	else:
		print(f"[{os.getpid()}] Initializing process group with: {env_dict}")  
		dist.init_process_group(backend="nccl")

	print(
		f"[{os.getpid()}]: world_size = {dist.get_world_size()}, "
		+ f"rank = {dist.get_rank()}, backend={dist.get_backend()} \n", end=''
	)

	demo_basic(local_world_size, local_rank)

	dist.destroy_process_group()


if __name__ == "__main__":
	parser = argparse.ArgumentParser()
	parser.add_argument("--local_rank", type=int, default=0)
	parser.add_argument("--local_world_size", type=int, default=1)
	args = parser.parse_args()
	spmd_main(args.local_world_size, args.local_rank)

import numpy as np
import torch

np.random.seed(2)

T = 20
L = 1000
N = 100

x = np.empty((N, L), 'int64')
x[:] = np.array(range(L)) + np.random.randint(-4 * T, 4 * T, N).reshape(N, 1)
data = np.sin(x / 1.0 / T).astype('float64')
torch.save(data, open('traindata.pt', 'wb'))

import os
import torch
import torch.optim as optim
import torch.nn.functional as F


def train(rank, args, model, device, dataset, dataloader_kwargs):
	torch.manual_seed(args.seed + rank)

	train_loader = torch.utils.data.DataLoader(dataset, **dataloader_kwargs)

	optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)
	for epoch in range(1, args.epochs + 1):
		train_epoch(epoch, args, model, device, train_loader, optimizer)


def test(args, model, device, dataset, dataloader_kwargs):
	torch.manual_seed(args.seed)

	test_loader = torch.utils.data.DataLoader(dataset, **dataloader_kwargs)

	test_epoch(model, device, test_loader)


def train_epoch(epoch, args, model, device, data_loader, optimizer):
	model.train()
	pid = os.getpid()
	for batch_idx, (data, target) in enumerate(data_loader):
		optimizer.zero_grad()
		output = model(data.to(device))
		loss = F.nll_loss(output, target.to(device))
		loss.backward()
		optimizer.step()
		if batch_idx % args.log_interval == 0:
			print('{}\tTrain Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
				pid, epoch, batch_idx * len(data), len(data_loader.dataset),
				100. * batch_idx / len(data_loader), loss.item()))
			if args.dry_run:
				break


def test_epoch(model, device, data_loader):
	model.eval()
	test_loss = 0
	correct = 0
	with torch.no_grad():
		for data, target in data_loader:
			output = model(data.to(device))
			test_loss += F.nll_loss(output, target.to(device), reduction='sum').item() # sum up batch loss
			pred = output.max(1)[1] # get the index of the max log-probability
			correct += pred.eq(target.to(device)).sum().item()

	test_loss /= len(data_loader.dataset)
	print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
		test_loss, correct, len(data_loader.dataset),
		100. * correct / len(data_loader.dataset)))

import torch
from torch.fx import Proxy, Graph, GraphModule




graph = Graph()
tracer = torch.fx.proxy.GraphAppendingTracer(graph)

raw1 = graph.placeholder('x')
raw2 = graph.placeholder('y')

y = Proxy(raw1, tracer)
z = Proxy(raw2, tracer)

a = torch.cat([y, z])
b = torch.tanh(a)
c = torch.neg(b)
z = torch.add(b, c)

graph.output(c.node)

mod = GraphModule(torch.nn.Module(), graph)

import torch
from torch.fx import symbolic_trace, replace_pattern



class M(torch.nn.Module):
	def __init__(self):
		super().__init__()

	def forward(self, x, w1, w2):
		val1 = torch.neg(w1)
		m1 = torch.cat([val1, w2]).sum()
		val2 = torch.neg(w1)
		m2 = torch.cat([val2, w2]).sum()
		return x + torch.max(m1) + torch.max(m2)

traced = symbolic_trace(M())

def pattern(a1, a2):
	val1 = torch.neg(a1)
	return torch.cat([val1, a2]).sum()

def replacement(w1, w2):
	return torch.stack([w1, w2])

replace_pattern(traced, pattern, replacement)


import torch.utils.data as data

from os import listdir
from os.path import join
from PIL import Image


def is_image_file(filename):
	return any(filename.endswith(extension) for extension in [".png", ".jpg", ".jpeg"])


def load_img(filepath):
	img = Image.open(filepath).convert('YCbCr')
	y, _, _ = img.split()
	return y


class DatasetFromFolder(data.Dataset):
	def __init__(self, image_dir, input_transform=None, target_transform=None):
		super(DatasetFromFolder, self).__init__()
		self.image_filenames = [join(image_dir, x) for x in listdir(image_dir) if is_image_file(x)]

		self.input_transform = input_transform
		self.target_transform = target_transform

	def __getitem__(self, index):
		input = load_img(self.image_filenames[index])
		target = input.copy()
		if self.input_transform:
			input = self.input_transform(input)
		if self.target_transform:
			target = self.target_transform(target)

		return input, target

	def __len__(self):
		return len(self.image_filenames)

import os
from argparse import ArgumentParser

def makedirs(name):

	import os, errno

	try:
		os.makedirs(name)
	except OSError as ex:
		if ex.errno == errno.EEXIST and os.path.isdir(name):
			pass
		else:
			raise


def get_args():
	parser = ArgumentParser(description='PyTorch/torchtext SNLI example')
	parser.add_argument('--epochs', type=int, default=50,
						help='the number of total epochs to run.')
	parser.add_argument('--batch_size', type=int, default=128,
						help='batch size. (default: 128)')
	parser.add_argument('--d_embed', type=int, default=100,
						help='the size of each embedding vector.')
	parser.add_argument('--d_proj', type=int, default=300,
						help='the size of each projection layer.')
	parser.add_argument('--d_hidden', type=int, default=300,
						help='the number of features in the hidden state.')
	parser.add_argument('--n_layers', type=int, default=1,
						help='the number of recurrent layers. (default: 50)')
	parser.add_argument('--log_every', type=int, default=50,
						help='iteration period to output log.')
	parser.add_argument('--lr',type=float, default=.001,
						help='initial learning rate.')
	parser.add_argument('--dev_every', type=int, default=1000,
						help='log period of validation results.')
	parser.add_argument('--save_every', type=int, default=1000,
						help='model checkpoint period.')
	parser.add_argument('--dp_ratio', type=int, default=0.2,
						help='probability of an element to be zeroed.')
	parser.add_argument('--no-bidirectional', action='store_false', dest='birnn',
						help='disable bidirectional LSTM.')
	parser.add_argument('--preserve-case', action='store_false', dest='lower',
						help='case-sensitivity.')
	parser.add_argument('--no-projection', action='store_false', dest='projection',
						help='disable projection layer.')
	parser.add_argument('--train_embed', action='store_false', dest='fix_emb',
						help='enable embedding word training.')
	parser.add_argument('--gpu', type=int, default=0,
						help='gpu id to use. (default: 0)')
	parser.add_argument('--save_path', type=str, default='results',
						help='save path of results.')
	parser.add_argument('--vector_cache', type=str, default=os.path.join(os.getcwd(), '.vector_cache/input_vectors.pt'),
						help='name of vector cache directory, which saved input word-vectors.')
	parser.add_argument('--word_vectors', type=str, default='glove.6B.100d',
						help='one of or a list containing instantiations of the GloVe, CharNGram, or Vectors classes.'
						'Alternatively, one of or a list of available pretrained vectors: '
						'charngram.100d fasttext.en.300d fasttext.simple.300d'
						'glove.42B.300d glove.840B.300d glove.twitter.27B.25d'
						'glove.twitter.27B.50d glove.twitter.27B.100d glove.twitter.27B.200d'
						'glove.6B.50d glove.6B.100d glove.6B.200d glove.6B.300d')
	parser.add_argument('--resume_snapshot', type=str, default='',
						help='model snapshot to resume.')
	parser.add_argument('--dry-run', action='store_true',
						help='run only a few iterations')
	args = parser.parse_args()
	return args

from collections import namedtuple

import torch
from torchvision import models


class Vgg16(torch.nn.Module):
	def __init__(self, requires_grad=False):
		super(Vgg16, self).__init__()
		vgg_pretrained_features = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1).features
		self.slice1 = torch.nn.Sequential()
		self.slice2 = torch.nn.Sequential()
		self.slice3 = torch.nn.Sequential()
		self.slice4 = torch.nn.Sequential()
		for x in range(4):
			self.slice1.add_module(str(x), vgg_pretrained_features[x])
		for x in range(4, 9):
			self.slice2.add_module(str(x), vgg_pretrained_features[x])
		for x in range(9, 16):
			self.slice3.add_module(str(x), vgg_pretrained_features[x])
		for x in range(16, 23):
			self.slice4.add_module(str(x), vgg_pretrained_features[x])
		if not requires_grad:
			for param in self.parameters():
				param.requires_grad = False

	def forward(self, X):
		h = self.slice1(X)
		h_relu1_2 = h
		h = self.slice2(h)
		h_relu2_2 = h
		h = self.slice3(h)
		h_relu3_3 = h
		h = self.slice4(h)
		h_relu4_3 = h
		vgg_outputs = namedtuple("VggOutputs", ['relu1_2', 'relu2_2', 'relu3_3', 'relu4_3'])
		out = vgg_outputs(h_relu1_2, h_relu2_2, h_relu3_3, h_relu4_3)
		return out

from __future__ import division
from __future__ import print_function

import argparse
import gzip
import os
import sys
import urllib

try:
	from urllib.error import URLError
	from urllib.request import urlretrieve
except ImportError:
	from urllib2 import URLError
	from urllib import urlretrieve

RESOURCES = [
	'train-images-idx3-ubyte.gz',
	'train-labels-idx1-ubyte.gz',
	't10k-images-idx3-ubyte.gz',
	't10k-labels-idx1-ubyte.gz',
]


def report_download_progress(chunk_number, chunk_size, file_size):
	if file_size != -1:
		percent = min(1, (chunk_number * chunk_size) / file_size)
		bar = '#' * int(64 * percent)
		sys.stdout.write('\r0% |{:<64}| {}%'.format(bar, int(percent * 100)))


def download(destination_path, url, quiet):
	if os.path.exists(destination_path):
		if not quiet:
			print('{} already exists, skipping ...'.format(destination_path))
	else:
		print('Downloading {} ...'.format(url))
		try:
			hook = None if quiet else report_download_progress
			urlretrieve(url, destination_path, reporthook=hook)
		except URLError:
			raise RuntimeError('Error downloading resource!')
		finally:
			if not quiet:
				print()


def unzip(zipped_path, quiet):
	unzipped_path = os.path.splitext(zipped_path)[0]
	if os.path.exists(unzipped_path):
		if not quiet:
			print('{} already exists, skipping ... '.format(unzipped_path))
		return
	with gzip.open(zipped_path, 'rb') as zipped_file:
		with open(unzipped_path, 'wb') as unzipped_file:
			unzipped_file.write(zipped_file.read())
			if not quiet:
				print('Unzipped {} ...'.format(zipped_path))


def main():
	parser = argparse.ArgumentParser(
		description='Download the MNIST dataset from the internet')
	parser.add_argument(
		'-d', '--destination', default='.', help='Destination directory')
	parser.add_argument(
		'-q',
		'--quiet',
		action='store_true',
		help="Don't report about progress")
	options = parser.parse_args()

	if not os.path.exists(options.destination):
		os.makedirs(options.destination)

	try:
		for resource in RESOURCES:
			path = os.path.join(options.destination, resource)
			url = 'http://yann.lecun.com/exdb/mnist/{}'.format(resource)
			download(path, url, options.quiet)
			unzip(path, options.quiet)
	except KeyboardInterrupt:
		print('Interrupted')


if __name__ == '__main__':
	main()

import torch
from torchvision import models

model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)

for param in model.parameters():
	param.requires_grad = False

resnet18 = torch.nn.Sequential(*list(model.children())[:-1])

example_input = torch.rand(1, 3, 224, 224)
script_module = torch.jit.trace(resnet18, example_input)
script_module.save('resnet18_without_last_layer.pt')

import torch
from torch.fx import Proxy, symbolic_trace
from torch.fx.node import map_arg




class M(torch.nn.Module):
	def __init__(self):
		super().__init__()
		self.relu = torch.nn.ReLU()

	def forward(self, x):
		return self.relu(x) + 1.0

m = symbolic_trace(M())

tracer = torch.fx.proxy.GraphAppendingTracer(m.graph)
for node in m.graph.nodes:
	if (node.op, node.target) == ("call_module", "relu"):
		with m.graph.inserting_before(node):
			proxy_args = map_arg(node.args, lambda n: Proxy(n, tracer))
			proxy_kwargs = map_arg(node.kwargs, lambda n: Proxy(n, tracer))
			proxy_output = m.relu(*proxy_args, **proxy_kwargs)
			node.replace_all_uses_with(proxy_output.node)
			m.graph.erase_node(node)

import os
from io import open
import torch

class Dictionary(object):
	def __init__(self):
		self.word2idx = {}
		self.idx2word = []

	def add_word(self, word):
		if word not in self.word2idx:
			self.idx2word.append(word)
			self.word2idx[word] = len(self.idx2word) - 1
		return self.word2idx[word]

	def __len__(self):
		return len(self.idx2word)


class Corpus(object):
	def __init__(self, path):
		self.dictionary = Dictionary()
		self.train = self.tokenize(os.path.join(path, 'train.txt'))
		self.valid = self.tokenize(os.path.join(path, 'valid.txt'))
		self.test = self.tokenize(os.path.join(path, 'test.txt'))

	def tokenize(self, path):
		assert os.path.exists(path)
		with open(path, 'r', encoding="utf8") as f:
			for line in f:
				words = line.split() + ['<eos>']
				for word in words:
					self.dictionary.add_word(word)

		with open(path, 'r', encoding="utf8") as f:
			idss = []
			for line in f:
				words = line.split() + ['<eos>']
				ids = []
				for word in words:
					ids.append(self.dictionary.word2idx[word])
				idss.append(torch.tensor(ids).type(torch.int64))
			ids = torch.cat(idss)

		return ids

import torch
import torch.fx


def sigmoid_lowp(x : torch.Tensor):
	x = x.float()
	x = x.sigmoid()
	return x.half()

torch.fx.wrap(sigmoid_lowp)

def add_lowp(a : torch.Tensor, b : torch.Tensor):
	a, b = a.float(), b.float()
	c = a + b
	return c.half()

torch.fx.wrap(add_lowp)



class Foo(torch.nn.Module):
	def forward(self, x, y):
		x = sigmoid_lowp(x)
		y = sigmoid_lowp(y)
		return add_lowp(x, y)


traced = torch.fx.symbolic_trace(Foo())
print(traced.code)




def inline_lowp_func(n : torch.fx.Node):
	if n.op == 'call_function' and n.target.__module__ == inline_lowp_func.__module__:
		tracer = torch.fx.proxy.GraphAppendingTracer(n.graph)
		with n.graph.inserting_before(n):
			proxy_args = torch.fx.node.map_arg(n.args, lambda x: torch.fx.Proxy(x, tracer))
			proxy_kwargs = torch.fx.node.map_arg(n.kwargs, lambda x: torch.fx.Proxy(x, tracer))
			output_proxy = n.target(*proxy_args, **proxy_kwargs)
			node.replace_all_uses_with(output_proxy.node)
			node.graph.erase_node(node)

for node in traced.graph.nodes:
	if node.op == 'call_function' and node.target is sigmoid_lowp:
		inline_lowp_func(node)

traced.recompile()

print(traced.code)



f = Foo()

class InliningTracer(torch.fx.Tracer):
	FNS_TO_INLINE = [add_lowp]

	def create_node(self, kind, target, args, kwargs, name=None, type_expr=None):
		if kind == 'call_function' and target in self.FNS_TO_INLINE:
			tracer = torch.fx.proxy.GraphAppendingTracer(self.graph)
			proxy_args = torch.fx.node.map_arg(args, lambda x: torch.fx.Proxy(x, tracer))
			proxy_kwargs = torch.fx.node.map_arg(kwargs, lambda x: torch.fx.Proxy(x, tracer))
			return target(*proxy_args, **proxy_kwargs).node
		else:
			return super().create_node(kind, target, args, kwargs, name, type_expr)


tracer = InliningTracer()
graph = tracer.trace(f)
module = torch.fx.GraphModule(f, graph)
print(module.code)



import os
import argparse
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from transformers import AutoTokenizer, GPT2TokenizerFast
from transformers import T5Tokenizer, T5ForConditionalGeneration
import functools
from torch.optim.lr_scheduler import StepLR
import torch.nn.functional as F
import torch.distributed as dist
import torch.multiprocessing as mp
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data.distributed import DistributedSampler
from transformers.models.t5.modeling_t5 import T5Block

from torch.distributed.fsdp import (
	FullyShardedDataParallel as FSDP,
	CPUOffload,
	MixedPrecision,
	BackwardPrefetch,
	ShardingStrategy,
	FullStateDictConfig,
	StateDictType,
)

from functools import partial
from torch.utils.data import DataLoader
from pathlib import Path
from summarization_dataset import *
import policies
import model_checkpointing
from configs import fsdp_config, train_config
from utils import (bfloat_support, setup,
				   cleanup, get_date_of_run,
				   format_metrics_to_gb,
				   train,validation,setup_model)
from transformers.models.t5.modeling_t5 import T5Block
from typing import Type
import time
import tqdm
from datetime import datetime


def get_policies(cfg, rank):


	mixed_precision_policy = None
	wrapping_policy = None

	if cfg.mixed_precision:
		bfloat_available = bfloat_support()
		if bfloat_available and not cfg.use_fp16:
			mixed_precision_policy = policies.bfSixteen
			if rank == 0:
				print(f"bFloat16 enabled for mixed precision - using bfSixteen policy")
		elif cfg.use_fp16:
			mixed_precision_policy = policies.fpSixteen
			if rank == 0:
				print(f"FP16 enabled. ")
		else:
			print(
				f"bFloat16 support not present. Will use FP32, and not mixed precision"
			)

	wrapping_policy = policies.get_t5_wrapper()

	return mixed_precision_policy, wrapping_policy


def fsdp_main(args):

	model, tokenizer = setup_model(train_config.model_name)

	local_rank = int(os.environ['LOCAL_RANK'])
	rank = int(os.environ['RANK'])
	world_size = int(os.environ['WORLD_SIZE'])


	dataset = load_dataset('wikihow', 'all', data_dir='data/')
	print(dataset.keys())
	print("Size of train dataset: ", dataset['train'].shape)
	print("Size of Validation dataset: ", dataset['validation'].shape)

   
	train_dataset = wikihow(tokenizer, 'train', 1500, 512, 150, False) 
	val_dataset = wikihow(tokenizer, 'validation', 300, 512, 150, False)
 
	sampler1 = DistributedSampler(train_dataset, rank=rank, num_replicas=world_size, shuffle=True)
	sampler2 = DistributedSampler(val_dataset, rank=rank, num_replicas=world_size)

	setup()


	train_kwargs = {'batch_size': args.batch_size, 'sampler': sampler1}
	test_kwargs = {'batch_size': args.test_batch_size, 'sampler': sampler2}
	cuda_kwargs = {'num_workers': 2,
					'pin_memory': True,
					'shuffle': False}
	train_kwargs.update(cuda_kwargs)
	test_kwargs.update(cuda_kwargs)

	train_loader = torch.utils.data.DataLoader(train_dataset,**train_kwargs)
	val_loader = torch.utils.data.DataLoader(val_dataset, **test_kwargs)
 
	torch.cuda.set_device(local_rank)
	
	mixed_precision_policy, t5_auto_wrap_policy = get_policies(train_config, rank)
	
	model = FSDP(model,
		auto_wrap_policy=t5_auto_wrap_policy,
		mixed_precision=mixed_precision_policy,
		sharding_strategy=fsdp_config.sharding_strategy,
		device_id=torch.cuda.current_device(),
		limit_all_gathers=fsdp_config.limit_all_gathers)
	
	if fsdp_config.fsdp_activation_checkpointing:
		policies.apply_fsdp_checkpointing(model)

	optimizer = optim.AdamW(model.parameters(), lr=train_config.lr)

	scheduler = StepLR(optimizer, step_size=1, gamma=train_config.gamma)
	best_val_loss = float("inf")
	curr_val_loss = float("inf")
	file_save_name = "T5-model-"

	if rank == 0:
		time_of_run = get_date_of_run()
		dur = []
		train_acc_tracking = []
		val_acc_tracking = []
		training_start_time = time.time()

	if rank == 0 and args.track_memory:
		mem_alloc_tracker = []
		mem_reserved_tracker = []

	for epoch in range(1, args.epochs + 1):
		t0 = time.time()
		train_accuracy = train(args, model, rank, world_size, train_loader, optimizer, epoch, sampler=sampler1)
		if args.run_validation:
			curr_val_loss = validation(model, rank, world_size, val_loader)
		scheduler.step()
		
		if rank == 0:

			print(f"--> epoch {epoch} completed...entering save and stats zone")

			dur.append(time.time() - t0)
			train_acc_tracking.append(train_accuracy.item())

			if args.run_validation:
				val_acc_tracking.append(curr_val_loss.item())

			if args.track_memory:
				mem_alloc_tracker.append(
					format_metrics_to_gb(torch.cuda.memory_allocated())
				)
				mem_reserved_tracker.append(
					format_metrics_to_gb(torch.cuda.memory_reserved())
				)

		if train_config.save_model and curr_val_loss < best_val_loss:
			
			if fsdp_config.checkpoint_type == StateDictType.FULL_STATE_DICT:
				model_checkpointing.save_model_checkpoint(
					model, optimizer, rank, fsdp_config, epoch=1
				)
			elif fsdp_config.checkpoint_type == StateDictType.SHARDED_STATE_DICT:
				model_checkpointing.save_model_and_optimizer_sharded(model, rank, fsdp_config)
				if fsdp_config.save_optimizer:
					model_checkpointing.save_model_and_optimizer_sharded(model, rank, fsdp_config, optim=optimizer)

			if fsdp_config.save_optimizer:
				model_checkpointing.save_optimizer_checkpoint(
					model, optimizer, rank, fsdp_config, epoch=1
				)		   
		if curr_val_loss < best_val_loss:

			best_val_loss = curr_val_loss
			if rank==0:
				print(f"-->>>> New Val Loss Record: {best_val_loss}")

	dist.barrier()
	cleanup()


if __name__ == '__main__':
	parser = argparse.ArgumentParser(description='PyTorch T5 FSDP Example')
	parser.add_argument('--batch-size', type=int, default=4, metavar='N',
						help='input batch size for training (default: 64)')
	parser.add_argument('--test-batch-size', type=int, default=4, metavar='N',
						help='input batch size for testing (default: 1000)')
	parser.add_argument('--epochs', type=int, default=2, metavar='N',
						help='number of epochs to train (default: 3)')
	parser.add_argument('--seed', type=int, default=1, metavar='S',
						help='random seed (default: 1)')
	parser.add_argument('--track_memory', action='store_false', default=True,
						help='track the gpu memory')
	parser.add_argument('--run_validation', action='store_false', default=True,
						help='running the validation')
	args = parser.parse_args()

	torch.manual_seed(args.seed)
	
	fsdp_main(args)


import os
import zipfile

try:
	from torch.utils.model_zoo import _download_url_to_file
except ImportError:
	try:
		from torch.hub import download_url_to_file as _download_url_to_file
	except ImportError:
		from torch.hub import _download_url_to_file


def unzip(source_filename, dest_dir):
	with zipfile.ZipFile(source_filename) as zf:
		zf.extractall(path=dest_dir)


if __name__ == '__main__':
	_download_url_to_file('https://www.dropbox.com/s/lrvwfehqdcxoza8/saved_models.zip?dl=1', 'saved_models.zip', None, True)
	unzip('saved_models.zip', '.')

import torch
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from datautils import MyTrainDataset


class Trainer:
	def __init__(
		self,
		model: torch.nn.Module,
		train_data: DataLoader,
		optimizer: torch.optim.Optimizer,
		gpu_id: int,
		save_every: int, 
	) -> None:
		self.gpu_id = gpu_id
		self.model = model.to(gpu_id)
		self.train_data = train_data
		self.optimizer = optimizer
		self.save_every = save_every

	def _run_batch(self, source, targets):
		self.optimizer.zero_grad()
		output = self.model(source)
		loss = F.cross_entropy(output, targets)
		loss.backward()
		self.optimizer.step()

	def _run_epoch(self, epoch):
		b_sz = len(next(iter(self.train_data))[0])
		print(f"[GPU{self.gpu_id}] Epoch {epoch} | Batchsize: {b_sz} | Steps: {len(self.train_data)}")
		for source, targets in self.train_data:
			source = source.to(self.gpu_id)
			targets = targets.to(self.gpu_id)
			self._run_batch(source, targets)

	def _save_checkpoint(self, epoch):
		ckp = self.model.state_dict()
		PATH = "checkpoint.pt"
		torch.save(ckp, PATH)
		print(f"Epoch {epoch} | Training checkpoint saved at {PATH}")

	def train(self, max_epochs: int):
		for epoch in range(max_epochs):
			self._run_epoch(epoch)
			if epoch % self.save_every == 0:
				self._save_checkpoint(epoch)


def load_train_objs():
	train_set = MyTrainDataset(2048)  # load your dataset
	model = torch.nn.Linear(20, 1)  # load your model
	optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)
	return train_set, model, optimizer


def prepare_dataloader(dataset: Dataset, batch_size: int):
	return DataLoader(
		dataset,
		batch_size=batch_size,
		pin_memory=True,
		shuffle=True
	)


def main(device, total_epochs, save_every, batch_size):
	dataset, model, optimizer = load_train_objs()
	train_data = prepare_dataloader(dataset, batch_size)
	trainer = Trainer(model, train_data, optimizer, device, save_every)
	trainer.train(total_epochs)


if __name__ == "__main__":
	import argparse
	parser = argparse.ArgumentParser(description='simple distributed training job')
	parser.add_argument('total_epochs', type=int, help='Total epochs to train the model')
	parser.add_argument('save_every', type=int, help='How often to save a snapshot')
	parser.add_argument('--batch_size', default=32, type=int, help='Input batch size on each device (default: 32)')
	args = parser.parse_args()
	
	device = 0  # shorthand for cuda:0
	main(device, args.total_epochs, args.save_every, args.batch_size)

import argparse
import glob
import os
import json
import time
import logging
import random
import re
from itertools import chain
from string import punctuation

import pandas as pd
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader

from datasets import load_dataset, load_metric


from transformers import (
	AdamW,
	T5ForConditionalGeneration,
	T5Tokenizer,
	get_linear_schedule_with_warmup
)

class wikihow(Dataset):
	def __init__(self, tokenizer, type_path, num_samples, input_length, output_length, print_text=False):		 
		self.dataset =  load_dataset('wikihow', 'all', data_dir='data/', split=type_path)
		if num_samples:
			self.dataset = self.dataset.select(list(range(0, num_samples)))
		self.input_length = input_length
		self.tokenizer = tokenizer
		self.output_length = output_length
		self.print_text = print_text
  
	def __len__(self):
		return self.dataset.shape[0]
	
	def clean_text(self, text):
		text = text.replace('Example of text:', '')
		text = text.replace('Example of Summary:', '')
		text = text.replace('\n','')
		text = text.replace('``', '')
		text = text.replace('"', '')
		
		return text
	
	
	def convert_to_features(self, example_batch):
		
		if self.print_text:
			print("Input Text: ", self.clean_text(example_batch['text']))
		
		input_ = self.clean_text(example_batch['text'])
		target_ = self.clean_text(example_batch['headline'])
		
		source = self.tokenizer.batch_encode_plus([input_], max_length=self.input_length, 
													 padding='max_length', truncation=True, return_tensors="pt")
		
		targets = self.tokenizer.batch_encode_plus([target_], max_length=self.output_length, 
													 padding='max_length', truncation=True, return_tensors="pt")
	
	   
		return source, targets
  
	def __getitem__(self, index):
		source, targets = self.convert_to_features(self.dataset[index])
		
		source_ids = source["input_ids"].squeeze()
		target_ids = targets["input_ids"].squeeze()

		src_mask	= source["attention_mask"].squeeze()
		target_mask = targets["attention_mask"].squeeze()

		return {"source_ids": source_ids, "source_mask": src_mask, "target_ids": target_ids, "target_mask": target_mask}
		
def get_dataset(tokenizer, type_path, num_samples, args):
	  return wikihow(tokenizer=tokenizer, type_path=type_path, num_samples=num_samples,  input_length=max_input_length, 
						output_length=max_output_length)

from pathlib import Path
from datetime import datetime
import torch
import time

from torch.distributed.fsdp import (
	FullyShardedDataParallel as FSDP,
	StateDictType,
	FullStateDictConfig,  # general model non-sharded, non-flattened params
	LocalStateDictConfig,  # flattened params, usable only by FSDP
)

from torch.distributed._shard.checkpoint import (
	FileSystemReader,
	FileSystemWriter,
	save_state_dict,
	load_state_dict,
)
from torch.distributed.checkpoint.default_planner import (
	DefaultSavePlanner,
	DefaultLoadPlanner,
)


from torch.distributed.fsdp.fully_sharded_data_parallel import StateDictType
import torch.distributed._shard.checkpoint as dist_cp
import torch.distributed as dist


def get_date_of_run():
	date_of_run = datetime.now().strftime("%Y-%m-%d-%I:%M:%S_%p")
	print(f"--> current date and time of run = {date_of_run}")
	return date_of_run


fullstate_save_policy = FullStateDictConfig(offload_to_cpu=True, rank0_only=True)


def load_model_sharded(model, rank, cfg, verbose=True):
	folder_name = (
		cfg.dist_checkpoint_root_folder
		+ "/"
		+ cfg.dist_checkpoint_folder
		+ "-"
		+ cfg.model_name
	)

	load_dir = Path.cwd() / folder_name

	if not load_dir.exists():
		if rank == 0:
			print(f"No sharded_state_dict checkpoint directory found...skipping")
		return

	reader = FileSystemReader(load_dir)

	with FSDP.state_dict_type(model, StateDictType.SHARDED_STATE_DICT):
		checkpoint = model.state_dict()
		if rank == 0:
			ck = checkpoint.keys()
			print(f" checkpoint key len = {len(ck)} and \n keys =  {ck}")
	  
		dist_cp.load_state_dict(
			state_dict=checkpoint,
			storage_reader=reader,
		)
		if rank == 0:
			print(f"checkpoint after load_state_dict()")
			ck = checkpoint.keys()
			print(f" checkpoint key len = {len(ck)} and \n keys =  {ck}")
		model.load_state_dict(checkpoint)
	if rank == 0:
		print(f"Sharded state checkpoint loaded from {load_dir}")


def save_model_and_optimizer_sharded(model, rank, cfg,optim=None, verbose=True):
	folder_name = (
		cfg.dist_checkpoint_root_folder
		+ "/"
		+ cfg.dist_checkpoint_folder
		+ "-"
		+ cfg.model_name
	)

	save_dir = Path.cwd() / folder_name
	if rank == 0:
		print(f"Saving model to {save_dir}")

	distributed_writer = dist_cp.FileSystemWriter(
		save_dir,
	)
	t0 = time.perf_counter()

	with FSDP.state_dict_type(model, StateDictType.SHARDED_STATE_DICT):

		state_dict = {"model": model.state_dict()}
		if optim is not None:
			state_dict["optim"] = FSDP.optim_state_dict(model, optim)

		dist_cp.save_state_dict(
			state_dict=state_dict,
			storage_writer=distributed_writer,
			planner=DefaultSavePlanner(),
			
		)
	dist.barrier()
	t1 = time.perf_counter()
	if rank == 0:
		print(f"Sharded state checkpoint saved to {save_dir}")
		print(
			f"Checkpoint Time = {t1-t0:.4f}\n using {cfg.save_using_num_threads=} total threads"
		)
		
def save_model_checkpoint(
	model,
	optimizer,
	rank,
	cfg,
	epoch=1,
):

	if not cfg.checkpoint_type == StateDictType.FULL_STATE_DICT:
		print(f" unable to handle checkpoint type {cfg.checkpoint_type}, aborting")

	with FSDP.state_dict_type(
		model, StateDictType.FULL_STATE_DICT, fullstate_save_policy
	):
		cpu_state = model.state_dict()

	if cfg.verbose:
		print(f"saving process: rank {rank}  done w model state_dict\n")
   

	if rank == 0:
		print(f"--> saving model ...")
		save_dir = Path.cwd() / cfg.checkpoint_folder
		save_dir.mkdir(parents=True, exist_ok=True)
		save_name = cfg.model_save_name + "-" + str(epoch) + ".pt"
		save_full_path = str(save_dir) + "/" + save_name

		torch.save(cpu_state, save_full_path)

		if cfg.verbose:
			print(f"model checkpoint saved for epoch {epoch} at {save_full_path}\n")
	  


def load_model_checkpoint(model, rank, cfg, verbose=True):

	if rank != 0:
		return

	full_state_dict_model_path = (
		Path.cwd() / cfg.checkpoint_folder / cfg.checkpoint_model_filename
	)
	if not full_state_dict_model_path.is_file():
		print(
			f"model checkpoint {full_state_dict_model_path} not present. Returning..."
		)
		return


	model_checkpoint = torch.load(full_state_dict_model_path)
	model.load_state_dict(model_checkpoint)

	if cfg.verbose:
		print(f"model checkpoint loaded to rank0 cpu")


def save_optimizer_checkpoint(model, optimizer, rank, cfg, epoch=1):

	if cfg.verbose:
		print(f"--> optim state call on rank {rank}\n")


	optim_state = FSDP.full_optim_state_dict(model, optimizer)

	if cfg.verbose:
		print(f"optim state dict ready on {rank} and len of {len(optim_state)}\n")

	if rank == 0:
		save_dir = Path.cwd() / cfg.checkpoint_folder
		save_dir.mkdir(parents=True, exist_ok=True)

		opt_save_name = (
			cfg.optimizer_name + "-" + cfg.model_save_name + "-" + str(epoch) + ".pt"
		)
		opt_save_full_path = save_dir / opt_save_name

		print(f"--> saving optimizer state...")

		torch.save(optim_state, opt_save_full_path)

		print(f"--> saved {opt_save_full_path} to disk")


def load_optimizer_checkpoint(model, optimizer, rank, cfg):

	opt_file_path = Path.cwd() / cfg.checkpoint_folder / cfg.optimizer_checkpoint_file

	if not opt_file_path.is_file():
		print(
			f"warning - optimizer checkpoint not present {opt_file_path}. Returning. "
		)
		return

	full_osd = None

	if rank == 0:
		full_osd = torch.load(opt_file_path)

		if cfg.verbose:
			print(f"loaded full osd on rank 0")

	sharded_osd = FSDP.scatter_full_optim_state_dict(full_osd, model)

	if cfg.verbose:
		print(f"optimizer shard loaded on rank {rank}")



def load_distributed_model_checkpoint(model, rank, cfg):
	if cfg.checkpoint_type == StateDictType.LOCAL_STATE_DICT:
		print(f"loading distributed checkpoint, rank {rank}...")
		folder_name = (
			cfg.dist_checkpoint_root_folder
			+ "/"
			+ cfg.dist_checkpoint_folder
			+ "-"
			+ cfg.model_name
		)

		checkdir = Path.cwd() / folder_name

		if not checkdir.exists():
			if rank == 0:
				print(f"No checkpoint directory found...skipping")
			return


		reader = FileSystemReader(checkdir)

		with FSDP.state_dict_type(
			model,
			StateDictType.LOCAL_STATE_DICT,
		):
			state_dict = model.state_dict()
			load_state_dict(state_dict, reader)
			model.load_state_dict(state_dict)

		print(f"--> local state loaded on rank {rank}")

		return


def save_distributed_model_checkpoint(model, rank, cfg, epoch=1):

	if cfg.checkpoint_type == StateDictType.LOCAL_STATE_DICT:
		folder_name = (
			cfg.dist_checkpoint_root_folder
			+ "/"
			+ cfg.dist_checkpoint_folder
			+ "-"
			+ cfg.model_name
		)
		save_dir = Path.cwd() / folder_name

		writer = FileSystemWriter(
			save_dir,
		)

		with FSDP.state_dict_type(
			model,
			StateDictType.LOCAL_STATE_DICT,
		):
			state_dict = model.state_dict()
	   

		save_state_dict(state_dict, writer)

		return

import torch
import torch.nn as nn
import torch.distributed.rpc as rpc
from torch.distributed.rpc import RRef


def _call_method(method, rref, *args, **kwargs):
	return method(rref.local_value(), *args, **kwargs)


def _remote_method(method, rref, *args, **kwargs):
	return rpc.rpc_sync(
		rref.owner(),
		_call_method,
		args=[method, rref] + list(args),
		kwargs=kwargs
	)


def _parameter_rrefs(module):
	param_rrefs = []
	for param in module.parameters():
		param_rrefs.append(RRef(param))
	return param_rrefs


class EmbeddingTable(nn.Module):
	def __init__(self, ntoken, ninp, dropout):
		super(EmbeddingTable, self).__init__()
		self.drop = nn.Dropout(dropout)
		self.encoder = nn.Embedding(ntoken, ninp)
		if torch.cuda.is_available():
			self.encoder = self.encoder.cuda()
		nn.init.uniform_(self.encoder.weight, -0.1, 0.1)

	def forward(self, input):
		if torch.cuda.is_available():
			input = input.cuda()
		return self.drop(self.encoder(input)).cpu()


class Decoder(nn.Module):
	def __init__(self, ntoken, nhid, dropout):
		super(Decoder, self).__init__()
		self.drop = nn.Dropout(dropout)
		self.decoder = nn.Linear(nhid, ntoken)
		nn.init.zeros_(self.decoder.bias)
		nn.init.uniform_(self.decoder.weight, -0.1, 0.1)

	def forward(self, output):
		return self.decoder(self.drop(output))


class RNNModel(nn.Module):
	def __init__(self, ps, ntoken, ninp, nhid, nlayers, dropout=0.5):
		super(RNNModel, self).__init__()

		self.emb_table_rref = rpc.remote(ps, EmbeddingTable, args=(ntoken, ninp, dropout))
		self.rnn = nn.LSTM(ninp, nhid, nlayers, dropout=dropout)
		self.decoder_rref = rpc.remote(ps, Decoder, args=(ntoken, nhid, dropout))

	def forward(self, input, hidden):
		emb = _remote_method(EmbeddingTable.forward, self.emb_table_rref, input)
		output, hidden = self.rnn(emb, hidden)
		decoded = _remote_method(Decoder.forward, self.decoder_rref, output)
		return decoded, hidden

	def parameter_rrefs(self):
		remote_params = []
		remote_params.extend(_remote_method(_parameter_rrefs, self.emb_table_rref))
		remote_params.extend(_parameter_rrefs(self.rnn))
		remote_params.extend(_remote_method(_parameter_rrefs, self.decoder_rref))
		return remote_params

import argparse
import gym
import numpy as np
from itertools import count
from collections import deque
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.distributions import Categorical


parser = argparse.ArgumentParser(description='PyTorch REINFORCE example')
parser.add_argument('--gamma', type=float, default=0.99, metavar='G',
					help='discount factor (default: 0.99)')
parser.add_argument('--seed', type=int, default=543, metavar='N',
					help='random seed (default: 543)')
parser.add_argument('--render', action='store_true',
					help='render the environment')
parser.add_argument('--log-interval', type=int, default=10, metavar='N',
					help='interval between training status logs (default: 10)')
args = parser.parse_args()


env = gym.make('CartPole-v1')
env.reset(seed=args.seed)
torch.manual_seed(args.seed)


class Policy(nn.Module):
	def __init__(self):
		super(Policy, self).__init__()
		self.affine1 = nn.Linear(4, 128)
		self.dropout = nn.Dropout(p=0.6)
		self.affine2 = nn.Linear(128, 2)

		self.saved_log_probs = []
		self.rewards = []

	def forward(self, x):
		x = self.affine1(x)
		x = self.dropout(x)
		x = F.relu(x)
		action_scores = self.affine2(x)
		return F.softmax(action_scores, dim=1)


policy = Policy()
optimizer = optim.Adam(policy.parameters(), lr=1e-2)
eps = np.finfo(np.float32).eps.item()


def select_action(state):
	state = torch.from_numpy(state).float().unsqueeze(0)
	probs = policy(state)
	m = Categorical(probs)
	action = m.sample()
	policy.saved_log_probs.append(m.log_prob(action))
	return action.item()


def finish_episode():
	R = 0
	policy_loss = []
	returns = deque()
	for r in policy.rewards[::-1]:
		R = r + args.gamma * R
		returns.appendleft(R)
	returns = torch.tensor(returns)
	returns = (returns - returns.mean()) / (returns.std() + eps)
	for log_prob, R in zip(policy.saved_log_probs, returns):
		policy_loss.append(-log_prob * R)
	optimizer.zero_grad()
	policy_loss = torch.cat(policy_loss).sum()
	policy_loss.backward()
	optimizer.step()
	del policy.rewards[:]
	del policy.saved_log_probs[:]


def main():
	running_reward = 10
	for i_episode in count(1):
		state, _ = env.reset()
		ep_reward = 0
		for t in range(1, 10000):  # Don't infinite loop while learning
			action = select_action(state)
			state, reward, done, _, _ = env.step(action)
			if args.render:
				env.render()
			policy.rewards.append(reward)
			ep_reward += reward
			if done:
				break

		running_reward = 0.05 * ep_reward + (1 - 0.05) * running_reward
		finish_episode()
		if i_episode % args.log_interval == 0:
			print('Episode {}\tLast reward: {:.2f}\tAverage reward: {:.2f}'.format(
				  i_episode, ep_reward, running_reward))
		if running_reward > env.spec.reward_threshold:
			print("Solved! Running reward is now {} and "
				  "the last episode runs to {} time steps!".format(running_reward, t))
			break


if __name__ == '__main__':
	main()


from dataclasses import dataclass, asdict
from collections import OrderedDict
from typing import Optional, Any, Dict
import os

import torch
from torch.utils.data import Dataset, DataLoader
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data.distributed import DistributedSampler

import boto3
from urllib.parse import urlparse
import fsspec
import io

@dataclass
class TrainerConfig:
	max_epochs: int = None
	batch_size: int = None
	data_loader_workers: int = None
	grad_norm_clip: float = None
	snapshot_path: Optional[str] = None
	save_every: int = None
	use_amp: bool = None

@dataclass
class Snapshot:
	model_state: 'OrderedDict[str, torch.Tensor]'
	optimizer_state: Dict[str, Any]
	finished_epoch: int

def upload_to_s3(obj, dst):
	buffer = io.BytesIO()
	torch.save(obj, buffer)
	buffer.seek(0)
	dst = urlparse(dst, allow_fragments=False)
	boto3.client('s3').upload_fileobj(buffer, dst.netloc, dst.path.lstrip('/'))

class Trainer:

	def __init__(self, trainer_config: TrainerConfig, model, optimizer, train_dataset, test_dataset=None):
		self.config = trainer_config
		self.local_rank = int(os.environ["LOCAL_RANK"])
		self.global_rank = int(os.environ["RANK"])  
		self.train_dataset = train_dataset
		self.train_loader = self._prepare_dataloader(train_dataset)
		self.test_loader = self._prepare_dataloader(test_dataset) if test_dataset else None
		self.epochs_run = 0
		self.model = model.to(self.local_rank)
		self.optimizer = optimizer		
		self.save_every = self.config.save_every
		if self.config.use_amp:
			self.scaler = torch.cuda.amp.GradScaler()
		if self.config.snapshot_path is None:
			self.config.snapshot_path = "snapshot.pt"
		self._load_snapshot()
		self.model = DDP(self.model, device_ids=[self.local_rank])
		
	def _prepare_dataloader(self, dataset: Dataset):
		return DataLoader(
			dataset,
			batch_size=self.config.batch_size,
			pin_memory=True,
			shuffle=False,
			num_workers=self.config.data_loader_workers,
			sampler=DistributedSampler(dataset)
		)

	def _load_snapshot(self):
		try:
			snapshot = fsspec.open(self.config.snapshot_path)
			with snapshot as f:
				snapshot_data = torch.load(f, map_location="cpu")
		except FileNotFoundError:
			print("Snapshot not found. Training model from scratch")
			return 

		snapshot = Snapshot(**snapshot_data)
		self.model.load_state_dict(snapshot.model_state)
		self.optimizer.load_state_dict(snapshot.optimizer_state)
		self.epochs_run = snapshot.finished_epoch
		print(f"Resuming training from snapshot at Epoch {self.epochs_run}")


	def _run_batch(self, source, targets, train: bool = True) -> float:
		with torch.set_grad_enabled(train), torch.amp.autocast(device_type="cuda", dtype=torch.float16, enabled=(self.config.use_amp)):
			_, loss = self.model(source, targets)
		
		if train:
			self.optimizer.zero_grad(set_to_none=True)
			if self.config.use_amp: 
				self.scaler.scale(loss).backward()
				torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.grad_norm_clip)
				self.scaler.step(self.optimizer)
				self.scaler.update()
			else:
				loss.backward()
				torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.grad_norm_clip)
				self.optimizer.step()
		
		return loss.item()

	def _run_epoch(self, epoch: int, dataloader: DataLoader, train: bool = True):
		dataloader.sampler.set_epoch(epoch)
		for iter, (source, targets) in enumerate(dataloader):
			step_type = "Train" if train else "Eval"
			source = source.to(self.local_rank)
			targets = targets.to(self.local_rank)
			batch_loss = self._run_batch(source, targets, train)
			if iter % 100 == 0:
				print(f"[GPU{self.global_rank}] Epoch {epoch} | Iter {iter} | {step_type} Loss {batch_loss:.5f}")

	def _save_snapshot(self, epoch):
		model = self.model
		raw_model = model.module if hasattr(model, "module") else model
		snapshot = Snapshot(
			model_state=raw_model.state_dict(),
			optimizer_state=self.optimizer.state_dict(),
			finished_epoch=epoch
		)
		snapshot = asdict(snapshot)
		if self.config.snapshot_path.startswith("s3://"):
			upload_to_s3(snapshot, self.config.snapshot_path)
		else:
			torch.save(snapshot, self.config.snapshot_path)
			
		print(f"Snapshot saved at epoch {epoch}")

	def train(self):
		for epoch in range(self.epochs_run, self.config.max_epochs):
			epoch += 1
			self._run_epoch(epoch, self.train_loader, train=True)
			if self.local_rank == 0 and epoch % self.save_every == 0:
				self._save_snapshot(epoch)
			if self.test_loader:
				self._run_epoch(epoch, self.test_loader, train=False)

import torch
from PIL import Image


def load_image(filename, size=None, scale=None):
	img = Image.open(filename).convert('RGB')
	if size is not None:
		img = img.resize((size, size), Image.ANTIALIAS)
	elif scale is not None:
		img = img.resize((int(img.size[0] / scale), int(img.size[1] / scale)), Image.ANTIALIAS)
	return img


def save_image(filename, data):
	img = data.clone().clamp(0, 255).numpy()
	img = img.transpose(1, 2, 0).astype("uint8")
	img = Image.fromarray(img)
	img.save(filename)


def gram_matrix(y):
	(b, ch, h, w) = y.size()
	features = y.view(b, ch, w * h)
	features_t = features.transpose(1, 2)
	gram = features.bmm(features_t) / (ch * h * w)
	return gram


def normalize_batch(batch):
	mean = batch.new_tensor([0.485, 0.456, 0.406]).view(-1, 1, 1)
	std = batch.new_tensor([0.229, 0.224, 0.225]).view(-1, 1, 1)
	batch = batch.div_(255.0)
	return (batch - mean) / std

import torch


class TransformerNet(torch.nn.Module):
	def __init__(self):
		super(TransformerNet, self).__init__()
		self.conv1 = ConvLayer(3, 32, kernel_size=9, stride=1)
		self.in1 = torch.nn.InstanceNorm2d(32, affine=True)
		self.conv2 = ConvLayer(32, 64, kernel_size=3, stride=2)
		self.in2 = torch.nn.InstanceNorm2d(64, affine=True)
		self.conv3 = ConvLayer(64, 128, kernel_size=3, stride=2)
		self.in3 = torch.nn.InstanceNorm2d(128, affine=True)
		self.res1 = ResidualBlock(128)
		self.res2 = ResidualBlock(128)
		self.res3 = ResidualBlock(128)
		self.res4 = ResidualBlock(128)
		self.res5 = ResidualBlock(128)
		self.deconv1 = UpsampleConvLayer(128, 64, kernel_size=3, stride=1, upsample=2)
		self.in4 = torch.nn.InstanceNorm2d(64, affine=True)
		self.deconv2 = UpsampleConvLayer(64, 32, kernel_size=3, stride=1, upsample=2)
		self.in5 = torch.nn.InstanceNorm2d(32, affine=True)
		self.deconv3 = ConvLayer(32, 3, kernel_size=9, stride=1)
		self.relu = torch.nn.ReLU()

	def forward(self, X):
		y = self.relu(self.in1(self.conv1(X)))
		y = self.relu(self.in2(self.conv2(y)))
		y = self.relu(self.in3(self.conv3(y)))
		y = self.res1(y)
		y = self.res2(y)
		y = self.res3(y)
		y = self.res4(y)
		y = self.res5(y)
		y = self.relu(self.in4(self.deconv1(y)))
		y = self.relu(self.in5(self.deconv2(y)))
		y = self.deconv3(y)
		return y


class ConvLayer(torch.nn.Module):
	def __init__(self, in_channels, out_channels, kernel_size, stride):
		super(ConvLayer, self).__init__()
		reflection_padding = kernel_size // 2
		self.reflection_pad = torch.nn.ReflectionPad2d(reflection_padding)
		self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride)

	def forward(self, x):
		out = self.reflection_pad(x)
		out = self.conv2d(out)
		return out


class ResidualBlock(torch.nn.Module):

	def __init__(self, channels):
		super(ResidualBlock, self).__init__()
		self.conv1 = ConvLayer(channels, channels, kernel_size=3, stride=1)
		self.in1 = torch.nn.InstanceNorm2d(channels, affine=True)
		self.conv2 = ConvLayer(channels, channels, kernel_size=3, stride=1)
		self.in2 = torch.nn.InstanceNorm2d(channels, affine=True)
		self.relu = torch.nn.ReLU()

	def forward(self, x):
		residual = x
		out = self.relu(self.in1(self.conv1(x)))
		out = self.in2(self.conv2(out))
		out = out + residual
		return out


class UpsampleConvLayer(torch.nn.Module):

	def __init__(self, in_channels, out_channels, kernel_size, stride, upsample=None):
		super(UpsampleConvLayer, self).__init__()
		self.upsample = upsample
		reflection_padding = kernel_size // 2
		self.reflection_pad = torch.nn.ReflectionPad2d(reflection_padding)
		self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride)

	def forward(self, x):
		x_in = x
		if self.upsample:
			x_in = torch.nn.functional.interpolate(x_in, mode='nearest', scale_factor=self.upsample)
		out = self.reflection_pad(x_in)
		out = self.conv2d(out)
		return out

import torch
import os
import torch.distributed as dist
from torch.distributed.algorithms._checkpoint.checkpoint_wrapper import (
	checkpoint_wrapper,
	CheckpointImpl,
	apply_activation_checkpointing,
)

from transformers.models.t5.modeling_t5 import T5Block

from functools import partial

non_reentrant_wrapper = partial(
	checkpoint_wrapper,
	offload_to_cpu=False,
	checkpoint_impl=CheckpointImpl.NO_REENTRANT,
)

check_fn = lambda submodule: isinstance(submodule, T5Block)


def apply_fsdp_checkpointing(model):
	print(f"--> applying fdsp activation checkpointing...")

	apply_activation_checkpointing(
		model, checkpoint_wrapper_fn=non_reentrant_wrapper, check_fn=check_fn
	)

import torch
import torch.fx as fx


invert_mapping = {}
def add_inverse(a, b):
	invert_mapping[a] = b
	invert_mapping[b] = a
inverses = [
	(torch.sin, torch.arcsin),
	(torch.cos, torch.arccos),
	(torch.tan, torch.arctan),
	(torch.exp, torch.log),
]
for a, b in inverses:
	add_inverse(a, b)

def invert(model: torch.nn.Module) -> torch.nn.Module:
	fx_model = fx.symbolic_trace(model)
	new_graph = fx.Graph()  # As we're building up a new graph
	env = {}
	for node in reversed(fx_model.graph.nodes):
		if node.op == 'call_function':
			new_node = new_graph.call_function(invert_mapping[node.target], (env[node.name],))
			env[node.args[0].name] = new_node
		elif node.op == 'output':
			new_node = new_graph.placeholder(node.name)
			env[node.args[0].name] = new_node
		elif node.op == 'placeholder':
			new_graph.output(env[node.name])
		else:
			raise RuntimeError("Not implemented")

	new_graph.lint()
	return fx.GraphModule(fx_model, new_graph)


def f(x):
	return torch.exp(torch.tan(x))

res = invert(f)
print(res.code)
print(f(res((torch.arange(5) + 1))))  # [1., 2., 3., 4, 5.]

import torch
from torch.utils.data import Dataset

class MyTrainDataset(Dataset):
	def __init__(self, size):
		self.size = size
		self.data = [(torch.rand(20), torch.rand(1)) for _ in range(size)]

	def __len__(self):
		return self.size
	
	def __getitem__(self, index):
		return self.data[index]
from __future__ import print_function
import argparse
import torch
from PIL import Image
from torchvision.transforms import ToTensor

import numpy as np

parser = argparse.ArgumentParser(description='PyTorch Super Res Example')
parser.add_argument('--input_image', type=str, required=True, help='input image to use')
parser.add_argument('--model', type=str, required=True, help='model file to use')
parser.add_argument('--output_filename', type=str, help='where to save the output image')
parser.add_argument('--cuda', action='store_true', help='use cuda')
opt = parser.parse_args()

print(opt)
img = Image.open(opt.input_image).convert('YCbCr')
y, cb, cr = img.split()

model = torch.load(opt.model)
img_to_tensor = ToTensor()
input = img_to_tensor(y).view(1, -1, y.size[1], y.size[0])

if opt.cuda:
	model = model.cuda()
	input = input.cuda()

out = model(input)
out = out.cpu()
out_img_y = out[0].detach().numpy()
out_img_y *= 255.0
out_img_y = out_img_y.clip(0, 255)
out_img_y = Image.fromarray(np.uint8(out_img_y[0]), mode='L')

out_img_cb = cb.resize(out_img_y.size, Image.BICUBIC)
out_img_cr = cr.resize(out_img_y.size, Image.BICUBIC)
out_img = Image.merge('YCbCr', [out_img_y, out_img_cb, out_img_cr]).convert('RGB')

out_img.save(opt.output_filename)
print('output image saved to ', opt.output_filename)

import os
import threading
from datetime import datetime

import torch
import torch.distributed.rpc as rpc
import torch.multiprocessing as mp
import torch.nn as nn
from torch import optim

import torchvision


batch_size = 20
image_w = 64
image_h = 64
num_classes = 30
batch_update_size = 5
num_batches = 6


def timed_log(text):
	print(f"{datetime.now().strftime('%H:%M:%S')} {text}")


class BatchUpdateParameterServer(object):

	def __init__(self, batch_update_size=batch_update_size):
		self.model = torchvision.models.resnet50(num_classes=num_classes)
		self.lock = threading.Lock()
		self.future_model = torch.futures.Future()
		self.batch_update_size = batch_update_size
		self.curr_update_size = 0
		self.optimizer = optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9)
		for p in self.model.parameters():
			p.grad = torch.zeros_like(p)

	def get_model(self):
		return self.model

	@staticmethod
	@rpc.functions.async_execution
	def update_and_fetch_model(ps_rref, grads):
		self = ps_rref.local_value()
		timed_log(f"PS got {self.curr_update_size}/{batch_update_size} updates")
		for p, g in zip(self.model.parameters(), grads):
			p.grad += g
		with self.lock:
			self.curr_update_size += 1
			fut = self.future_model

			if self.curr_update_size >= self.batch_update_size:
				for p in self.model.parameters():
					p.grad /= self.batch_update_size
				self.curr_update_size = 0
				self.optimizer.step()
				self.optimizer.zero_grad(set_to_none=False)
				fut.set_result(self.model)
				timed_log("PS updated model")
				self.future_model = torch.futures.Future()

		return fut


class Trainer(object):

	def __init__(self, ps_rref):
		self.ps_rref = ps_rref
		self.loss_fn = nn.MSELoss()
		self.one_hot_indices = torch.LongTensor(batch_size) \
									.random_(0, num_classes) \
									.view(batch_size, 1)

	def get_next_batch(self):
		for _ in range(num_batches):
			inputs = torch.randn(batch_size, 3, image_w, image_h)
			labels = torch.zeros(batch_size, num_classes) \
						.scatter_(1, self.one_hot_indices, 1)
			yield inputs.cuda(), labels.cuda()

	def train(self):
		name = rpc.get_worker_info().name
		m = self.ps_rref.rpc_sync().get_model().cuda()
		for inputs, labels in self.get_next_batch():
			timed_log(f"{name} processing one batch")
			self.loss_fn(m(inputs), labels).backward()
			timed_log(f"{name} reporting grads")
			m = rpc.rpc_sync(
				self.ps_rref.owner(),
				BatchUpdateParameterServer.update_and_fetch_model,
				args=(self.ps_rref, [p.grad for p in m.cpu().parameters()]),
			).cuda()
			timed_log(f"{name} got updated model")


def run_trainer(ps_rref):
	trainer = Trainer(ps_rref)
	trainer.train()


def run_ps(trainers):
	timed_log("Start training")
	ps_rref = rpc.RRef(BatchUpdateParameterServer())
	futs = []
	for trainer in trainers:
		futs.append(
			rpc.rpc_async(trainer, run_trainer, args=(ps_rref,))
		)

	torch.futures.wait_all(futs)
	timed_log("Finish training")


def run(rank, world_size):
	os.environ['MASTER_ADDR'] = 'localhost'
	os.environ['MASTER_PORT'] = '29500'
	options=rpc.TensorPipeRpcBackendOptions(
		num_worker_threads=16,
		rpc_timeout=0  # infinite timeout
	 )
	if rank != 0:
		rpc.init_rpc(
			f"trainer{rank}",
			rank=rank,
			world_size=world_size,
			rpc_backend_options=options
		)
	else:
		rpc.init_rpc(
			"ps",
			rank=rank,
			world_size=world_size,
			rpc_backend_options=options
		)
		run_ps([f"trainer{r}" for r in range(1, world_size)])

	rpc.shutdown()


if __name__=="__main__":
	world_size = batch_update_size + 1
	mp.spawn(run, args=(world_size, ), nprocs=world_size, join=True)

import logging
import torch

logging.basicConfig(
	format="%(asctime)s %(message)s", datefmt="%m/%d/%Y %I:%M:%S %p", level=logging.INFO
)

def get_logger():
	return logging.getLogger(__name__)


def rank_log(_rank, logger, msg):
	if _rank == 0:
		logger.info(f" {msg}")


def verify_min_gpu_count(min_gpus: int = 2) -> bool:
	has_cuda = torch.cuda.is_available()
	gpu_count = torch.cuda.device_count()
	return has_cuda and gpu_count >= min_gpus

import os
import sys
import torch
import torch.nn as nn

from torch.distributed.tensor.parallel import (
	parallelize_module,
	ColwiseParallel,
	RowwiseParallel,
)

from log_utils import rank_log, get_logger, verify_min_gpu_count

_min_gpu_count = 2

if not verify_min_gpu_count(min_gpus=_min_gpu_count):
	print(f"Unable to locate sufficient {_min_gpu_count} gpus to run this example. Exiting.")
	sys.exit()

from torch.distributed._tensor.device_mesh import init_device_mesh





class ToyModel(nn.Module):

	def __init__(self):
		super(ToyModel, self).__init__()
		self.in_proj = nn.Linear(10, 32)
		self.relu = nn.ReLU()
		self.out_proj = nn.Linear(32, 5)

	def forward(self, x):
		return self.out_proj(self.relu(self.in_proj(x)))


logger = get_logger()

_world_size = int(os.environ["WORLD_SIZE"])

device_mesh = init_device_mesh(device_type="cuda", mesh_shape=(_world_size,))
_rank = device_mesh.get_rank()


print(f"Starting PyTorch TP example on rank {_rank}.")
assert (
	_world_size % 2 == 0
), f"TP examples require even number of GPUs, but got {_world_size} gpus"

rank_log(_rank, logger, f"Device Mesh created: {device_mesh=}")

tp_model = ToyModel().to("cuda")

lr = 0.25
optimizer = torch.optim.AdamW(tp_model.parameters(), lr=lr, foreach=True)

tp_model = parallelize_module(
	module=tp_model,
	device_mesh=device_mesh,
	parallelize_plan={
		"in_proj": ColwiseParallel(),
		"out_proj": RowwiseParallel(),
	},
)
num_iters = 10
rank_log(_rank, logger, "Tensor Parallel training starting...")

for i in range(num_iters):
	torch.manual_seed(i)
	inp = torch.rand(20, 10, device="cuda")
	output = tp_model(inp)
	output.sum().backward()
	optimizer.step()
	rank_log(_rank, logger, f"Tensor Parallel iter {i} completed")

rank_log(_rank, logger, "Tensor Parallel training completed!")




import os
import sys

import pytorch_sphinx_theme

current_dir = os.path.dirname(__file__)
target_dir = os.path.abspath(os.path.join(current_dir, "../.."))
sys.path.insert(0, target_dir)
print(target_dir)


project = "PyTorchExamples"
copyright = "2022, Meta"
author = "Meta"

release = "1.11"


extensions = ["sphinx.ext.napoleon", "sphinx.ext.autodoc", 'sphinx_panels']
panels_add_bootstrap_css = False

templates_path = ["_templates"]

exclude_patterns = []


html_theme = "pytorch_sphinx_theme"
html_theme_path = [pytorch_sphinx_theme.get_html_theme_path()]


html_static_path = ["_static"]
panels_add_fontawesome_latex = True

html_theme_options = {
	'pytorch_project': 'examples',
	'collapse_navigation': False,
	'display_version': True,
	'logo_only': False,
	'analytics_id': 'UA-117752657-2',
}

import torch
from torch.fx import symbolic_trace, Tracer, Graph, GraphModule, Node
from typing import Any, Callable, Dict, Optional, Tuple, Union







class M1(torch.nn.Module):
	def __init__(self):
		super().__init__()
		self.relu = torch.nn.ReLU()

	def forward(self, x):
		return self.relu(x)

default_traced: GraphModule = symbolic_trace(M1())
default_traced.graph.print_tabular()

class LowerReluTracer(Tracer):
	def is_leaf_module(self, m : torch.nn.Module, qualname : str):
		if isinstance(m, torch.nn.ReLU):
			return False
		return super().is_leaf_module(m, qualname)

lower_relu_tracer = LowerReluTracer()
custom_traced_graph: Graph = lower_relu_tracer.trace(M1())
custom_traced_graph.print_tabular()




class M2(torch.nn.Module):
	def forward(self, a, b):
		return a + b

class TaggingTracer(Tracer):
	def create_node(self, kind : str, target : Union[str, Callable],
					args : Tuple[Any], kwargs : Dict[str, Any], name : Optional[str] = None,
					type_expr : Optional[Any] = None) -> Node:
		n = super().create_node(kind, target, args, kwargs, name)
		n.tag = "foo"
		return n

custom_traced_graph: Graph = TaggingTracer().trace(M2())

def assert_all_nodes_have_tags(g: Graph) -> bool:
	for n in g.nodes:
		if not hasattr(n, "tag") or not n.tag == "foo":
			return False
	return True

print(assert_all_nodes_have_tags(custom_traced_graph))


from __future__ import print_function
import argparse
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.multiprocessing as mp
from torch.utils.data.sampler import Sampler
from torchvision import datasets, transforms

from train import train, test

parser = argparse.ArgumentParser(description='PyTorch MNIST Example')
parser.add_argument('--batch-size', type=int, default=64, metavar='N',
					help='input batch size for training (default: 64)')
parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',
					help='input batch size for testing (default: 1000)')
parser.add_argument('--epochs', type=int, default=10, metavar='N',
					help='number of epochs to train (default: 10)')
parser.add_argument('--lr', type=float, default=0.01, metavar='LR',
					help='learning rate (default: 0.01)')
parser.add_argument('--momentum', type=float, default=0.5, metavar='M',
					help='SGD momentum (default: 0.5)')
parser.add_argument('--seed', type=int, default=1, metavar='S',
					help='random seed (default: 1)')
parser.add_argument('--log-interval', type=int, default=10, metavar='N',
					help='how many batches to wait before logging training status')
parser.add_argument('--num-processes', type=int, default=2, metavar='N',
					help='how many training processes to use (default: 2)')
parser.add_argument('--cuda', action='store_true', default=False,
					help='enables CUDA training')
parser.add_argument('--mps', action='store_true', default=False,
					help='enables macOS GPU training')
parser.add_argument('--save_model', action='store_true', default=False,
					help='save the trained model to state_dict')
parser.add_argument('--dry-run', action='store_true', default=False,
					help='quickly check a single pass')

class Net(nn.Module):
	def __init__(self):
		super(Net, self).__init__()
		self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
		self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
		self.conv2_drop = nn.Dropout2d()
		self.fc1 = nn.Linear(320, 50)
		self.fc2 = nn.Linear(50, 10)

	def forward(self, x):
		x = F.relu(F.max_pool2d(self.conv1(x), 2))
		x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
		x = x.view(-1, 320)
		x = F.relu(self.fc1(x))
		x = F.dropout(x, training=self.training)
		x = self.fc2(x)
		return F.log_softmax(x, dim=1)


if __name__ == '__main__':
	args = parser.parse_args()

	use_cuda = args.cuda and torch.cuda.is_available()
	use_mps = args.mps and torch.backends.mps.is_available()
	if use_cuda:
		device = torch.device("cuda")
	elif use_mps:
		device = torch.device("mps")
	else:
		device = torch.device("cpu")

	transform=transforms.Compose([
		transforms.ToTensor(),
		transforms.Normalize((0.1307,), (0.3081,))
		])
	dataset1 = datasets.MNIST('../data', train=True, download=True,
					   transform=transform)
	dataset2 = datasets.MNIST('../data', train=False,
					   transform=transform)
	kwargs = {'batch_size': args.batch_size,
			  'shuffle': True}
	if use_cuda:
		kwargs.update({'num_workers': 1,
					   'pin_memory': True,
					  })

	torch.manual_seed(args.seed)
	mp.set_start_method('spawn', force=True)

	model = Net().to(device)
	model.share_memory() # gradients are allocated lazily, so they are not shared here

	processes = []
	for rank in range(args.num_processes):
		p = mp.Process(target=train, args=(rank, args, model, device,
										   dataset1, kwargs))
		p.start()
		processes.append(p)
	for p in processes:
		p.join()

	if args.save_model:
		torch.save(model.state_dict(), "MNIST_hogwild.pt")

	test(args, model, device, dataset2, kwargs)

import torch
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from datautils import MyTrainDataset

import torch.multiprocessing as mp
from torch.utils.data.distributed import DistributedSampler
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.distributed import init_process_group, destroy_process_group
import os


def ddp_setup():
	init_process_group(backend="nccl")
	torch.cuda.set_device(int(os.environ["LOCAL_RANK"]))

class Trainer:
	def __init__(
		self,
		model: torch.nn.Module,
		train_data: DataLoader,
		optimizer: torch.optim.Optimizer,
		save_every: int,
		snapshot_path: str,
	) -> None:
		self.local_rank = int(os.environ["LOCAL_RANK"])
		self.global_rank = int(os.environ["RANK"])
		self.model = model.to(self.local_rank)
		self.train_data = train_data
		self.optimizer = optimizer
		self.save_every = save_every
		self.epochs_run = 0
		self.snapshot_path = snapshot_path
		if os.path.exists(snapshot_path):
			print("Loading snapshot")
			self._load_snapshot(snapshot_path)

		self.model = DDP(self.model, device_ids=[self.local_rank])

	def _load_snapshot(self, snapshot_path):
		loc = f"cuda:{self.local_rank}"
		snapshot = torch.load(snapshot_path, map_location=loc)
		self.model.load_state_dict(snapshot["MODEL_STATE"])
		self.epochs_run = snapshot["EPOCHS_RUN"]
		print(f"Resuming training from snapshot at Epoch {self.epochs_run}")

	def _run_batch(self, source, targets):
		self.optimizer.zero_grad()
		output = self.model(source)
		loss = F.cross_entropy(output, targets)
		loss.backward()
		self.optimizer.step()

	def _run_epoch(self, epoch):
		b_sz = len(next(iter(self.train_data))[0])
		print(f"[GPU{self.global_rank}] Epoch {epoch} | Batchsize: {b_sz} | Steps: {len(self.train_data)}")
		self.train_data.sampler.set_epoch(epoch)
		for source, targets in self.train_data:
			source = source.to(self.local_rank)
			targets = targets.to(self.local_rank)
			self._run_batch(source, targets)

	def _save_snapshot(self, epoch):
		snapshot = {
			"MODEL_STATE": self.model.module.state_dict(),
			"EPOCHS_RUN": epoch,
		}
		torch.save(snapshot, self.snapshot_path)
		print(f"Epoch {epoch} | Training snapshot saved at {self.snapshot_path}")

	def train(self, max_epochs: int):
		for epoch in range(self.epochs_run, max_epochs):
			self._run_epoch(epoch)
			if self.local_rank == 0 and epoch % self.save_every == 0:
				self._save_snapshot(epoch)


def load_train_objs():
	train_set = MyTrainDataset(2048)  # load your dataset
	model = torch.nn.Linear(20, 1)  # load your model
	optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)
	return train_set, model, optimizer


def prepare_dataloader(dataset: Dataset, batch_size: int):
	return DataLoader(
		dataset,
		batch_size=batch_size,
		pin_memory=True,
		shuffle=False,
		sampler=DistributedSampler(dataset)
	)


def main(save_every: int, total_epochs: int, batch_size: int, snapshot_path: str = "snapshot.pt"):
	ddp_setup()
	dataset, model, optimizer = load_train_objs()
	train_data = prepare_dataloader(dataset, batch_size)
	trainer = Trainer(model, train_data, optimizer, save_every, snapshot_path)
	trainer.train(total_epochs)
	destroy_process_group()


if __name__ == "__main__":
	import argparse
	parser = argparse.ArgumentParser(description='simple distributed training job')
	parser.add_argument('total_epochs', type=int, help='Total epochs to train the model')
	parser.add_argument('save_every', type=int, help='How often to save a snapshot')
	parser.add_argument('--batch_size', default=32, type=int, help='Input batch size on each device (default: 32)')
	args = parser.parse_args()
	
	main(args.save_every, args.total_epochs, args.batch_size)

import os
import torch
import torch.distributed as dist
from datetime import datetime
import tqdm
from transformers import AutoTokenizer, GPT2TokenizerFast
from transformers import T5Tokenizer, T5ForConditionalGeneration

g_gigabyte = 1024**3

def setup():
	dist.init_process_group("nccl")


def cleanup():
	dist.destroy_process_group()

def get_date_of_run():
	date_of_run = datetime.now().strftime("%Y-%m-%d-%I:%M:%S_%p")
	print(f"--> current date and time of run = {date_of_run}")
	return date_of_run



def format_metrics_to_gb(item):
	metric_num = item / g_gigabyte
	metric_num = round(metric_num, ndigits=4)
	return metric_num

def train(args, model, rank, world_size, train_loader, optimizer, epoch, sampler=None):
	model.train()
	local_rank = int(os.environ['LOCAL_RANK'])
	fsdp_loss = torch.zeros(2).to(local_rank)
  
	if sampler:
		sampler.set_epoch(epoch)
	if rank==0:
		inner_pbar = tqdm.tqdm(
			range(len(train_loader)), colour="blue", desc="r0 Training Epoch"
		)
	for batch in train_loader:
		for key in batch.keys():
			batch[key] = batch[key].to(local_rank)
		optimizer.zero_grad()
		output = model(input_ids=batch["source_ids"],attention_mask=batch["source_mask"],labels=batch["target_ids"] )
		loss = output["loss"]
		loss.backward()
		optimizer.step()
		fsdp_loss[0] += loss.item()
		fsdp_loss[1] += len(batch)
		if rank==0:
			inner_pbar.update(1)

	dist.all_reduce(fsdp_loss, op=dist.ReduceOp.SUM)
	train_accuracy = fsdp_loss[0] / fsdp_loss[1]


	if rank == 0:
		inner_pbar.close()
		print(
				f"Train Epoch: \t{epoch}, Loss: \t{train_accuracy:.4f}"
			)
	return train_accuracy


def validation(model, rank, world_size, val_loader):
	model.eval()
	correct = 0
	local_rank = int(os.environ['LOCAL_RANK'])
	fsdp_loss = torch.zeros(2).to(local_rank)
	if rank == 0:
		inner_pbar = tqdm.tqdm(
			range(len(val_loader)), colour="green", desc="Validation Epoch"
		)
	with torch.no_grad():
		for batch in val_loader:
			for key in batch.keys():
				batch[key] = batch[key].to(local_rank)
			output = model(input_ids=batch["source_ids"],attention_mask=batch["source_mask"],labels=batch["target_ids"])
			fsdp_loss[0] += output["loss"].item()  # sum up batch loss
			fsdp_loss[1] += len(batch)

			if rank==0:
				inner_pbar.update(1)

	dist.all_reduce(fsdp_loss, op=dist.ReduceOp.SUM)
	val_loss = fsdp_loss[0] / fsdp_loss[1]
	if rank == 0:
		inner_pbar.close()
		print(f"Validation Loss: {val_loss:.4f}")
	return val_loss


def setup_model(model_name):
		model = T5ForConditionalGeneration.from_pretrained(model_name)
		tokenizer =  T5Tokenizer.from_pretrained(model_name)
		return model, tokenizer

from dataclasses import dataclass
from typing import ClassVar


@dataclass
class train_config:
	model_name: str="t5-base"
	run_validation: bool=True
	batch_size_training: int=4
	num_workers_dataloader: int=2
	lr: float=0.002
	weight_decay: float=0.0
	gamma: float= 0.85
	use_fp16: bool=False
	mixed_precision: bool=True
	save_model: bool=False
	
	
	
import argparse
import torch

import data

parser = argparse.ArgumentParser(description='PyTorch Wikitext-2 Language Model')
parser.add_argument('--data', type=str, default='./data/wikitext-2',
					help='location of the data corpus')
parser.add_argument('--checkpoint', type=str, default='./model.pt',
					help='model checkpoint to use')
parser.add_argument('--outf', type=str, default='generated.txt',
					help='output file for generated text')
parser.add_argument('--words', type=int, default='1000',
					help='number of words to generate')
parser.add_argument('--seed', type=int, default=1111,
					help='random seed')
parser.add_argument('--cuda', action='store_true',
					help='use CUDA')
parser.add_argument('--mps', action='store_true', default=False,
						help='enables macOS GPU training')
parser.add_argument('--temperature', type=float, default=1.0,
					help='temperature - higher will increase diversity')
parser.add_argument('--log-interval', type=int, default=100,
					help='reporting interval')
args = parser.parse_args()

torch.manual_seed(args.seed)
if torch.cuda.is_available():
	if not args.cuda:
		print("WARNING: You have a CUDA device, so you should probably run with --cuda.")
if torch.backends.mps.is_available():
	if not args.mps:
		print("WARNING: You have mps device, to enable macOS GPU run with --mps.")
		
use_mps = args.mps and torch.backends.mps.is_available()
if args.cuda:
	device = torch.device("cuda")
elif use_mps:
	device = torch.device("mps")
else:
	device = torch.device("cpu")

if args.temperature < 1e-3:
	parser.error("--temperature has to be greater or equal 1e-3.")

with open(args.checkpoint, 'rb') as f:
	model = torch.load(f, map_location=device)
model.eval()

corpus = data.Corpus(args.data)
ntokens = len(corpus.dictionary)

is_transformer_model = hasattr(model, 'model_type') and model.model_type == 'Transformer'
if not is_transformer_model:
	hidden = model.init_hidden(1)
input = torch.randint(ntokens, (1, 1), dtype=torch.long).to(device)

with open(args.outf, 'w') as outf:
	with torch.no_grad():  # no tracking history
		for i in range(args.words):
			if is_transformer_model:
				output = model(input, False)
				word_weights = output[-1].squeeze().div(args.temperature).exp().cpu()
				word_idx = torch.multinomial(word_weights, 1)[0]
				word_tensor = torch.Tensor([[word_idx]]).long().to(device)
				input = torch.cat([input, word_tensor], 0)
			else:
				output, hidden = model(input, hidden)
				word_weights = output.squeeze().div(args.temperature).exp().cpu()
				word_idx = torch.multinomial(word_weights, 1)[0]
				input.fill_(word_idx)

			word = corpus.dictionary.idx2word[word_idx]

			outf.write(word + ('\n' if i % 20 == 19 else ' '))

			if i % args.log_interval == 0:
				print('| Generated {}/{} words'.format(i, args.words))

import os
import sys
import torch
import torch.nn as nn

from torch.distributed._tensor import Shard

from torch.distributed.tensor.parallel import (
	parallelize_module,
	ColwiseParallel,
	RowwiseParallel,
)

from log_utils import rank_log, get_logger, verify_min_gpu_count


_min_gpu_count = 2

if not verify_min_gpu_count(min_gpus=_min_gpu_count):
	print(f"Unable to locate sufficient {_min_gpu_count} gpus to run this example. Exiting.")
	sys.exit()


from torch.distributed._tensor.device_mesh import init_device_mesh





class ToyModel(nn.Module):

	def __init__(self):
		super().__init__()
		self.in_proj = nn.Linear(10, 32)
		self.relu = nn.ReLU()
		self.out_proj = nn.Linear(32, 5)

	def forward(self, x):
		return self.out_proj(self.relu(self.in_proj(x)))


logger = get_logger()

device_mesh = init_device_mesh(
	device_type="cuda", mesh_shape=(int(os.environ["WORLD_SIZE"]),)
)

_rank = device_mesh.get_rank()

print(f"Starting PyTorch Sequence Parallel example on rank {_rank}.")

rank_log(_rank, logger, f"Device Mesh created: {device_mesh=}")

model = ToyModel().to("cuda")

sp_model = parallelize_module(
	module=model,
	device_mesh=device_mesh,
	parallelize_plan={
		"in_proj": ColwiseParallel(input_layouts=Shard(0)),
		"out_proj": RowwiseParallel(output_layouts=Shard(0)),
	},
)


lr = 0.25
optimizer = torch.optim.AdamW(sp_model.parameters(), lr=lr, foreach=True)


num_iters = 10
rank_log(_rank, logger, "Sequence Parallel training starting...")

for i in range(num_iters):
	inp = torch.rand(20, 10, device="cuda")
	output = sp_model(inp)
	output.sum().backward()
	optimizer.step()
	rank_log(_rank, logger, f"Sequence Parallel iter {i} completed")

rank_log(_rank, logger, "Sequence Parallel training completed!")

import sys
import torch
import torch.distributed as dist
import torch.nn as nn
import torch.nn.functional as F

from torch.distributed.fsdp import FullyShardedDataParallel as FSDP
from torch.distributed.tensor.parallel import (
	parallelize_module,
	ColwiseParallel,
	RowwiseParallel,
)

import os
from log_utils import rank_log, get_logger, verify_min_gpu_count


_min_gpu_count = 4

if not verify_min_gpu_count(min_gpus=_min_gpu_count):
	print(f"Unable to locate sufficient {_min_gpu_count} gpus to run this example. Exiting.")
	sys.exit()

from torch.distributed._tensor.device_mesh import init_device_mesh




def find_multiple(n: int, k: int) -> int:
	if n % k == 0:
		return n
	return n + k - (n % k)


class MLP_swiglu(nn.Module):

	def __init__(self, mlp_dim: int = 1024) -> None:
		super().__init__()
		hidden_dim = 4 * mlp_dim
		scaled_hidden = int(2 * hidden_dim / 3)
		rounded_hidden = find_multiple(scaled_hidden, 256)

		self.in_proj = nn.Linear(mlp_dim, rounded_hidden, bias=False)
		self.gate_proj = nn.Linear(mlp_dim, rounded_hidden, bias=False)
		self.out_proj = nn.Linear(rounded_hidden, mlp_dim, bias=False)

	def forward(self, x: torch.Tensor) -> torch.Tensor:
		x = F.silu(self.in_proj(x)) * self.gate_proj(x)
		x = self.out_proj(x)
		return x


tp_size = 2
logger = get_logger()

_rank = int(os.environ["RANK"])
_world_size = int(os.environ["WORLD_SIZE"])


print(f"Starting PyTorch 2D (FSDP + TP) example on rank {_rank}.")
assert (
	_world_size % tp_size == 0
), f"World size {_world_size} needs to be divisible by TP size {tp_size}"


dp_size = _world_size // tp_size

device_mesh = init_device_mesh("cuda", (dp_size, tp_size), mesh_dim_names=("dp", "tp"))

rank_log(_rank, logger, f"Device Mesh created: {device_mesh=}")
tp_mesh = device_mesh["tp"]
dp_mesh = device_mesh["dp"]

dp_rank = dp_mesh.get_local_rank()

_mlp_dim = 1024
base_model_swiglu = MLP_swiglu(mlp_dim=_mlp_dim).to("cuda")


custom_tp_model = parallelize_module(
	module=base_model_swiglu,
	device_mesh=tp_mesh,
	parallelize_plan={
		"in_proj": ColwiseParallel(),
		"gate_proj": ColwiseParallel(),
		"out_proj": RowwiseParallel(),
	},
)

rank_log(_rank, logger, f"Model after parallelization {custom_tp_model=}\n")

sharded_model = FSDP(custom_tp_model, device_mesh=dp_mesh, use_orig_params=True)

lr = 3e-3
rank_log(_rank, logger, f"Creating AdamW optimizer with learning rate {lr}")
optimizer = torch.optim.AdamW(sharded_model.parameters(), lr=lr, foreach=True)

rank_log(_rank, logger, "\nStarting 2D training...")
num_iterations = 10
batch_size = 2

for i in range(num_iterations):
	torch.manual_seed(i + dp_rank)
	inp = torch.rand(batch_size, _mlp_dim, device="cuda")

	output = sharded_model(inp)
	output.sum().backward()
	optimizer.step()
	rank_log(_rank, logger, f"2D iter {i} complete")

rank_log(_rank, logger, "2D training successfully completed!")

from dataclasses import dataclass, field
from typing import ClassVar
from torch.distributed.fsdp import ShardingStrategy
from torch.distributed.fsdp.fully_sharded_data_parallel import StateDictType

@dataclass
class fsdp_config:
	mixed_precision: bool=True
	use_fp16: bool=False
	seed: int=42
	fsdp_activation_checkpointing: bool=True
	limit_all_gathers: bool=True
	sharding_strategy: ShardingStrategy = ShardingStrategy.FULL_SHARD #HYBRID_SHARD, SHARD_GRAD_OP
	checkpoint_type: StateDictType = StateDictType.FULL_STATE_DICT # alternatively can use SHARDED_STATE_DICT to avoid OOMs
	save_optimizer: bool=False
	
	
	
	
import argparse
import gym
import numpy as np
from itertools import count
from collections import namedtuple

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.distributions import Categorical


parser = argparse.ArgumentParser(description='PyTorch actor-critic example')
parser.add_argument('--gamma', type=float, default=0.99, metavar='G',
					help='discount factor (default: 0.99)')
parser.add_argument('--seed', type=int, default=543, metavar='N',
					help='random seed (default: 543)')
parser.add_argument('--render', action='store_true',
					help='render the environment')
parser.add_argument('--log-interval', type=int, default=10, metavar='N',
					help='interval between training status logs (default: 10)')
args = parser.parse_args()


env = gym.make('CartPole-v1')
env.reset(seed=args.seed)
torch.manual_seed(args.seed)


SavedAction = namedtuple('SavedAction', ['log_prob', 'value'])


class Policy(nn.Module):
	def __init__(self):
		super(Policy, self).__init__()
		self.affine1 = nn.Linear(4, 128)

		self.action_head = nn.Linear(128, 2)

		self.value_head = nn.Linear(128, 1)

		self.saved_actions = []
		self.rewards = []

	def forward(self, x):
		x = F.relu(self.affine1(x))

		action_prob = F.softmax(self.action_head(x), dim=-1)

		state_values = self.value_head(x)

		return action_prob, state_values


model = Policy()
optimizer = optim.Adam(model.parameters(), lr=3e-2)
eps = np.finfo(np.float32).eps.item()


def select_action(state):
	state = torch.from_numpy(state).float()
	probs, state_value = model(state)

	m = Categorical(probs)

	action = m.sample()

	model.saved_actions.append(SavedAction(m.log_prob(action), state_value))

	return action.item()


def finish_episode():
	R = 0
	saved_actions = model.saved_actions
	policy_losses = [] # list to save actor (policy) loss
	value_losses = [] # list to save critic (value) loss
	returns = [] # list to save the true values

	for r in model.rewards[::-1]:
		R = r + args.gamma * R
		returns.insert(0, R)

	returns = torch.tensor(returns)
	returns = (returns - returns.mean()) / (returns.std() + eps)

	for (log_prob, value), R in zip(saved_actions, returns):
		advantage = R - value.item()

		policy_losses.append(-log_prob * advantage)

		value_losses.append(F.smooth_l1_loss(value, torch.tensor([R])))

	optimizer.zero_grad()

	loss = torch.stack(policy_losses).sum() + torch.stack(value_losses).sum()

	loss.backward()
	optimizer.step()

	del model.rewards[:]
	del model.saved_actions[:]


def main():
	running_reward = 10

	for i_episode in count(1):

		state, _ = env.reset()
		ep_reward = 0

		for t in range(1, 10000):

			action = select_action(state)

			state, reward, done, _, _ = env.step(action)

			if args.render:
				env.render()

			model.rewards.append(reward)
			ep_reward += reward
			if done:
				break

		running_reward = 0.05 * ep_reward + (1 - 0.05) * running_reward

		finish_episode()

		if i_episode % args.log_interval == 0:
			print('Episode {}\tLast reward: {:.2f}\tAverage reward: {:.2f}'.format(
				  i_episode, ep_reward, running_reward))

		if running_reward > env.spec.reward_threshold:
			print("Solved! Running reward is now {} and "
				  "the last episode runs to {} time steps!".format(running_reward, t))
			break


if __name__ == '__main__':
	main()

import torch
from torch.utils.data import Dataset
import fsspec
from dataclasses import dataclass


@dataclass
class DataConfig:
	path: str = None
	block_size: int = None
	train_split: float = None
	truncate: float = 1.0

class CharDataset(Dataset):

	def __init__(self, data_cfg: DataConfig): #data_path: str, block_size):
		data = fsspec.open(data_cfg.path).open().read().decode('utf-8')
		data = data[ : int(len(data) * data_cfg.truncate)]

		chars = sorted(list(set(data)))
		data_size, vocab_size = len(data), len(chars)
		print('Data has %d characters, %d unique.' % (data_size, vocab_size))

		self.stoi = {ch: i for i, ch in enumerate(chars)}
		self.itos = {i: ch for i, ch in enumerate(chars)}
		self.block_size = data_cfg.block_size
		self.vocab_size = vocab_size
		self.data = data

	def __len__(self):
		return len(self.data) - self.block_size

	def __getitem__(self, idx):
		chunk = self.data[idx:idx + self.block_size + 1]
		dix = [self.stoi[s] for s in chunk]
		x = torch.tensor(dix[:-1], dtype=torch.long)
		y = torch.tensor(dix[1:], dtype=torch.long)
		return x, y

import torch

from torch.distributed.fsdp import (
	MixedPrecision,
)

fpSixteen = MixedPrecision(
	param_dtype=torch.float16,
	reduce_dtype=torch.float16,
	buffer_dtype=torch.float16,
)

bfSixteen = MixedPrecision(
	param_dtype=torch.bfloat16,
	reduce_dtype=torch.bfloat16,
	buffer_dtype=torch.bfloat16,
)

bfSixteen_working = MixedPrecision(
	param_dtype=torch.float32,
	reduce_dtype=torch.bfloat16,
	buffer_dtype=torch.bfloat16,
)

fp32_policy = MixedPrecision(
	param_dtype=torch.float32,
	reduce_dtype=torch.float32,
	buffer_dtype=torch.float32,
)

import argparse
import os
from threading import Lock

import torch
import torch.distributed.autograd as dist_autograd
import torch.distributed.rpc as rpc
import torch.multiprocessing as mp
import torch.nn as nn
import torch.nn.functional as F
from torch import optim
from torch.distributed.optim import DistributedOptimizer
from torchvision import datasets, transforms



class Net(nn.Module):
	def __init__(self, num_gpus=0):
		super(Net, self).__init__()
		print(f"Using {num_gpus} GPUs to train")
		self.num_gpus = num_gpus
		device = torch.device(
			"cuda:0" if torch.cuda.is_available() and self.num_gpus > 0 else "cpu")
		print(f"Putting first 2 convs on {str(device)}")
		self.conv1 = nn.Conv2d(1, 32, 3, 1).to(device)
		self.conv2 = nn.Conv2d(32, 64, 3, 1).to(device)
		if "cuda" in str(device) and num_gpus > 1:
			device = torch.device("cuda:1")

		print(f"Putting rest of layers on {str(device)}")
		self.dropout1 = nn.Dropout2d(0.25).to(device)
		self.dropout2 = nn.Dropout2d(0.5).to(device)
		self.fc1 = nn.Linear(9216, 128).to(device)
		self.fc2 = nn.Linear(128, 10).to(device)

	def forward(self, x):
		x = self.conv1(x)
		x = F.relu(x)
		x = self.conv2(x)
		x = F.max_pool2d(x, 2)

		x = self.dropout1(x)
		x = torch.flatten(x, 1)
		next_device = next(self.fc1.parameters()).device
		x = x.to(next_device)

		x = self.fc1(x)
		x = F.relu(x)
		x = self.dropout2(x)
		x = self.fc2(x)
		output = F.log_softmax(x, dim=1)
		return output



def call_method(method, rref, *args, **kwargs):
	return method(rref.local_value(), *args, **kwargs)



def remote_method(method, rref, *args, **kwargs):
	args = [method, rref] + list(args)
	return rpc.rpc_sync(rref.owner(), call_method, args=args, kwargs=kwargs)


class ParameterServer(nn.Module):
	def __init__(self, num_gpus=0):
		super().__init__()
		model = Net(num_gpus=num_gpus)
		self.model = model
		self.input_device = torch.device(
			"cuda:0" if torch.cuda.is_available() and num_gpus > 0 else "cpu")

	def forward(self, inp):
		inp = inp.to(self.input_device)
		out = self.model(inp)
		out = out.to("cpu")
		return out

	def get_dist_gradients(self, cid):
		grads = dist_autograd.get_gradients(cid)
		cpu_grads = {}
		for k, v in grads.items():
			k_cpu, v_cpu = k.to("cpu"), v.to("cpu")
			cpu_grads[k_cpu] = v_cpu
		return cpu_grads

	def get_param_rrefs(self):
		param_rrefs = [rpc.RRef(param) for param in self.model.parameters()]
		return param_rrefs


param_server = None
global_lock = Lock()


def get_parameter_server(num_gpus=0):
	global param_server
	with global_lock:
		if not param_server:
			param_server = ParameterServer(num_gpus=num_gpus)
		return param_server


def run_parameter_server(rank, world_size):
	print("PS master initializing RPC")
	rpc.init_rpc(name="parameter_server", rank=rank, world_size=world_size)
	print("RPC initialized! Running parameter server...")
	rpc.shutdown()
	print("RPC shutdown on parameter server.")



class TrainerNet(nn.Module):
	def __init__(self, num_gpus=0):
		super().__init__()
		self.num_gpus = num_gpus
		self.param_server_rref = rpc.remote(
			"parameter_server", get_parameter_server, args=(num_gpus,))

	def get_global_param_rrefs(self):
		remote_params = remote_method(
			ParameterServer.get_param_rrefs,
			self.param_server_rref)
		return remote_params

	def forward(self, x):
		model_output = remote_method(
			ParameterServer.forward, self.param_server_rref, x)
		return model_output


def run_training_loop(rank, num_gpus, train_loader, test_loader):
	net = TrainerNet(num_gpus=num_gpus)
	param_rrefs = net.get_global_param_rrefs()
	opt = DistributedOptimizer(optim.SGD, param_rrefs, lr=0.03)
	for i, (data, target) in enumerate(train_loader):
		with dist_autograd.context() as cid:
			model_output = net(data)
			target = target.to(model_output.device)
			loss = F.nll_loss(model_output, target)
			if i % 5 == 0:
				print(f"Rank {rank} training batch {i} loss {loss.item()}")
			dist_autograd.backward(cid, [loss])
			assert remote_method(
				ParameterServer.get_dist_gradients,
				net.param_server_rref,
				cid) != {}
			opt.step(cid)

	print("Training complete!")
	print("Getting accuracy....")
	get_accuracy(test_loader, net)


def get_accuracy(test_loader, model):
	model.eval()
	correct_sum = 0
	device = torch.device("cuda:0" if model.num_gpus > 0
		and torch.cuda.is_available() else "cpu")
	with torch.no_grad():
		for i, (data, target) in enumerate(test_loader):
			out = model(data)
			pred = out.argmax(dim=1, keepdim=True)
			pred, target = pred.to(device), target.to(device)
			correct = pred.eq(target.view_as(pred)).sum().item()
			correct_sum += correct

	print(f"Accuracy {correct_sum / len(test_loader.dataset)}")


def run_worker(rank, world_size, num_gpus, train_loader, test_loader):
	print(f"Worker rank {rank} initializing RPC")
	rpc.init_rpc(
		name=f"trainer_{rank}",
		rank=rank,
		world_size=world_size)

	print(f"Worker {rank} done initializing RPC")

	run_training_loop(rank, num_gpus, train_loader, test_loader)
	rpc.shutdown()



if __name__ == '__main__':
	parser = argparse.ArgumentParser(
		description="Parameter-Server RPC based training")
	parser.add_argument(
		"--world_size",
		type=int,
		default=4,
	parser.add_argument(
		"--rank",
		type=int,
		default=None,
		help="Global rank of this process. Pass in 0 for master.")
	parser.add_argument(
		"--num_gpus",
		type=int,
		default=0,
	parser.add_argument(
		"--master_addr",
		type=str,
		default="localhost",
	parser.add_argument(
		"--master_port",
		type=str,
		default="29500",

	args = parser.parse_args()
	assert args.rank is not None, "must provide rank argument."
	assert args.num_gpus <= 3, f"Only 0-2 GPUs currently supported (got {args.num_gpus})."
	os.environ['MASTER_ADDR'] = args.master_addr
	os.environ['MASTER_PORT'] = args.master_port
	processes = []
	world_size = args.world_size

	mp.set_start_method("spawn")

	if args.rank == 0:
		p = mp.Process(target=run_parameter_server, args=(0, world_size))
		p.start()
		processes.append(p)
	else:
		train_loader = torch.utils.data.DataLoader(
			datasets.MNIST('../data', train=True, download=True,
						   transform=transforms.Compose([
							   transforms.ToTensor(),
							   transforms.Normalize((0.1307,), (0.3081,))
						   ])),
			batch_size=32, shuffle=True)
		test_loader = torch.utils.data.DataLoader(
			datasets.MNIST('../data', train=False,
						   transform=transforms.Compose([
							   transforms.ToTensor(),
							   transforms.Normalize((0.1307,), (0.3081,))
						   ])),
			batch_size=32, shuffle=True)
		p = mp.Process(
			target=run_worker,
			args=(
				args.rank,
				world_size, args.num_gpus,
				train_loader,
				test_loader))
		p.start()
		processes.append(p)

	for p in processes:
		p.join()

import torch
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from datautils import MyTrainDataset

import torch.multiprocessing as mp
from torch.utils.data.distributed import DistributedSampler
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.distributed import init_process_group, destroy_process_group
import os


def ddp_setup(rank, world_size):
	os.environ["MASTER_ADDR"] = "localhost"
	os.environ["MASTER_PORT"] = "12355"
	init_process_group(backend="nccl", rank=rank, world_size=world_size)
	torch.cuda.set_device(rank)

class Trainer:
	def __init__(
		self,
		model: torch.nn.Module,
		train_data: DataLoader,
		optimizer: torch.optim.Optimizer,
		gpu_id: int,
		save_every: int,
	) -> None:
		self.gpu_id = gpu_id
		self.model = model.to(gpu_id)
		self.train_data = train_data
		self.optimizer = optimizer
		self.save_every = save_every
		self.model = DDP(model, device_ids=[gpu_id])

	def _run_batch(self, source, targets):
		self.optimizer.zero_grad()
		output = self.model(source)
		loss = F.cross_entropy(output, targets)
		loss.backward()
		self.optimizer.step()

	def _run_epoch(self, epoch):
		b_sz = len(next(iter(self.train_data))[0])
		print(f"[GPU{self.gpu_id}] Epoch {epoch} | Batchsize: {b_sz} | Steps: {len(self.train_data)}")
		self.train_data.sampler.set_epoch(epoch)
		for source, targets in self.train_data:
			source = source.to(self.gpu_id)
			targets = targets.to(self.gpu_id)
			self._run_batch(source, targets)

	def _save_checkpoint(self, epoch):
		ckp = self.model.module.state_dict()
		PATH = "checkpoint.pt"
		torch.save(ckp, PATH)
		print(f"Epoch {epoch} | Training checkpoint saved at {PATH}")

	def train(self, max_epochs: int):
		for epoch in range(max_epochs):
			self._run_epoch(epoch)
			if self.gpu_id == 0 and epoch % self.save_every == 0:
				self._save_checkpoint(epoch)


def load_train_objs():
	train_set = MyTrainDataset(2048)  # load your dataset
	model = torch.nn.Linear(20, 1)  # load your model
	optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)
	return train_set, model, optimizer


def prepare_dataloader(dataset: Dataset, batch_size: int):
	return DataLoader(
		dataset,
		batch_size=batch_size,
		pin_memory=True,
		shuffle=False,
		sampler=DistributedSampler(dataset)
	)


def main(rank: int, world_size: int, save_every: int, total_epochs: int, batch_size: int):
	ddp_setup(rank, world_size)
	dataset, model, optimizer = load_train_objs()
	train_data = prepare_dataloader(dataset, batch_size)
	trainer = Trainer(model, train_data, optimizer, rank, save_every)
	trainer.train(total_epochs)
	destroy_process_group()


if __name__ == "__main__":
	import argparse
	parser = argparse.ArgumentParser(description='simple distributed training job')
	parser.add_argument('total_epochs', type=int, help='Total epochs to train the model')
	parser.add_argument('save_every', type=int, help='How often to save a snapshot')
	parser.add_argument('--batch_size', default=32, type=int, help='Input batch size on each device (default: 32)')
	args = parser.parse_args()
	
	world_size = torch.cuda.device_count()
	mp.spawn(main, args=(world_size, args.save_every, args.total_epochs, args.batch_size), nprocs=world_size)

import torch
import torch.fx

class Foo(torch.nn.Module):
  def forward(self, x):
	with torch.profiler.record_function('foo'):
	  return torch.relu(x)

f = Foo()
x = torch.randn(5, 3, 2)
with torch.autograd.profiler.profile() as prof:
  f(x)

print(prof)


traced = torch.fx.symbolic_trace(f)
with torch.autograd.profiler.profile() as prof:
  traced(x)

print(prof)


class ProfilerTracer(torch.fx.Tracer):
  def trace(self, root, concrete_args=None):
	orig_record_function_enter = torch.autograd.profiler.record_function.__enter__
	orig_record_function_exit = torch.autograd.profiler.record_function.__exit__

	def fake_profiler_enter(_self):
	  nonlocal self
	  handle_proxy = self.create_proxy(
		  kind='call_function',
		  target=torch.ops.profiler._record_function_enter,
		  args=(_self.name,),
		  kwargs={})
	  
	  assert getattr(_self, '_fx_profiler_ctx', None) is None
	  setattr(_self, '_fx_profiler_ctx', handle_proxy)
	  return handle_proxy

	def fake_profiler_exit(_self, exc_type, exc_value, traceback):
	  assert hasattr(_self, '_fx_profiler_ctx')
	  handle_proxy = _self._fx_profiler_ctx
	  torch.ops.profiler._record_function_exit(handle_proxy)
	  setattr(_self, '_fx_profiler_ctx', None)

	torch.autograd.profiler.record_function.__enter__ = fake_profiler_enter
	torch.autograd.profiler.record_function.__exit__ = fake_profiler_exit

	try:
	  return super().trace(root, concrete_args)
	finally:
	  torch.autograd.profiler.record_function.__enter__ = orig_record_function_enter
	  torch.autograd.profiler.record_function.__exit__ = orig_record_function_exit

pt = ProfilerTracer()

graph_with_profiler = pt.trace(f)
traced_with_profiler = torch.fx.GraphModule(pt.root, graph_with_profiler)

with torch.autograd.profiler.profile() as prof:
  traced_with_profiler(x)

print(prof)


from enum import Enum, auto

import torch
from torch.fx import GraphModule, Node, Proxy, symbolic_trace



class M(torch.nn.Module):
	def __init__(self):
		super().__init__()

	def forward(self, x, y):
		y = torch.cat([x, y])
		return y

traced = symbolic_trace(M())

class ActivationFunction(Enum):
	RELU = auto()
	LEAKY_RELU = auto()
	PRELU = auto()

activation_functions = {
	ActivationFunction.RELU: torch.nn.ReLU(),
	ActivationFunction.LEAKY_RELU: torch.nn.LeakyReLU(),
	ActivationFunction.PRELU: torch.nn.PReLU(),
}

def wrap_in_activation_function(m: GraphModule, fn: ActivationFunction) -> GraphModule:
	output_node: Optional[Node] = None
	for n in reversed(m.graph.nodes):
		if n.op == "output":
			output_node = n
			break
	assert output_node

	assert len(output_node.all_input_nodes) == 1
	wrap_node = output_node.all_input_nodes[0]

	wrap_proxy = Proxy(wrap_node)

	fn_impl = activation_functions[fn]
	fn_impl_traced = symbolic_trace(fn_impl)

	with traced.graph.inserting_after(wrap_node):
		fn_impl_output_node = fn_impl_traced(wrap_proxy)
		new_args = (fn_impl_output_node.node,)
		output_node.args = new_args

	m.recompile()


x, y = torch.randn(5, 3), torch.randn(5, 3)
orig_output = traced(x, y)

wrap_in_activation_function(traced, ActivationFunction.LEAKY_RELU)
new_output = traced(x, y)

torch.testing.assert_close(new_output, torch.nn.LeakyReLU()(orig_output))

import torch
import torch.nn as nn


class Bottle(nn.Module):

	def forward(self, input):
		if len(input.size()) <= 2:
			return super(Bottle, self).forward(input)
		size = input.size()[:2]
		out = super(Bottle, self).forward(input.view(size[0]*size[1], -1))
		return out.view(size[0], size[1], -1)


class Linear(Bottle, nn.Linear):
	pass


class Encoder(nn.Module):

	def __init__(self, config):
		super(Encoder, self).__init__()
		self.config = config
		input_size = config.d_proj if config.projection else config.d_embed
		dropout = 0 if config.n_layers == 1 else config.dp_ratio
		self.rnn = nn.LSTM(input_size=input_size, hidden_size=config.d_hidden,
						num_layers=config.n_layers, dropout=dropout,
						bidirectional=config.birnn)

	def forward(self, inputs):
		batch_size = inputs.size()[1]
		state_shape = self.config.n_cells, batch_size, self.config.d_hidden
		h0 = c0 = inputs.new_zeros(state_shape)
		outputs, (ht, ct) = self.rnn(inputs, (h0, c0))
		return ht[-1] if not self.config.birnn else ht[-2:].transpose(0, 1).contiguous().view(batch_size, -1)


class SNLIClassifier(nn.Module):

	def __init__(self, config):
		super(SNLIClassifier, self).__init__()
		self.config = config
		self.embed = nn.Embedding(config.n_embed, config.d_embed)
		self.projection = Linear(config.d_embed, config.d_proj)
		self.encoder = Encoder(config)
		self.dropout = nn.Dropout(p=config.dp_ratio)
		self.relu = nn.ReLU()
		seq_in_size = 2*config.d_hidden
		if self.config.birnn:
			seq_in_size *= 2
		lin_config = [seq_in_size]*2
		self.out = nn.Sequential(
			Linear(*lin_config),
			self.relu,
			self.dropout,
			Linear(*lin_config),
			self.relu,
			self.dropout,
			Linear(*lin_config),
			self.relu,
			self.dropout,
			Linear(seq_in_size, config.d_out))

	def forward(self, batch):
		prem_embed = self.embed(batch.premise)
		hypo_embed = self.embed(batch.hypothesis)
		if self.config.fix_emb:
			prem_embed = prem_embed.detach()
			hypo_embed = hypo_embed.detach()
		if self.config.projection:
			prem_embed = self.relu(self.projection(prem_embed))
			hypo_embed = self.relu(self.projection(hypo_embed))
		premise = self.encoder(prem_embed)
		hypothesis = self.encoder(hypo_embed)
		scores = self.out(torch.cat([premise, hypothesis], 1))
		return scores

import torch
from torch.fx import symbolic_trace
import operator


class M(torch.nn.Module):
	def forward(self, x, y):
		return x + y, torch.add(x, y), x.add(y)

traced = symbolic_trace(M())


patterns = set([operator.add, torch.add, "add"])

for n in traced.graph.nodes:
	if any(n.target == pattern for pattern in patterns):
		with traced.graph.inserting_after(n):
			new_node = traced.graph.call_function(torch.bitwise_and, n.args, n.kwargs)
			n.replace_all_uses_with(new_node)
		traced.graph.erase_node(n)

traced.recompile()



import torch.distributed as dist
import torch.nn as nn
import torch

from transformers.models.t5.modeling_t5 import T5Block

from torch.distributed.fsdp.fully_sharded_data_parallel import (
	FullyShardedDataParallel as FSDP,
	CPUOffload,
	BackwardPrefetch,
	MixedPrecision,
)
from torch.distributed.fsdp.wrap import (
	transformer_auto_wrap_policy,
	size_based_auto_wrap_policy,
	enable_wrap,
	wrap,
)

import functools
from typing import Type


def get_size_policy(min_params=1e8):
	num_wrap_policy = functools.partial(
		size_based_auto_wrap_policy, min_num_params=min_params
	)
	return num_wrap_policy


def get_t5_wrapper():

	t5_auto_wrap_policy = functools.partial(
		transformer_auto_wrap_policy,
		transformer_layer_cls={
			T5Block,
		},
	)

	return t5_auto_wrap_policy




from pkg_resources import packaging
import torch
import torch.cuda.nccl as nccl
import torch.distributed as dist


def bfloat_support():
	return (
		torch.version.cuda
		and torch.cuda.is_bf16_supported()
		and packaging.version.parse(torch.version.cuda).release >= (11, 0)
		and dist.is_nccl_available()
		and nccl.version() >= (2, 10)
	)

import torch
import torch.fx
from typing import Any, Callable, Dict, Optional, Tuple

class ModulePathTracer(torch.fx.Tracer):

	current_module_qualified_name : str = ''
	node_to_originating_module : Dict[torch.fx.Node, str] = {}

	def call_module(self, m: torch.nn.Module, forward: Callable[..., Any],
					args : Tuple[Any, ...], kwargs : Dict[str, Any]) -> Any:
		old_qualname = self.current_module_qualified_name
		try:
			self.current_module_qualified_name = self.path_of_module(m)
			return super().call_module(m, forward, args, kwargs)
		finally:
			self.current_module_qualified_name = old_qualname

	def create_proxy(self, kind: str, target: torch.fx.node.Target, args: Tuple[Any, ...],
					 kwargs: Dict[str, Any], name: Optional[str] = None, type_expr: Optional[Any] = None):
		proxy = super().create_proxy(kind, target, args, kwargs, name, type_expr)
		self.node_to_originating_module[proxy.node] = self.current_module_qualified_name
		return proxy


import torchvision.models as models

rn18 = models.resnet18()

tracer = ModulePathTracer()
traced_rn18 = tracer.trace(rn18)

for node in traced_rn18.nodes:
	module_qualname = tracer.node_to_originating_module.get(node)
	print('Node', node, 'is from module', module_qualname)

from __future__ import print_function
from __future__ import unicode_literals

import argparse

import matplotlib.pyplot as plt
import torch


parser = argparse.ArgumentParser()
parser.add_argument("-i", "--sample-file", required=True)
parser.add_argument("-o", "--out-file", default="out.png")
parser.add_argument("-d", "--dimension", type=int, default=3)
options = parser.parse_args()

module = torch.jit.load(options.sample_file)
images = list(module.parameters())[0]

for index in range(options.dimension * options.dimension):
	image = images[index].detach().cpu().reshape(28, 28).mul(255).to(torch.uint8)
	array = image.numpy()
	axis = plt.subplot(options.dimension, options.dimension, 1 + index)
	plt.imshow(array, cmap="gray")
	axis.get_xaxis().set_visible(False)
	axis.get_yaxis().set_visible(False)

plt.savefig(options.out_file)
print("Saved ", options.out_file)

