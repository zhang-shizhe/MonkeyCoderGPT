{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4737e4-b920-41cd-887b-eea2cc1e9b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f31df58-4700-4380-88a8-bbb297c931df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it in to inspect it\n",
    "# data_file = 'sample_scripts.txt'\n",
    "# data_file = 'dataset/adamw.txt'\n",
    "with open('../data/sample_scripts.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c19f8cc-ea26-4b5b-ab62-2d22cdbc15b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  2247598\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e0b01c0-81dc-4641-83a3-792396633be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import Dict, Union, Iterator\n",
      "\n",
      "import torch\n",
      "\n",
      "from allennlp.common.registrable import Regi\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b72fd8ba-74d7-4040-a498-eacaa9b0e723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\t\\n\\x1b !\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ƒ†‚ñÅü§ó'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77b7f505-3c24-41cf-8c16-070ba7d26eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dbdd55-c84b-462a-83fa-5b9272b1e97f",
   "metadata": {},
   "source": [
    "# encoding and decoding for chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "444a70cd-2509-42c9-bdac-214c6076d9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76, 80, 83, 82, 85, 87, 3, 87, 82, 85, 70, 75]\n",
      "import torch\n"
     ]
    }
   ],
   "source": [
    "# create a mapping from characters to integers\n",
    "ch_to_idx = { ch:i for i,ch in enumerate(chars) }\n",
    "idx_to_ch = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [ch_to_idx[ch] for ch in s] # encoder: take a string, output a list of mapping idx\n",
    "decode = lambda l: ''.join([idx_to_ch[idx] for idx in l]) # decoder: take a list of index, output a string\n",
    "\n",
    "print(encode(\"import torch\"))\n",
    "print(decode(encode(\"import torch\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f4c44dc-93a7-4184-a915-42f1d8400198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2247598]) torch.int64\n",
      "tensor([73, 85, 82, 80,  3, 87, 92, 83, 76, 81, 74,  3, 76, 80, 83, 82, 85, 87,\n",
      "         3, 39, 76, 70, 87, 15,  3, 56, 81, 76, 82, 81, 15,  3, 44, 87, 72, 85,\n",
      "        68, 87, 82, 85,  1,  1, 76, 80, 83, 82, 85, 87,  3, 87, 82, 85, 70, 75,\n",
      "         1,  1, 73, 85, 82, 80,  3, 68, 79, 79, 72, 81, 81, 79, 83, 17, 70, 82,\n",
      "        80, 80, 82, 81, 17, 85, 72, 74, 76, 86, 87, 85, 68, 69, 79, 72,  3, 76,\n",
      "        80, 83, 82, 85, 87,  3, 53, 72, 74, 76])\n"
     ]
    }
   ],
   "source": [
    "# encode the entire text dataset and store it into a torch.Tensor\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9427660-f082-46be-97d9-cd471b8aa26c",
   "metadata": {},
   "source": [
    "# train dev split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "725693c4-15e1-4d3b-a036-cb52b2b42089",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce40248d-dabc-4c5e-a2cf-8970ebfe5cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cacc69e-43e0-4561-8475-7f7305c1203c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([73]) the target: 85\n",
      "when input is tensor([73, 85]) the target: 82\n",
      "when input is tensor([73, 85, 82]) the target: 80\n",
      "when input is tensor([73, 85, 82, 80]) the target: 3\n",
      "when input is tensor([73, 85, 82, 80,  3]) the target: 87\n",
      "when input is tensor([73, 85, 82, 80,  3, 87]) the target: 92\n",
      "when input is tensor([73, 85, 82, 80,  3, 87, 92]) the target: 83\n",
      "when input is tensor([73, 85, 82, 80,  3, 87, 92, 83]) the target: 76\n"
     ]
    }
   ],
   "source": [
    "context_length = 8\n",
    "x = train_data[:context_length]\n",
    "y = train_data[1:context_length+1]\n",
    "for t in range(context_length):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f83221-8143-46b7-812d-02eea5067558",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08cf2024-2f73-4275-83b4-dff95ec0050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "context_length = 256\n",
    "max_iters = 1000\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_interval = 100\n",
    "eval_iters = 200\n",
    "\n",
    "num_heads = 6\n",
    "emb_dim = 64 * num_heads\n",
    "num_layers = 6\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ca0020-50db-4d97-88fa-abe53f5fe019",
   "metadata": {},
   "source": [
    "# data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ec801a0-ce4b-4011-877f-0067e665d340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([64, 256])\n",
      "tensor([[74, 11,  5,  ..., 82, 71, 72],\n",
      "        [32,  3, 71,  ..., 68, 80, 83],\n",
      "        [72, 89, 68,  ..., 49, 82, 81],\n",
      "        ...,\n",
      "        [74, 72, 87,  ..., 76, 81, 74],\n",
      "        [68, 76, 81,  ..., 72, 15,  3],\n",
      "        [72, 81, 66,  ...,  0, 83, 68]], device='cuda:0')\n",
      "targets:\n",
      "torch.Size([64, 256])\n",
      "tensor([[11,  5, 60,  ..., 71, 72, 79],\n",
      "        [ 3, 71, 85,  ..., 80, 83, 79],\n",
      "        [89, 68, 79,  ..., 82, 81, 72],\n",
      "        ...,\n",
      "        [72, 87, 66,  ..., 81, 74, 66],\n",
      "        [76, 81, 66,  ..., 15,  3, 68],\n",
      "        [81, 66, 80,  ..., 83, 68, 86]], device='cuda:0')\n",
      "----\n",
      "when input is [74] the target: 11\n",
      "when input is [74, 11] the target: 5\n",
      "when input is [74, 11, 5] the target: 60\n",
      "when input is [74, 11, 5, 60] the target: 82\n",
      "when input is [74, 11, 5, 60, 82] the target: 88\n",
      "when input is [74, 11, 5, 60, 82, 88] the target: 3\n",
      "when input is [74, 11, 5, 60, 82, 88, 3] the target: 68\n",
      "when input is [74, 11, 5, 60, 82, 88, 3, 68] the target: 85\n",
      "when input is [32] the target: 3\n",
      "when input is [32, 3] the target: 71\n",
      "when input is [32, 3, 71] the target: 85\n",
      "when input is [32, 3, 71, 85] the target: 82\n",
      "when input is [32, 3, 71, 85, 82] the target: 83\n",
      "when input is [32, 3, 71, 85, 82, 83] the target: 83\n",
      "when input is [32, 3, 71, 85, 82, 83, 83] the target: 72\n",
      "when input is [32, 3, 71, 85, 82, 83, 83, 72] the target: 71\n",
      "when input is [72] the target: 89\n",
      "when input is [72, 89] the target: 68\n",
      "when input is [72, 89, 68] the target: 79\n",
      "when input is [72, 89, 68, 79] the target: 66\n",
      "when input is [72, 89, 68, 79, 66] the target: 71\n",
      "when input is [72, 89, 68, 79, 66, 71] the target: 68\n",
      "when input is [72, 89, 68, 79, 66, 71, 68] the target: 87\n",
      "when input is [72, 89, 68, 79, 66, 71, 68, 87] the target: 68\n",
      "when input is [81] the target: 76\n",
      "when input is [81, 76] the target: 93\n",
      "when input is [81, 76, 93] the target: 72\n",
      "when input is [81, 76, 93, 72] the target: 85\n",
      "when input is [81, 76, 93, 72, 85] the target: 17\n",
      "when input is [81, 76, 93, 72, 85, 17] the target: 86\n",
      "when input is [81, 76, 93, 72, 85, 17, 86] the target: 68\n",
      "when input is [81, 76, 93, 72, 85, 17, 86, 68] the target: 89\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(111)\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    start_idxs = torch.randint(len(data) - context_length, (batch_size,))\n",
    "    context_idxs = torch.stack([data[start_idx : start_idx+context_length] for start_idx in start_idxs])\n",
    "    target_idxs = torch.stack([data[start_idx+1 : start_idx+context_length+1] for start_idx in start_idxs])\n",
    "    \n",
    "    context_idxs, target_idxs = context_idxs.to(device), target_idxs.to(device)\n",
    "    \n",
    "    return context_idxs, target_idxs\n",
    "\n",
    "context_idxs, target_idxs = get_batch('train')\n",
    "print('inputs:')\n",
    "print(context_idxs.shape)\n",
    "print(context_idxs)\n",
    "print('targets:')\n",
    "print(target_idxs.shape)\n",
    "print(target_idxs)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(4): # batch dimension\n",
    "    for step in range(8): # context length dimension\n",
    "        context = context_idxs[b, :step+1]\n",
    "        target = target_idxs[b,step]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06bd74f5-5346-40af-b033-aa2800a905f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [1., 1., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [1., 1., 1., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [1., 1., 1., 1., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [1., 1., 1., 1., 1., -inf, -inf, -inf, -inf, -inf],\n",
      "        [1., 1., 1., 1., 1., 1., -inf, -inf, -inf, -inf],\n",
      "        [1., 1., 1., 1., 1., 1., 1., -inf, -inf, -inf],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., -inf, -inf],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., -inf],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111,\n",
      "         0.0000],\n",
      "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000]])\n",
      "tensor([[0.7131, 0.2829, 0.2022],\n",
      "        [0.9751, 0.6093, 0.4938],\n",
      "        [0.3388, 0.7835, 0.5464],\n",
      "        [0.9675, 0.1693, 0.7911],\n",
      "        [0.6869, 0.2606, 0.3294],\n",
      "        [0.1775, 0.6404, 0.1907],\n",
      "        [0.5397, 0.6074, 0.6554],\n",
      "        [0.9637, 0.4888, 0.3861],\n",
      "        [0.1893, 0.8997, 0.3442],\n",
      "        [0.6087, 0.7237, 0.9903]])\n",
      "tensor([[0.7131, 0.2829, 0.2022],\n",
      "        [0.8441, 0.4461, 0.3480],\n",
      "        [0.6756, 0.5586, 0.4142],\n",
      "        [0.7486, 0.4612, 0.5084],\n",
      "        [0.7363, 0.4211, 0.4726],\n",
      "        [0.6432, 0.4577, 0.4256],\n",
      "        [0.6284, 0.4790, 0.4584],\n",
      "        [0.6703, 0.4803, 0.4494],\n",
      "        [0.6168, 0.5269, 0.4377],\n",
      "        [0.6160, 0.5466, 0.4929]])\n"
     ]
    }
   ],
   "source": [
    "weight_test = torch.tril(torch.ones(10,10))\n",
    "print(weight_test)\n",
    "weight_test = weight_test.masked_fill(weight_test == 0, float('-inf'))\n",
    "print(weight_test)\n",
    "weight_test = F.softmax(weight_test, dim=-1)\n",
    "print(weight_test)\n",
    "v_test = torch.rand((10,3))\n",
    "print(v_test)\n",
    "out = weight_test @ v_test\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f932fba-e8df-4b4c-92ba-661410748042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
